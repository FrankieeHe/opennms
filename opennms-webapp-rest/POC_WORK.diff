diff --git a/bin/functions.pl b/bin/functions.pl
index 94ec7b4a44e..c6e99dc8964 100755
--- a/bin/functions.pl
+++ b/bin/functions.pl
@@ -81,7 +81,7 @@ $MVN = $ENV{'MVN'};
 if (not defined $MVN or not -x $MVN) {
 	$MVN = File::Spec->catfile($PREFIX, 'maven', 'bin', 'mvn');
 	if ($^O =~ /(mswin|msys)/i) {
-		$MVN .= '.bat';
+		$MVN .= '.cmd';
 	}
 }
 
@@ -348,10 +348,26 @@ sub get_minimum_java {
 sub get_version_from_java {
 	my $javacmd = shift;
 
-	if (not defined $javacmd or not -x $javacmd) {
+	if (not defined $javacmd) {
+		warning("\$javacmd is not defined.\n");
 		return ();
 	}
 
+	# Check Windows and Windows GitBash (mingW64)
+	if ($^O =~ /(mswin|msys)/i) {
+		$javacmd .= '.exe';
+		if (not -e $javacmd) {
+			warning("$javacmd does not exist.\n");
+			return ();
+		}
+	} else {
+		# Check Linux
+		if (not -x $javacmd) {
+			warning("$javacmd is not Executable.\n");
+			return ();
+		}
+	}
+
 	my ($output, $bindir, $shortversion, $version, $build, $java_home);
 
 	$output = `"$javacmd" -version 2>\&1`;
@@ -372,10 +388,6 @@ sub find_java_home {
 	my $versions = {};
 	my $javacmd = 'java';
 
-	if ($^O =~ /(mswin|msys)/i) {
-		$javacmd .= '.exe';
-	}
-
 	for my $searchdir (@JAVA_SEARCH_DIRS) {
 		my @javas = (
 			glob(File::Spec->catfile($searchdir, 'bin', $javacmd)),
diff --git a/checkstyle/src/main/resources/license-suppressions.xml b/checkstyle/src/main/resources/license-suppressions.xml
index 5e4339a1e68..b7ae54abc0b 100644
--- a/checkstyle/src/main/resources/license-suppressions.xml
+++ b/checkstyle/src/main/resources/license-suppressions.xml
@@ -3,26 +3,28 @@
     "-//Puppy Crawl//DTD Suppressions 1.1//EN"
     "http://www.puppycrawl.com/dtds/suppressions_1_1.dtd">
 
+<!-- NOTE: We use '[\\/]' instead of '/' in the paths in order to match
+     the files when compiling with both Linux and Windows. -->
 <suppressions>
     <!-- BSD and GPL - see headers for details -->
-    <suppress files="org/opennms/core/test/dns/DNSServer.java" checks=".*"/>
+    <suppress files="org[\\/]opennms[\\/]core[\\/]test[\\/]dns[\\/]DNSServer.java" checks=".*"/>
     <!-- APLv2 -->
-    <suppress files="org/opennms/netmgt/snmp/snmp4j/Integer32IgnoreTooManyBytes.java" checks=".*"/>
-    <suppress files="org/opennms/core/soa/support/OnmsOSGiBridgeActivator.java" checks=".*"/>
-    <suppress files="org/opennms/vaadin/extender/.*" checks=".*"/>
-    <suppress files="org/opennms/poller/remote/Mac.*" checks=".*"/>
-    <suppress files="org/opennms/container/web/.*" checks=".*"/>
-    <suppress files="org/opennms/features/osgi/script/.*" checks=".*"/>
-    <suppress files="org/apache/taglibs/standard/lang/.*" checks=".*"/>
+    <suppress files="org[\\/]opennms[\\/]netmgt[\\/]snmp[\\/]snmp4j[\\/]Integer32IgnoreTooManyBytes.java" checks=".*"/>
+    <suppress files="org[\\/]opennms[\\/]core[\\/]soa[\\/]support[\\/]OnmsOSGiBridgeActivator.java" checks=".*"/>
+    <suppress files="org[\\/]opennms[\\/]vaadin[\\/]extender[\\/].*" checks=".*"/>
+    <suppress files="org[\\/]opennms[\\/]features[\\/]osgi[\\/]script[\\/].*" checks=".*"/>
+    <suppress files="org[\\/]opennms[\\/]poller[\\/]remote[\\/]Mac.*" checks=".*"/>
+    <suppress files="org[\\/]opennms[\\/]container[\\/]web[\\/].*" checks=".*"/>
+    <suppress files="org[\\/]apache[\\/]taglibs[\\/]standard[\\/]lang[\\/].*" checks=".*"/>
 
     <!-- BSD style -->
-    <suppress files="org/opennms/netmgt/syslogd/SyslogClient.java" checks=".*"/>
-    <suppress files="org/opennms/plugins/com/impossibl/postgres/jdbc/.*" checks=".*"/>
+    <suppress files="org[\\/]opennms[\\/]netmgt[\\/]syslogd[\\/]SyslogClient.java" checks=".*"/>
+    <suppress files="org[\\/]opennms[\\/]plugins[\\/]com[\\/]impossibl[\\/]postgres[\\/]jdbc[\\/].*" checks=".*"/>
     <!-- EPL - see headers for details -->
-    <suppress files="org/opennms/protocols/vmware/VmwareViJavaAccess.java" checks=".*"/>
-    <suppress files="org/opennms/netmgt/collectd/VmwareCimCollector.java" checks=".*"/>
-    <suppress files="org/opennms/netmgt/poller/monitors/VmwareCimMonitor.java" checks=".*"/>
-    <suppress files="org/opennms/netmgt/collectd/vmware/VmwareViJavaAccessTest.java" checks=".*"/>
+    <suppress files="org[\\/]opennms[\\/]protocols[\\/]vmware[\\/]VmwareViJavaAccess.java" checks=".*"/>
+    <suppress files="org[\\/]opennms[\\/]netmgt[\\/]collectd[\\/]VmwareCimCollector.java" checks=".*"/>
+    <suppress files="org[\\/]opennms[\\/]netmgt[\\/]poller[\\/]monitors[\\/]VmwareCimMonitor.java" checks=".*"/>
+    <suppress files="org[\\/]opennms[\\/]netmgt[\\/]collectd[\\/]vmware[\\/]VmwareViJavaAccessTest.java" checks=".*"/>
     <!-- LGPLv3 -->
-    <suppress files="org/opennms/reporting/jasperreports/compiler/CustomJRJdtCompiler.java" checks=".*"/>
+    <suppress files="org[\\/]opennms[\\/]reporting[\\/]jasperreports[\\/]compiler[\\/]CustomJRJdtCompiler.java" checks=".*"/>
 </suppressions>
diff --git a/container/features/pom.xml b/container/features/pom.xml
index 020d1331049..3e4ef677a14 100644
--- a/container/features/pom.xml
+++ b/container/features/pom.xml
@@ -258,6 +258,7 @@
             <feature>opennms-icmp-best</feature>
             <feature>opennms-icmp-commands</feature>
             <feature>opennms-javamail</feature>
+            <feature>opennms-kafka-producer</feature>
             <feature>opennms-model</feature>
             <feature>opennms-poller-api</feature>
             <feature>opennms-poller-shell</feature>
@@ -793,6 +794,12 @@
       <version>${project.version}</version>
       <scope>provided</scope>
     </dependency>
+    <dependency>
+      <groupId>org.opennms.features.kafka</groupId>
+      <artifactId>org.opennms.features.kafka.producer</artifactId>
+      <version>${project.version}</version>
+      <scope>provided</scope>
+    </dependency>
   </dependencies>
 
   <!-- Required for com.eclipsesource.jaxrs/* -->
diff --git a/container/features/src/main/resources/features.xml b/container/features/src/main/resources/features.xml
index 70a5be91185..7fdc39fbb5a 100644
--- a/container/features/src/main/resources/features.xml
+++ b/container/features/src/main/resources/features.xml
@@ -1098,6 +1098,27 @@
       <bundle>mvn:org.opennms.features.poller/org.opennms.features.poller.shell/${project.version}</bundle>
     </feature>
 
+    <feature name="kafka-streams" description="Kafka Streams" version="${kafkaStreamsVersion}">
+      <!-- Wrap the kafka-streams bundle instead of using the servicemix implementation since the later doesn't include the required imports for rocksdb -->
+      <bundle dependency="true">wrap:mvn:org.apache.kafka/kafka-streams/${kafkaStreamsVersion}$Bundle-Version=${kafkaStreamsVersion}&amp;Export-Package=*;-noimport:=true:version="${kafkaStreamsVersion}"</bundle>
+      <bundle dependency="true">mvn:org.apache.servicemix.bundles/org.apache.servicemix.bundles.kafka-clients/${kafkaStreamsBundleVersion}</bundle>
+      <bundle dependency="true">wrap:mvn:org.apache.kafka/connect-json/${kafkaStreamsVersion}</bundle>
+      <bundle dependency="true">wrap:mvn:org.apache.kafka/connect-api/${kafkaStreamsVersion}</bundle>
+      <bundle dependency="true">mvn:org.lz4/lz4-java/1.4</bundle>
+      <bundle dependency="true">mvn:org.xerial.snappy/snappy-java/1.1.4</bundle>
+      <bundle dependency="true">mvn:com.fasterxml.jackson.core/jackson-databind/2.6.6</bundle>
+      <bundle dependency="true">mvn:com.fasterxml.jackson.core/jackson-annotations/2.6.6</bundle>
+      <bundle dependency="true">mvn:com.fasterxml.jackson.core/jackson-core/2.6.6</bundle>
+      <bundle dependency="true">wrap:mvn:org.rocksdb/rocksdbjni/5.7.3</bundle>
+    </feature>
+
+    <feature name="opennms-kafka-producer" description="OpenNMS :: Kafka :: Producer" version="${project.version}">
+      <feature version="${guavaVersion}">guava</feature>
+      <feature version="${kafkaStreamsVersion}">kafka-streams</feature>
+      <bundle>mvn:com.google.protobuf/protobuf-java/${protobuf3Version}</bundle>
+      <bundle>mvn:org.opennms.features.kafka/org.opennms.features.kafka.producer/${project.version}</bundle>
+    </feature>
+
     <feature name="opennms-telemetry-collection" description="OpenNMS :: Telemetry :: Collection" version="${project.version}">
       <feature>guava</feature>
 
diff --git a/container/features/src/main/resources/karaf/spring-legacy.xml b/container/features/src/main/resources/karaf/spring-legacy.xml
index 36d4756f527..2f4c793d66a 100644
--- a/container/features/src/main/resources/karaf/spring-legacy.xml
+++ b/container/features/src/main/resources/karaf/spring-legacy.xml
@@ -16,13 +16,13 @@
       See the License for the specific language governing permissions and
       limitations under the License.
 -->
-<features name="spring-legacy-4.1.2" xmlns="http://karaf.apache.org/xmlns/features/v1.3.0" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://karaf.apache.org/xmlns/features/v1.3.0 http://karaf.apache.org/xmlns/features/v1.3.0">
+<features name="spring-legacy-4.1.5" xmlns="http://karaf.apache.org/xmlns/features/v1.3.0" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://karaf.apache.org/xmlns/features/v1.3.0 http://karaf.apache.org/xmlns/features/v1.3.0">
 
     <repository>mvn:org.ops4j.pax.web/pax-web-features/${paxWebVersion}/xml/features</repository>
 
     <!-- ################ START OPENNMS CUSTOMIZATION ############ -->
     <!-- Import the OpenNMS-modified standard features instead of the unmodified Karaf version -->
-    <!-- <repository>mvn:org.apache.karaf.features/standard/4.1.2/xml/features</repository> -->
+    <!-- <repository>mvn:org.apache.karaf.features/standard/4.1.5/xml/features</repository> -->
     <repository>mvn:${project.groupId}/${project.artifactId}/${project.version}/xml/standard</repository>
     <!-- ################ END OPENNMS CUSTOMIZATION ############## -->
 
@@ -36,11 +36,11 @@
         <bundle start-level="30">mvn:org.springframework.osgi/spring-osgi-annotation/1.2.1</bundle>
         <conditional>
             <condition>deployer</condition>
-            <bundle start-level="30">mvn:org.apache.karaf.deployer/org.apache.karaf.deployer.spring/4.1.2</bundle>
+            <bundle start-level="30">mvn:org.apache.karaf.deployer/org.apache.karaf.deployer.spring/4.1.5</bundle>
         </conditional>
         <conditional>
             <condition>bundle</condition>
-            <bundle start-level="30">mvn:org.apache.karaf.bundle/org.apache.karaf.bundle.springstate/4.1.2</bundle>
+            <bundle start-level="30">mvn:org.apache.karaf.bundle/org.apache.karaf.bundle.springstate/4.1.5</bundle>
         </conditional>
     </feature>
 
@@ -116,10 +116,10 @@
     </feature>
 
     <feature name="spring-web" description="Spring 3.1.x Web support" version="3.1.4.RELEASE">
-    	<feature version="[3.1.4.RELEASE,3.2)">spring</feature>
-    	<feature>http</feature>
-    	<bundle start-level="30">mvn:org.springframework/spring-web/3.1.4.RELEASE</bundle>
-		<bundle start-level="30">mvn:org.springframework/spring-webmvc/3.1.4.RELEASE</bundle>
+        <feature version="[3.1.4.RELEASE,3.2)">spring</feature>
+        <feature>http</feature>
+        <bundle start-level="30">mvn:org.springframework/spring-web/3.1.4.RELEASE</bundle>
+        <bundle start-level="30">mvn:org.springframework/spring-webmvc/3.1.4.RELEASE</bundle>
     </feature>
 
     <feature name="spring-web-portlet" description="Spring 3.1.x Web Portlet support" version="3.1.4.RELEASE">
@@ -208,75 +208,75 @@
 
     <!-- Spring 4.0.x support -->
 
-    <feature name="spring" description="Spring 4.0.x support" version="4.0.7.RELEASE_3">
+    <feature name="spring" description="Spring 4.0.x support" version="4.0.9.RELEASE_1">
         <bundle dependency="true" start-level="30">mvn:org.apache.servicemix.bundles/org.apache.servicemix.bundles.aopalliance/1.0_6</bundle>
-        <bundle start-level="30">mvn:org.apache.servicemix.bundles/org.apache.servicemix.bundles.spring-core/4.0.7.RELEASE_3</bundle>
-        <bundle start-level="30">mvn:org.apache.servicemix.bundles/org.apache.servicemix.bundles.spring-expression/4.0.7.RELEASE_3</bundle>
-        <bundle start-level="30">mvn:org.apache.servicemix.bundles/org.apache.servicemix.bundles.spring-beans/4.0.7.RELEASE_3</bundle>
-        <bundle start-level="30">mvn:org.apache.servicemix.bundles/org.apache.servicemix.bundles.spring-aop/4.0.7.RELEASE_3</bundle>
-        <bundle start-level="30">mvn:org.apache.servicemix.bundles/org.apache.servicemix.bundles.spring-context/4.0.7.RELEASE_3</bundle>
-        <bundle start-level="30">mvn:org.apache.servicemix.bundles/org.apache.servicemix.bundles.spring-context-support/4.0.7.RELEASE_3</bundle>
+        <bundle start-level="30">mvn:org.apache.servicemix.bundles/org.apache.servicemix.bundles.spring-core/4.0.9.RELEASE_1</bundle>
+        <bundle start-level="30">mvn:org.apache.servicemix.bundles/org.apache.servicemix.bundles.spring-expression/4.0.9.RELEASE_1</bundle>
+        <bundle start-level="30">mvn:org.apache.servicemix.bundles/org.apache.servicemix.bundles.spring-beans/4.0.9.RELEASE_1</bundle>
+        <bundle start-level="30">mvn:org.apache.servicemix.bundles/org.apache.servicemix.bundles.spring-aop/4.0.9.RELEASE_1</bundle>
+        <bundle start-level="30">mvn:org.apache.servicemix.bundles/org.apache.servicemix.bundles.spring-context/4.0.9.RELEASE_1</bundle>
+        <bundle start-level="30">mvn:org.apache.servicemix.bundles/org.apache.servicemix.bundles.spring-context-support/4.0.9.RELEASE_1</bundle>
     </feature>
 
-    <feature name="spring-aspects" description="Spring 4.0.x AOP support" version="4.0.7.RELEASE_3">
-        <feature version="[4.0.7.RELEASE_3,4.1)">spring</feature>
-        <bundle start-level="30">mvn:org.apache.servicemix.bundles/org.apache.servicemix.bundles.spring-aspects/4.0.7.RELEASE_3</bundle>
+    <feature name="spring-aspects" description="Spring 4.0.x AOP support" version="4.0.9.RELEASE_1">
+        <feature version="[4.0.9.RELEASE_1,4.1)">spring</feature>
+        <bundle start-level="30">mvn:org.apache.servicemix.bundles/org.apache.servicemix.bundles.spring-aspects/4.0.9.RELEASE_1</bundle>
     </feature>
 
-    <feature name="spring-instrument" description="Spring 4.0.x Instrument support" version="4.0.7.RELEASE_3">
-        <feature version="[4.0.7.RELEASE_3,4.1)">spring</feature>
-        <bundle start-level="30">mvn:org.apache.servicemix.bundles/org.apache.servicemix.bundles.spring-instrument/4.0.7.RELEASE_3</bundle>
+    <feature name="spring-instrument" description="Spring 4.0.x Instrument support" version="4.0.9.RELEASE_1">
+        <feature version="[4.0.9.RELEASE_1,4.1)">spring</feature>
+        <bundle start-level="30">mvn:org.apache.servicemix.bundles/org.apache.servicemix.bundles.spring-instrument/4.0.9.RELEASE_1</bundle>
     </feature>
 
-    <feature name="spring-jdbc" description="Spring 4.0.x JDBC support" version="4.0.7.RELEASE_3">
-        <feature version="[4.0.7.RELEASE_3,4.1)">spring-tx</feature>
-        <bundle start-level="30">mvn:org.apache.servicemix.bundles/org.apache.servicemix.bundles.spring-jdbc/4.0.7.RELEASE_3</bundle>
+    <feature name="spring-jdbc" description="Spring 4.0.x JDBC support" version="4.0.9.RELEASE_1">
+        <feature version="[4.0.9.RELEASE_1,4.1)">spring-tx</feature>
+        <bundle start-level="30">mvn:org.apache.servicemix.bundles/org.apache.servicemix.bundles.spring-jdbc/4.0.9.RELEASE_1</bundle>
     </feature>
 
-    <feature name="spring-jms" description="Spring 4.0.x JMS support" version="4.0.7.RELEASE_3">
-        <feature version="[4.0.7.RELEASE_3,4.1)">spring-tx</feature>
+    <feature name="spring-jms" description="Spring 4.0.x JMS support" version="4.0.9.RELEASE_1">
+        <feature version="[4.0.9.RELEASE_1,4.1)">spring-tx</feature>
         <bundle dependency="true" start-level="10">mvn:org.apache.geronimo.specs/geronimo-jta_1.1_spec/1.1.1</bundle>
         <bundle dependency="true" start-level="10">mvn:org.apache.geronimo.specs/geronimo-jms_1.1_spec/1.1.1</bundle>
-        <bundle start-level="30">mvn:org.apache.servicemix.bundles/org.apache.servicemix.bundles.spring-jms/4.0.7.RELEASE_3</bundle>
+        <bundle start-level="30">mvn:org.apache.servicemix.bundles/org.apache.servicemix.bundles.spring-jms/4.0.9.RELEASE_1</bundle>
     </feature>
 
-    <feature name="spring-test" description="Spring 4.0.x Test support" version="4.0.7.RELEASE_3">
-        <feature version="[4.0.7.RELEASE_3,4.1)">spring</feature>
-        <bundle start-level="30">mvn:org.apache.servicemix.bundles/org.apache.servicemix.bundles.spring-test/4.0.7.RELEASE_3</bundle>
+    <feature name="spring-test" description="Spring 4.0.x Test support" version="4.0.9.RELEASE_1">
+        <feature version="[4.0.9.RELEASE_1,4.1)">spring</feature>
+        <bundle start-level="30">mvn:org.apache.servicemix.bundles/org.apache.servicemix.bundles.spring-test/4.0.9.RELEASE_1</bundle>
     </feature>
 
-    <feature name="spring-orm" description="Spring 4.0.x ORM support" version="4.0.7.RELEASE_3">
-        <feature version="[4.0.7.RELEASE_3,4.1)">spring-jdbc</feature>
-        <bundle start-level="30">mvn:org.apache.servicemix.bundles/org.apache.servicemix.bundles.spring-orm/4.0.7.RELEASE_3</bundle>
+    <feature name="spring-orm" description="Spring 4.0.x ORM support" version="4.0.9.RELEASE_1">
+        <feature version="[4.0.9.RELEASE_1,4.1)">spring-jdbc</feature>
+        <bundle start-level="30">mvn:org.apache.servicemix.bundles/org.apache.servicemix.bundles.spring-orm/4.0.9.RELEASE_1</bundle>
     </feature>
 
-    <feature name="spring-oxm" description="Spring 4.0.x OXM support" version="4.0.7.RELEASE_3">
-        <feature version="[4.0.7.RELEASE_3,4.1)">spring</feature>
-        <bundle start-level="30">mvn:org.apache.servicemix.bundles/org.apache.servicemix.bundles.spring-oxm/4.0.7.RELEASE_3</bundle>
+    <feature name="spring-oxm" description="Spring 4.0.x OXM support" version="4.0.9.RELEASE_1">
+        <feature version="[4.0.9.RELEASE_1,4.1)">spring</feature>
+        <bundle start-level="30">mvn:org.apache.servicemix.bundles/org.apache.servicemix.bundles.spring-oxm/4.0.9.RELEASE_1</bundle>
     </feature>
 
-    <feature name="spring-tx" description="Spring 4.0.x Transaction (TX) support" version="4.0.7.RELEASE_3">
-        <feature version="[4.0.7.RELEASE_3,4.1)">spring</feature>
-        <bundle start-level="30">mvn:org.apache.servicemix.bundles/org.apache.servicemix.bundles.spring-tx/4.0.7.RELEASE_3</bundle>
+    <feature name="spring-tx" description="Spring 4.0.x Transaction (TX) support" version="4.0.9.RELEASE_1">
+        <feature version="[4.0.9.RELEASE_1,4.1)">spring</feature>
+        <bundle start-level="30">mvn:org.apache.servicemix.bundles/org.apache.servicemix.bundles.spring-tx/4.0.9.RELEASE_1</bundle>
     </feature>
 
-    <feature name="spring-web" description="Spring 4.0.x Web support" version="4.0.7.RELEASE_3">
-        <feature version="[4.0.7.RELEASE_3,4.1)">spring</feature>
+    <feature name="spring-web" description="Spring 4.0.x Web support" version="4.0.9.RELEASE_1">
+        <feature version="[4.0.9.RELEASE_1,4.1)">spring</feature>
         <feature>http</feature>
-        <bundle start-level="30">mvn:org.apache.servicemix.bundles/org.apache.servicemix.bundles.spring-web/4.0.7.RELEASE_3</bundle>
-        <bundle start-level="30">mvn:org.apache.servicemix.bundles/org.apache.servicemix.bundles.spring-webmvc/4.0.7.RELEASE_3</bundle>
+        <bundle start-level="30">mvn:org.apache.servicemix.bundles/org.apache.servicemix.bundles.spring-web/4.0.9.RELEASE_1</bundle>
+        <bundle start-level="30">mvn:org.apache.servicemix.bundles/org.apache.servicemix.bundles.spring-webmvc/4.0.9.RELEASE_1</bundle>
     </feature>
 
-    <feature name="spring-web-portlet" description="Spring 4.0.x Web Portlet support" version="4.0.7.RELEASE_3">
+    <feature name="spring-web-portlet" description="Spring 4.0.x Web Portlet support" version="4.0.9.RELEASE_1">
         <feature prerequisite="true">wrap</feature>
-        <feature version="[4.0.7.RELEASE_3,4.1)">spring-web</feature>
+        <feature version="[4.0.9.RELEASE_1,4.1)">spring-web</feature>
         <bundle dependency="true" start-level="30">wrap:mvn:javax.portlet/portlet-api/2.0$Export-Package=javax.portlet.*;version=2.0</bundle>
-        <bundle start-level="30">mvn:org.apache.servicemix.bundles/org.apache.servicemix.bundles.spring-webmvc-portlet/4.0.7.RELEASE_3</bundle>
+        <bundle start-level="30">mvn:org.apache.servicemix.bundles/org.apache.servicemix.bundles.spring-webmvc-portlet/4.0.9.RELEASE_1</bundle>
     </feature>
 
-    <feature name="spring-websocket" description="Spring 4.0.x WebSocket support" version="4.0.7.RELEASE_3">
-        <feature version="[4.0.7.RELEASE_3,4.1)">spring-web</feature>
-        <bundle start-level="30">mvn:org.apache.servicemix.bundles/org.apache.servicemix.bundles.spring-websocket/4.0.7.RELEASE_3</bundle>
+    <feature name="spring-websocket" description="Spring 4.0.x WebSocket support" version="4.0.9.RELEASE_1">
+        <feature version="[4.0.9.RELEASE_1,4.1)">spring-web</feature>
+        <bundle start-level="30">mvn:org.apache.servicemix.bundles/org.apache.servicemix.bundles.spring-websocket/4.0.9.RELEASE_1</bundle>
     </feature>
 
     <!-- Spring 4.1.x support -->
@@ -429,7 +429,7 @@
 
     <feature name="spring-security" description="Spring Security 3.1.x support" version="3.1.4.RELEASE">
         <feature>war</feature>
-	    <feature version="[3,4)">spring-web</feature>
+        <feature version="[3,4)">spring-web</feature>
         <bundle dependency="true">mvn:org.apache.servicemix.bundles/org.apache.servicemix.bundles.aspectj/1.7.4_1</bundle>
         <bundle start-level="30">mvn:org.springframework.security/spring-security-core/3.1.4.RELEASE</bundle>
         <bundle start-level="30">mvn:org.springframework.security/spring-security-config/3.1.4.RELEASE</bundle>
diff --git a/container/features/src/main/resources/karaf/spring.xml b/container/features/src/main/resources/karaf/spring.xml
index 9ddcc2b238c..898fb1b580c 100755
--- a/container/features/src/main/resources/karaf/spring.xml
+++ b/container/features/src/main/resources/karaf/spring.xml
@@ -16,91 +16,91 @@
       See the License for the specific language governing permissions and
       limitations under the License.
 -->
-<features name="spring-4.1.2" xmlns="http://karaf.apache.org/xmlns/features/v1.3.0" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://karaf.apache.org/xmlns/features/v1.3.0 http://karaf.apache.org/xmlns/features/v1.3.0">
+<features name="spring-4.1.5" xmlns="http://karaf.apache.org/xmlns/features/v1.3.0" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://karaf.apache.org/xmlns/features/v1.3.0 http://karaf.apache.org/xmlns/features/v1.3.0">
 
     <!-- NB: this file is not the one really used. This file is used by the karaf-maven-plugin to define the start-level of bundles in the generated feature.xml -->
 
     <!-- ################ START OPENNMS CUSTOMIZATION ############ -->
     <!-- Import the OpenNMS-modified standard features instead of the unmodified Karaf version -->
-    <!-- <repository>mvn:org.apache.karaf.features/standard/4.1.2/xml/features</repository> -->
+    <!-- <repository>mvn:org.apache.karaf.features/standard/4.1.5/xml/features</repository> -->
     <repository>mvn:${project.groupId}/${project.artifactId}/${project.version}/xml/standard</repository>
     <!-- ################ END OPENNMS CUSTOMIZATION ############## -->
 
     <!-- Spring 4.3.x support -->
 
-    <feature name="spring" description="Spring 4.3.x support" version="4.3.10.RELEASE_1">
+    <feature name="spring" description="Spring 4.3.x support" version="4.3.14.RELEASE_1">
         <bundle dependency="true" start-level="30">mvn:org.apache.servicemix.bundles/org.apache.servicemix.bundles.aopalliance/1.0_6</bundle>
-        <bundle start-level="30">mvn:org.apache.servicemix.bundles/org.apache.servicemix.bundles.spring-core/4.3.10.RELEASE_1</bundle>
-        <bundle start-level="30">mvn:org.apache.servicemix.bundles/org.apache.servicemix.bundles.spring-expression/4.3.10.RELEASE_1</bundle>
-        <bundle start-level="30">mvn:org.apache.servicemix.bundles/org.apache.servicemix.bundles.spring-beans/4.3.10.RELEASE_1</bundle>
-        <bundle start-level="30">mvn:org.apache.servicemix.bundles/org.apache.servicemix.bundles.spring-aop/4.3.10.RELEASE_1</bundle>
-        <bundle start-level="30">mvn:org.apache.servicemix.bundles/org.apache.servicemix.bundles.spring-context/4.3.10.RELEASE_1</bundle>
-        <bundle start-level="30">mvn:org.apache.servicemix.bundles/org.apache.servicemix.bundles.spring-context-support/4.3.10.RELEASE_1</bundle>
+        <bundle start-level="30">mvn:org.apache.servicemix.bundles/org.apache.servicemix.bundles.spring-core/4.3.14.RELEASE_1</bundle>
+        <bundle start-level="30">mvn:org.apache.servicemix.bundles/org.apache.servicemix.bundles.spring-expression/4.3.14.RELEASE_1</bundle>
+        <bundle start-level="30">mvn:org.apache.servicemix.bundles/org.apache.servicemix.bundles.spring-beans/4.3.14.RELEASE_1</bundle>
+        <bundle start-level="30">mvn:org.apache.servicemix.bundles/org.apache.servicemix.bundles.spring-aop/4.3.14.RELEASE_1</bundle>
+        <bundle start-level="30">mvn:org.apache.servicemix.bundles/org.apache.servicemix.bundles.spring-context/4.3.14.RELEASE_1</bundle>
+        <bundle start-level="30">mvn:org.apache.servicemix.bundles/org.apache.servicemix.bundles.spring-context-support/4.3.14.RELEASE_1</bundle>
     </feature>
 
-    <feature name="spring-aspects" description="Spring 4.3.x AOP support" version="4.3.10.RELEASE_1">
-        <feature version="[4.3.10.RELEASE_1,4.4)">spring</feature>
-        <bundle start-level="30">mvn:org.apache.servicemix.bundles/org.apache.servicemix.bundles.spring-aspects/4.3.10.RELEASE_1</bundle>
+    <feature name="spring-aspects" description="Spring 4.3.x AOP support" version="4.3.14.RELEASE_1">
+        <feature version="[4.3.14.RELEASE_1,4.4)">spring</feature>
+        <bundle start-level="30">mvn:org.apache.servicemix.bundles/org.apache.servicemix.bundles.spring-aspects/4.3.14.RELEASE_1</bundle>
     </feature>
 
-    <feature name="spring-instrument" description="Spring 4.3.x Instrument support" version="4.3.10.RELEASE_1">
-        <feature version="[4.3.10.RELEASE_1,4.4)">spring</feature>
-        <bundle start-level="30">mvn:org.apache.servicemix.bundles/org.apache.servicemix.bundles.spring-instrument/4.3.10.RELEASE_1</bundle>
+    <feature name="spring-instrument" description="Spring 4.3.x Instrument support" version="4.3.14.RELEASE_1">
+        <feature version="[4.3.14.RELEASE_1,4.4)">spring</feature>
+        <bundle start-level="30">mvn:org.apache.servicemix.bundles/org.apache.servicemix.bundles.spring-instrument/4.3.14.RELEASE_1</bundle>
     </feature>
 
-    <feature name="spring-jdbc" description="Spring 4.3.x JDBC support" version="4.3.10.RELEASE_1">
-        <feature version="[4.3.10.RELEASE_1,4.4)">spring-tx</feature>
-        <bundle start-level="30">mvn:org.apache.servicemix.bundles/org.apache.servicemix.bundles.spring-jdbc/4.3.10.RELEASE_1</bundle>
+    <feature name="spring-jdbc" description="Spring 4.3.x JDBC support" version="4.3.14.RELEASE_1">
+        <feature version="[4.3.14.RELEASE_1,4.4)">spring-tx</feature>
+        <bundle start-level="30">mvn:org.apache.servicemix.bundles/org.apache.servicemix.bundles.spring-jdbc/4.3.14.RELEASE_1</bundle>
     </feature>
 
-    <feature name="spring-jms" description="Spring 4.3.x JMS support" version="4.3.10.RELEASE_1">
-        <feature version="[4.3.10.RELEASE_1,4.4)">spring-tx</feature>
+    <feature name="spring-jms" description="Spring 4.3.x JMS support" version="4.3.14.RELEASE_1">
+        <feature version="[4.3.14.RELEASE_1,4.4)">spring-tx</feature>
         <bundle dependency="true" start-level="10">mvn:org.apache.geronimo.specs/geronimo-jta_1.1_spec/1.1.1</bundle>
         <bundle dependency="true" start-level="10">mvn:org.apache.geronimo.specs/geronimo-jms_1.1_spec/1.1.1</bundle>
-        <bundle start-level="30">mvn:org.apache.servicemix.bundles/org.apache.servicemix.bundles.spring-jms/4.3.10.RELEASE_1</bundle>
+        <bundle start-level="30">mvn:org.apache.servicemix.bundles/org.apache.servicemix.bundles.spring-jms/4.3.14.RELEASE_1</bundle>
     </feature>
 
-    <feature name="spring-test" description="Spring 4.3.x Test support" version="4.3.10.RELEASE_1">
-        <feature version="[4.3.10.RELEASE_1,4.4)">spring</feature>
+    <feature name="spring-test" description="Spring 4.3.x Test support" version="4.3.14.RELEASE_1">
+        <feature version="[4.3.14.RELEASE_1,4.4)">spring</feature>
         <bundle dependency="true">mvn:javax.websocket/javax.websocket-api/1.1</bundle>
         <bundle dependency="true">mvn:org.apache.httpcomponents/httpcore-osgi/4.4.6</bundle>
         <bundle dependency="true">mvn:org.apache.httpcomponents/httpclient-osgi/4.5.2</bundle>
-        <bundle start-level="30">mvn:org.apache.servicemix.bundles/org.apache.servicemix.bundles.spring-test/4.3.10.RELEASE_1</bundle>
+        <bundle start-level="30">mvn:org.apache.servicemix.bundles/org.apache.servicemix.bundles.spring-test/4.3.14.RELEASE_1</bundle>
     </feature>
 
-    <feature name="spring-orm" description="Spring 4.3.x ORM support" version="4.3.10.RELEASE_1">
-        <feature version="[4.3.10.RELEASE_1,4.4)">spring-jdbc</feature>
-        <bundle start-level="30">mvn:org.apache.servicemix.bundles/org.apache.servicemix.bundles.spring-orm/4.3.10.RELEASE_1</bundle>
+    <feature name="spring-orm" description="Spring 4.3.x ORM support" version="4.3.14.RELEASE_1">
+        <feature version="[4.3.14.RELEASE_1,4.4)">spring-jdbc</feature>
+        <bundle start-level="30">mvn:org.apache.servicemix.bundles/org.apache.servicemix.bundles.spring-orm/4.3.14.RELEASE_1</bundle>
     </feature>
 
-    <feature name="spring-oxm" description="Spring 4.3.x OXM support" version="4.3.10.RELEASE_1">
-        <feature version="[4.3.10.RELEASE_1,4.4)">spring</feature>
-        <bundle start-level="30">mvn:org.apache.servicemix.bundles/org.apache.servicemix.bundles.spring-oxm/4.3.10.RELEASE_1</bundle>
+    <feature name="spring-oxm" description="Spring 4.3.x OXM support" version="4.3.14.RELEASE_1">
+        <feature version="[4.3.14.RELEASE_1,4.4)">spring</feature>
+        <bundle start-level="30">mvn:org.apache.servicemix.bundles/org.apache.servicemix.bundles.spring-oxm/4.3.14.RELEASE_1</bundle>
     </feature>
 
-    <feature name="spring-tx" description="Spring 4.3.x Transaction (TX) support" version="4.3.10.RELEASE_1">
-        <feature version="[4.3.10.RELEASE_1,4.4)">spring</feature>
-        <bundle start-level="30">mvn:org.apache.servicemix.bundles/org.apache.servicemix.bundles.spring-tx/4.3.10.RELEASE_1</bundle>
+    <feature name="spring-tx" description="Spring 4.3.x Transaction (TX) support" version="4.3.14.RELEASE_1">
+        <feature version="[4.3.14.RELEASE_1,4.4)">spring</feature>
+        <bundle start-level="30">mvn:org.apache.servicemix.bundles/org.apache.servicemix.bundles.spring-tx/4.3.14.RELEASE_1</bundle>
     </feature>
 
-    <feature name="spring-web" description="Spring 4.3.x Web support" version="4.3.10.RELEASE_1">
-        <feature version="[4.3.10.RELEASE_1,4.4)">spring</feature>
+    <feature name="spring-web" description="Spring 4.3.x Web support" version="4.3.14.RELEASE_1">
+        <feature version="[4.3.14.RELEASE_1,4.4)">spring</feature>
         <feature>http</feature>
-        <bundle start-level="30">mvn:org.apache.servicemix.bundles/org.apache.servicemix.bundles.spring-web/4.3.10.RELEASE_1</bundle>
-        <bundle start-level="30">mvn:org.apache.servicemix.bundles/org.apache.servicemix.bundles.spring-webmvc/4.3.10.RELEASE_1</bundle>
+        <bundle start-level="30">mvn:org.apache.servicemix.bundles/org.apache.servicemix.bundles.spring-web/4.3.14.RELEASE_1</bundle>
+        <bundle start-level="30">mvn:org.apache.servicemix.bundles/org.apache.servicemix.bundles.spring-webmvc/4.3.14.RELEASE_1</bundle>
     </feature>
 
-    <feature name="spring-web-portlet" description="Spring 4.3.x Web Portlet support" version="4.3.10.RELEASE_1">
+    <feature name="spring-web-portlet" description="Spring 4.3.x Web Portlet support" version="4.3.14.RELEASE_1">
         <feature prerequisite="true">wrap</feature>
-        <feature version="[4.3.10.RELEASE_1,4.4)">spring-web</feature>
+        <feature version="[4.3.14.RELEASE_1,4.4)">spring-web</feature>
         <bundle dependency="true" start-level="30">wrap:mvn:javax.portlet/portlet-api/2.0$Export-Package=javax.portlet.*;version=2.0</bundle>
-        <bundle start-level="30">mvn:org.apache.servicemix.bundles/org.apache.servicemix.bundles.spring-webmvc-portlet/4.3.10.RELEASE_1</bundle>
+        <bundle start-level="30">mvn:org.apache.servicemix.bundles/org.apache.servicemix.bundles.spring-webmvc-portlet/4.3.14.RELEASE_1</bundle>
     </feature>
 
-    <feature name="spring-websocket" description="Spring 4.3.x WebSocket support" version="4.3.10.RELEASE_1">
+    <feature name="spring-websocket" description="Spring 4.3.x WebSocket support" version="4.3.14.RELEASE_1">
         <bundle dependency="true">mvn:javax.websocket/javax.websocket-api/1.1</bundle>
-        <feature version="[4.3.10.RELEASE_1,4.4)">spring-web</feature>
-        <bundle start-level="30">mvn:org.apache.servicemix.bundles/org.apache.servicemix.bundles.spring-websocket/4.3.10.RELEASE_1</bundle>
+        <feature version="[4.3.14.RELEASE_1,4.4)">spring-web</feature>
+        <bundle start-level="30">mvn:org.apache.servicemix.bundles/org.apache.servicemix.bundles.spring-websocket/4.3.14.RELEASE_1</bundle>
     </feature>    
 
     <!-- Aries Blueprint Spring support -->
diff --git a/container/features/src/main/resources/karaf/standard.xml b/container/features/src/main/resources/karaf/standard.xml
index 7155c08d26c..fe9c7098a45 100644
--- a/container/features/src/main/resources/karaf/standard.xml
+++ b/container/features/src/main/resources/karaf/standard.xml
@@ -16,35 +16,37 @@
       See the License for the specific language governing permissions and
       limitations under the License.
 -->
-<features name="standard-4.1.2" xmlns="http://karaf.apache.org/xmlns/features/v1.3.0" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://karaf.apache.org/xmlns/features/v1.3.0 http://karaf.apache.org/xmlns/features/v1.3.0">
+<features name="standard-4.1.5" xmlns="http://karaf.apache.org/xmlns/features/v1.3.0" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://karaf.apache.org/xmlns/features/v1.3.0 http://karaf.apache.org/xmlns/features/v1.3.0">
 
 	<repository>mvn:org.ops4j.pax.web/pax-web-features/${paxWebVersion}/xml/features</repository>
 
-    <feature version="4.1.2" description="OSGi Security for Karaf" name="framework-security">
+    <feature version="4.1.5" description="OSGi Security for Karaf" name="framework-security">
         <bundle start="false" start-level="1">mvn:org.apache.felix/org.apache.felix.framework.security/2.6.0</bundle>
     </feature>
 
-    <feature version="4.1.2" description="Services Security for Karaf" name="service-security">
+    <feature version="4.1.5" description="Services Security for Karaf" name="service-security">
         <feature>jaas-boot</feature>
         <feature>aries-proxy</feature>
-        <bundle start="true" start-level="10">mvn:org.apache.karaf.service/org.apache.karaf.service.guard/4.1.2</bundle>
+        <bundle start="true" start-level="10">mvn:org.apache.karaf.service/org.apache.karaf.service.guard/4.1.5</bundle>
     </feature>
 
-    <feature name="aries-proxy" description="Aries Proxy" version="4.1.2">
+    <feature name="aries-proxy" description="Aries Proxy" version="4.1.5">
         <!-- false to avoid restarts of proxy which cascades badly -->
         <bundle dependency="false" start-level="20">mvn:org.ow2.asm/asm-all/5.2</bundle>
         <bundle start-level="20">mvn:org.apache.aries.proxy/org.apache.aries.proxy/1.1.1</bundle>
     </feature>
 
-    <feature name="aries-blueprint" description="Aries Blueprint" version="4.1.2">
+    <feature name="aries-blueprint" description="Aries Blueprint" version="4.1.5">
         <feature>aries-proxy</feature>
         <bundle dependency="true" start-level="20">mvn:org.apache.aries/org.apache.aries.util/1.1.3</bundle>
+        <!-- Making the compatibility bundle a dependency allows it to only be installed on-demand -->
+        <bundle dependency="true" start-level="20">mvn:org.apache.aries.blueprint/org.apache.aries.blueprint.core.compatibility/1.0.0</bundle>
         <bundle start-level="20">mvn:org.apache.aries.blueprint/org.apache.aries.blueprint.api/1.0.1</bundle>
         <bundle start-level="20">mvn:org.apache.aries.blueprint/org.apache.aries.blueprint.cm/1.1.0</bundle>
-        <bundle start-level="20">mvn:org.apache.aries.blueprint/org.apache.aries.blueprint.core/1.8.2</bundle>
+        <bundle start-level="20">mvn:org.apache.aries.blueprint/org.apache.aries.blueprint.core/1.8.3</bundle>
         <conditional>
             <condition>bundle</condition>
-            <bundle start-level="30">mvn:org.apache.karaf.bundle/org.apache.karaf.bundle.blueprintstate/4.1.2</bundle>
+            <bundle start-level="30">mvn:org.apache.karaf.bundle/org.apache.karaf.bundle.blueprintstate/4.1.5</bundle>
         </conditional>
         <capability>
             osgi.service;effective:=active;objectClass=org.apache.aries.blueprint.services.ParserService,
@@ -52,9 +54,9 @@
         </capability>
     </feature>
 
-    <feature name="feature" description="Features Support" version="4.1.2">
-        <bundle start-level="1">mvn:org.apache.karaf.features/org.apache.karaf.features.extension/4.1.2</bundle>
-        <bundle start-level="15">mvn:org.apache.karaf.features/org.apache.karaf.features.core/4.1.2</bundle>
+    <feature name="feature" description="Features Support" version="4.1.5">
+        <bundle start-level="1">mvn:org.apache.karaf.features/org.apache.karaf.features.extension/4.1.5</bundle>
+        <bundle start-level="15">mvn:org.apache.karaf.features/org.apache.karaf.features.core/4.1.5</bundle>
         <config name="org.apache.karaf.features.repos">
             #
             # This file describes the features repository URL
@@ -105,17 +107,17 @@
                 stop = admin
                 update = admin
             </config>
-            <bundle start-level="30">mvn:org.apache.karaf.features/org.apache.karaf.features.command/4.1.2</bundle>
+            <bundle start-level="30">mvn:org.apache.karaf.features/org.apache.karaf.features.command/4.1.5</bundle>
         </conditional>
     </feature>
 
     <feature name="jaas-boot" hidden="true">
         <library export="true" delegate="true" type="boot">
-            mvn:org.apache.karaf.jaas/org.apache.karaf.jaas.boot/4.1.2
+            mvn:org.apache.karaf.jaas/org.apache.karaf.jaas.boot/4.1.5
         </library>
     </feature>
 
-    <feature name="shell" description="Karaf Shell" version="4.1.2">
+    <feature name="shell" description="Karaf Shell" version="4.1.5">
         <feature>jaas-boot</feature>
         <config name="org.apache.karaf.command.acl.shell">
             #
@@ -175,10 +177,9 @@
             hostKeyFormat = simple
 
             #
-            # Role name used for SSH access authorization
-            # If not set, this defaults to the ${karaf.admin.role} configured in etc/system.properties
+            # shRole defines the role required to access the console through ssh
             #
-            # sshRole = admin
+            sshRole = admin
 
             #
             # Self defined key size in 1024, 2048, 3072, or 4096
@@ -244,52 +245,52 @@
 
             completionMode = GLOBAL
         </config>
-        <bundle dependency="true" start-level="30">mvn:org.fusesource.jansi/jansi/1.16</bundle>
-        <bundle dependency="true" start-level="30">mvn:org.jline/jline/3.4.0</bundle>
-        <bundle start-level="30">mvn:org.apache.karaf.shell/org.apache.karaf.shell.core/4.1.2</bundle>
-        <bundle start-level="30">mvn:org.apache.karaf.shell/org.apache.karaf.shell.commands/4.1.2</bundle>
+        <bundle dependency="true" start-level="30">mvn:org.fusesource.jansi/jansi/1.17</bundle>
+        <bundle dependency="true" start-level="30">mvn:org.jline/jline/3.6.0</bundle>
+        <bundle start-level="30">mvn:org.apache.karaf.shell/org.apache.karaf.shell.core/4.1.5</bundle>
+        <bundle start-level="30">mvn:org.apache.karaf.shell/org.apache.karaf.shell.commands/4.1.5</bundle>
     </feature>
 
-    <feature name="shell-compat" description="Karaf Shell Compatibility" version="4.1.2">
+    <feature name="shell-compat" description="Karaf Shell Compatibility" version="4.1.5">
         <feature>aries-blueprint</feature>
         <feature>shell</feature>
-        <bundle start-level="30">mvn:org.apache.karaf.shell/org.apache.karaf.shell.console/4.1.2</bundle>
-        <bundle start-level="30">mvn:org.apache.karaf.shell/org.apache.karaf.shell.table/4.1.2</bundle>
+        <bundle start-level="30">mvn:org.apache.karaf.shell/org.apache.karaf.shell.console/4.1.5</bundle>
+        <bundle start-level="30">mvn:org.apache.karaf.shell/org.apache.karaf.shell.table/4.1.5</bundle>
     </feature>
 
-    <feature name="deployer" description="Karaf Deployer" version="4.1.2">
-        <bundle start="true" start-level="26">mvn:org.apache.karaf.deployer/org.apache.karaf.deployer.features/4.1.2</bundle>
+    <feature name="deployer" description="Karaf Deployer" version="4.1.5">
+        <bundle start="true" start-level="26">mvn:org.apache.karaf.deployer/org.apache.karaf.deployer.features/4.1.5</bundle>
         <conditional>
             <condition>wrap</condition>
-            <bundle start="true" start-level="24">mvn:org.apache.karaf.deployer/org.apache.karaf.deployer.wrap/4.1.2</bundle>
+            <bundle start="true" start-level="24">mvn:org.apache.karaf.deployer/org.apache.karaf.deployer.wrap/4.1.5</bundle>
         </conditional>
         <conditional>
             <condition>req:osgi.extender;filter:="(&amp;(osgi.extender=osgi.blueprint)(version>=1.0))"</condition>
-            <bundle start="true" start-level="24">mvn:org.apache.karaf.deployer/org.apache.karaf.deployer.blueprint/4.1.2</bundle>
+            <bundle start="true" start-level="24">mvn:org.apache.karaf.deployer/org.apache.karaf.deployer.blueprint/4.1.5</bundle>
         </conditional>
         <conditional>
             <condition>kar</condition>
-            <bundle start="true" start-level="24">mvn:org.apache.karaf.deployer/org.apache.karaf.deployer.kar/4.1.2</bundle>
+            <bundle start="true" start-level="24">mvn:org.apache.karaf.deployer/org.apache.karaf.deployer.kar/4.1.5</bundle>
         </conditional>
     </feature>
 
-    <feature name="wrapper" description="Provide OS integration" version="4.1.2">
-        <bundle start-level="30">mvn:org.apache.karaf.wrapper/org.apache.karaf.wrapper.core/4.1.2</bundle>
+    <feature name="wrapper" description="Provide OS integration" version="4.1.5">
+        <bundle start-level="30">mvn:org.apache.karaf.wrapper/org.apache.karaf.wrapper.core/4.1.5</bundle>
     </feature>
-    <feature name="service-wrapper" description="Provide OS integration (alias to wrapper feature)" version="4.1.2">
+    <feature name="service-wrapper" description="Provide OS integration (alias to wrapper feature)" version="4.1.5">
         <feature>wrapper</feature>
     </feature>
 
-    <feature name="obr" description="Provide OSGi Bundle Repository (OBR) support" version="4.1.2">
+    <feature name="obr" description="Provide OSGi Bundle Repository (OBR) support" version="4.1.5">
         <bundle start-level="30">mvn:org.apache.felix/org.osgi.service.obr/1.0.2</bundle>
         <bundle start-level="30">mvn:org.apache.felix/org.apache.felix.bundlerepository/2.0.10</bundle>
-        <bundle start-level="30">mvn:org.apache.karaf.obr/org.apache.karaf.obr.core/4.1.2</bundle>
-        <bundle start-level="30">mvn:org.ops4j.pax.url/pax-url-obr/2.5.2/jar/uber</bundle>
+        <bundle start-level="30">mvn:org.apache.karaf.obr/org.apache.karaf.obr.core/4.1.5</bundle>
+        <bundle start-level="30">mvn:org.ops4j.pax.url/pax-url-obr/2.5.4/jar/uber</bundle>
     </feature>
 
-    <feature name="bundle" description="Provide Bundle support" version="4.1.2">
+    <feature name="bundle" description="Provide Bundle support" version="4.1.5">
         <feature>jaas-boot</feature>
-        <bundle start-level="30" start="true">mvn:org.apache.karaf.bundle/org.apache.karaf.bundle.core/4.1.2</bundle>
+        <bundle start-level="30" start="true">mvn:org.apache.karaf.bundle/org.apache.karaf.bundle.core/4.1.5</bundle>
         <conditional>
             <condition>management</condition>
             <config name="jmx.acl.org.apache.karaf.bundle">
@@ -346,8 +347,8 @@
         </conditional>
     </feature>
 
-    <feature name="config" description="Provide OSGi ConfigAdmin support" version="4.1.2">
-        <bundle start-level="30" start="true">mvn:org.apache.karaf.config/org.apache.karaf.config.core/4.1.2</bundle>
+    <feature name="config" description="Provide OSGi ConfigAdmin support" version="4.1.5">
+        <bundle start-level="30" start="true">mvn:org.apache.karaf.config/org.apache.karaf.config.core/4.1.5</bundle>
         <conditional>
             <condition>management</condition>
             <config name="jmx.acl.org.apache.karaf.config">
@@ -418,18 +419,18 @@
         </conditional>
     </feature>
 
-    <feature name="diagnostic" description="Provide Diagnostic support" version="4.1.2">
-        <bundle start-level="30" start="true">mvn:org.apache.karaf.diagnostic/org.apache.karaf.diagnostic.core/4.1.2</bundle>
+    <feature name="diagnostic" description="Provide Diagnostic support" version="4.1.5">
+        <bundle start-level="30" start="true">mvn:org.apache.karaf.diagnostic/org.apache.karaf.diagnostic.core/4.1.5</bundle>
         <library export="true" type="boot">
-            mvn:org.apache.karaf.diagnostic/org.apache.karaf.diagnostic.boot/4.1.2
+            mvn:org.apache.karaf.diagnostic/org.apache.karaf.diagnostic.boot/4.1.5
         </library>
     </feature>
 
-    <feature name="instance" description="Provide Instance support" version="4.1.2">
-        <bundle start-level="30" start="true">mvn:org.apache.karaf.instance/org.apache.karaf.instance.core/4.1.2</bundle>
+    <feature name="instance" description="Provide Instance support" version="4.1.5">
+        <bundle start-level="30" start="true">mvn:org.apache.karaf.instance/org.apache.karaf.instance.core/4.1.5</bundle>
     </feature>
 
-    <feature name="jaas" description="Provide JAAS support" version="4.1.2">
+    <feature name="jaas" description="Provide JAAS support" version="4.1.5">
         <config name="org.apache.karaf.jaas">
             #
             # Boolean enabling / disabling encrypted passwords
@@ -475,11 +476,11 @@
             encryption.encoding = hexadecimal
         </config>
         <feature>jaas-boot</feature>
-        <bundle start-level="30" start="true">mvn:org.apache.karaf.jaas/org.apache.karaf.jaas.config/4.1.2</bundle>
-        <bundle start-level="30" start="true">mvn:org.apache.karaf.jaas/org.apache.karaf.jaas.modules/4.1.2</bundle>
+        <bundle start-level="30" start="true">mvn:org.apache.karaf.jaas/org.apache.karaf.jaas.config/4.1.5</bundle>
+        <bundle start-level="30" start="true">mvn:org.apache.karaf.jaas/org.apache.karaf.jaas.modules/4.1.5</bundle>
         <conditional>
             <condition>aries-blueprint</condition>
-            <bundle start-level="30" start="true">mvn:org.apache.karaf.jaas.blueprint/org.apache.karaf.jaas.blueprint.config/4.1.2</bundle>
+            <bundle start-level="30" start="true">mvn:org.apache.karaf.jaas.blueprint/org.apache.karaf.jaas.blueprint.config/4.1.5</bundle>
         </conditional>
         <conditional>
             <condition>shell</condition>
@@ -489,11 +490,11 @@
                 # Jaas commands commands have no effect until update is called.
                 update = admin
             </config>
-            <bundle start-level="30" start="true">mvn:org.apache.karaf.jaas/org.apache.karaf.jaas.command/4.1.2</bundle>
+            <bundle start-level="30" start="true">mvn:org.apache.karaf.jaas/org.apache.karaf.jaas.command/4.1.5</bundle>
         </conditional>
     </feature>
 
-    <feature name="log" description="Provide Log support" version="4.1.2">
+    <feature name="log" description="Provide Log support" version="4.1.5">
         <config name="org.apache.karaf.log">
             #
             # This configuration file is used to configure the default values for the log:display
@@ -513,19 +514,19 @@
             #
             pattern = %d{ISO8601} | %-5.5p | %-16.16t | %-32.32c{1} | %X{bundle.id} - %X{bundle.name} - %X{bundle.version} | %m%n
         </config>
-        <bundle start-level="30" start="true">mvn:org.apache.karaf.log/org.apache.karaf.log.core/4.1.2</bundle>
+        <bundle start-level="30" start="true">mvn:org.apache.karaf.log/org.apache.karaf.log.core/4.1.5</bundle>
     </feature>
 
-    <feature name="package" version="4.1.2" description="Package commands and mbeans">
-        <bundle start-level="30">mvn:org.apache.karaf.package/org.apache.karaf.package.core/4.1.2</bundle>
+    <feature name="package" version="4.1.5" description="Package commands and mbeans">
+        <bundle start-level="30">mvn:org.apache.karaf.package/org.apache.karaf.package.core/4.1.5</bundle>
     </feature>
 
-    <feature name="service" description="Provide Service support" version="4.1.2">
-        <bundle start-level="30" start="true">mvn:org.apache.karaf.service/org.apache.karaf.service.core/4.1.2</bundle>
+    <feature name="service" description="Provide Service support" version="4.1.5">
+        <bundle start-level="30" start="true">mvn:org.apache.karaf.service/org.apache.karaf.service.core/4.1.5</bundle>
     </feature>
 
-    <feature name="system" description="Provide System support" version="4.1.2">
-        <bundle start-level="30" start="true">mvn:org.apache.karaf.system/org.apache.karaf.system.core/4.1.2</bundle>
+    <feature name="system" description="Provide System support" version="4.1.5">
+        <bundle start-level="30" start="true">mvn:org.apache.karaf.system/org.apache.karaf.system.core/4.1.5</bundle>
         <conditional>
             <condition>shell</condition>
             <config name="org.apache.karaf.command.acl.system">
@@ -534,7 +535,7 @@
                 #
                 property = admin
                 shutdown = admin
-                start-level[/.*[0-9][0-9][0-9]+.*/] = manager # manager can set startlevels above 100
+                start-level[/.*[1-9][0-9][0-9]+.*/] = manager # manager can set startlevels above 100
                 start-level[/[^0-9]*/] = viewer               # viewer can obtain the current start level
                 start-level = admin                           # admin can set any start level, including &lt; 100
             </config>
@@ -542,39 +543,39 @@
     </feature>
 
     <!-- ################ START OPENNMS CUSTOMIZATION ############ -->
-    <feature name="http" version="4.1.2" description="Implementation of the OSGI HTTP Service">
+    <feature name="http" version="4.1.5" description="Implementation of the OSGI HTTP Service">
         <!-- <feature dependency="true">pax-http-service</feature> -->
         <feature dependency="true">opennms-bridge-http-service</feature>
         <requirement>http-service</requirement>
     </feature>
 
-    <feature name="httplite" version="4.1.2" description="Felix Httplite OSGi HTTP Service">
+    <feature name="httplite" version="4.1.5" description="Felix Httplite OSGi HTTP Service">
         <bundle start-level="30">mvn:org.apache.felix/org.apache.felix.httplite.complete/0.1.6</bundle>
         <capability>http-service;provider:=felix-httplite</capability>
     </feature>
 
     <!-- Replace the Pax Web HTTP service with our servlet bridge -->
     <feature name="opennms-bridge-http-service" description="OpenNMS Bridge OSGi HTTP Service" version="${opennms.osgi.version}">
-        <!-- <bundle start-level="30">mvn:org.apache.karaf.http/org.apache.karaf.http.core/4.1.2</bundle> -->
+        <!-- <bundle start-level="30">mvn:org.apache.karaf.http/org.apache.karaf.http.core/4.1.5</bundle> -->
         <bundle start-level="30">mvn:org.opennms.container/org.opennms.container.bridge/${project.version}</bundle>
         <capability>http-service;provider:=opennms-http</capability>
         <conditional>
             <condition>webconsole</condition>
-            <bundle start-level="30">mvn:org.apache.karaf.webconsole/org.apache.karaf.webconsole.http/4.1.2</bundle>
+            <bundle start-level="30">mvn:org.apache.karaf.webconsole/org.apache.karaf.webconsole.http/4.1.5</bundle>
         </conditional>
     </feature>
 
-    <feature name="http-whiteboard" description="Provide HTTP Whiteboard pattern support" version="4.1.2">
+    <feature name="http-whiteboard" description="Provide HTTP Whiteboard pattern support" version="4.1.5">
         <feature>http</feature>
         <!-- <feature>pax-http-whiteboard</feature> -->
         <feature>opennms-http-whiteboard</feature>
     </feature>
 
-    <feature name="war" description="Turn Karaf as a full WebContainer" version="4.1.2">
+    <feature name="war" description="Turn Karaf as a full WebContainer" version="4.1.5">
         <feature>http</feature>
         <!-- <feature>pax-war</feature> -->
         <feature>opennms-war</feature>
-        <bundle start-level="30">mvn:org.apache.karaf.web/org.apache.karaf.web.core/4.1.2</bundle>
+        <bundle start-level="30">mvn:org.apache.karaf.web/org.apache.karaf.web.core/4.1.5</bundle>
     </feature>
 
     <!-- Copied out of PAX Web features.xml at mvn:org.ops4j.pax.web/pax-web-features/${paxWebVersion}/xml/features -->
@@ -615,8 +616,43 @@
 
     <!-- ################ END OPENNMS CUSTOMIZATION ############## -->
 
-    <feature name="jetty" version="9.3.9.v20160517">
-        <feature>pax-jetty</feature>
+    <feature name="jetty" version="9.3.21.v20170918">
+        <bundle dependency="true" start-level="30">mvn:org.apache.servicemix.specs/org.apache.servicemix.specs.activation-api-1.1/2.9.0</bundle>
+        <bundle dependency="true" start-level="30">mvn:javax.servlet/javax.servlet-api/3.1.0</bundle>
+        <bundle dependency="true" start-level="30">mvn:javax.mail/mail/1.4.5</bundle>
+        <bundle dependency="true" start-level="30">mvn:org.apache.geronimo.specs/geronimo-jta_1.1_spec/1.1.1</bundle>
+        <bundle dependency="true" start-level="30">mvn:javax.annotation/javax.annotation-api/1.2</bundle>
+        <bundle dependency="true" start-level="30">mvn:org.apache.geronimo.specs/geronimo-jaspic_1.0_spec/1.1</bundle>
+        <bundle dependency="true" start-level="30">mvn:org.ow2.asm/asm-all/5.2</bundle>
+        <bundle dependency="true" start-level="30">mvn:org.apache.aries.spifly/org.apache.aries.spifly.dynamic.bundle/1.0.2</bundle>
+        <bundle dependency="true" start-level="30">mvn:org.apache.aries/org.apache.aries.util/1.1.3</bundle>
+        <bundle start-level="30">mvn:org.eclipse.jetty/jetty-continuation/9.3.21.v20170918</bundle>
+        <bundle start-level="30">mvn:org.eclipse.jetty/jetty-http/9.3.21.v20170918</bundle>
+        <bundle start-level="30">mvn:org.eclipse.jetty/jetty-io/9.3.21.v20170918</bundle>
+        <bundle start-level="30">mvn:org.eclipse.jetty/jetty-jaspi/9.3.21.v20170918</bundle>
+        <bundle start-level="30">mvn:org.eclipse.jetty/jetty-plus/9.3.21.v20170918</bundle>
+       	<bundle start-level="30">mvn:org.eclipse.jetty/jetty-jndi/9.3.21.v20170918</bundle>
+        <bundle start-level="30">mvn:org.eclipse.jetty/jetty-rewrite/9.3.21.v20170918</bundle>
+        <bundle start-level="30">mvn:org.eclipse.jetty/jetty-security/9.3.21.v20170918</bundle>
+        <bundle start-level="30">mvn:org.eclipse.jetty/jetty-server/9.3.21.v20170918</bundle>
+        <bundle start-level="30">mvn:org.eclipse.jetty/jetty-servlet/9.3.21.v20170918</bundle>
+        <bundle start-level="30">mvn:org.eclipse.jetty/jetty-servlets/9.3.21.v20170918</bundle>
+        <bundle start-level="30">mvn:org.eclipse.jetty/jetty-util/9.3.21.v20170918</bundle>
+        <bundle start-level="30">mvn:org.eclipse.jetty/jetty-util-ajax/9.3.21.v20170918</bundle>
+        <bundle start-level="30">mvn:org.eclipse.jetty/jetty-webapp/9.3.21.v20170918</bundle>
+        <bundle start-level="30">mvn:org.eclipse.jetty/jetty-jaas/9.3.21.v20170918</bundle>
+        <bundle start-level="30">mvn:org.eclipse.jetty/jetty-xml/9.3.21.v20170918</bundle>
+        <bundle start-level="30">mvn:org.eclipse.jetty/jetty-client/9.3.21.v20170918</bundle>
+        <bundle start-level="30">mvn:org.eclipse.jetty/jetty-deploy/9.3.21.v20170918</bundle>
+        <bundle start-level="30">mvn:org.eclipse.jetty/jetty-jmx/9.3.21.v20170918</bundle>
+        <bundle start-level="30">mvn:org.eclipse.jetty.websocket/websocket-server/9.3.21.v20170918</bundle>
+        <bundle start-level="30">mvn:org.eclipse.jetty.websocket/websocket-client/9.3.21.v20170918</bundle>
+        <bundle start-level="30">mvn:org.eclipse.jetty.websocket/websocket-common/9.3.21.v20170918</bundle>
+        <bundle start-level="30">mvn:org.eclipse.jetty.websocket/websocket-servlet/9.3.21.v20170918</bundle>
+        <bundle start-level="30">mvn:org.eclipse.jetty.websocket/websocket-api/9.3.21.v20170918</bundle>
+        <bundle start-level="30">mvn:org.eclipse.jetty.websocket/javax-websocket-server-impl/9.3.21.v20170918</bundle>
+        <bundle start-level="30">mvn:org.eclipse.jetty.websocket/javax-websocket-client-impl/9.3.21.v20170918</bundle>
+        <bundle start-level="30">mvn:javax.websocket/javax.websocket-api/1.1</bundle>
     </feature>
 
     <feature name="jetty" version="8.1.14.v20131031">
@@ -629,8 +665,8 @@
         <bundle start-level="30">mvn:org.eclipse.jetty.aggregate/jetty-all-server/8.1.14.v20131031</bundle>
     </feature>
 
-    <feature name="kar" description="Provide KAR (KARaf archive) support" version="4.1.2">
-        <bundle start-level="30">mvn:org.apache.karaf.kar/org.apache.karaf.kar.core/4.1.2</bundle>
+    <feature name="kar" description="Provide KAR (KARaf archive) support" version="4.1.5">
+        <bundle start-level="30">mvn:org.apache.karaf.kar/org.apache.karaf.kar.core/4.1.5</bundle>
         <conditional>
             <condition>shell</condition>
             <config name="org.apache.karaf.command.acl.kar">
@@ -646,43 +682,37 @@
         </conditional>
     </feature>
 
-    <feature name="webconsole" description="Base support of the Karaf WebConsole" version="4.1.2">
+    <feature name="webconsole" description="Base support of the Karaf WebConsole" version="4.1.5">
         <feature>jaas-boot</feature>
         <config name="org.apache.karaf.webconsole">
             realm=karaf
         </config>
         <feature>http</feature>
-        <bundle start-level="30">mvn:org.apache.felix/org.apache.felix.metatype/1.1.2</bundle>
-        <bundle start-level="30">mvn:org.apache.karaf.webconsole/org.apache.karaf.webconsole.console/4.1.2</bundle>
+        <bundle start-level="30">mvn:org.apache.felix/org.apache.felix.metatype/1.1.6</bundle>
+        <bundle start-level="30">mvn:org.apache.karaf.webconsole/org.apache.karaf.webconsole.console/4.1.5</bundle>
         <conditional>
             <condition>instance</condition>
-            <bundle start-level="30">mvn:org.apache.karaf.webconsole/org.apache.karaf.webconsole.instance/4.1.2</bundle>
+            <bundle start-level="30">mvn:org.apache.karaf.webconsole/org.apache.karaf.webconsole.instance/4.1.5</bundle>
         </conditional>
         <conditional>
             <condition>shell</condition>
-            <bundle start-level="30">mvn:org.apache.karaf.webconsole/org.apache.karaf.webconsole.gogo/4.1.2</bundle>
+            <bundle start-level="30">mvn:org.apache.karaf.webconsole/org.apache.karaf.webconsole.gogo/4.1.5</bundle>
         </conditional>
         <conditional>
             <condition>feature</condition>
-            <bundle start-level="30">mvn:org.apache.karaf.webconsole/org.apache.karaf.webconsole.features/4.1.2</bundle>
+            <bundle start-level="30">mvn:org.apache.karaf.webconsole/org.apache.karaf.webconsole.features/4.1.5</bundle>
         </conditional>
     </feature>
 
-    <feature name="ssh" description="Provide a SSHd server on Karaf" version="4.1.2">
-        <config name="org.apache.karaf.shell">
-            sshPort=8101
-            sshHost=0.0.0.0
-            sshRealm=karaf
-            hostKey=${karaf.etc}/host.key
-        </config>
+    <feature name="ssh" description="Provide a SSHd server on Karaf" version="4.1.5">
         <feature>shell</feature>
         <feature>jaas</feature>
         <bundle start="true" start-level="30">mvn:org.apache.sshd/sshd-core/1.6.0</bundle>
         <bundle start="true" start-level="30">mvn:org.apache.servicemix.bundles/org.apache.servicemix.bundles.not-yet-commons-ssl/0.3.11_1</bundle>
-        <bundle start="true" start-level="30">mvn:org.apache.karaf.shell/org.apache.karaf.shell.ssh/4.1.2</bundle>
+        <bundle start="true" start-level="30">mvn:org.apache.karaf.shell/org.apache.karaf.shell.ssh/4.1.5</bundle>
     </feature>
 
-    <feature name="management" description="Provide a JMX MBeanServer and a set of MBeans in Karaf" version="4.1.2">
+    <feature name="management" description="Provide a JMX MBeanServer and a set of MBeans in Karaf" version="4.1.5">
         <config name="jmx.acl">
             #
             # Generic JMX ACL
@@ -900,7 +930,7 @@
         </config>
         <feature>jaas</feature>
         <bundle dependency="true" start-level="20">mvn:org.apache.aries/org.apache.aries.util/1.1.3</bundle>
-        <bundle start-level="30">mvn:org.apache.karaf.management/org.apache.karaf.management.server/4.1.2</bundle>
+        <bundle start-level="30">mvn:org.apache.karaf.management/org.apache.karaf.management.server/4.1.5</bundle>
         <bundle start-level="30">mvn:org.apache.aries.jmx/org.apache.aries.jmx.api/1.1.5</bundle>
         <bundle start-level="30">mvn:org.apache.aries.jmx/org.apache.aries.jmx.core/1.1.7</bundle>
         <bundle start-level="30">mvn:org.apache.aries.jmx/org.apache.aries.jmx.whiteboard/1.1.5</bundle>
@@ -911,36 +941,55 @@
         </conditional>
     </feature>
 
-    <feature name="scheduler" description="Provide a scheduler service in Karaf to fire events" version="4.1.2">
-        <bundle start-level="30">mvn:org.apache.karaf.scheduler/org.apache.karaf.scheduler.core/4.1.2</bundle>
+    <feature name="scheduler" description="Provide a scheduler service in Karaf to fire events" version="4.1.5">
+        <config name="org.apache.karaf.scheduler.quartz">
+            #============================================================================
+            # Configure Karaf Scheduler Properties
+            #============================================================================
+            org.quartz.scheduler.instanceName=Karaf
+            org.quartz.scheduler.instanceId=AUTO
+
+            #============================================================================
+            # Configure ThreadPool
+            #============================================================================
+            org.quartz.threadPool.class=org.quartz.simpl.SimpleThreadPool
+            org.quartz.threadPool.threadCount=30
+            org.quartz.threadPool.threadPriority=5
+
+            #============================================================================
+            # Configure JobStore
+            #============================================================================
+            org.quartz.jobStore.class=org.quartz.simpl.RAMJobStore
+        </config>
+        <bundle start-level="30">mvn:org.apache.karaf.scheduler/org.apache.karaf.scheduler.core/4.1.5</bundle>
     </feature>
 
-    <feature name="eventadmin" description="OSGi Event Admin service specification for event-based communication" version="4.1.2">
+    <feature name="eventadmin" description="OSGi Event Admin service specification for event-based communication" version="4.1.5">
         <config name="org.apache.felix.eventadmin.impl.EventAdmin">
             org.apache.felix.eventadmin.AddTimestamp=true
             org.apache.felix.eventadmin.AddSubject=true
         </config>
-        <bundle start-level="5">mvn:org.apache.felix/org.apache.felix.metatype/1.1.2</bundle>
-        <bundle start-level="5">mvn:org.apache.karaf.services/org.apache.karaf.services.eventadmin/4.1.2</bundle>
+        <bundle start-level="5">mvn:org.apache.felix/org.apache.felix.metatype/1.1.6</bundle>
+        <bundle start-level="5">mvn:org.apache.karaf.services/org.apache.karaf.services.eventadmin/4.1.5</bundle>
         <conditional>
             <condition>shell</condition>
-            <bundle>mvn:org.apache.karaf/org.apache.karaf.event/4.1.2</bundle>
+            <bundle>mvn:org.apache.karaf/org.apache.karaf.event/4.1.5</bundle>
         </conditional>
         <conditional>
             <condition>webconsole</condition>
-            <bundle start-level="30">mvn:org.apache.felix/org.apache.felix.webconsole.plugins.event/1.1.6</bundle>
+            <bundle start-level="30">mvn:org.apache.felix/org.apache.felix.webconsole.plugins.event/1.1.8</bundle>
         </conditional>
     </feature>
     
-    <feature name="jasypt-encryption" description="Advanced encryption support for Karaf security" version="4.1.2">
+    <feature name="jasypt-encryption" description="Advanced encryption support for Karaf security" version="4.1.5">
         <feature>jaas</feature>
         <bundle dependency="true" start-level="30">mvn:commons-codec/commons-codec/1.10</bundle>
         <bundle dependency="true" start-level="30">mvn:commons-lang/commons-lang/2.6</bundle>
         <bundle dependency="true" start-level="30">mvn:org.apache.servicemix.bundles/org.apache.servicemix.bundles.jasypt/1.9.2_1</bundle>
-        <bundle start-level="30">mvn:org.apache.karaf.jaas/org.apache.karaf.jaas.jasypt/4.1.2</bundle>
+        <bundle start-level="30">mvn:org.apache.karaf.jaas/org.apache.karaf.jaas.jasypt/4.1.5</bundle>
         <conditional>
             <condition>aries-blueprint</condition>
-            <bundle start-level="30" start="true">mvn:org.apache.karaf.jaas.blueprint/org.apache.karaf.jaas.blueprint.jasypt/4.1.2</bundle>
+            <bundle start-level="30" start="true">mvn:org.apache.karaf.jaas.blueprint/org.apache.karaf.jaas.blueprint.jasypt/4.1.5</bundle>
         </conditional>
         <conditional>
             <condition>spring</condition>
@@ -948,26 +997,26 @@
         </conditional>
     </feature>
 
-    <feature name="scr" description="Declarative Service support" version="4.1.2">
-        <bundle dependency="true" start-level="30">mvn:org.apache.felix/org.apache.felix.metatype/1.1.2</bundle>
+    <feature name="scr" description="Declarative Service support" version="4.1.5">
+        <bundle dependency="true" start-level="30">mvn:org.apache.felix/org.apache.felix.metatype/1.1.6</bundle>
         <bundle start-level="30">mvn:org.apache.felix/org.apache.felix.scr/2.0.12</bundle>
         <bundle start-level="30">mvn:org.apache.felix/org.apache.felix.scr.compat/1.0.4</bundle>
         <conditional>
             <condition>management</condition>
-            <bundle start-level="30">mvn:org.apache.karaf.scr/org.apache.karaf.scr.management/4.1.2</bundle>
+            <bundle start-level="30">mvn:org.apache.karaf.scr/org.apache.karaf.scr.management/4.1.5</bundle>
         </conditional>
         <conditional>
             <condition>webconsole</condition>
             <bundle start-level="30">mvn:org.apache.felix/org.apache.felix.inventory/1.0.4</bundle>
-            <bundle start-level="30">mvn:org.apache.felix/org.apache.felix.webconsole.plugins.ds/2.0.6</bundle>
+            <bundle start-level="30">mvn:org.apache.felix/org.apache.felix.webconsole.plugins.ds/2.0.8</bundle>
         </conditional>
         <conditional>
             <condition>shell</condition>
-            <bundle start-level="30">mvn:org.apache.karaf.scr/org.apache.karaf.scr.command/4.1.2</bundle>
+            <bundle start-level="30">mvn:org.apache.karaf.scr/org.apache.karaf.scr.command/4.1.5</bundle>
         </conditional>
         <conditional>
             <condition>bundle</condition>
-            <bundle start-level="30">mvn:org.apache.karaf.scr/org.apache.karaf.scr.state/4.1.2</bundle>
+            <bundle start-level="30">mvn:org.apache.karaf.scr/org.apache.karaf.scr.state/4.1.5</bundle>
         </conditional>
         <capability>
             osgi.service;effective:=active;objectClass=org.apache.felix.scr.ScrService,
@@ -976,23 +1025,23 @@
     </feature>
 
     <feature name="blueprint-web" description="Provides an OSGI-aware Servlet ContextListener for bootstrapping
-        blueprint inside web-bundle containers" version="4.1.2">
+        blueprint inside web-bundle containers" version="4.1.5">
         <feature>war</feature>
         <feature>aries-blueprint</feature>
         <bundle>mvn:org.apache.aries.blueprint/org.apache.aries.blueprint.webosgi/1.0.1</bundle>
     </feature>
 
     <feature name="wrap" description="Wrap URL handler">
-        <bundle start="true" start-level="5">mvn:org.ops4j.pax.url/pax-url-wrap/2.5.2/jar/uber</bundle>
+        <bundle start="true" start-level="5">mvn:org.ops4j.pax.url/pax-url-wrap/2.5.4/jar/uber</bundle>
     </feature>
 
-    <feature name="profile" description="Profiles support" version="4.1.2">
+    <feature name="profile" description="Profiles support" version="4.1.5">
         <config name="org.apache.karaf.profile">
             profilesDirectory = ${karaf.home}/profiles
         </config>
-        <bundle>mvn:org.apache.karaf.profile/org.apache.karaf.profile.core/4.1.2</bundle>
-        <bundle>mvn:org.apache.karaf.tooling/org.apache.karaf.tools.utils/4.1.2</bundle>
-        <bundle>mvn:commons-io/commons-io/2.4</bundle>
+        <bundle>mvn:org.apache.karaf.profile/org.apache.karaf.profile.core/4.1.5</bundle>
+        <bundle>mvn:org.apache.karaf.tooling/org.apache.karaf.tools.utils/4.1.5</bundle>
+        <bundle>mvn:commons-io/commons-io/2.6</bundle>
     </feature>
 
     <feature name="jolokia" description="Jolokia monitoring support" version="1.3.5">
@@ -1005,7 +1054,7 @@
         <bundle>mvn:org.jolokia/jolokia-osgi/1.3.5</bundle>
     </feature>
     
-    <feature name="standard" description="Wrap feature describing all features part of a standard distribution" version="4.1.2">
+    <feature name="standard" description="Wrap feature describing all features part of a standard distribution" version="4.1.5">
         <feature>wrap</feature>
         <feature>aries-blueprint</feature>
         <feature>shell</feature>
@@ -1027,7 +1076,7 @@
         <feature>system</feature>
     </feature>
 
-    <feature name="minimal" description="Wrap feature describing all features part of a minimal distribution" version="4.1.2">
+    <feature name="minimal" description="Wrap feature describing all features part of a minimal distribution" version="4.1.5">
         <feature>jaas</feature>
         <feature>shell</feature>
         <feature>feature</feature>
diff --git a/container/jaas-login-module/src/main/java/org/opennms/container/jaas/OpenNMSBackingEngine.java b/container/jaas-login-module/src/main/java/org/opennms/container/jaas/OpenNMSBackingEngine.java
index 29d39d3bf2c..fc6ba336514 100644
--- a/container/jaas-login-module/src/main/java/org/opennms/container/jaas/OpenNMSBackingEngine.java
+++ b/container/jaas-login-module/src/main/java/org/opennms/container/jaas/OpenNMSBackingEngine.java
@@ -66,6 +66,15 @@ public class OpenNMSBackingEngine implements BackingEngine {
 		return Collections.singletonList(new UserPrincipal("admin"));
 	}
 
+	@Override
+	public UserPrincipal lookupUser(String s) {
+		if ("admin".equals(s)) {
+			return new UserPrincipal("admin");
+		} else {
+			return null;
+		}
+	}
+
 	@Override
 	public List<GroupPrincipal> listGroups(UserPrincipal user) {
 		return Collections.emptyList();
diff --git a/container/karaf/src/main/filtered-resources/etc/config.properties b/container/karaf/src/main/filtered-resources/etc/config.properties
index e4f1fde26c2..c6510ced435 100644
--- a/container/karaf/src/main/filtered-resources/etc/config.properties
+++ b/container/karaf/src/main/filtered-resources/etc/config.properties
@@ -50,8 +50,8 @@ karaf.framework=felix
 #
 # Location of the OSGi frameworks
 #
-karaf.framework.equinox=mvn\:org.eclipse.platform/org.eclipse.osgi/3.11.3
-karaf.framework.felix=mvn\:org.apache.felix/org.apache.felix.framework/5.6.6
+karaf.framework.equinox=mvn\:org.eclipse.platform/org.eclipse.osgi/3.12.50
+karaf.framework.felix=mvn\:org.apache.felix/org.apache.felix.framework/5.6.10
 
 #
 # Framework config properties.
@@ -78,9 +78,9 @@ org.osgi.framework.system.packages= \
  org.osgi.service.startlevel;version="1.1";uses:="org.osgi.framework",\
  org.osgi.service.url;version="1.0",\
  org.osgi.util.tracker;version="1.5.1";uses:="org.osgi.framework",\
- org.apache.karaf.version;version="4.1.2",\
- org.apache.karaf.jaas.boot.principal;uses:=javax.security.auth;version="4.1.2",\
- org.apache.karaf.jaas.boot;uses:="javax.security.auth,javax.security.auth.callback,javax.security.auth.login,javax.security.auth.spi,org.osgi.framework";version="4.1.2",\
+ org.apache.karaf.version;version="4.1.5",\
+ org.apache.karaf.jaas.boot.principal;uses:=javax.security.auth;version="4.1.5",\
+ org.apache.karaf.jaas.boot;uses:="javax.security.auth,javax.security.auth.callback,javax.security.auth.login,javax.security.auth.spi,org.osgi.framework";version="4.1.5",\
  ${jre-${java.specification.version}}
 
 #
@@ -89,6 +89,24 @@ org.osgi.framework.system.packages= \
 org.osgi.framework.system.packages.extra = \
     org.apache.karaf.branding, \
     sun.misc, \
+    javax.activation;version=1.1, \
+    javax.xml.ws;uses:=\"javax.xml.bind,javax.xml.bind.annotation,javax.xml.namespace,javax.xml.transform,javax.xml.ws.handler,javax.xml.ws.spi,javax.xml.ws.spi.http,org.w3c.dom\";version=2.2, \
+    javax.xml.ws.handler;uses:=\"javax.xml.namespace,javax.xml.ws\";version=2.2, \
+    javax.xml.ws.handler.soap;uses:=\"javax.xml.bind,javax.xml.namespace,javax.xml.soap,javax.xml.ws.handler\";version=2.2, \
+    javax.xml.ws.http;uses:=javax.xml.ws;version=2.2, \
+    javax.xml.ws.soap;uses:=\"javax.xml.soap,javax.xml.ws,javax.xml.ws.spi\";version=2.2, \
+    javax.xml.ws.spi;uses:=\"javax.xml.bind,javax.xml.namespace,javax.xml.transform,javax.xml.ws,javax.xml.ws.handler,javax.xml.ws.wsaddressing,org.w3c.dom\";version=2.2, \
+    javax.xml.ws.spi.http;version=2.2, \
+    javax.xml.ws.wsaddressing;uses:=\"javax.xml.bind.annotation,javax.xml.namespace,javax.xml.transform,javax.xml.ws,org.w3c.dom\";version=2.2, \
+    javax.xml.bind;uses:=\"javax.xml.bind.annotation.adapters,javax.xml.bind.attachment,javax.xml.namespace,javax.xml.stream,javax.xml.transform,javax.xml.validation,org.w3c.dom,org.xml.sax\";version=2.2.1, \
+    javax.xml.bind.annotation;uses:=\"javax.xml.bind,javax.xml.parsers,javax.xml.transform,javax.xml.transform.dom,org.w3c.dom\";version=2.2.1, \
+    javax.xml.bind.annotation.adapters;version=2.2.1, \
+    javax.xml.bind.attachment;uses:=javax.activation;version=2.2.1, \
+    javax.xml.bind.helpers;uses:=\"javax.xml.bind,javax.xml.bind.annotation.adapters,javax.xml.bind.attachment,javax.xml.stream,javax.xml.transform,javax.xml.validation,org.w3c.dom,org.xml.sax\";version=2.2.1, \
+    javax.xml.bind.util;uses:=\"javax.xml.bind,javax.xml.transform.sax\";version=2.2.1, \
+    javax.annotation;version=1.2, \
+    javax.annotation.security;version=1.2, \
+    javax.annotation.sql;version=1.2, \
     javax.xml.stream;uses:=\"javax.xml.namespace,javax.xml.stream.events,javax.xml.stream.util,javax.xml.transform\";version=1.2, \
     javax.xml.stream.events;uses:=\"javax.xml.namespace,javax.xml.stream\";version=1.2, \
     javax.xml.stream.util;uses:=\"javax.xml.namespace,javax.xml.stream,javax.xml.stream.events\";version=1.2, \
@@ -117,53 +135,9 @@ org.osgi.framework.system.packages.extra = \
     org.xml.sax;version=2.0.2, \
     org.xml.sax.ext;uses:=\"org.xml.sax,org.xml.sax.helpers\";version=2.0.2, \
     org.xml.sax.helpers;uses:=org.xml.sax;version=2.0.2, \
-    javax.xml.bind;uses:=\"javax.xml.bind.annotation.adapters,javax.xml.bind.attachment,javax.xml.namespace,javax.xml.stream,javax.xml.transform,javax.xml.validation,org.w3c.dom,org.xml.sax\";version=2.2.1, \
-    javax.xml.bind.annotation;uses:=\"javax.xml.bind,javax.xml.parsers,javax.xml.transform,javax.xml.transform.dom,org.w3c.dom\";version=2.2.1, \
-    javax.xml.bind.annotation.adapters;version=2.2.1, \
-    javax.xml.bind.attachment;uses:=javax.activation;version=2.2.1, \
-    javax.xml.bind.helpers;uses:=\"javax.xml.bind,javax.xml.bind.annotation.adapters,javax.xml.bind.attachment,javax.xml.stream,javax.xml.transform,javax.xml.validation,org.w3c.dom,org.xml.sax\";version=2.2.1, \
-    javax.xml.bind.util;uses:=\"javax.xml.bind,javax.xml.transform.sax\";version=2.2.1, \
-    org.apache.html.dom;uses:=\"org.w3c.dom.html,org.apache.xerces.dom,org.w3c.dom,org.xml.sax\";version=2.11.0, \
-    org.apache.wml.dom;uses:=\"org.apache.wml,org.apache.xerces.dom,org.w3c.dom\";version=2.11.0, \
-    org.apache.wml;uses:=org.w3c.dom;version=2.11.0, \
-    org.apache.xerces.xpointer;uses:=\"org.apache.xerces.util,org.apache.xerces.xni,org.apache.xerces.xni.parser,org.apache.xerces.impl,org.apache.xerces.xs,org.apache.xerces.impl.dv,org.apache.xerces.xinclude\";version=2.11.0, \
-    org.apache.xerces.xni.grammars;uses:=\"org.apache.xerces.xni,org.apache.xerces.xni.parser,org.apache.xerces.xs\";version=2.11.0, \
-    org.apache.xerces.impl.xs.util;uses:=\"org.apache.xerces.xs,org.w3c.dom.ls,org.apache.xerces.xs.datatypes,org.apache.xerces.xni,org.apache.xerces.util,org.apache.xerces.xni.grammars,org.apache.xerces.impl.xs,org.apache.xerces.xni.parser,javax.xml.namespace\";version=2.11.0, \
-    org.apache.xerces.jaxp.validation;uses:=\"org.apache.xerces.xni.grammars,javax.xml.validation,org.apache.xerces.xni,javax.xml.transform.dom,org.w3c.dom,org.apache.xerces.xs,org.apache.xerces.impl.dv,org.apache.xerces.dom,org.apache.xerces.xni.parser,org.apache.xerces.util,org.apache.xerces.impl.xs.util,javax.xml.parsers,org.xml.sax,org.apache.xerces.impl.validation,javax.xml.transform,org.apache.xerces.impl.xs,org.apache.xerces.impl,javax.xml.stream,javax.xml.transform.stax,javax.xml.stream.events,javax.xml.namespace,org.apache.xerces.parsers,org.apache.xml.serialize,javax.xml.transform.stream,org.apache.xerces.impl.msg,org.w3c.dom.ls,org.xml.sax.ext,javax.xml.transform.sax\";version=2.11.0, \
-    org.apache.xerces.impl.dtd.models;uses:=org.apache.xerces.xni;version=2.11.0, \
-    org.apache.xerces.impl.xpath;uses:=\"org.apache.xerces.util,org.apache.xerces.xni\";version=2.11.0, \
-    org.apache.xerces.dom3.as;uses:=\"org.w3c.dom,org.w3c.dom.ls\";version=2.11.0, \
-    org.apache.xerces.impl.dv.xs;uses:=\"org.apache.xerces.xs.datatypes,javax.xml.datatype,org.apache.xerces.jaxp.datatype,org.apache.xerces.impl.dv,org.apache.xerces.util,org.apache.xerces.impl.dv.util,org.apache.xerces.xs,org.apache.xerces.impl.xs,org.apache.xerces.xni,javax.xml.namespace,org.apache.xerces.impl.xs.util,org.apache.xerces.impl.xpath.regex,org.w3c.dom\";version=2.11.0, \
-    org.apache.xerces.util;uses:=\"org.xml.sax.ext,org.apache.xerces.xni,org.xml.sax,org.w3c.dom.ls,org.apache.xerces.xni.grammars,org.apache.xerces.xni.parser,org.apache.xerces.dom,org.w3c.dom,org.apache.xerces.impl.xs.opti,org.apache.xerces.impl,javax.xml.namespace,javax.xml.stream,javax.xml.stream.events,javax.xml.parsers,org.apache.xml.resolver.readers,org.apache.xerces.jaxp,org.apache.xml.resolver\";version=2.11.0, \
-    org.apache.xerces.impl.xs.opti;uses:=\"org.w3c.dom,org.apache.xerces.xni.parser,org.apache.xerces.xni,org.apache.xerces.util,org.apache.xerces.impl.xs,org.apache.xerces.impl,org.apache.xerces.xni.grammars,org.apache.xerces.parsers,org.apache.xerces.impl.validation,org.apache.xerces.impl.dv,org.apache.xerces.impl.msg\";version=2.11.0, \
-    org.apache.xerces.impl.xs.identity;uses:=\"org.apache.xerces.xs,org.apache.xerces.impl.xs.util,org.apache.xerces.impl.xpath,org.apache.xerces.util,org.apache.xerces.xni,org.apache.xerces.impl.xs\";version=2.11.0, \
-    org.apache.xerces.jaxp;uses:=\"org.xml.sax.helpers,org.xml.sax,org.apache.xerces.util,org.apache.xerces.parsers,javax.xml.parsers,javax.xml.validation,org.apache.xerces.jaxp.validation,org.apache.xerces.xni.parser,org.w3c.dom,org.apache.xerces.impl.validation,org.apache.xerces.dom,org.apache.xerces.xni,org.apache.xerces.impl.xs,org.apache.xerces.impl,org.w3c.dom.ls,org.apache.xerces.impl.xs.opti,org.apache.xerces.xs,org.apache.xerces.xni.grammars\";version=2.11.0, \
-    org.apache.xerces.impl.dv;uses:=\"org.apache.xerces.util,org.apache.xerces.xs,org.apache.xerces.impl.xs.util\";version=2.11.0, \
-    org.apache.xerces.xs.datatypes;uses:=\"org.apache.xerces.xs,javax.xml.datatype,org.apache.xerces.xni,javax.xml.namespace\";version=2.11.0, \
-    org.apache.xerces.impl.msg;uses:=org.apache.xerces.util;version=2.11.0, \
-    org.apache.xerces.dom.events;uses:=\"org.w3c.dom.events,org.w3c.dom.views,org.w3c.dom\";version=2.11.0, \
-    org.apache.xerces.xni;uses:=org.apache.xerces.xni.parser;version=2.11.0, \
-    org.apache.xerces.impl.xs;uses:=\"org.apache.xerces.xs,org.apache.xerces.impl.dv,org.apache.xerces.impl.xs.util,org.apache.xerces.util,org.apache.xerces.xni.grammars,org.apache.xerces.parsers,org.apache.xerces.impl.dv.xs,org.apache.xerces.xni,org.apache.xerces.xni.parser,org.xml.sax,org.apache.xerces.impl.xs.identity,org.apache.xerces.xs.datatypes,org.w3c.dom,org.apache.xerces.impl.xs.opti,org.apache.xerces.impl.xs.traversers,org.w3c.dom.ls,org.apache.xerces.impl.xs.models,org.apache.xerces.dom,org.apache.xerces.impl,javax.xml.namespace,org.apache.xerces.impl.validation\";version=2.11.0, \
-    org.apache.xerces.impl;uses:=\"org.apache.xerces.xni.grammars,org.apache.xerces.xni,org.apache.xerces.xni.parser,org.apache.xerces.util,org.apache.xerces.impl.dtd,org.apache.xerces.impl.io,org.apache.xerces.impl.validation,org.xml.sax\";version=2.11.0, \
-    org.apache.xerces.stax.events;uses:=\"javax.xml.stream,javax.xml.stream.events,javax.xml.namespace,org.apache.xerces.util,org.apache.xerces.stax\";version=2.11.0, \
-    org.apache.xerces.impl.io;uses:=\"org.apache.xerces.util,org.apache.xerces.impl.msg\";version=2.11.0, \
-    org.apache.xerces.xinclude;uses:=\"org.apache.xerces.util,org.apache.xerces.xni,org.apache.xerces.xni.parser,org.apache.xerces.impl.io,org.apache.xerces.xpointer,org.apache.xerces.impl\";version=2.11.0, \
-    org.apache.xerces.jaxp.datatype;uses:=\"javax.xml.datatype,org.apache.xerces.util,javax.xml.namespace\";version=2.11.0, \
-    org.apache.xerces.parsers;uses:=\"org.apache.xerces.util,org.apache.xerces.xs,org.w3c.dom.ls,org.apache.xerces.impl.dv,org.apache.xerces.dom,org.apache.xerces.xni.parser,org.apache.xerces.xni,org.w3c.dom,org.xml.sax.ext,org.xml.sax,org.apache.xerces.xni.grammars,org.apache.xerces.impl.xs,org.apache.xerces.dom3.as,org.xml.sax.helpers,org.apache.xerces.impl,org.apache.xerces.impl.dtd,org.apache.xerces.impl.validation,org.apache.xerces.impl.msg,org.apache.xerces.xinclude,org.apache.xerces.xpointer\";version=2.11.0, \
-    org.apache.xerces.impl.dv.util;uses:=\"org.apache.xerces.xs,org.apache.xerces.xs.datatypes\";version=2.11.0, \
-    org.apache.xerces.xni.parser;uses:=org.apache.xerces.xni;version=2.11.0, \
-    org.apache.xerces.impl.xs.traversers;uses:=\"org.apache.xerces.util,org.apache.xerces.impl.xs.opti,org.apache.xerces.xni.parser,org.apache.xerces.xni,org.w3c.dom,org.xml.sax.helpers,org.xml.sax,javax.xml.stream,javax.xml.stream.events,javax.xml.namespace,org.apache.xerces.xs,org.apache.xerces.impl.validation,org.apache.xerces.impl.xs.util,org.apache.xerces.impl.dv,org.apache.xerces.impl.xs,org.apache.xerces.impl.xs.identity,org.apache.xerces.impl.xpath,org.apache.xerces.impl.dv.xs,org.apache.xerces.xni.grammars,org.apache.xerces.parsers,org.apache.xerces.xs.datatypes,org.apache.xerces.impl\";version=2.11.0, \
-    org.apache.xerces.impl.dv.dtd;uses:=\"org.apache.xerces.impl.dv,org.apache.xerces.util\";version=2.11.0, \
-    org.apache.xerces.xs;uses:=\"org.w3c.dom.ls,org.w3c.dom,org.apache.xerces.xs.datatypes\";version=2.11.0, \
-    org.apache.xerces.impl.validation;uses:=\"org.apache.xerces.util,org.apache.xerces.impl.dv,org.apache.xerces.xni\";version=2.11.0, \
-    org.apache.xerces.impl.dtd;uses:=\"org.apache.xerces.util,org.apache.xerces.xni,org.apache.xerces.impl.validation,org.apache.xerces.xni.grammars,org.apache.xerces.impl.dv,org.apache.xerces.impl.dtd.models,org.apache.xerces.xni.parser,org.apache.xerces.impl,org.apache.xerces.impl.msg\";version=2.11.0, \
-    org.apache.xerces.impl.xs.models;uses:=\"org.apache.xerces.xs,org.apache.xerces.impl.dtd.models,org.apache.xerces.impl.xs,org.apache.xerces.util,org.apache.xerces.xni.parser,org.apache.xerces.impl,org.apache.xerces.xni\";version=2.11.0, \
-    org.apache.xerces.impl.xpath.regex;uses:=org.apache.xerces.util;version=2.11.0, \
-    org.apache.xerces.stax;uses:=\"javax.xml.namespace,javax.xml.stream,javax.xml.stream.events,org.apache.xerces.stax.events\";version=2.11.0, \
-    org.apache.xerces.dom;uses:=\"org.apache.xerces.parsers,org.apache.xerces.dom3.as,org.w3c.dom,org.apache.xerces.impl.xs,org.apache.xerces.xni,org.apache.xerces.impl.dv.xs,org.apache.xerces.impl,org.apache.xerces.impl.dtd,org.apache.xerces.util,org.w3c.dom.ls,org.apache.xml.serialize,org.w3c.dom.events,org.apache.xerces.xni.grammars,org.apache.xerces.xni.parser,org.apache.xerces.impl.validation,org.apache.xerces.impl.dv,org.apache.xerces.impl.msg,org.apache.xerces.impl.xs.util,org.apache.xerces.xs,org.apache.xerces.dom.events,org.w3c.dom.traversal,org.w3c.dom.ranges\";version=2.11.0, \
-    org.apache.xml.serialize;uses:=\"org.apache.xerces.util,org.w3c.dom.ls,org.xml.sax.ext,org.apache.xerces.dom,org.w3c.dom,org.xml.sax,org.apache.xerces.impl,sun.io,org.w3c.dom.html,org.apache.xerces.xni,org.xml.sax.helpers\";version=2.11.0, \
-    javax.activation;version=1.1, \
-    javax.xml.soap;uses:=\"javax.activation,javax.xml.namespace,javax.xml.transform,javax.xml.transform.dom,org.w3c.dom\";version=1.3, \
+    org.apache.xml.serializer;uses:=\"org.xml.sax.helpers,org.xml.sax,org.apache.xml.serializer.utils,javax.xml.transform,org.w3c.dom.ls,org.w3c.dom,org.xml.sax.ext,org.apache.xml.serializer.dom3\";version=2.7.2, \
+    org.apache.xml.serializer.utils;uses:=\"org.w3c.dom,org.xml.sax,javax.xml.transform\";version=2.7.2, \
+    org.apache.xml.serializer.dom3;uses:=\"org.apache.xml.serializer,org.w3c.dom.ls,org.apache.xml.serializer.utils,org.w3c.dom,org.xml.sax,org.xml.sax.ext,org.xml.sax.helpers\";version=2.7.2, \
     java_cup.runtime;version=2.7.2, \
     org.apache.xalan;version=2.7.2, \
     org.apache.xalan.xslt;uses:=\"org.w3c.dom,org.xml.sax,org.apache.xalan,org.xml.sax.helpers,javax.xml.transform.sax,org.apache.xalan.res,org.apache.xml.utils,org.apache.xalan.transformer,javax.xml.transform.dom,javax.xml.parsers,javax.xml.transform,org.apache.xalan.trace,javax.xml.transform.stream\";version=2.7.2, \
@@ -192,7 +166,6 @@ org.osgi.framework.system.packages.extra = \
     org.apache.xml.dtm.ref;uses:=\"org.apache.xml.res,org.xml.sax.ext,org.xml.sax,org.apache.xml.dtm,org.w3c.dom,org.apache.xml.utils,javax.xml.transform,org.xml.sax.helpers,javax.xml.transform.sax,org.apache.xml.dtm.ref.sax2dtm,org.apache.xml.dtm.ref.dom2dtm,javax.xml.parsers,javax.xml.transform.dom,javax.xml.transform.stream,org.w3c.dom.traversal,org.apache.xpath,org.apache.xerces.parsers,org.apache.xml.serialize\";version=2.7.2, \
     org.apache.xml.dtm.ref.sax2dtm;uses:=\"org.apache.xml.dtm,org.xml.sax.ext,org.apache.xml.res,org.xml.sax,org.apache.xml.utils,org.apache.xml.dtm.ref,javax.xml.transform,org.apache.xml.serializer\";version=2.7.2, \
     org.apache.xml.res;version=2.7.2, \
-    org.apache.xml.serializer.utils;uses:=\"org.w3c.dom,org.xml.sax,javax.xml.transform\";version=2.7.2, \
     org.apache.xml.serializer;uses:=\"org.xml.sax.helpers,org.xml.sax,org.apache.xml.serializer.utils,javax.xml.transform,org.w3c.dom,org.w3c.dom.ls,org.xml.sax.ext,org.apache.xml.serializer.dom3\";version=2.7.2, \
     org.apache.xml.serializer.dom3;uses:=\"org.apache.xml.serializer,org.w3c.dom,org.w3c.dom.ls,org.xml.sax,org.apache.xml.serializer.utils,org.xml.sax.ext,org.xml.sax.helpers\";version=2.7.2, \
     org.apache.xml.utils.res;version=2.7.2, \
@@ -207,12 +180,49 @@ org.osgi.framework.system.packages.extra = \
     org.apache.xpath.functions;uses:=\"org.apache.xpath,org.apache.xpath.objects,javax.xml.transform,org.apache.xalan.res,org.apache.xml.dtm,org.apache.xpath.axes,org.apache.xpath.patterns,org.apache.xalan.templates,org.apache.xml.utils,org.apache.xalan.transformer,org.apache.xpath.res,org.apache.xpath.compiler,org.xml.sax\";version=2.7.2, \
     org.apache.xpath.jaxp;uses:=\"org.w3c.dom,javax.xml.namespace,org.apache.xpath.objects,org.apache.xpath,org.apache.xpath.functions,org.apache.xalan.res,org.apache.xml.utils,javax.xml.transform,javax.xml.xpath,javax.xml.parsers,org.w3c.dom.traversal,org.xml.sax\";version=2.7.2, \
     org.apache.xpath.axes;uses:=\"org.apache.xml.dtm,org.apache.xpath.compiler,javax.xml.transform,org.apache.xpath,org.apache.xalan.res,org.apache.xpath.patterns,org.apache.xml.utils,org.w3c.dom,org.w3c.dom.traversal,org.apache.xpath.objects,org.apache.xpath.operations,org.apache.xpath.functions,org.xml.sax\";version=2.7.2, \
-    org.apache.xml.serializer;uses:=\"org.xml.sax.helpers,org.xml.sax,org.apache.xml.serializer.utils,javax.xml.transform,org.w3c.dom.ls,org.w3c.dom,org.xml.sax.ext,org.apache.xml.serializer.dom3\";version=2.7.2, \
-    org.apache.xml.serializer.dom3;uses:=\"org.apache.xml.serializer,org.w3c.dom.ls,org.apache.xml.serializer.utils,org.w3c.dom,org.xml.sax,org.xml.sax.ext,org.xml.sax.helpers\";version=2.7.2, \
-    org.apache.karaf.diagnostic.core;uses:=org.osgi.framework;version=4.1.2, \
-    org.apache.karaf.diagnostic.core.common;uses:=org.apache.karaf.diagnostic.core;version=4.1.2, \
-    org.apache.karaf.jaas.boot.principal;uses:=javax.security.auth;version=4.1.2, \
-    org.apache.karaf.jaas.boot;uses:=\"javax.security.auth,javax.security.auth.callback,javax.security.auth.login,javax.security.auth.spi,org.osgi.framework\";version=4.1.2
+    org.apache.html.dom;uses:=\"org.w3c.dom.html,org.apache.xerces.dom,org.w3c.dom,org.xml.sax\";version=2.11.0, \
+    org.apache.wml.dom;uses:=\"org.apache.wml,org.apache.xerces.dom,org.w3c.dom\";version=2.11.0, \
+    org.apache.wml;uses:=org.w3c.dom;version=2.11.0, \
+    org.apache.xerces.xpointer;uses:=\"org.apache.xerces.util,org.apache.xerces.xni,org.apache.xerces.xni.parser,org.apache.xerces.impl,org.apache.xerces.xs,org.apache.xerces.impl.dv,org.apache.xerces.xinclude\";version=2.11.0, \
+    org.apache.xerces.xni.grammars;uses:=\"org.apache.xerces.xni,org.apache.xerces.xni.parser,org.apache.xerces.xs\";version=2.11.0, \
+    org.apache.xerces.impl.xs.util;uses:=\"org.apache.xerces.xs,org.w3c.dom.ls,org.apache.xerces.xs.datatypes,org.apache.xerces.xni,org.apache.xerces.util,org.apache.xerces.xni.grammars,org.apache.xerces.impl.xs,org.apache.xerces.xni.parser,javax.xml.namespace\";version=2.11.0, \
+    org.apache.xerces.jaxp.validation;uses:=\"org.apache.xerces.xni.grammars,javax.xml.validation,org.apache.xerces.xni,javax.xml.transform.dom,org.w3c.dom,org.apache.xerces.xs,org.apache.xerces.impl.dv,org.apache.xerces.dom,org.apache.xerces.xni.parser,org.apache.xerces.util,org.apache.xerces.impl.xs.util,javax.xml.parsers,org.xml.sax,org.apache.xerces.impl.validation,javax.xml.transform,org.apache.xerces.impl.xs,org.apache.xerces.impl,javax.xml.stream,javax.xml.transform.stax,javax.xml.stream.events,javax.xml.namespace,org.apache.xerces.parsers,org.apache.xml.serialize,javax.xml.transform.stream,org.apache.xerces.impl.msg,org.w3c.dom.ls,org.xml.sax.ext,javax.xml.transform.sax\";version=2.11.0, \
+    org.apache.xerces.impl.dtd.models;uses:=org.apache.xerces.xni;version=2.11.0, \
+    org.apache.xerces.impl.xpath;uses:=\"org.apache.xerces.util,org.apache.xerces.xni\";version=2.11.0, \
+    org.apache.xerces.dom3.as;uses:=\"org.w3c.dom,org.w3c.dom.ls\";version=2.11.0, \
+    org.apache.xerces.impl.dv.xs;uses:=\"org.apache.xerces.xs.datatypes,javax.xml.datatype,org.apache.xerces.jaxp.datatype,org.apache.xerces.impl.dv,org.apache.xerces.util,org.apache.xerces.impl.dv.util,org.apache.xerces.xs,org.apache.xerces.impl.xs,org.apache.xerces.xni,javax.xml.namespace,org.apache.xerces.impl.xs.util,org.apache.xerces.impl.xpath.regex,org.w3c.dom\";version=2.11.0, \
+    org.apache.xerces.util;uses:=\"org.xml.sax.ext,org.apache.xerces.xni,org.xml.sax,org.w3c.dom.ls,org.apache.xerces.xni.grammars,org.apache.xerces.xni.parser,org.apache.xerces.dom,org.w3c.dom,org.apache.xerces.impl.xs.opti,org.apache.xerces.impl,javax.xml.namespace,javax.xml.stream,javax.xml.stream.events,javax.xml.parsers,org.apache.xml.resolver.readers,org.apache.xerces.jaxp,org.apache.xml.resolver\";version=2.11.0, \
+    org.apache.xerces.impl.xs.opti;uses:=\"org.w3c.dom,org.apache.xerces.xni.parser,org.apache.xerces.xni,org.apache.xerces.util,org.apache.xerces.impl.xs,org.apache.xerces.impl,org.apache.xerces.xni.grammars,org.apache.xerces.parsers,org.apache.xerces.impl.validation,org.apache.xerces.impl.dv,org.apache.xerces.impl.msg\";version=2.11.0, \
+    org.apache.xerces.impl.xs.identity;uses:=\"org.apache.xerces.xs,org.apache.xerces.impl.xs.util,org.apache.xerces.impl.xpath,org.apache.xerces.util,org.apache.xerces.xni,org.apache.xerces.impl.xs\";version=2.11.0, \
+    org.apache.xerces.jaxp;uses:=\"org.xml.sax.helpers,org.xml.sax,org.apache.xerces.util,org.apache.xerces.parsers,javax.xml.parsers,javax.xml.validation,org.apache.xerces.jaxp.validation,org.apache.xerces.xni.parser,org.w3c.dom,org.apache.xerces.impl.validation,org.apache.xerces.dom,org.apache.xerces.xni,org.apache.xerces.impl.xs,org.apache.xerces.impl,org.w3c.dom.ls,org.apache.xerces.impl.xs.opti,org.apache.xerces.xs,org.apache.xerces.xni.grammars\";version=2.11.0, \
+    org.apache.xerces.impl.dv;uses:=\"org.apache.xerces.util,org.apache.xerces.xs,org.apache.xerces.impl.xs.util\";version=2.11.0, \
+    org.apache.xerces.xs.datatypes;uses:=\"org.apache.xerces.xs,javax.xml.datatype,org.apache.xerces.xni,javax.xml.namespace\";version=2.11.0, \
+    org.apache.xerces.impl.msg;uses:=org.apache.xerces.util;version=2.11.0, \
+    org.apache.xerces.dom.events;uses:=\"org.w3c.dom.events,org.w3c.dom.views,org.w3c.dom\";version=2.11.0, \
+    org.apache.xerces.xni;uses:=org.apache.xerces.xni.parser;version=2.11.0, \
+    org.apache.xerces.impl.xs;uses:=\"org.apache.xerces.xs,org.apache.xerces.impl.dv,org.apache.xerces.impl.xs.util,org.apache.xerces.util,org.apache.xerces.xni.grammars,org.apache.xerces.parsers,org.apache.xerces.impl.dv.xs,org.apache.xerces.xni,org.apache.xerces.xni.parser,org.xml.sax,org.apache.xerces.impl.xs.identity,org.apache.xerces.xs.datatypes,org.w3c.dom,org.apache.xerces.impl.xs.opti,org.apache.xerces.impl.xs.traversers,org.w3c.dom.ls,org.apache.xerces.impl.xs.models,org.apache.xerces.dom,org.apache.xerces.impl,javax.xml.namespace,org.apache.xerces.impl.validation\";version=2.11.0, \
+    org.apache.xerces.impl;uses:=\"org.apache.xerces.xni.grammars,org.apache.xerces.xni,org.apache.xerces.xni.parser,org.apache.xerces.util,org.apache.xerces.impl.dtd,org.apache.xerces.impl.io,org.apache.xerces.impl.validation,org.xml.sax\";version=2.11.0, \
+    org.apache.xerces.stax.events;uses:=\"javax.xml.stream,javax.xml.stream.events,javax.xml.namespace,org.apache.xerces.util,org.apache.xerces.stax\";version=2.11.0, \
+    org.apache.xerces.impl.io;uses:=\"org.apache.xerces.util,org.apache.xerces.impl.msg\";version=2.11.0, \
+    org.apache.xerces.xinclude;uses:=\"org.apache.xerces.util,org.apache.xerces.xni,org.apache.xerces.xni.parser,org.apache.xerces.impl.io,org.apache.xerces.xpointer,org.apache.xerces.impl\";version=2.11.0, \
+    org.apache.xerces.jaxp.datatype;uses:=\"javax.xml.datatype,org.apache.xerces.util,javax.xml.namespace\";version=2.11.0, \
+    org.apache.xerces.parsers;uses:=\"org.apache.xerces.util,org.apache.xerces.xs,org.w3c.dom.ls,org.apache.xerces.impl.dv,org.apache.xerces.dom,org.apache.xerces.xni.parser,org.apache.xerces.xni,org.w3c.dom,org.xml.sax.ext,org.xml.sax,org.apache.xerces.xni.grammars,org.apache.xerces.impl.xs,org.apache.xerces.dom3.as,org.xml.sax.helpers,org.apache.xerces.impl,org.apache.xerces.impl.dtd,org.apache.xerces.impl.validation,org.apache.xerces.impl.msg,org.apache.xerces.xinclude,org.apache.xerces.xpointer\";version=2.11.0, \
+    org.apache.xerces.impl.dv.util;uses:=\"org.apache.xerces.xs,org.apache.xerces.xs.datatypes\";version=2.11.0, \
+    org.apache.xerces.xni.parser;uses:=org.apache.xerces.xni;version=2.11.0, \
+    org.apache.xerces.impl.xs.traversers;uses:=\"org.apache.xerces.util,org.apache.xerces.impl.xs.opti,org.apache.xerces.xni.parser,org.apache.xerces.xni,org.w3c.dom,org.xml.sax.helpers,org.xml.sax,javax.xml.stream,javax.xml.stream.events,javax.xml.namespace,org.apache.xerces.xs,org.apache.xerces.impl.validation,org.apache.xerces.impl.xs.util,org.apache.xerces.impl.dv,org.apache.xerces.impl.xs,org.apache.xerces.impl.xs.identity,org.apache.xerces.impl.xpath,org.apache.xerces.impl.dv.xs,org.apache.xerces.xni.grammars,org.apache.xerces.parsers,org.apache.xerces.xs.datatypes,org.apache.xerces.impl\";version=2.11.0, \
+    org.apache.xerces.impl.dv.dtd;uses:=\"org.apache.xerces.impl.dv,org.apache.xerces.util\";version=2.11.0, \
+    org.apache.xerces.xs;uses:=\"org.w3c.dom.ls,org.w3c.dom,org.apache.xerces.xs.datatypes\";version=2.11.0, \
+    org.apache.xerces.impl.validation;uses:=\"org.apache.xerces.util,org.apache.xerces.impl.dv,org.apache.xerces.xni\";version=2.11.0, \
+    org.apache.xerces.impl.dtd;uses:=\"org.apache.xerces.util,org.apache.xerces.xni,org.apache.xerces.impl.validation,org.apache.xerces.xni.grammars,org.apache.xerces.impl.dv,org.apache.xerces.impl.dtd.models,org.apache.xerces.xni.parser,org.apache.xerces.impl,org.apache.xerces.impl.msg\";version=2.11.0, \
+    org.apache.xerces.impl.xs.models;uses:=\"org.apache.xerces.xs,org.apache.xerces.impl.dtd.models,org.apache.xerces.impl.xs,org.apache.xerces.util,org.apache.xerces.xni.parser,org.apache.xerces.impl,org.apache.xerces.xni\";version=2.11.0, \
+    org.apache.xerces.impl.xpath.regex;uses:=org.apache.xerces.util;version=2.11.0, \
+    org.apache.xerces.stax;uses:=\"javax.xml.namespace,javax.xml.stream,javax.xml.stream.events,org.apache.xerces.stax.events\";version=2.11.0, \
+    org.apache.xerces.dom;uses:=\"org.apache.xerces.parsers,org.apache.xerces.dom3.as,org.w3c.dom,org.apache.xerces.impl.xs,org.apache.xerces.xni,org.apache.xerces.impl.dv.xs,org.apache.xerces.impl,org.apache.xerces.impl.dtd,org.apache.xerces.util,org.w3c.dom.ls,org.apache.xml.serialize,org.w3c.dom.events,org.apache.xerces.xni.grammars,org.apache.xerces.xni.parser,org.apache.xerces.impl.validation,org.apache.xerces.impl.dv,org.apache.xerces.impl.msg,org.apache.xerces.impl.xs.util,org.apache.xerces.xs,org.apache.xerces.dom.events,org.w3c.dom.traversal,org.w3c.dom.ranges\";version=2.11.0, \
+    org.apache.xml.serialize;uses:=\"org.apache.xerces.util,org.w3c.dom.ls,org.xml.sax.ext,org.apache.xerces.dom,org.w3c.dom,org.xml.sax,org.apache.xerces.impl,sun.io,org.w3c.dom.html,org.apache.xerces.xni,org.xml.sax.helpers\";version=2.11.0, \
+    org.apache.karaf.diagnostic.core;uses:=org.osgi.framework;version=4.1.5, \
+    org.apache.karaf.diagnostic.core.common;uses:=org.apache.karaf.diagnostic.core;version=4.1.5, \
+    org.apache.karaf.jaas.boot.principal;uses:=javax.security.auth;version=4.1.5, \
+    org.apache.karaf.jaas.boot;uses:=\"javax.security.auth,javax.security.auth.callback,javax.security.auth.login,javax.security.auth.spi,org.osgi.framework\";version=4.1.5
 
 org.osgi.framework.system.capabilities= \
  ${eecap-${java.specification.version}}, \
diff --git a/container/karaf/src/main/filtered-resources/etc/startup.properties b/container/karaf/src/main/filtered-resources/etc/startup.properties
index dfdf7be9e11..6c7e3e1694d 100644
--- a/container/karaf/src/main/filtered-resources/etc/startup.properties
+++ b/container/karaf/src/main/filtered-resources/etc/startup.properties
@@ -1,13 +1,14 @@
 # Bundles to be started on startup, with startlevel
-mvn\:org.apache.karaf.features/org.apache.karaf.features.extension/4.1.2 = 1
-mvn\:org.apache.felix/org.apache.felix.metatype/1.1.2 = 5
-mvn\:org.apache.karaf.services/org.apache.karaf.services.eventadmin/4.1.2 = 5
-mvn\:org.ops4j.pax.url/pax-url-aether/2.5.2 = 5
+mvn\:org.apache.karaf.features/org.apache.karaf.features.extension/4.1.5 = 1
+mvn\:org.apache.felix/org.apache.felix.metatype/1.1.6 = 5
+mvn\:org.apache.karaf.services/org.apache.karaf.services.eventadmin/4.1.5 = 5
+mvn\:org.ops4j.pax.url/pax-url-aether/2.5.4 = 5
+mvn\:org.fusesource.jansi/jansi/1.17 = 8
 mvn\:org.ops4j.pax.logging/pax-logging-api/1.10.1 = 8
 mvn\:org.ops4j.pax.logging/pax-logging-log4j2/1.10.1 = 8
-mvn\:org.apache.felix/org.apache.felix.configadmin/1.8.14 = 10
-mvn\:org.apache.felix/org.apache.felix.fileinstall/3.6.0 = 11
-mvn\:org.apache.karaf.features/org.apache.karaf.features.core/4.1.2 = 15
+mvn\:org.apache.felix/org.apache.felix.configadmin/1.8.16 = 10
+mvn\:org.apache.felix/org.apache.felix.fileinstall/3.6.4 = 11
+mvn\:org.apache.karaf.features/org.apache.karaf.features.core/4.1.5 = 15
 
 # OPENNMS: Add JNA bundles to prevent jline from refreshing (KARAF-5251)
 mvn\:net.java.dev.jna/jna/${jnaVersion} = 5
diff --git a/container/karaf/src/main/filtered-resources/etc/system.properties b/container/karaf/src/main/filtered-resources/etc/system.properties
index 8432fb19b9d..803e01270ba 100644
--- a/container/karaf/src/main/filtered-resources/etc/system.properties
+++ b/container/karaf/src/main/filtered-resources/etc/system.properties
@@ -55,7 +55,7 @@ karaf.default.repository = system
 # additional commands.
 # Do not use absolute paths to avoid problems on windows.
 #
-karaf.shell.init.script = etc/shell.init.script,etc/scripts/*.script
+# karaf.shell.init.script = etc/shell.init.script,etc/scripts/*.script
 
 #
 # Sets the maximum size of the shell command history. If not set,
diff --git a/core/lib/src/main/java/org/opennms/core/utils/DBTools.java b/core/lib/src/main/java/org/opennms/core/utils/DBTools.java
index 2bb42665915..ec3d456b4bb 100644
--- a/core/lib/src/main/java/org/opennms/core/utils/DBTools.java
+++ b/core/lib/src/main/java/org/opennms/core/utils/DBTools.java
@@ -46,7 +46,7 @@ public abstract class DBTools {
      * 
      * @see #constructUrl
      */
-    private static final String JDBC_HOST = "localhost:5432";
+    private static final String OPENNMS_JDBC_HOSTNAME = "OPENNMS_JDBC_HOSTNAME";
 
     /**
      * Minimal port range
@@ -82,12 +82,12 @@ public abstract class DBTools {
     public static final String DEFAULT_DATABASE_PASSWORD = "";
 
     /**
-     * Default vendor protocol, like jdbc:sybase:Tds:
+     * Default vendor protocol, like jdbc:postgresql
      */
-    public static final String DEFAULT_URL = "jdbc:postgresql://" + JDBC_HOST + "/opennms";
+    public static final String DEFAULT_URL = "jdbc:postgresql://" + OPENNMS_JDBC_HOSTNAME + "/opennms";
 
     // Pattern for the JDBC_HOST
-    private static final Pattern _pattern = Pattern.compile(JDBC_HOST);
+    private static final Pattern _pattern = Pattern.compile(OPENNMS_JDBC_HOSTNAME);
 
     /**
      * Constructs a JDBC url given a set of fragments. The resulting Url will
@@ -97,13 +97,13 @@ public abstract class DBTools {
      * @param hostname_
      *            The hostname where the database server is
      * @param url_
-     *            (for example jdbc:sybase:Tds:@{link #JDBC_HOST
-     *            JDBC_HOST}:4100/tempdb). The JDBC_HOST is replaced by the real
+     *            (for example jdbc:sybase:Tds:@{link #OPENNMS_JDBC_HOSTNAME
+     *            OPENNMS_JDBC_HOSTNAME}:4100/tempdb). The OPENNMS_JDBC_HOSTNAME is replaced by the real
      *            hostname
      * @throws java.lang.NullPointerException
      *             If one of the arguments is null
      * @throws java.lang.IllegalArgumentException
-     *             If the JDBC_HOST is not part of the JDBC url
+     *             If the OPENNMS_JDBC_HOSTNAME is not part of the JDBC url
      * @return a {@link java.lang.String} object.
      */
     public static String constructUrl(String url_, String hostname_) throws IllegalArgumentException, NullPointerException {
diff --git a/core/lib/src/test/java/org/opennms/core/utils/DBToolsTest.java b/core/lib/src/test/java/org/opennms/core/utils/DBToolsTest.java
new file mode 100644
index 00000000000..c2c134d212f
--- /dev/null
+++ b/core/lib/src/test/java/org/opennms/core/utils/DBToolsTest.java
@@ -0,0 +1,46 @@
+/*******************************************************************************
+ * This file is part of OpenNMS(R).
+ *
+ * Copyright (C) 2007-2018 The OpenNMS Group, Inc.
+ * OpenNMS(R) is Copyright (C) 1999-2018 The OpenNMS Group, Inc.
+ *
+ * OpenNMS(R) is a registered trademark of The OpenNMS Group, Inc.
+ *
+ * OpenNMS(R) is free software: you can redistribute it and/or modify
+ * it under the terms of the GNU Affero General Public License as published
+ * by the Free Software Foundation, either version 3 of the License,
+ * or (at your option) any later version.
+ *
+ * OpenNMS(R) is distributed in the hope that it will be useful,
+ * but WITHOUT ANY WARRANTY; without even the implied warranty of
+ * MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
+ * GNU Affero General Public License for more details.
+ *
+ * You should have received a copy of the GNU Affero General Public License
+ * along with OpenNMS(R).  If not, see:
+ *      http://www.gnu.org/licenses/
+ *
+ * For more information contact:
+ *     OpenNMS(R) Licensing <license@opennms.org>
+ *     http://www.opennms.org/
+ *     http://www.opennms.com/
+ *******************************************************************************/
+
+package org.opennms.core.utils;
+
+import static org.junit.Assert.assertEquals;
+
+import org.junit.Test;
+
+public class DBToolsTest {
+
+    @Test
+    public void verifyHostNameMatching() {
+        // configs use this pattern for JDBC URL
+        final String URL = "jdbc:postgresql://OPENNMS_JDBC_HOSTNAME:5432/opennms";
+        String resultingUrl = DBTools.constructUrl(URL, "localhost");
+        assertEquals("jdbc:postgresql://localhost:5432/opennms", resultingUrl);
+
+    }
+
+}
diff --git a/core/schema/src/main/liquibase/21.0.0/changelog.xml b/core/schema/src/main/liquibase/21.0.0/changelog.xml
index 4e4e97ffd41..25f94c90151 100644
--- a/core/schema/src/main/liquibase/21.0.0/changelog.xml
+++ b/core/schema/src/main/liquibase/21.0.0/changelog.xml
@@ -111,5 +111,28 @@
     <dropColumn tableName="snmpinterface" columnName="snmpipadentnetmask" />
   </changeSet>
 
+  <changeSet author="jwhite" id="21.0.0-alarm-correlation">
+    <addColumn tableName="alarms">
+      <column name="cause" type="boolean" defaultValue="false">
+        <constraints nullable="false"/>
+      </column>
+    </addColumn>
+    <addColumn tableName="alarms">
+      <column name="impacted" type="boolean" defaultValue="false">
+        <constraints nullable="false"/>
+      </column>
+    </addColumn>
+    <createTable tableName="impacted_alarms">
+      <column name="cause_alarmid" type="integer">
+        <constraints nullable="false"/>
+      </column>
+      <column name="impacted_alarmid" type="integer">
+        <constraints nullable="false"/>
+      </column>
+    </createTable>
+    <addUniqueConstraint tableName="impacted_alarms" columnNames="cause_alarmid, impacted_alarmid"/>
+    <addForeignKeyConstraint constraintName="fk_impacted_alarms_cause_alarm_id" baseTableName="impacted_alarms" baseColumnNames="cause_alarmid" referencedTableName="alarms" referencedColumnNames="alarmid"/>
+    <addForeignKeyConstraint constraintName="fk_impacted_alarms_impacted_alarmid" baseTableName="impacted_alarms" baseColumnNames="impacted_alarmid" referencedTableName="alarms" referencedColumnNames="alarmid"/>
+  </changeSet>
 
 </databaseChangeLog>
diff --git a/core/schema/src/main/liquibase/changelog.xml b/core/schema/src/main/liquibase/changelog.xml
index d15565703aa..5219148b95b 100644
--- a/core/schema/src/main/liquibase/changelog.xml
+++ b/core/schema/src/main/liquibase/changelog.xml
@@ -81,6 +81,7 @@
 	<include file="19.1.1/changelog.xml"/>
 	<include file="foundation-2017/changelog.xml"/>
 	<include file="21.0.0/changelog.xml"/>
+	<include file="correlation_poc/changelog.xml"/>
 
 	<include file="stored-procedures/getManagePercentAvailIntfWindow.xml" />
 	<include file="stored-procedures/getManagePercentAvailNodeWindow.xml" />
diff --git a/core/schema/src/main/liquibase/correlation_poc/changelog.xml b/core/schema/src/main/liquibase/correlation_poc/changelog.xml
new file mode 100644
index 00000000000..713fb9e0249
--- /dev/null
+++ b/core/schema/src/main/liquibase/correlation_poc/changelog.xml
@@ -0,0 +1,57 @@
+<?xml version="1.0" encoding="UTF-8"?>
+<databaseChangeLog
+  xmlns="http://www.liquibase.org/xml/ns/dbchangelog"
+  xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"
+  xmlns:ext="http://www.liquibase.org/xml/ns/dbchangelog-ext"
+  xsi:schemaLocation="
+    http://www.liquibase.org/xml/ns/dbchangelog http://www.liquibase.org/xml/ns/dbchangelog/dbchangelog-2.0.xsd
+    http://www.liquibase.org/xml/ns/dbchangelog-ext http://www.liquibase.org/xml/ns/dbchangelog/dbchangelog-ext.xsd
+  ">
+
+  <changeSet author="smith" id="22.0.0-correlation_poc_impacts_fk">
+    <validCheckSum>ANY</validCheckSum>
+
+    <dropForeignKeyConstraint baseTableName="impacted_alarms" constraintName="fk_impacted_alarms_cause_alarm_id" />
+    <addForeignKeyConstraint constraintName="fk_impacted_alarms_cause_alarm_id" onDelete="CASCADE" 
+      baseTableName="impacted_alarms" baseColumnNames="cause_alarmid" referencedTableName="alarms" referencedColumnNames="alarmid"/>
+
+    <dropForeignKeyConstraint baseTableName="impacted_alarms" constraintName="fk_impacted_alarms_impacted_alarmid" />
+    <addForeignKeyConstraint constraintName="fk_impacted_alarms_impacted_alarmid" onDelete="CASCADE" 
+      baseTableName="impacted_alarms" baseColumnNames="impacted_alarmid" referencedTableName="alarms" referencedColumnNames="alarmid"/>
+
+  </changeSet>
+
+  <changeSet author="smith" id="22.0.0-correlation_poc_inventory">
+    <validCheckSum>ANY</validCheckSum>
+
+    <createTable tableName="hwentityalias">
+      <column name="id" type="integer">
+        <constraints primaryKey="true" nullable="false" />
+      </column>
+      <column name="hwentityid" type="integer">
+        <constraints nullable="false" />
+      </column>
+      <column name="index" type="integer">
+        <constraints nullable="false" />
+      </column>
+      <column name="oid" type="varchar(256)">
+        <constraints nullable="false" />
+      </column>
+    </createTable>
+
+    <ext:addAutoIncrement tableName="hwentityalias" columnName="id" sequenceName="opennmsnxtid" />
+    <addForeignKeyConstraint constraintName="fk_hwentity_hwentityalias" onDelete="CASCADE" 
+      baseTableName="hwentityalias" baseColumnNames="hwentityid" 
+      referencedTableName="hwentity" referencedColumnNames="id" />
+    <createIndex tableName="hwentityalias" indexName="hwentityalias_unique_idx" unique="true">
+      <column name="hwentityid" />
+      <column name="index" />
+    </createIndex>
+
+    <rollback>
+      <dropTable tableName="hwentityalias" />
+    </rollback>
+  </changeSet>
+
+</databaseChangeLog>
+
diff --git a/core/test-api/kafka/pom.xml b/core/test-api/kafka/pom.xml
index 1b5ebed9748..231db05585a 100644
--- a/core/test-api/kafka/pom.xml
+++ b/core/test-api/kafka/pom.xml
@@ -46,6 +46,21 @@
       <groupId>commons-io</groupId>
       <artifactId>commons-io</artifactId>
     </dependency>
+    <dependency>
+      <groupId>org.apache.servicemix.bundles</groupId>
+      <artifactId>org.apache.servicemix.bundles.kafka-clients</artifactId>
+      <version>0.10.1.1_1</version>
+      <exclusions>
+        <exclusion>
+          <artifactId>log4j</artifactId>
+          <groupId>log4j</groupId>
+        </exclusion>
+        <exclusion>
+          <artifactId>slf4j-log4j12</artifactId>
+          <groupId>org.slf4j</groupId>
+        </exclusion>
+      </exclusions>
+    </dependency>
     <dependency>
       <groupId>org.apache.servicemix.bundles</groupId>
       <artifactId>org.apache.servicemix.bundles.kafka_2.10</artifactId>
diff --git a/core/test-api/kafka/src/main/java/org/opennms/core/test/kafka/JUnitKafkaServer.java b/core/test-api/kafka/src/main/java/org/opennms/core/test/kafka/JUnitKafkaServer.java
index 88e8be80d55..5cc8ce6ca15 100644
--- a/core/test-api/kafka/src/main/java/org/opennms/core/test/kafka/JUnitKafkaServer.java
+++ b/core/test-api/kafka/src/main/java/org/opennms/core/test/kafka/JUnitKafkaServer.java
@@ -40,6 +40,7 @@ import java.net.ServerSocket;
 import java.net.UnknownHostException;
 import java.util.ArrayList;
 import java.util.List;
+import java.util.Objects;
 import java.util.Properties;
 import java.util.concurrent.atomic.AtomicInteger;
 import org.I0Itec.zkclient.ZkClient;
@@ -48,6 +49,7 @@ import org.apache.commons.io.FileUtils;
 import org.apache.curator.test.TestingServer;
 import org.junit.After;
 import org.junit.rules.ExternalResource;
+import org.junit.rules.TemporaryFolder;
 import org.slf4j.Logger;
 import org.slf4j.LoggerFactory;
 
@@ -74,33 +76,52 @@ public class JUnitKafkaServer extends ExternalResource {
 
     private String localhost = "localhost";
     private AtomicInteger kafkaPort = new AtomicInteger(9092);
+    private String kafkaLogDir;
+    private TemporaryFolder temporaryFolder;
 
     private KafkaConfig kafkaConfig;
     private KafkaServer kafkaServer;
     private TestingServer zkServer;
 
+    public JUnitKafkaServer() {
+        this("target/kafka-log");
+    }
+
+    public JUnitKafkaServer(String kafkaLogDir) {
+        this.kafkaLogDir = Objects.requireNonNull(kafkaLogDir);
+    }
+
+    public JUnitKafkaServer(TemporaryFolder temporaryFolder) {
+        this.temporaryFolder = temporaryFolder;
+    }
+
     @Override
     public void before() throws Exception {
-        zkServer = new TestingServer();
+        File zkTempDirectory = null;
+        if (temporaryFolder != null) {
+            kafkaLogDir = temporaryFolder.newFolder("kafka-log").getAbsolutePath();
+            zkTempDirectory = temporaryFolder.newFolder("zookeeper");
+        } else {
+            FileUtils.deleteDirectory(new File(kafkaLogDir));
+        }
+
+        zkServer = new TestingServer(-1, zkTempDirectory, true);
         // Start ZooKeeper, this method will block until the service has started
         zkServer.start();
 
         getAvailablePort(kafkaPort, 9192);
-
-        // Delete any existing Kafka log directory
-        FileUtils.deleteDirectory(new File("target/kafka-log"));
-
         localhost = getLocalhost();
 
         final Properties properties = new Properties();
         properties.put("broker.id", "1");
         properties.put("auto.create.topics.enable", "true");
-        properties.put("num.partitions", "100");
+        properties.put("num.partitions", "10");
         properties.put("enable.zookeeper", "true");
         properties.put("host.name", localhost);
-        properties.put("log.dir", "target/kafka-log");
+        properties.put("log.dir", kafkaLogDir);
         properties.put("port", String.valueOf(kafkaPort.get()));
         properties.put("zookeeper.connect", zkServer.getConnectString());
+        properties.put("offsets.topic.replication.factor", (short)1);
         properties.put("listeners", "PLAINTEXT://" + "localhost:" + String.valueOf(kafkaPort.get()));
 
         System.err.println("Kafka server properties: " + properties);
diff --git a/core/test-api/kafka/src/main/java/org/opennms/core/test/kafka/SystemTime.java b/core/test-api/kafka/src/main/java/org/opennms/core/test/kafka/SystemTime.java
index 0189a1cd75b..4bfa67a7fb6 100644
--- a/core/test-api/kafka/src/main/java/org/opennms/core/test/kafka/SystemTime.java
+++ b/core/test-api/kafka/src/main/java/org/opennms/core/test/kafka/SystemTime.java
@@ -32,6 +32,7 @@ import java.util.concurrent.TimeUnit;
 
 import kafka.utils.Time;
 
+
 public class SystemTime implements Time {
     @Override
     public long milliseconds() {
diff --git a/core/test-api/karaf/src/main/java/org/opennms/core/test/karaf/KarafTestCase.java b/core/test-api/karaf/src/main/java/org/opennms/core/test/karaf/KarafTestCase.java
index ba904404550..2e7b998a207 100644
--- a/core/test-api/karaf/src/main/java/org/opennms/core/test/karaf/KarafTestCase.java
+++ b/core/test-api/karaf/src/main/java/org/opennms/core/test/karaf/KarafTestCase.java
@@ -95,7 +95,7 @@ public abstract class KarafTestCase {
     public static final String MAX_SSH_PORT = "8888";
 
     protected static String getKarafVersion() {
-        final String karafVersion = System.getProperty("karafVersion", "4.1.2");
+        final String karafVersion = System.getProperty("karafVersion", "4.1.5");
         Objects.requireNonNull(karafVersion, "Please define a system property 'karafVersion'.");
         return karafVersion;
     }
@@ -262,8 +262,8 @@ public abstract class KarafTestCase {
             editConfigurationFilePut("etc/org.apache.karaf.shell.cfg", "sshPort", sshPort),
 
             // Work around bug KARAF-5251
-            editConfigurationFilePut("etc/startup.properties", "mvn:net.java.dev.jna/jna/4.4.0", "5"),
-            editConfigurationFilePut("etc/startup.properties", "mvn:net.java.dev.jna/jna-platform/4.4.0", "5"),
+            editConfigurationFilePut("etc/startup.properties", "mvn:net.java.dev.jna/jna/4.5.0", "5"),
+            editConfigurationFilePut("etc/startup.properties", "mvn:net.java.dev.jna/jna-platform/4.5.0", "5"),
 
             // This port is already being allocated according to an org.ops4j.net.FreePort call
             //editConfigurationFilePut("etc/system.properties", "org.ops4j.pax.exam.rbc.rmi.port", paxExamRmiRegistryPort),
diff --git a/core/test-api/karaf/src/test/java/org/opennms/core/test/karaf/test/FeatureInstallKarafIT.java b/core/test-api/karaf/src/test/java/org/opennms/core/test/karaf/test/FeatureInstallKarafIT.java
index 637a80fe1b4..2b475c40630 100644
--- a/core/test-api/karaf/src/test/java/org/opennms/core/test/karaf/test/FeatureInstallKarafIT.java
+++ b/core/test-api/karaf/src/test/java/org/opennms/core/test/karaf/test/FeatureInstallKarafIT.java
@@ -103,7 +103,7 @@ public class FeatureInstallKarafIT extends KarafTestCase {
      */
     @Test
     public void testInstallAllSpringFeatures() {
-        addFeaturesUrl(maven().groupId("org.apache.karaf.features").artifactId("spring-legacy").version("4.1.2").type("xml").classifier("features").getURL());
+        addFeaturesUrl(maven().groupId("org.apache.karaf.features").artifactId("spring-legacy").version("4.1.5").type("xml").classifier("features").getURL());
 
         installFeature("spring", "4.2.9.RELEASE_1");
         installFeature("spring-aspects", "4.2.9.RELEASE_1");
diff --git a/core/web-assets/package.json b/core/web-assets/package.json
index ac9a6afafd6..c47a48ce355 100644
--- a/core/web-assets/package.json
+++ b/core/web-assets/package.json
@@ -12,9 +12,9 @@
         "angular-mocks": "1.5.11",
         "assets-webpack-plugin": "^3.5.1",
         "babel-cli": "^6.26.0",
-        "babel-eslint": "^8.2.1",
-        "babel-jest": "^22.1.0",
-        "babel-loader": "^7.1.2",
+        "babel-eslint": "^8.2.2",
+        "babel-jest": "^22.4.3",
+        "babel-loader": "^7.1.4",
         "babel-plugin-angularjs-annotate": "^0.8.2",
         "babel-plugin-resolver": "^1.1.0",
         "babel-plugin-syntax-async-functions": "^6.13.0",
@@ -30,40 +30,40 @@
         "babel-preset-es2015-nostrict": "^6.6.2",
         "babel-preset-latest": "^6.24.1",
         "cache-loader": "^1.2.2",
-        "copy-webpack-plugin": "^4.3.1",
-        "css-loader": "^0.28.8",
-        "eslint": "^3.2.2",
-        "eslint-loader": "^1.9.0",
-        "expose-loader": "^0.7.4",
+        "copy-webpack-plugin": "^4.5.1",
+        "css-loader": "^0.28.11",
+        "eslint": "^4.19.1",
+        "eslint-loader": "^2.0.0",
+        "expose-loader": "^0.7.5",
         "extract-text-webpack-plugin": "^4.0.0-beta.0",
         "file": "^0.2.2",
-        "file-loader": "^1.1.6",
-        "html-loader": "^0.5.4",
+        "file-loader": "^1.1.11",
+        "html-loader": "^0.5.5",
         "identity-obj-proxy": "^3.0.0",
-        "imports-loader": "^0.7.1",
-        "jasmine-core": "2.4.1",
-        "jest": "^22.1.2",
+        "imports-loader": "^0.8.0",
+        "jasmine-core": "^3.1.0",
+        "jest": "^22.4.3",
         "lodash.clonedeep": "^4.5.0",
-        "main-bower-files": "2.13.1",
+        "main-bower-files": "^2.13.1",
         "ngtemplate-loader": "^2.0.1",
-        "node-sass": "^4.7.2",
-        "parallel-webpack": "^2.2.0",
-        "phantomjs-prebuilt": "2.1.16",
+        "node-sass": "^4.8.3",
+        "parallel-webpack": "^2.3.0",
+        "phantomjs-prebuilt": "^2.1.16",
         "regenerator-runtime": "^0.11.1",
-        "sass-loader": "^6.0.6",
+        "sass-loader": "^6.0.7",
         "script-loader": "^0.7.2",
         "string-replace-webpack-plugin": "^0.1.3",
-        "style-loader": "^0.19.1",
-        "ts-loader": "^4.0.0",
+        "style-loader": "^0.20.3",
+        "ts-loader": "^4.1.0",
         "tslint": "^5.9.1",
         "tslint-loader": "https://github.com/wbuchwalter/tslint-loader.git#093230076f3b453c4f8b7aa2ee074932aa109e84",
-        "typescript": "^2.7.2",
-        "uglifyjs-webpack-plugin": "^1.2.2",
-        "webpack": "^4.0.1",
-        "webpack-bundle-analyzer": "^2.9.2",
-        "webpack-cli": "^2.0.9",
+        "typescript": "^2.8.1",
+        "uglifyjs-webpack-plugin": "^1.2.4",
+        "webpack": "^4.3.0",
+        "webpack-bundle-analyzer": "^2.11.1",
+        "webpack-cli": "^2.0.13",
         "webpack-md5-hash": "^0.0.6",
-        "yargs": "^10.1.1"
+        "yargs": "^11.0.0"
     },
     "dependencies": {
         "angular": "1.5.11",
diff --git a/core/web-assets/webpack.config.js b/core/web-assets/webpack.config.js
index 0a99cf56c74..0d62fce60fd 100644
--- a/core/web-assets/webpack.config.js
+++ b/core/web-assets/webpack.config.js
@@ -38,9 +38,11 @@ if (isProduction) {
 
 console.log('=== running ' + (isProduction? 'production':'development') + ' build of OpenNMS ' + opennmsVersion + ' assets ===');
 
-var styleroot = path.join(__dirname, 'src/main/assets/style');
-var jsroot = path.join(__dirname, 'src/main/assets/js');
-var moduleroot = path.join(__dirname, 'src/main/assets/modules');
+var assetsroot = path.join(__dirname, 'src', 'main', 'assets');
+var styleroot = path.join(assetsroot, 'style');
+var jsroot = path.join(assetsroot, 'js');
+var moduleroot = path.join(assetsroot, 'modules');
+var staticroot = path.join(assetsroot, 'static');
 
 var styleEntries = {};
 var appEntries = {};
@@ -65,14 +67,14 @@ const scanUtils = (start, dirs, names) => {
         continue;
       }
       const entryPath = path.join(start,file);
-      if (entryPath.indexOf('/vendor/') >= 0) {
+      if (entryPath.indexOf(path.sep + 'vendor' + path.sep) >= 0) {
         checkEntry('vendor', entry);
         vendorEntries[entry] = entryPath;
       } else {
         checkEntry('lib', entry);
         appEntries[entry] = entryPath;
       }
-      if (entryPath.indexOf('/vaadin/') >= 0) {
+      if (entryPath.indexOf(path.sep + 'vaadin' + path.sep) >= 0) {
         vaadinEntries[entry] = entryPath;
       }
       allEntries[entry] = entryPath;
@@ -89,7 +91,7 @@ const scanApps = (start, dirs, names) => {
       const entry = path.basename(path.dirname(relative));
       const entryPath = path.join(start,file);
       checkEntry('app', entry);
-      if (entryPath.indexOf('/vaadin/') >= 0) {
+      if (entryPath.indexOf(path.sep + 'vaadin' + path.sep) >= 0) {
         vaadinEntries[entry] = entryPath;
       }
       allEntries[entry] = entryPath;
@@ -157,10 +159,7 @@ var config = {
   entry: allEntries,
   output: {
     path: distdir,
-    libraryTarget: 'umd'/*,
-    umdNamedDefine: true,
-    publicPath: 'assets/'
-    */
+    libraryTarget: 'umd'
   },
   target: 'web',
   module: {
@@ -282,7 +281,7 @@ var config = {
             {
               loader: 'cache-loader',
               options: {
-                cacheDirectory: path.resolve('target/cache-loader')
+                cacheDirectory: path.resolve(path.join('target', 'cache-loader'))
               }
             },
             {
@@ -334,7 +333,7 @@ var config = {
           {
             loader: 'cache-loader',
             options: {
-              cacheDirectory: path.resolve('target/cache-loader')
+              cacheDirectory: path.resolve(path.join('target', 'cache-loader'))
             }
           },
           {
@@ -353,7 +352,7 @@ var config = {
           {
             loader: 'cache-loader',
             options: {
-              cacheDirectory: path.resolve('target/cache-loader')
+              cacheDirectory: path.resolve(path.join('target', 'cache-loader'))
             }
           },
           {
@@ -373,17 +372,11 @@ var config = {
     ]
   },
   resolve: {
-    /*
-    alias: {
-      // fix a weird issue in angular-ui-bootstrap not finding its modules
-      uib: path.join(__dirname, 'node_modules', 'angular-ui-bootstrap')
-    },
-    */
     modules: [
-      path.resolve('./src/main/assets/modules'),
-      path.resolve('./src/main/assets/js'),
-      path.resolve('./src/main/assets/style'),
-      path.resolve('./node_modules')
+      moduleroot,
+      jsroot,
+      styleroot,
+      path.resolve(path.join(__dirname, 'node_modules'))
     ],
     descriptionFiles: ['package.json', 'bower.json'],
     extensions: ['.tsx', '.ts', '.jsx', '.js']
@@ -537,7 +530,7 @@ function createConfig(options) {
 
   myconf.plugins.push(new CopyWebpackPlugin([
     {
-      from: 'src/main/assets/static'
+      from: staticroot
     }
   ]));
 
diff --git a/core/web-assets/yarn.lock b/core/web-assets/yarn.lock
index 19e443c187d..1a7e6e029fa 100644
--- a/core/web-assets/yarn.lock
+++ b/core/web-assets/yarn.lock
@@ -71,6 +71,10 @@
     lodash "^4.2.0"
     to-fast-properties "^2.0.0"
 
+"@sindresorhus/is@^0.7.0":
+  version "0.7.0"
+  resolved "https://registry.yarnpkg.com/@sindresorhus/is/-/is-0.7.0.tgz#9a06f4f137ee84d7df0460c1fdb1135ffa6c50fd"
+
 "@types/lodash@^4.14.104":
   version "4.14.104"
   resolved "https://registry.yarnpkg.com/@types/lodash/-/lodash-4.14.104.tgz#53ee2357fa2e6e68379341d92eb2ecea4b11bb80"
@@ -116,26 +120,26 @@ acorn@^5.0.0, acorn@^5.3.0:
   version "5.5.0"
   resolved "https://registry.yarnpkg.com/acorn/-/acorn-5.5.0.tgz#1abb587fbf051f94e3de20e6b26ef910b1828298"
 
-acorn@^5.2.1:
-  version "5.2.1"
-  resolved "https://registry.yarnpkg.com/acorn/-/acorn-5.2.1.tgz#317ac7821826c22c702d66189ab8359675f135d7"
+acorn@^5.5.0:
+  version "5.5.3"
+  resolved "https://registry.yarnpkg.com/acorn/-/acorn-5.5.3.tgz#f473dd47e0277a08e28e9bec5aeeb04751f0b8c9"
 
-ajv-keywords@^1.0.0:
-  version "1.5.1"
-  resolved "https://registry.yarnpkg.com/ajv-keywords/-/ajv-keywords-1.5.1.tgz#314dd0a4b3368fad3dfcdc54ede6171b886daf3c"
+ajv-keywords@^2.1.0:
+  version "2.1.1"
+  resolved "https://registry.yarnpkg.com/ajv-keywords/-/ajv-keywords-2.1.1.tgz#617997fc5f60576894c435f940d819e135b80762"
 
 ajv-keywords@^3.1.0:
   version "3.1.0"
   resolved "https://registry.yarnpkg.com/ajv-keywords/-/ajv-keywords-3.1.0.tgz#ac2b27939c543e95d2c06e7f7f5c27be4aa543be"
 
-ajv@^4.7.0, ajv@^4.9.1, ajv@^4.9.2:
+ajv@^4.9.1, ajv@^4.9.2:
   version "4.11.8"
   resolved "https://registry.yarnpkg.com/ajv/-/ajv-4.11.8.tgz#82ffb02b29e662ae53bdc20af15947706739c536"
   dependencies:
     co "^4.6.0"
     json-stable-stringify "^1.0.1"
 
-ajv@^5.0.0, ajv@^5.1.0:
+ajv@^5.1.0, ajv@^5.2.3, ajv@^5.3.0:
   version "5.5.2"
   resolved "https://registry.yarnpkg.com/ajv/-/ajv-5.5.2.tgz#73b5eeca3fab653e3d3f9422b341ad42205dc965"
   dependencies:
@@ -212,7 +216,7 @@ angular@1.5.11:
   version "1.5.11"
   resolved "https://registry.yarnpkg.com/angular/-/angular-1.5.11.tgz#8c5ba7386f15965c9acf3429f6881553aada30d6"
 
-ansi-escapes@^1.0.0, ansi-escapes@^1.1.0:
+ansi-escapes@^1.0.0:
   version "1.4.0"
   resolved "https://registry.yarnpkg.com/ansi-escapes/-/ansi-escapes-1.4.0.tgz#d3a8a83b319aa67793662b13e761c7911422306e"
 
@@ -238,10 +242,20 @@ ansi-styles@^3.2.0:
   dependencies:
     color-convert "^1.9.0"
 
+ansi-styles@^3.2.1:
+  version "3.2.1"
+  resolved "https://registry.yarnpkg.com/ansi-styles/-/ansi-styles-3.2.1.tgz#41fbb20243e50b12be0f04b8dedbf07520ce841d"
+  dependencies:
+    color-convert "^1.9.0"
+
 ansi-styles@~1.0.0:
   version "1.0.0"
   resolved "https://registry.yarnpkg.com/ansi-styles/-/ansi-styles-1.0.0.tgz#cb102df1c56f5123eab8b67cd7b98027a0279178"
 
+any-observable@^0.2.0:
+  version "0.2.0"
+  resolved "https://registry.yarnpkg.com/any-observable/-/any-observable-0.2.0.tgz#c67870058003579009083f54ac0abafb5c33d242"
+
 anymatch@^1.3.0:
   version "1.3.2"
   resolved "https://registry.yarnpkg.com/anymatch/-/anymatch-1.3.2.tgz#553dcb8f91e3c889845dfdba34c77721b90b9d7a"
@@ -249,6 +263,13 @@ anymatch@^1.3.0:
     micromatch "^2.1.5"
     normalize-path "^2.0.0"
 
+anymatch@^2.0.0:
+  version "2.0.0"
+  resolved "https://registry.yarnpkg.com/anymatch/-/anymatch-2.0.0.tgz#bcb24b4f37934d9aa7ac17b4adaf89e7c76ef2eb"
+  dependencies:
+    micromatch "^3.1.4"
+    normalize-path "^2.1.1"
+
 append-transform@^0.4.0:
   version "0.4.0"
   resolved "https://registry.yarnpkg.com/append-transform/-/append-transform-0.4.0.tgz#d76ebf8ca94d276e247a36bad44a4b74ab611991"
@@ -272,10 +293,6 @@ argparse@^1.0.7:
   dependencies:
     sprintf-js "~1.0.2"
 
-argv@0.0.2:
-  version "0.0.2"
-  resolved "https://registry.yarnpkg.com/argv/-/argv-0.0.2.tgz#ecbd16f8949b157183711b1bda334f37840185ab"
-
 arr-diff@^2.0.0:
   version "2.0.0"
   resolved "https://registry.yarnpkg.com/arr-diff/-/arr-diff-2.0.0.tgz#8f3b827f955a8bd669697e4a4256ac3ceae356cf"
@@ -376,9 +393,9 @@ ast-types@0.10.1:
   version "0.10.1"
   resolved "https://registry.yarnpkg.com/ast-types/-/ast-types-0.10.1.tgz#f52fca9715579a14f841d67d7f8d25432ab6a3dd"
 
-ast-types@0.10.2:
-  version "0.10.2"
-  resolved "https://registry.yarnpkg.com/ast-types/-/ast-types-0.10.2.tgz#aef76a04fde54634976fc94defaad1a67e2eadb0"
+ast-types@0.11.3:
+  version "0.11.3"
+  resolved "https://registry.yarnpkg.com/ast-types/-/ast-types-0.11.3.tgz#c20757fe72ee71278ea0ff3d87e5c2ca30d9edf8"
 
 ast-types@0.9.6:
   version "0.9.6"
@@ -404,7 +421,7 @@ async@^1.2.1, async@^1.4.0, async@^1.5.0:
   version "1.5.2"
   resolved "https://registry.yarnpkg.com/async/-/async-1.5.2.tgz#ec6a61ae56480c0c3cb241c95618e20892f9672a"
 
-async@^2.0.0, async@^2.1.2, async@^2.1.4, async@^2.1.5, async@^2.4.1:
+async@^2.1.4, async@^2.4.1, async@^2.6.0:
   version "2.6.0"
   resolved "https://registry.yarnpkg.com/async/-/async-2.6.0.tgz#61a29abb6fcc026fea77e56d1c6ec53a795951f4"
   dependencies:
@@ -466,7 +483,7 @@ babel-cli@^6.26.0:
   optionalDependencies:
     chokidar "^1.6.1"
 
-babel-code-frame@^6.16.0, babel-code-frame@^6.22.0, babel-code-frame@^6.26.0:
+babel-code-frame@^6.22.0, babel-code-frame@^6.26.0:
   version "6.26.0"
   resolved "https://registry.yarnpkg.com/babel-code-frame/-/babel-code-frame-6.26.0.tgz#63fd43f7dc1e3bb7ce35947db8fe369a3f58c74b"
   dependencies:
@@ -498,9 +515,9 @@ babel-core@^6.0.0, babel-core@^6.26.0:
     slash "^1.0.0"
     source-map "^0.5.6"
 
-babel-eslint@^8.2.1:
+babel-eslint@^8.2.2:
   version "8.2.2"
-  resolved "https://registry.yarnpkg.com/babel-eslint/-/babel-eslint-8.2.2.tgz#1102273354c6f0b29b4ea28a65f97d122296b68b"
+  resolved "http://registry.npmjs.org/babel-eslint/-/babel-eslint-8.2.2.tgz#1102273354c6f0b29b4ea28a65f97d122296b68b"
   dependencies:
     "@babel/code-frame" "^7.0.0-beta.40"
     "@babel/traverse" "^7.0.0-beta.40"
@@ -640,16 +657,16 @@ babel-helpers@^6.24.1:
     babel-runtime "^6.22.0"
     babel-template "^6.24.1"
 
-babel-jest@^22.1.0, babel-jest@^22.4.1:
-  version "22.4.1"
-  resolved "https://registry.yarnpkg.com/babel-jest/-/babel-jest-22.4.1.tgz#ff53ebca45957347f27ff4666a31499fbb4c4ddd"
+babel-jest@^22.4.3:
+  version "22.4.3"
+  resolved "https://registry.yarnpkg.com/babel-jest/-/babel-jest-22.4.3.tgz#4b7a0b6041691bbd422ab49b3b73654a49a6627a"
   dependencies:
     babel-plugin-istanbul "^4.1.5"
-    babel-preset-jest "^22.4.1"
+    babel-preset-jest "^22.4.3"
 
-babel-loader@^7.1.2:
-  version "7.1.3"
-  resolved "https://registry.yarnpkg.com/babel-loader/-/babel-loader-7.1.3.tgz#ff5b440da716e9153abb946251a9ab7670037b16"
+babel-loader@^7.1.4:
+  version "7.1.4"
+  resolved "https://registry.yarnpkg.com/babel-loader/-/babel-loader-7.1.4.tgz#e3463938bd4e6d55d1c174c5485d406a188ed015"
   dependencies:
     find-cache-dir "^1.0.0"
     loader-utils "^1.0.2"
@@ -683,9 +700,9 @@ babel-plugin-istanbul@^4.1.5:
     istanbul-lib-instrument "^1.7.5"
     test-exclude "^4.1.1"
 
-babel-plugin-jest-hoist@^22.4.1:
-  version "22.4.1"
-  resolved "https://registry.yarnpkg.com/babel-plugin-jest-hoist/-/babel-plugin-jest-hoist-22.4.1.tgz#d712fe5da8b6965f3191dacddbefdbdf4fb66d63"
+babel-plugin-jest-hoist@^22.4.3:
+  version "22.4.3"
+  resolved "https://registry.yarnpkg.com/babel-plugin-jest-hoist/-/babel-plugin-jest-hoist-22.4.3.tgz#7d8bcccadc2667f96a0dcc6afe1891875ee6c14a"
 
 babel-plugin-resolver@^1.1.0:
   version "1.1.0"
@@ -1108,11 +1125,11 @@ babel-preset-es2017@^6.24.1:
     babel-plugin-syntax-trailing-function-commas "^6.22.0"
     babel-plugin-transform-async-to-generator "^6.24.1"
 
-babel-preset-jest@^22.4.1:
-  version "22.4.1"
-  resolved "https://registry.yarnpkg.com/babel-preset-jest/-/babel-preset-jest-22.4.1.tgz#efa2e5f5334242a9457a068452d7d09735db172a"
+babel-preset-jest@^22.4.3:
+  version "22.4.3"
+  resolved "https://registry.yarnpkg.com/babel-preset-jest/-/babel-preset-jest-22.4.3.tgz#e92eef9813b7026ab4ca675799f37419b5a44156"
   dependencies:
-    babel-plugin-jest-hoist "^22.4.1"
+    babel-plugin-jest-hoist "^22.4.3"
     babel-plugin-syntax-object-rest-spread "^6.13.0"
 
 babel-preset-latest@^6.24.1:
@@ -1214,6 +1231,10 @@ babylon@^6.17.3, babylon@^6.18.0:
   version "6.18.0"
   resolved "https://registry.yarnpkg.com/babylon/-/babylon-6.18.0.tgz#af2f3b88fa6f5c1e4c634d1a0f8eac4f55b395e3"
 
+babylon@^7.0.0-beta.30:
+  version "7.0.0-beta.42"
+  resolved "https://registry.yarnpkg.com/babylon/-/babylon-7.0.0-beta.42.tgz#67cfabcd4f3ec82999d29031ccdea89d0ba99657"
+
 "backshift@https://github.com/opennms/backshift.git#master":
   version "1.2.3-SNAPSHOT"
   resolved "https://github.com/opennms/backshift.git#6f95db39f847cc6955f4e7f25bd64ae32e76d607"
@@ -1346,7 +1367,7 @@ braces@^1.8.2:
     preserve "^0.2.0"
     repeat-element "^1.1.2"
 
-braces@^2.3.1:
+braces@^2.3.0, braces@^2.3.1:
   version "2.3.1"
   resolved "https://registry.yarnpkg.com/braces/-/braces-2.3.1.tgz#7086c913b4e5a08dbe37ac0ee6a2500c4ba691bb"
   dependencies:
@@ -1449,6 +1470,10 @@ bser@^2.0.0:
   dependencies:
     node-int64 "^0.4.0"
 
+buffer-from@^1.0.0:
+  version "1.0.0"
+  resolved "https://registry.yarnpkg.com/buffer-from/-/buffer-from-1.0.0.tgz#4cb8832d23612589b0406e9e2956c17f06fdf531"
+
 buffer-xor@^1.0.3:
   version "1.0.3"
   resolved "https://registry.yarnpkg.com/buffer-xor/-/buffer-xor-1.0.3.tgz#26e61ed1422fb70dd42e6e36729ed51d855fe8d9"
@@ -1479,7 +1504,7 @@ c3@0.4.18:
   dependencies:
     d3 "~3.5.0"
 
-cacache@^10.0.1:
+cacache@^10.0.4:
   version "10.0.4"
   resolved "https://registry.yarnpkg.com/cacache/-/cacache-10.0.4.tgz#6452367999eff9d4188aefd9a14e9d7c6a263460"
   dependencies:
@@ -1520,6 +1545,18 @@ cache-loader@^1.2.2:
     neo-async "^2.5.0"
     schema-utils "^0.4.2"
 
+cacheable-request@^2.1.1:
+  version "2.1.4"
+  resolved "https://registry.yarnpkg.com/cacheable-request/-/cacheable-request-2.1.4.tgz#0d808801b6342ad33c91df9d0b44dc09b91e5c3d"
+  dependencies:
+    clone-response "1.0.2"
+    get-stream "3.0.0"
+    http-cache-semantics "3.8.1"
+    keyv "3.0.0"
+    lowercase-keys "1.0.0"
+    normalize-url "2.0.1"
+    responselike "1.0.2"
+
 caller-path@^0.1.0:
   version "0.1.0"
   resolved "https://registry.yarnpkg.com/caller-path/-/caller-path-0.1.0.tgz#94085ef63581ecd3daa92444a8fe94e82577751f"
@@ -1614,6 +1651,14 @@ chalk@^2.0.0, chalk@^2.0.1, chalk@^2.1.0, chalk@^2.3.0, chalk@^2.3.1:
     escape-string-regexp "^1.0.5"
     supports-color "^5.2.0"
 
+chalk@^2.3.2:
+  version "2.3.2"
+  resolved "https://registry.yarnpkg.com/chalk/-/chalk-2.3.2.tgz#250dc96b07491bfd601e648d66ddf5f60c7a5c65"
+  dependencies:
+    ansi-styles "^3.2.1"
+    escape-string-regexp "^1.0.5"
+    supports-color "^5.3.0"
+
 chalk@~0.4.0:
   version "0.4.0"
   resolved "https://registry.yarnpkg.com/chalk/-/chalk-0.4.0.tgz#5199a3ddcd0c1efe23bc08c1b027b06176e0c64f"
@@ -1634,7 +1679,7 @@ check-types@^7.3.0:
   version "7.3.0"
   resolved "https://registry.yarnpkg.com/check-types/-/check-types-7.3.0.tgz#468f571a4435c24248f5fd0cb0e8d87c3c341e7d"
 
-chokidar@^1.6.1, chokidar@^1.7.0:
+chokidar@^1.6.1:
   version "1.7.0"
   resolved "https://registry.yarnpkg.com/chokidar/-/chokidar-1.7.0.tgz#798e689778151c8076b4b360e5edd28cda2bb468"
   dependencies:
@@ -1649,6 +1694,24 @@ chokidar@^1.6.1, chokidar@^1.7.0:
   optionalDependencies:
     fsevents "^1.0.0"
 
+chokidar@^2.0.2:
+  version "2.0.3"
+  resolved "https://registry.yarnpkg.com/chokidar/-/chokidar-2.0.3.tgz#dcbd4f6cbb2a55b4799ba8a840ac527e5f4b1176"
+  dependencies:
+    anymatch "^2.0.0"
+    async-each "^1.0.0"
+    braces "^2.3.0"
+    glob-parent "^3.1.0"
+    inherits "^2.0.1"
+    is-binary-path "^1.0.0"
+    is-glob "^4.0.0"
+    normalize-path "^2.1.1"
+    path-is-absolute "^1.0.0"
+    readdirp "^2.0.0"
+    upath "^1.0.0"
+  optionalDependencies:
+    fsevents "^1.1.2"
+
 chownr@^1.0.1:
   version "1.0.1"
   resolved "https://registry.yarnpkg.com/chownr/-/chownr-1.0.1.tgz#e2a75042a9551908bebd25b8523d5f9769d79181"
@@ -1693,7 +1756,7 @@ clean-css@4.1.x:
   dependencies:
     source-map "0.5.x"
 
-cli-cursor@^1.0.1, cli-cursor@^1.0.2:
+cli-cursor@^1.0.2:
   version "1.0.2"
   resolved "https://registry.yarnpkg.com/cli-cursor/-/cli-cursor-1.0.2.tgz#64da3f7d56a54412e59794bd62dc35295e8f2987"
   dependencies:
@@ -1754,14 +1817,20 @@ clone-buffer@^1.0.0:
   version "1.0.0"
   resolved "https://registry.yarnpkg.com/clone-buffer/-/clone-buffer-1.0.0.tgz#e3e25b207ac4e701af721e2cb5a16792cac3dc58"
 
-clone-deep@^0.3.0:
-  version "0.3.0"
-  resolved "https://registry.yarnpkg.com/clone-deep/-/clone-deep-0.3.0.tgz#348c61ae9cdbe0edfe053d91ff4cc521d790ede8"
+clone-deep@^2.0.1:
+  version "2.0.2"
+  resolved "https://registry.yarnpkg.com/clone-deep/-/clone-deep-2.0.2.tgz#00db3a1e173656730d1188c3d6aced6d7ea97713"
   dependencies:
     for-own "^1.0.0"
-    is-plain-object "^2.0.1"
-    kind-of "^3.2.2"
-    shallow-clone "^0.1.2"
+    is-plain-object "^2.0.4"
+    kind-of "^6.0.0"
+    shallow-clone "^1.0.0"
+
+clone-response@1.0.2:
+  version "1.0.2"
+  resolved "https://registry.yarnpkg.com/clone-response/-/clone-response-1.0.2.tgz#d1dc973920314df67fbeb94223b4ee350239e96b"
+  dependencies:
+    mimic-response "^1.0.0"
 
 clone-stats@^0.0.1:
   version "0.0.1"
@@ -1801,14 +1870,6 @@ code-point-at@^1.0.0:
   version "1.1.0"
   resolved "https://registry.yarnpkg.com/code-point-at/-/code-point-at-1.1.0.tgz#0d070b4d043a5bea33a2f1a40e2edb3d9a4ccf77"
 
-codecov@^3.0.0:
-  version "3.0.0"
-  resolved "https://registry.yarnpkg.com/codecov/-/codecov-3.0.0.tgz#c273b8c4f12945723e8dc9d25803d89343e5f28e"
-  dependencies:
-    argv "0.0.2"
-    request "2.81.0"
-    urlgrey "0.4.4"
-
 collection-visit@^1.0.0:
   version "1.0.0"
   resolved "https://registry.yarnpkg.com/collection-visit/-/collection-visit-1.0.0.tgz#4bc0373c164bc3291b4d368c829cf1a80a59dca0"
@@ -1886,7 +1947,7 @@ concat-map@0.0.1:
   version "0.0.1"
   resolved "https://registry.yarnpkg.com/concat-map/-/concat-map-0.0.1.tgz#d8a96bd77fd68df7793a73036a3ba0d5405d477b"
 
-concat-stream@1.6.0, concat-stream@^1.4.7, concat-stream@^1.5.0, concat-stream@^1.5.2:
+concat-stream@1.6.0, concat-stream@^1.5.0:
   version "1.6.0"
   resolved "https://registry.yarnpkg.com/concat-stream/-/concat-stream-1.6.0.tgz#0aac662fd52be78964d5532f694784e70110acf7"
   dependencies:
@@ -1894,6 +1955,15 @@ concat-stream@1.6.0, concat-stream@^1.4.7, concat-stream@^1.5.0, concat-stream@^
     readable-stream "^2.2.2"
     typedarray "^0.0.6"
 
+concat-stream@^1.6.0:
+  version "1.6.2"
+  resolved "https://registry.yarnpkg.com/concat-stream/-/concat-stream-1.6.2.tgz#904bdf194cd3122fc675c77fc4ac3d4ff0fd1a34"
+  dependencies:
+    buffer-from "^1.0.0"
+    inherits "^2.0.3"
+    readable-stream "^2.2.2"
+    typedarray "^0.0.6"
+
 console-browserify@^1.1.0:
   version "1.1.0"
   resolved "https://registry.yarnpkg.com/console-browserify/-/console-browserify-1.1.0.tgz#f0241c45730a9fc6323b206dbf38edc741d0bb10"
@@ -1947,15 +2017,15 @@ copy-descriptor@^0.1.0:
   version "0.1.1"
   resolved "https://registry.yarnpkg.com/copy-descriptor/-/copy-descriptor-0.1.1.tgz#676f6eb3c39997c2ee1ac3a924fd6124748f578d"
 
-copy-webpack-plugin@^4.3.1:
-  version "4.4.2"
-  resolved "https://registry.yarnpkg.com/copy-webpack-plugin/-/copy-webpack-plugin-4.4.2.tgz#c92bcd7df4d5e42c51398cc36b23820d0d10446a"
+copy-webpack-plugin@^4.5.1:
+  version "4.5.1"
+  resolved "https://registry.yarnpkg.com/copy-webpack-plugin/-/copy-webpack-plugin-4.5.1.tgz#fc4f68f4add837cc5e13d111b20715793225d29c"
   dependencies:
-    cacache "^10.0.1"
+    cacache "^10.0.4"
     find-cache-dir "^1.0.0"
     globby "^7.1.1"
     is-glob "^4.0.0"
-    loader-utils "^0.2.15"
+    loader-utils "^1.1.0"
     minimatch "^3.0.4"
     p-limit "^1.0.0"
     serialize-javascript "^1.4.0"
@@ -2010,6 +2080,16 @@ cross-spawn@^5.0.1, cross-spawn@^5.1.0:
     shebang-command "^1.2.0"
     which "^1.2.9"
 
+cross-spawn@^6.0.5:
+  version "6.0.5"
+  resolved "https://registry.yarnpkg.com/cross-spawn/-/cross-spawn-6.0.5.tgz#4a5ec7c64dfae22c3a14124dbacdee846d80cbc4"
+  dependencies:
+    nice-try "^1.0.4"
+    path-key "^2.0.1"
+    semver "^5.5.0"
+    shebang-command "^1.2.0"
+    which "^1.2.9"
+
 crypt@~0.0.1:
   version "0.0.2"
   resolved "https://registry.yarnpkg.com/crypt/-/crypt-0.0.2.tgz#88d7ff7ec0dfb86f713dc87bbb42d044d3e6c41b"
@@ -2046,9 +2126,9 @@ css-color-names@0.0.4:
   version "0.0.4"
   resolved "https://registry.yarnpkg.com/css-color-names/-/css-color-names-0.0.4.tgz#808adc2e79cf84738069b646cb20ec27beb629e0"
 
-css-loader@^0.28.8:
-  version "0.28.10"
-  resolved "https://registry.yarnpkg.com/css-loader/-/css-loader-0.28.10.tgz#40282e79230f7bcb4e483efa631d670b735ebf42"
+css-loader@^0.28.11:
+  version "0.28.11"
+  resolved "https://registry.yarnpkg.com/css-loader/-/css-loader-0.28.11.tgz#c3f9864a700be2711bb5a2462b2389b1a392dab7"
   dependencies:
     babel-code-frame "^6.26.0"
     css-selector-tokenizer "^0.7.0"
@@ -2157,12 +2237,6 @@ d3@3.5.17, d3@~3.5.0:
   version "3.5.17"
   resolved "https://registry.yarnpkg.com/d3/-/d3-3.5.17.tgz#bc46748004378b21a360c9fc7cf5231790762fb8"
 
-d@1:
-  version "1.0.0"
-  resolved "https://registry.yarnpkg.com/d/-/d-1.0.0.tgz#754bb5bfe55451da69a58b94d45f4c5b0462d58f"
-  dependencies:
-    es5-ext "^0.10.9"
-
 dargs@^5.1.0:
   version "5.1.0"
   resolved "https://registry.yarnpkg.com/dargs/-/dargs-5.1.0.tgz#ec7ea50c78564cd36c9d5ec18f66329fade27829"
@@ -2181,11 +2255,11 @@ date-now@^0.1.4:
   version "0.1.4"
   resolved "https://registry.yarnpkg.com/date-now/-/date-now-0.1.4.tgz#eaf439fd4d4848ad74e5cc7dbef200672b9e345b"
 
-dateformat@^2.0.0:
-  version "2.2.0"
-  resolved "https://registry.yarnpkg.com/dateformat/-/dateformat-2.2.0.tgz#4065e2013cf9fb916ddfd82efb506ad4c6769062"
+dateformat@^3.0.2:
+  version "3.0.3"
+  resolved "https://registry.yarnpkg.com/dateformat/-/dateformat-3.0.3.tgz#a6e37499a4d9a9cf85ef5872044d62901c9889ae"
 
-debug@2.6.9, debug@^2.0.0, debug@^2.1.0, debug@^2.1.1, debug@^2.2.0, debug@^2.3.3, debug@^2.6.8:
+debug@2.6.9, debug@^2.2.0, debug@^2.3.3, debug@^2.6.8:
   version "2.6.9"
   resolved "https://registry.yarnpkg.com/debug/-/debug-2.6.9.tgz#5d128515df134ff327e90a4c93f4e077a536341f"
   dependencies:
@@ -2205,7 +2279,7 @@ decode-uri-component@^0.2.0:
   version "0.2.0"
   resolved "https://registry.yarnpkg.com/decode-uri-component/-/decode-uri-component-0.2.0.tgz#eb3913333458775cb84cd1a1fae062106bb87545"
 
-decompress-response@^3.2.0:
+decompress-response@^3.2.0, decompress-response@^3.3.0:
   version "3.3.0"
   resolved "https://registry.yarnpkg.com/decompress-response/-/decompress-response-3.3.0.tgz#80a4dd323748384bfa248083622aedec982adff3"
   dependencies:
@@ -2312,14 +2386,14 @@ detect-newline@^2.1.0:
   version "2.1.0"
   resolved "https://registry.yarnpkg.com/detect-newline/-/detect-newline-2.1.0.tgz#f41f1c10be4b00e87b5f13da680759f2c5bfd3e2"
 
-diff@^2.1.2:
-  version "2.2.3"
-  resolved "https://registry.yarnpkg.com/diff/-/diff-2.2.3.tgz#60eafd0d28ee906e4e8ff0a52c1229521033bf99"
-
-diff@^3.2.0, diff@^3.3.0, diff@^3.3.1:
+diff@^3.2.0, diff@^3.3.1:
   version "3.4.0"
   resolved "https://registry.yarnpkg.com/diff/-/diff-3.4.0.tgz#b1d85507daf3964828de54b37d0d73ba67dda56c"
 
+diff@^3.5.0:
+  version "3.5.0"
+  resolved "https://registry.yarnpkg.com/diff/-/diff-3.5.0.tgz#800c0dd1e0a8bfbc95835c202ad220fe317e5a12"
+
 diffie-hellman@^5.0.0:
   version "5.0.2"
   resolved "https://registry.yarnpkg.com/diffie-hellman/-/diffie-hellman-5.0.2.tgz#b5835739270cfe26acf632099fded2a07f209e5e"
@@ -2335,16 +2409,12 @@ dir-glob@^2.0.0:
     arrify "^1.0.1"
     path-type "^3.0.0"
 
-doctrine@^2.0.0:
-  version "2.0.2"
-  resolved "https://registry.yarnpkg.com/doctrine/-/doctrine-2.0.2.tgz#68f96ce8efc56cc42651f1faadb4f175273b0075"
+doctrine@^2.1.0:
+  version "2.1.0"
+  resolved "https://registry.yarnpkg.com/doctrine/-/doctrine-2.1.0.tgz#5cd01fc101621b42c4cd7f5d1a66243716d3f39d"
   dependencies:
     esutils "^2.0.2"
 
-dom-walk@^0.1.0:
-  version "0.1.1"
-  resolved "https://registry.yarnpkg.com/dom-walk/-/dom-walk-0.1.1.tgz#672226dc74c8f799ad35307df936aba11acd6018"
-
 domain-browser@^1.1.1:
   version "1.1.7"
   resolved "https://registry.yarnpkg.com/domain-browser/-/domain-browser-1.1.7.tgz#867aa4b093faa05f1de08c06f4d7b21fdf8698bc"
@@ -2441,15 +2511,6 @@ end-of-stream@^1.0.0, end-of-stream@^1.1.0:
   dependencies:
     once "^1.4.0"
 
-enhanced-resolve@^3.4.1:
-  version "3.4.1"
-  resolved "https://registry.yarnpkg.com/enhanced-resolve/-/enhanced-resolve-3.4.1.tgz#0421e339fd71419b3da13d129b3979040230476e"
-  dependencies:
-    graceful-fs "^4.1.2"
-    memory-fs "^0.4.0"
-    object-assign "^4.0.1"
-    tapable "^0.2.7"
-
 enhanced-resolve@^4.0.0:
   version "4.0.0"
   resolved "https://registry.yarnpkg.com/enhanced-resolve/-/enhanced-resolve-4.0.0.tgz#e34a6eaa790f62fccd71d93959f56b2b432db10a"
@@ -2464,7 +2525,7 @@ errno@^0.1.3, errno@~0.1.7:
   dependencies:
     prr "~1.0.1"
 
-error-ex@^1.2.0:
+error-ex@^1.2.0, error-ex@^1.3.1:
   version "1.3.1"
   resolved "https://registry.yarnpkg.com/error-ex/-/error-ex-1.3.1.tgz#f855a86ce61adc4e8621c3cda21e7a7612c3a8dc"
   dependencies:
@@ -2495,53 +2556,10 @@ es-to-primitive@^1.1.1:
     is-date-object "^1.0.1"
     is-symbol "^1.0.1"
 
-es5-ext@^0.10.14, es5-ext@^0.10.35, es5-ext@^0.10.9, es5-ext@~0.10.14:
-  version "0.10.37"
-  resolved "https://registry.yarnpkg.com/es5-ext/-/es5-ext-0.10.37.tgz#0ee741d148b80069ba27d020393756af257defc3"
-  dependencies:
-    es6-iterator "~2.0.1"
-    es6-symbol "~3.1.1"
-
-es6-iterator@^2.0.1, es6-iterator@~2.0.1:
-  version "2.0.3"
-  resolved "https://registry.yarnpkg.com/es6-iterator/-/es6-iterator-2.0.3.tgz#a7de889141a05a94b0854403b2d0a0fbfa98f3b7"
-  dependencies:
-    d "1"
-    es5-ext "^0.10.35"
-    es6-symbol "^3.1.1"
-
-es6-map@^0.1.3:
-  version "0.1.5"
-  resolved "https://registry.yarnpkg.com/es6-map/-/es6-map-0.1.5.tgz#9136e0503dcc06a301690f0bb14ff4e364e949f0"
-  dependencies:
-    d "1"
-    es5-ext "~0.10.14"
-    es6-iterator "~2.0.1"
-    es6-set "~0.1.5"
-    es6-symbol "~3.1.1"
-    event-emitter "~0.3.5"
-
 es6-promise@^4.0.3:
   version "4.2.2"
   resolved "https://registry.yarnpkg.com/es6-promise/-/es6-promise-4.2.2.tgz#f722d7769af88bd33bc13ec6605e1f92966b82d9"
 
-es6-set@~0.1.5:
-  version "0.1.5"
-  resolved "https://registry.yarnpkg.com/es6-set/-/es6-set-0.1.5.tgz#d2b3ec5d4d800ced818db538d28974db0a73ccb1"
-  dependencies:
-    d "1"
-    es5-ext "~0.10.14"
-    es6-iterator "~2.0.1"
-    es6-symbol "3.1.1"
-    event-emitter "~0.3.5"
-
-es6-symbol@3.1.1, es6-symbol@^3.1.1, es6-symbol@~3.1.1:
-  version "3.1.1"
-  resolved "https://registry.yarnpkg.com/es6-symbol/-/es6-symbol-3.1.1.tgz#bf00ef4fdab6ba1b46ecb7b629b4c7ed5715cc77"
-  dependencies:
-    d "1"
-    es5-ext "~0.10.14"
-
 es6-templates@^0.2.3:
   version "0.2.3"
   resolved "https://registry.yarnpkg.com/es6-templates/-/es6-templates-0.2.3.tgz#5cb9ac9fb1ded6eb1239342b81d792bbb4078ee4"
@@ -2549,15 +2567,6 @@ es6-templates@^0.2.3:
     recast "~0.11.12"
     through "~2.3.6"
 
-es6-weak-map@^2.0.1:
-  version "2.0.2"
-  resolved "https://registry.yarnpkg.com/es6-weak-map/-/es6-weak-map-2.0.2.tgz#5e3ab32251ffd1538a1f8e5ffa1357772f92d96f"
-  dependencies:
-    d "1"
-    es5-ext "^0.10.14"
-    es6-iterator "^2.0.1"
-    es6-symbol "^3.1.1"
-
 escape-html@~1.0.1, escape-html@~1.0.3:
   version "1.0.3"
   resolved "https://registry.yarnpkg.com/escape-html/-/escape-html-1.0.3.tgz#0258eae4d3d0c0974de1c169188ef0051d1d1988"
@@ -2577,18 +2586,9 @@ escodegen@^1.9.0:
   optionalDependencies:
     source-map "~0.6.1"
 
-escope@^3.6.0:
-  version "3.6.0"
-  resolved "https://registry.yarnpkg.com/escope/-/escope-3.6.0.tgz#e01975e812781a163a6dadfdd80398dc64c889c3"
-  dependencies:
-    es6-map "^0.1.3"
-    es6-weak-map "^2.0.1"
-    esrecurse "^4.1.0"
-    estraverse "^4.1.1"
-
-eslint-loader@^1.9.0:
-  version "1.9.0"
-  resolved "https://registry.yarnpkg.com/eslint-loader/-/eslint-loader-1.9.0.tgz#7e1be9feddca328d3dcfaef1ad49d5beffe83a13"
+eslint-loader@^2.0.0:
+  version "2.0.0"
+  resolved "https://registry.yarnpkg.com/eslint-loader/-/eslint-loader-2.0.0.tgz#d136619b5c684e36531ffc28c60a56e404608f5d"
   dependencies:
     loader-fs-cache "^1.0.0"
     loader-utils "^1.0.2"
@@ -2607,51 +2607,54 @@ eslint-visitor-keys@^1.0.0:
   version "1.0.0"
   resolved "https://registry.yarnpkg.com/eslint-visitor-keys/-/eslint-visitor-keys-1.0.0.tgz#3f3180fb2e291017716acb4c9d6d5b5c34a6a81d"
 
-eslint@^3.2.2:
-  version "3.19.0"
-  resolved "https://registry.yarnpkg.com/eslint/-/eslint-3.19.0.tgz#c8fc6201c7f40dd08941b87c085767386a679acc"
+eslint@^4.19.1:
+  version "4.19.1"
+  resolved "https://registry.yarnpkg.com/eslint/-/eslint-4.19.1.tgz#32d1d653e1d90408854bfb296f076ec7e186a300"
   dependencies:
-    babel-code-frame "^6.16.0"
-    chalk "^1.1.3"
-    concat-stream "^1.5.2"
-    debug "^2.1.1"
-    doctrine "^2.0.0"
-    escope "^3.6.0"
-    espree "^3.4.0"
+    ajv "^5.3.0"
+    babel-code-frame "^6.22.0"
+    chalk "^2.1.0"
+    concat-stream "^1.6.0"
+    cross-spawn "^5.1.0"
+    debug "^3.1.0"
+    doctrine "^2.1.0"
+    eslint-scope "^3.7.1"
+    eslint-visitor-keys "^1.0.0"
+    espree "^3.5.4"
     esquery "^1.0.0"
-    estraverse "^4.2.0"
     esutils "^2.0.2"
     file-entry-cache "^2.0.0"
-    glob "^7.0.3"
-    globals "^9.14.0"
-    ignore "^3.2.0"
+    functional-red-black-tree "^1.0.1"
+    glob "^7.1.2"
+    globals "^11.0.1"
+    ignore "^3.3.3"
     imurmurhash "^0.1.4"
-    inquirer "^0.12.0"
-    is-my-json-valid "^2.10.0"
+    inquirer "^3.0.6"
     is-resolvable "^1.0.0"
-    js-yaml "^3.5.1"
-    json-stable-stringify "^1.0.0"
+    js-yaml "^3.9.1"
+    json-stable-stringify-without-jsonify "^1.0.1"
     levn "^0.3.0"
-    lodash "^4.0.0"
-    mkdirp "^0.5.0"
+    lodash "^4.17.4"
+    minimatch "^3.0.2"
+    mkdirp "^0.5.1"
     natural-compare "^1.4.0"
     optionator "^0.8.2"
-    path-is-inside "^1.0.1"
-    pluralize "^1.2.1"
-    progress "^1.1.8"
-    require-uncached "^1.0.2"
-    shelljs "^0.7.5"
-    strip-bom "^3.0.0"
+    path-is-inside "^1.0.2"
+    pluralize "^7.0.0"
+    progress "^2.0.0"
+    regexpp "^1.0.1"
+    require-uncached "^1.0.3"
+    semver "^5.3.0"
+    strip-ansi "^4.0.0"
     strip-json-comments "~2.0.1"
-    table "^3.7.8"
+    table "4.0.2"
     text-table "~0.2.0"
-    user-home "^2.0.0"
 
-espree@^3.4.0:
-  version "3.5.2"
-  resolved "https://registry.yarnpkg.com/espree/-/espree-3.5.2.tgz#756ada8b979e9dcfcdb30aad8d1a9304a905e1ca"
+espree@^3.5.4:
+  version "3.5.4"
+  resolved "https://registry.yarnpkg.com/espree/-/espree-3.5.4.tgz#b0f447187c8a8bed944b815a660bddf5deb5d1a7"
   dependencies:
-    acorn "^5.2.1"
+    acorn "^5.5.0"
     acorn-jsx "^3.0.0"
 
 esprima@^2.6.0:
@@ -2690,13 +2693,6 @@ etag@~1.8.1:
   version "1.8.1"
   resolved "https://registry.yarnpkg.com/etag/-/etag-1.8.1.tgz#41ae2eeb65efa62268aebfea83ac7d79299b0887"
 
-event-emitter@~0.3.5:
-  version "0.3.5"
-  resolved "https://registry.yarnpkg.com/event-emitter/-/event-emitter-0.3.5.tgz#df8c69eef1647923c7157b9ce83840610b02cc39"
-  dependencies:
-    d "1"
-    es5-ext "~0.10.14"
-
 event-pubsub@4.3.0:
   version "4.3.0"
   resolved "https://registry.yarnpkg.com/event-pubsub/-/event-pubsub-4.3.0.tgz#f68d816bc29f1ec02c539dc58c8dd40ce72cb36e"
@@ -2768,20 +2764,20 @@ expand-tilde@^2.0.0, expand-tilde@^2.0.2:
   dependencies:
     homedir-polyfill "^1.0.1"
 
-expect@^22.4.0:
-  version "22.4.0"
-  resolved "https://registry.yarnpkg.com/expect/-/expect-22.4.0.tgz#371edf1ae15b83b5bf5ec34b42f1584660a36c16"
+expect@^22.4.3:
+  version "22.4.3"
+  resolved "https://registry.yarnpkg.com/expect/-/expect-22.4.3.tgz#d5a29d0a0e1fb2153557caef2674d4547e914674"
   dependencies:
     ansi-styles "^3.2.0"
-    jest-diff "^22.4.0"
-    jest-get-type "^22.1.0"
-    jest-matcher-utils "^22.4.0"
-    jest-message-util "^22.4.0"
-    jest-regex-util "^22.1.0"
+    jest-diff "^22.4.3"
+    jest-get-type "^22.4.3"
+    jest-matcher-utils "^22.4.3"
+    jest-message-util "^22.4.3"
+    jest-regex-util "^22.4.3"
 
-expose-loader@^0.7.4:
-  version "0.7.4"
-  resolved "https://registry.yarnpkg.com/expose-loader/-/expose-loader-0.7.4.tgz#9bcdd3878b5da9107930b55a03f65afe90b3314a"
+expose-loader@^0.7.5:
+  version "0.7.5"
+  resolved "https://registry.yarnpkg.com/expose-loader/-/expose-loader-0.7.5.tgz#e29ea2d9aeeed3254a3faa1b35f502db9f9c3f6f"
 
 express@^4.16.2:
   version "4.16.2"
@@ -2839,15 +2835,7 @@ extend@^3.0.0, extend@~3.0.0, extend@~3.0.1:
   version "3.0.1"
   resolved "https://registry.yarnpkg.com/extend/-/extend-3.0.1.tgz#a755ea7bc1adfcc5a31ce7e762dbaadc5e636444"
 
-external-editor@^1.1.0:
-  version "1.1.1"
-  resolved "https://registry.yarnpkg.com/external-editor/-/external-editor-1.1.1.tgz#12d7b0db850f7ff7e7081baf4005700060c4600b"
-  dependencies:
-    extend "^3.0.0"
-    spawn-sync "^1.0.15"
-    tmp "^0.0.29"
-
-external-editor@^2.0.4:
+external-editor@^2.0.4, external-editor@^2.1.0:
   version "2.1.0"
   resolved "https://registry.yarnpkg.com/external-editor/-/external-editor-2.1.0.tgz#3d026a21b7f95b5726387d4200ac160d372c3b48"
   dependencies:
@@ -2928,7 +2916,7 @@ fd-slicer@~1.0.1:
   dependencies:
     pend "~1.2.0"
 
-figures@^1.3.5, figures@^1.7.0:
+figures@^1.7.0:
   version "1.7.0"
   resolved "https://registry.yarnpkg.com/figures/-/figures-1.7.0.tgz#cbe1e3affcf1cd44b80cadfed28dc793a9701d2e"
   dependencies:
@@ -2954,9 +2942,9 @@ file-loader@^0.8.1:
   dependencies:
     loader-utils "~0.2.5"
 
-file-loader@^1.1.6:
-  version "1.1.10"
-  resolved "https://registry.yarnpkg.com/file-loader/-/file-loader-1.1.10.tgz#77e97dfeab13da64c7085ab3e3887e29ae588aea"
+file-loader@^1.1.11:
+  version "1.1.11"
+  resolved "https://registry.yarnpkg.com/file-loader/-/file-loader-1.1.11.tgz#6fe886449b0f2a936e43cabaac0cdbfb369506f8"
   dependencies:
     loader-utils "^1.0.2"
     schema-utils "^0.4.5"
@@ -3160,7 +3148,7 @@ fresh@0.5.2:
   version "0.5.2"
   resolved "https://registry.yarnpkg.com/fresh/-/fresh-0.5.2.tgz#3d8cadd90d976569fa835ab1f8e4b23a105605a7"
 
-from2@^2.1.0:
+from2@^2.1.0, from2@^2.1.1:
   version "2.3.0"
   resolved "https://registry.yarnpkg.com/from2/-/from2-2.3.0.tgz#8bfb5502bde4a4d36cfdeea007fcca21d7e382af"
   dependencies:
@@ -3192,7 +3180,7 @@ fs.realpath@^1.0.0:
   version "1.0.0"
   resolved "https://registry.yarnpkg.com/fs.realpath/-/fs.realpath-1.0.0.tgz#1504ad2523158caa40db4a2787cb01411994ea4f"
 
-fsevents@^1.0.0, fsevents@^1.1.1:
+fsevents@^1.0.0, fsevents@^1.1.1, fsevents@^1.1.2:
   version "1.1.3"
   resolved "https://registry.yarnpkg.com/fsevents/-/fsevents-1.1.3.tgz#11f82318f5fe7bb2cd22965a108e9306208216d8"
   dependencies:
@@ -3220,6 +3208,10 @@ function-bind@^1.0.2, function-bind@^1.1.1:
   version "1.1.1"
   resolved "https://registry.yarnpkg.com/function-bind/-/function-bind-1.1.1.tgz#a56899d3ea3c9bab874bb9773b7c5ede92f4895d"
 
+functional-red-black-tree@^1.0.1:
+  version "1.0.1"
+  resolved "https://registry.yarnpkg.com/functional-red-black-tree/-/functional-red-black-tree-1.0.1.tgz#1b0ab3bd553b2a0d6399d29c0e3ea0b252078327"
+
 gauge@~2.7.3:
   version "2.7.4"
   resolved "https://registry.yarnpkg.com/gauge/-/gauge-2.7.4.tgz#2c03405c7538c39d7eb37b317022e325fb018bf7"
@@ -3257,7 +3249,7 @@ get-stdin@^4.0.1:
   version "4.0.1"
   resolved "https://registry.yarnpkg.com/get-stdin/-/get-stdin-4.0.1.tgz#b968c6b0a04384324902e8bf1a5df32579a450fe"
 
-get-stream@^3.0.0:
+get-stream@3.0.0, get-stream@^3.0.0:
   version "3.0.0"
   resolved "https://registry.yarnpkg.com/get-stream/-/get-stream-3.0.0.tgz#8e943d1358dc37555054ecbe2edb05aa174ede14"
 
@@ -3304,7 +3296,7 @@ glob-parent@^2.0.0:
   dependencies:
     is-glob "^2.0.0"
 
-glob-parent@^3.0.0:
+glob-parent@^3.0.0, glob-parent@^3.1.0:
   version "3.1.0"
   resolved "https://registry.yarnpkg.com/glob-parent/-/glob-parent-3.1.0.tgz#9e6af6299d8d3bd2bd40430832bd113df906c5ae"
   dependencies:
@@ -3334,7 +3326,7 @@ glob@^5.0.3:
     once "^1.3.0"
     path-is-absolute "^1.0.0"
 
-glob@^6.0.1, glob@^6.0.4:
+glob@^6.0.4:
   version "6.0.4"
   resolved "https://registry.yarnpkg.com/glob/-/glob-6.0.4.tgz#0f08860f6a155127b2fadd4f9ce24b1aab6e4d22"
   dependencies:
@@ -3373,18 +3365,15 @@ global-prefix@^1.0.1:
     is-windows "^1.0.1"
     which "^1.2.14"
 
-global@^4.3.2:
-  version "4.3.2"
-  resolved "https://registry.yarnpkg.com/global/-/global-4.3.2.tgz#e76989268a6c74c38908b1305b10fc0e394e9d0f"
-  dependencies:
-    min-document "^2.19.0"
-    process "~0.5.1"
+globals@^11.0.1:
+  version "11.4.0"
+  resolved "https://registry.yarnpkg.com/globals/-/globals-11.4.0.tgz#b85c793349561c16076a3c13549238a27945f1bc"
 
 globals@^11.1.0:
   version "11.3.0"
   resolved "https://registry.yarnpkg.com/globals/-/globals-11.3.0.tgz#e04fdb7b9796d8adac9c8f64c14837b2313378b0"
 
-globals@^9.14.0, globals@^9.18.0:
+globals@^9.18.0:
   version "9.18.0"
   resolved "https://registry.yarnpkg.com/globals/-/globals-9.18.0.tgz#aa3896b3e69b487f17e31ed2143d69a8e30c2d8a"
 
@@ -3397,17 +3386,6 @@ globby@^2.0.0:
     glob "^5.0.3"
     object-assign "^3.0.0"
 
-globby@^4.0.0:
-  version "4.1.0"
-  resolved "https://registry.yarnpkg.com/globby/-/globby-4.1.0.tgz#080f54549ec1b82a6c60e631fc82e1211dbe95f8"
-  dependencies:
-    array-union "^1.0.1"
-    arrify "^1.0.0"
-    glob "^6.0.1"
-    object-assign "^4.0.1"
-    pify "^2.0.0"
-    pinkie-promise "^2.0.0"
-
 globby@^5.0.0:
   version "5.0.0"
   resolved "https://registry.yarnpkg.com/globby/-/globby-5.0.0.tgz#ebd84667ca0dbb330b99bcfc68eac2bc54370e0d"
@@ -3448,7 +3426,7 @@ globule@^1.0.0:
     lodash "~4.17.4"
     minimatch "~3.0.2"
 
-got@^7.0.0, got@^7.1.0:
+got@^7.0.0:
   version "7.1.0"
   resolved "https://registry.yarnpkg.com/got/-/got-7.1.0.tgz#05450fd84094e6bbea56f451a43a9c289166385a"
   dependencies:
@@ -3467,11 +3445,33 @@ got@^7.0.0, got@^7.1.0:
     url-parse-lax "^1.0.0"
     url-to-options "^1.0.1"
 
+got@^8.2.0:
+  version "8.3.0"
+  resolved "https://registry.yarnpkg.com/got/-/got-8.3.0.tgz#6ba26e75f8a6cc4c6b3eb1fe7ce4fec7abac8533"
+  dependencies:
+    "@sindresorhus/is" "^0.7.0"
+    cacheable-request "^2.1.1"
+    decompress-response "^3.3.0"
+    duplexer3 "^0.1.4"
+    get-stream "^3.0.0"
+    into-stream "^3.1.0"
+    is-retry-allowed "^1.1.0"
+    isurl "^1.0.0-alpha5"
+    lowercase-keys "^1.0.0"
+    mimic-response "^1.0.0"
+    p-cancelable "^0.4.0"
+    p-timeout "^2.0.1"
+    pify "^3.0.0"
+    safe-buffer "^5.1.1"
+    timed-out "^4.0.1"
+    url-parse-lax "^3.0.0"
+    url-to-options "^1.0.1"
+
 graceful-fs@^4.0.0, graceful-fs@^4.1.11, graceful-fs@^4.1.2, graceful-fs@^4.1.4, graceful-fs@^4.1.6, graceful-fs@^4.1.9:
   version "4.1.11"
   resolved "https://registry.yarnpkg.com/graceful-fs/-/graceful-fs-4.1.11.tgz#0e8bdfe4d1ddb8854d64e04ea7c00e2a026e5658"
 
-grouped-queue@^0.3.0, grouped-queue@^0.3.3:
+grouped-queue@^0.3.3:
   version "0.3.3"
   resolved "https://registry.yarnpkg.com/grouped-queue/-/grouped-queue-0.3.3.tgz#c167d2a5319c5a0e0964ef6a25b7c2df8996c85c"
   dependencies:
@@ -3557,10 +3557,6 @@ has-flag@^1.0.0:
   version "1.0.0"
   resolved "https://registry.yarnpkg.com/has-flag/-/has-flag-1.0.0.tgz#9d9e793165ce017a00f00418c43f942a7b1d11fa"
 
-has-flag@^2.0.0:
-  version "2.0.0"
-  resolved "https://registry.yarnpkg.com/has-flag/-/has-flag-2.0.0.tgz#e8207af1cc7b30d446cc70b734b5e8be18f88d51"
-
 has-flag@^3.0.0:
   version "3.0.0"
   resolved "https://registry.yarnpkg.com/has-flag/-/has-flag-3.0.0.tgz#b5d454dc2199ae225699f3467e5a07f3b955bafd"
@@ -3710,7 +3706,7 @@ html-encoding-sniffer@^1.0.2:
   dependencies:
     whatwg-encoding "^1.0.1"
 
-html-loader@^0.5.4:
+html-loader@^0.5.5:
   version "0.5.5"
   resolved "https://registry.yarnpkg.com/html-loader/-/html-loader-0.5.5.tgz#6356dbeb0c49756d8ebd5ca327f16ff06ab5faea"
   dependencies:
@@ -3733,6 +3729,10 @@ html-minifier@^3.5.8:
     relateurl "0.2.x"
     uglify-js "3.3.x"
 
+http-cache-semantics@3.8.1:
+  version "3.8.1"
+  resolved "https://registry.yarnpkg.com/http-cache-semantics/-/http-cache-semantics-3.8.1.tgz#39b0e16add9b605bf0a9ef3d9daaf4843b4cacd2"
+
 http-errors@1.6.2, http-errors@~1.6.2:
   version "1.6.2"
   resolved "https://registry.yarnpkg.com/http-errors/-/http-errors-1.6.2.tgz#0a002cc85707192a7e7946ceedc11155f60ec736"
@@ -3790,7 +3790,7 @@ iferr@^0.1.5:
   version "0.1.5"
   resolved "https://registry.yarnpkg.com/iferr/-/iferr-0.1.5.tgz#c60eed69e6d8fdb6b3104a1fcbca1c192dc5b501"
 
-ignore@^3.2.0, ignore@^3.3.5:
+ignore@^3.3.3, ignore@^3.3.5:
   version "3.3.7"
   resolved "https://registry.yarnpkg.com/ignore/-/ignore-3.3.7.tgz#612289bfb3c220e186a58118618d5be8c1bab021"
 
@@ -3801,12 +3801,12 @@ import-local@^1.0.0:
     pkg-dir "^2.0.0"
     resolve-cwd "^2.0.0"
 
-imports-loader@^0.7.1:
-  version "0.7.1"
-  resolved "https://registry.yarnpkg.com/imports-loader/-/imports-loader-0.7.1.tgz#f204b5f34702a32c1db7d48d89d5e867a0441253"
+imports-loader@^0.8.0:
+  version "0.8.0"
+  resolved "https://registry.yarnpkg.com/imports-loader/-/imports-loader-0.8.0.tgz#030ea51b8ca05977c40a3abfd9b4088fe0be9a69"
   dependencies:
     loader-utils "^1.0.2"
-    source-map "^0.5.6"
+    source-map "^0.6.1"
 
 imurmurhash@^0.1.4:
   version "0.1.4"
@@ -3853,58 +3853,39 @@ ini@^1.3.4, ini@~1.3.0:
   version "1.3.5"
   resolved "https://registry.yarnpkg.com/ini/-/ini-1.3.5.tgz#eee25f56db1c9ec6085e0c22778083f596abf927"
 
-inquirer@^0.12.0:
-  version "0.12.0"
-  resolved "https://registry.yarnpkg.com/inquirer/-/inquirer-0.12.0.tgz#1ef2bfd63504df0bc75785fff8c2c41df12f077e"
-  dependencies:
-    ansi-escapes "^1.1.0"
-    ansi-regex "^2.0.0"
-    chalk "^1.0.0"
-    cli-cursor "^1.0.1"
-    cli-width "^2.0.0"
-    figures "^1.3.5"
-    lodash "^4.3.0"
-    readline2 "^1.0.1"
-    run-async "^0.1.0"
-    rx-lite "^3.1.2"
-    string-width "^1.0.1"
-    strip-ansi "^3.0.0"
-    through "^2.3.6"
-
-inquirer@^1.0.2:
-  version "1.2.3"
-  resolved "https://registry.yarnpkg.com/inquirer/-/inquirer-1.2.3.tgz#4dec6f32f37ef7bb0b2ed3f1d1a5c3f545074918"
+inquirer@^3.0.6, inquirer@^3.3.0:
+  version "3.3.0"
+  resolved "https://registry.yarnpkg.com/inquirer/-/inquirer-3.3.0.tgz#9dd2f2ad765dcab1ff0443b491442a20ba227dc9"
   dependencies:
-    ansi-escapes "^1.1.0"
-    chalk "^1.0.0"
-    cli-cursor "^1.0.1"
+    ansi-escapes "^3.0.0"
+    chalk "^2.0.0"
+    cli-cursor "^2.1.0"
     cli-width "^2.0.0"
-    external-editor "^1.1.0"
-    figures "^1.3.5"
+    external-editor "^2.0.4"
+    figures "^2.0.0"
     lodash "^4.3.0"
-    mute-stream "0.0.6"
-    pinkie-promise "^2.0.0"
+    mute-stream "0.0.7"
     run-async "^2.2.0"
-    rx "^4.1.0"
-    string-width "^1.0.1"
-    strip-ansi "^3.0.0"
+    rx-lite "^4.0.8"
+    rx-lite-aggregates "^4.0.8"
+    string-width "^2.1.0"
+    strip-ansi "^4.0.0"
     through "^2.3.6"
 
-inquirer@^3.2.0, inquirer@^3.3.0:
-  version "3.3.0"
-  resolved "https://registry.yarnpkg.com/inquirer/-/inquirer-3.3.0.tgz#9dd2f2ad765dcab1ff0443b491442a20ba227dc9"
+inquirer@^5.1.0:
+  version "5.2.0"
+  resolved "https://registry.yarnpkg.com/inquirer/-/inquirer-5.2.0.tgz#db350c2b73daca77ff1243962e9f22f099685726"
   dependencies:
     ansi-escapes "^3.0.0"
     chalk "^2.0.0"
     cli-cursor "^2.1.0"
     cli-width "^2.0.0"
-    external-editor "^2.0.4"
+    external-editor "^2.1.0"
     figures "^2.0.0"
     lodash "^4.3.0"
     mute-stream "0.0.7"
     run-async "^2.2.0"
-    rx-lite "^4.0.8"
-    rx-lite-aggregates "^4.0.8"
+    rxjs "^5.5.2"
     string-width "^2.1.0"
     strip-ansi "^4.0.0"
     through "^2.3.6"
@@ -3913,6 +3894,13 @@ interpret@^1.0.0, interpret@^1.0.1, interpret@^1.0.4:
   version "1.1.0"
   resolved "https://registry.yarnpkg.com/interpret/-/interpret-1.1.0.tgz#7ed1b1410c6a0e0f78cf95d3b8440c63f78b8614"
 
+into-stream@^3.1.0:
+  version "3.1.0"
+  resolved "https://registry.yarnpkg.com/into-stream/-/into-stream-3.1.0.tgz#96fb0a936c12babd6ff1752a17d05616abd094c6"
+  dependencies:
+    from2 "^2.1.1"
+    p-is-promise "^1.1.0"
+
 invariant@^2.2.0, invariant@^2.2.2:
   version "2.2.3"
   resolved "https://registry.yarnpkg.com/invariant/-/invariant-2.2.3.tgz#1a827dfde7dcbd7c323f0ca826be8fa7c5e9d688"
@@ -3969,7 +3957,7 @@ is-binary-path@^1.0.0:
   dependencies:
     binary-extensions "^1.0.0"
 
-is-buffer@^1.0.2, is-buffer@^1.1.5, is-buffer@~1.1.1:
+is-buffer@^1.1.5, is-buffer@~1.1.1:
   version "1.1.6"
   resolved "https://registry.yarnpkg.com/is-buffer/-/is-buffer-1.1.6.tgz#efaa2ea9daa0d7ab2ea13a97b2b8ad51fefbe8be"
 
@@ -4087,7 +4075,7 @@ is-glob@^4.0.0:
   dependencies:
     is-extglob "^2.1.1"
 
-is-my-json-valid@^2.10.0, is-my-json-valid@^2.12.4:
+is-my-json-valid@^2.12.4:
   version "2.16.1"
   resolved "https://registry.yarnpkg.com/is-my-json-valid/-/is-my-json-valid-2.16.1.tgz#5a846777e2c2620d1e69104e5d3a03b1f6088f11"
   dependencies:
@@ -4116,6 +4104,12 @@ is-object@^1.0.1:
   version "1.0.1"
   resolved "https://registry.yarnpkg.com/is-object/-/is-object-1.0.1.tgz#8952688c5ec2ffd6b03ecc85e769e02903083470"
 
+is-observable@^0.2.0:
+  version "0.2.0"
+  resolved "https://registry.yarnpkg.com/is-observable/-/is-observable-0.2.0.tgz#b361311d83c6e5d726cabf5e250b0237106f5ae2"
+  dependencies:
+    symbol-observable "^0.2.2"
+
 is-odd@^2.0.0:
   version "2.0.0"
   resolved "https://registry.yarnpkg.com/is-odd/-/is-odd-2.0.0.tgz#7646624671fd7ea558ccd9a2795182f2958f1b24"
@@ -4176,7 +4170,7 @@ is-resolvable@^1.0.0:
   dependencies:
     tryit "^1.0.1"
 
-is-retry-allowed@^1.0.0:
+is-retry-allowed@^1.0.0, is-retry-allowed@^1.1.0:
   version "1.1.0"
   resolved "https://registry.yarnpkg.com/is-retry-allowed/-/is-retry-allowed-1.1.0.tgz#11a060568b67339444033d0125a61a20d564fb34"
 
@@ -4320,19 +4314,19 @@ isurl@^1.0.0-alpha5:
     has-to-string-tag-x "^1.2.0"
     is-object "^1.0.1"
 
-jasmine-core@2.4.1:
-  version "2.4.1"
-  resolved "https://registry.yarnpkg.com/jasmine-core/-/jasmine-core-2.4.1.tgz#6f83ab3a0f16951722ce07d206c773d57cc838be"
+jasmine-core@^3.1.0:
+  version "3.1.0"
+  resolved "https://registry.yarnpkg.com/jasmine-core/-/jasmine-core-3.1.0.tgz#a4785e135d5df65024dfc9224953df585bd2766c"
 
-jest-changed-files@^22.2.0:
-  version "22.2.0"
-  resolved "https://registry.yarnpkg.com/jest-changed-files/-/jest-changed-files-22.2.0.tgz#517610c4a8ca0925bdc88b0ca53bd678aa8d019e"
+jest-changed-files@^22.4.3:
+  version "22.4.3"
+  resolved "https://registry.yarnpkg.com/jest-changed-files/-/jest-changed-files-22.4.3.tgz#8882181e022c38bd46a2e4d18d44d19d90a90fb2"
   dependencies:
     throat "^4.0.0"
 
-jest-cli@^22.4.2:
-  version "22.4.2"
-  resolved "https://registry.yarnpkg.com/jest-cli/-/jest-cli-22.4.2.tgz#e6546dc651e13d164481aa3e76e53ac4f4edab06"
+jest-cli@^22.4.3:
+  version "22.4.3"
+  resolved "https://registry.yarnpkg.com/jest-cli/-/jest-cli-22.4.3.tgz#bf16c4a5fb7edc3fa5b9bb7819e34139e88a72c7"
   dependencies:
     ansi-escapes "^3.0.0"
     chalk "^2.0.1"
@@ -4345,20 +4339,20 @@ jest-cli@^22.4.2:
     istanbul-lib-coverage "^1.1.1"
     istanbul-lib-instrument "^1.8.0"
     istanbul-lib-source-maps "^1.2.1"
-    jest-changed-files "^22.2.0"
-    jest-config "^22.4.2"
-    jest-environment-jsdom "^22.4.1"
-    jest-get-type "^22.1.0"
-    jest-haste-map "^22.4.2"
-    jest-message-util "^22.4.0"
-    jest-regex-util "^22.1.0"
-    jest-resolve-dependencies "^22.1.0"
-    jest-runner "^22.4.2"
-    jest-runtime "^22.4.2"
-    jest-snapshot "^22.4.0"
-    jest-util "^22.4.1"
-    jest-validate "^22.4.2"
-    jest-worker "^22.2.2"
+    jest-changed-files "^22.4.3"
+    jest-config "^22.4.3"
+    jest-environment-jsdom "^22.4.3"
+    jest-get-type "^22.4.3"
+    jest-haste-map "^22.4.3"
+    jest-message-util "^22.4.3"
+    jest-regex-util "^22.4.3"
+    jest-resolve-dependencies "^22.4.3"
+    jest-runner "^22.4.3"
+    jest-runtime "^22.4.3"
+    jest-snapshot "^22.4.3"
+    jest-util "^22.4.3"
+    jest-validate "^22.4.3"
+    jest-worker "^22.4.3"
     micromatch "^2.3.11"
     node-notifier "^5.2.1"
     realpath-native "^1.0.0"
@@ -4369,101 +4363,101 @@ jest-cli@^22.4.2:
     which "^1.2.12"
     yargs "^10.0.3"
 
-jest-config@^22.4.2:
-  version "22.4.2"
-  resolved "https://registry.yarnpkg.com/jest-config/-/jest-config-22.4.2.tgz#580ba5819bf81a5e48f4fd470e8b81834f45c855"
+jest-config@^22.4.3:
+  version "22.4.3"
+  resolved "https://registry.yarnpkg.com/jest-config/-/jest-config-22.4.3.tgz#0e9d57db267839ea31309119b41dc2fa31b76403"
   dependencies:
     chalk "^2.0.1"
     glob "^7.1.1"
-    jest-environment-jsdom "^22.4.1"
-    jest-environment-node "^22.4.1"
-    jest-get-type "^22.1.0"
-    jest-jasmine2 "^22.4.2"
-    jest-regex-util "^22.1.0"
-    jest-resolve "^22.4.2"
-    jest-util "^22.4.1"
-    jest-validate "^22.4.2"
-    pretty-format "^22.4.0"
-
-jest-diff@^22.4.0:
-  version "22.4.0"
-  resolved "https://registry.yarnpkg.com/jest-diff/-/jest-diff-22.4.0.tgz#384c2b78519ca44ca126382df53f134289232525"
+    jest-environment-jsdom "^22.4.3"
+    jest-environment-node "^22.4.3"
+    jest-get-type "^22.4.3"
+    jest-jasmine2 "^22.4.3"
+    jest-regex-util "^22.4.3"
+    jest-resolve "^22.4.3"
+    jest-util "^22.4.3"
+    jest-validate "^22.4.3"
+    pretty-format "^22.4.3"
+
+jest-diff@^22.4.3:
+  version "22.4.3"
+  resolved "https://registry.yarnpkg.com/jest-diff/-/jest-diff-22.4.3.tgz#e18cc3feff0aeef159d02310f2686d4065378030"
   dependencies:
     chalk "^2.0.1"
     diff "^3.2.0"
-    jest-get-type "^22.1.0"
-    pretty-format "^22.4.0"
+    jest-get-type "^22.4.3"
+    pretty-format "^22.4.3"
 
-jest-docblock@^22.4.0:
-  version "22.4.0"
-  resolved "https://registry.yarnpkg.com/jest-docblock/-/jest-docblock-22.4.0.tgz#dbf1877e2550070cfc4d9b07a55775a0483159b8"
+jest-docblock@^22.4.3:
+  version "22.4.3"
+  resolved "https://registry.yarnpkg.com/jest-docblock/-/jest-docblock-22.4.3.tgz#50886f132b42b280c903c592373bb6e93bb68b19"
   dependencies:
     detect-newline "^2.1.0"
 
-jest-environment-jsdom@^22.4.1:
-  version "22.4.1"
-  resolved "https://registry.yarnpkg.com/jest-environment-jsdom/-/jest-environment-jsdom-22.4.1.tgz#754f408872441740100d3917e5ec40c74de6447f"
+jest-environment-jsdom@^22.4.3:
+  version "22.4.3"
+  resolved "https://registry.yarnpkg.com/jest-environment-jsdom/-/jest-environment-jsdom-22.4.3.tgz#d67daa4155e33516aecdd35afd82d4abf0fa8a1e"
   dependencies:
-    jest-mock "^22.2.0"
-    jest-util "^22.4.1"
+    jest-mock "^22.4.3"
+    jest-util "^22.4.3"
     jsdom "^11.5.1"
 
-jest-environment-node@^22.4.1:
-  version "22.4.1"
-  resolved "https://registry.yarnpkg.com/jest-environment-node/-/jest-environment-node-22.4.1.tgz#418850eb654596b8d6e36c2021cbedbc23df8e16"
+jest-environment-node@^22.4.3:
+  version "22.4.3"
+  resolved "https://registry.yarnpkg.com/jest-environment-node/-/jest-environment-node-22.4.3.tgz#54c4eaa374c83dd52a9da8759be14ebe1d0b9129"
   dependencies:
-    jest-mock "^22.2.0"
-    jest-util "^22.4.1"
+    jest-mock "^22.4.3"
+    jest-util "^22.4.3"
 
-jest-get-type@^22.1.0:
-  version "22.1.0"
-  resolved "https://registry.yarnpkg.com/jest-get-type/-/jest-get-type-22.1.0.tgz#4e90af298ed6181edc85d2da500dbd2753e0d5a9"
+jest-get-type@^22.4.3:
+  version "22.4.3"
+  resolved "https://registry.yarnpkg.com/jest-get-type/-/jest-get-type-22.4.3.tgz#e3a8504d8479342dd4420236b322869f18900ce4"
 
-jest-haste-map@^22.4.2:
-  version "22.4.2"
-  resolved "https://registry.yarnpkg.com/jest-haste-map/-/jest-haste-map-22.4.2.tgz#a90178e66146d4378bb076345a949071f3b015b4"
+jest-haste-map@^22.4.3:
+  version "22.4.3"
+  resolved "https://registry.yarnpkg.com/jest-haste-map/-/jest-haste-map-22.4.3.tgz#25842fa2ba350200767ac27f658d58b9d5c2e20b"
   dependencies:
     fb-watchman "^2.0.0"
     graceful-fs "^4.1.11"
-    jest-docblock "^22.4.0"
-    jest-serializer "^22.4.0"
-    jest-worker "^22.2.2"
+    jest-docblock "^22.4.3"
+    jest-serializer "^22.4.3"
+    jest-worker "^22.4.3"
     micromatch "^2.3.11"
     sane "^2.0.0"
 
-jest-jasmine2@^22.4.2:
-  version "22.4.2"
-  resolved "https://registry.yarnpkg.com/jest-jasmine2/-/jest-jasmine2-22.4.2.tgz#dfd3d259579ed6f52510d8f1ab692808f0d40691"
+jest-jasmine2@^22.4.3:
+  version "22.4.3"
+  resolved "https://registry.yarnpkg.com/jest-jasmine2/-/jest-jasmine2-22.4.3.tgz#4daf64cd14c793da9db34a7c7b8dcfe52a745965"
   dependencies:
     chalk "^2.0.1"
     co "^4.6.0"
-    expect "^22.4.0"
+    expect "^22.4.3"
     graceful-fs "^4.1.11"
     is-generator-fn "^1.0.0"
-    jest-diff "^22.4.0"
-    jest-matcher-utils "^22.4.0"
-    jest-message-util "^22.4.0"
-    jest-snapshot "^22.4.0"
-    jest-util "^22.4.1"
+    jest-diff "^22.4.3"
+    jest-matcher-utils "^22.4.3"
+    jest-message-util "^22.4.3"
+    jest-snapshot "^22.4.3"
+    jest-util "^22.4.3"
     source-map-support "^0.5.0"
 
-jest-leak-detector@^22.4.0:
-  version "22.4.0"
-  resolved "https://registry.yarnpkg.com/jest-leak-detector/-/jest-leak-detector-22.4.0.tgz#64da77f05b001c96d2062226e079f89989c4aa2f"
+jest-leak-detector@^22.4.3:
+  version "22.4.3"
+  resolved "https://registry.yarnpkg.com/jest-leak-detector/-/jest-leak-detector-22.4.3.tgz#2b7b263103afae8c52b6b91241a2de40117e5b35"
   dependencies:
-    pretty-format "^22.4.0"
+    pretty-format "^22.4.3"
 
-jest-matcher-utils@^22.4.0:
-  version "22.4.0"
-  resolved "https://registry.yarnpkg.com/jest-matcher-utils/-/jest-matcher-utils-22.4.0.tgz#d55f5faf2270462736bdf7c7485ee931c9d4b6a1"
+jest-matcher-utils@^22.4.3:
+  version "22.4.3"
+  resolved "https://registry.yarnpkg.com/jest-matcher-utils/-/jest-matcher-utils-22.4.3.tgz#4632fe428ebc73ebc194d3c7b65d37b161f710ff"
   dependencies:
     chalk "^2.0.1"
-    jest-get-type "^22.1.0"
-    pretty-format "^22.4.0"
+    jest-get-type "^22.4.3"
+    pretty-format "^22.4.3"
 
-jest-message-util@^22.4.0:
-  version "22.4.0"
-  resolved "https://registry.yarnpkg.com/jest-message-util/-/jest-message-util-22.4.0.tgz#e3d861df16d2fee60cb2bc8feac2188a42579642"
+jest-message-util@^22.4.3:
+  version "22.4.3"
+  resolved "https://registry.yarnpkg.com/jest-message-util/-/jest-message-util-22.4.3.tgz#cf3d38aafe4befddbfc455e57d65d5239e399eb7"
   dependencies:
     "@babel/code-frame" "^7.0.0-beta.35"
     chalk "^2.0.1"
@@ -4471,60 +4465,60 @@ jest-message-util@^22.4.0:
     slash "^1.0.0"
     stack-utils "^1.0.1"
 
-jest-mock@^22.2.0:
-  version "22.2.0"
-  resolved "https://registry.yarnpkg.com/jest-mock/-/jest-mock-22.2.0.tgz#444b3f9488a7473adae09bc8a77294afded397a7"
+jest-mock@^22.4.3:
+  version "22.4.3"
+  resolved "https://registry.yarnpkg.com/jest-mock/-/jest-mock-22.4.3.tgz#f63ba2f07a1511772cdc7979733397df770aabc7"
 
-jest-regex-util@^22.1.0:
-  version "22.1.0"
-  resolved "https://registry.yarnpkg.com/jest-regex-util/-/jest-regex-util-22.1.0.tgz#5daf2fe270074b6da63e5d85f1c9acc866768f53"
+jest-regex-util@^22.4.3:
+  version "22.4.3"
+  resolved "https://registry.yarnpkg.com/jest-regex-util/-/jest-regex-util-22.4.3.tgz#a826eb191cdf22502198c5401a1fc04de9cef5af"
 
-jest-resolve-dependencies@^22.1.0:
-  version "22.1.0"
-  resolved "https://registry.yarnpkg.com/jest-resolve-dependencies/-/jest-resolve-dependencies-22.1.0.tgz#340e4139fb13315cd43abc054e6c06136be51e31"
+jest-resolve-dependencies@^22.4.3:
+  version "22.4.3"
+  resolved "https://registry.yarnpkg.com/jest-resolve-dependencies/-/jest-resolve-dependencies-22.4.3.tgz#e2256a5a846732dc3969cb72f3c9ad7725a8195e"
   dependencies:
-    jest-regex-util "^22.1.0"
+    jest-regex-util "^22.4.3"
 
-jest-resolve@^22.4.2:
-  version "22.4.2"
-  resolved "https://registry.yarnpkg.com/jest-resolve/-/jest-resolve-22.4.2.tgz#25d88aa4147462c9c1c6a1ba16250d3794c24d00"
+jest-resolve@^22.4.3:
+  version "22.4.3"
+  resolved "https://registry.yarnpkg.com/jest-resolve/-/jest-resolve-22.4.3.tgz#0ce9d438c8438229aa9b916968ec6b05c1abb4ea"
   dependencies:
     browser-resolve "^1.11.2"
     chalk "^2.0.1"
 
-jest-runner@^22.4.2:
-  version "22.4.2"
-  resolved "https://registry.yarnpkg.com/jest-runner/-/jest-runner-22.4.2.tgz#19390ea9d99f768973e16f95a1efa351c0017e87"
+jest-runner@^22.4.3:
+  version "22.4.3"
+  resolved "https://registry.yarnpkg.com/jest-runner/-/jest-runner-22.4.3.tgz#298ddd6a22b992c64401b4667702b325e50610c3"
   dependencies:
     exit "^0.1.2"
-    jest-config "^22.4.2"
-    jest-docblock "^22.4.0"
-    jest-haste-map "^22.4.2"
-    jest-jasmine2 "^22.4.2"
-    jest-leak-detector "^22.4.0"
-    jest-message-util "^22.4.0"
-    jest-runtime "^22.4.2"
-    jest-util "^22.4.1"
-    jest-worker "^22.2.2"
+    jest-config "^22.4.3"
+    jest-docblock "^22.4.3"
+    jest-haste-map "^22.4.3"
+    jest-jasmine2 "^22.4.3"
+    jest-leak-detector "^22.4.3"
+    jest-message-util "^22.4.3"
+    jest-runtime "^22.4.3"
+    jest-util "^22.4.3"
+    jest-worker "^22.4.3"
     throat "^4.0.0"
 
-jest-runtime@^22.4.2:
-  version "22.4.2"
-  resolved "https://registry.yarnpkg.com/jest-runtime/-/jest-runtime-22.4.2.tgz#0de0444f65ce15ee4f2e0055133fc7c17b9168f3"
+jest-runtime@^22.4.3:
+  version "22.4.3"
+  resolved "https://registry.yarnpkg.com/jest-runtime/-/jest-runtime-22.4.3.tgz#b69926c34b851b920f666c93e86ba2912087e3d0"
   dependencies:
     babel-core "^6.0.0"
-    babel-jest "^22.4.1"
+    babel-jest "^22.4.3"
     babel-plugin-istanbul "^4.1.5"
     chalk "^2.0.1"
     convert-source-map "^1.4.0"
     exit "^0.1.2"
     graceful-fs "^4.1.11"
-    jest-config "^22.4.2"
-    jest-haste-map "^22.4.2"
-    jest-regex-util "^22.1.0"
-    jest-resolve "^22.4.2"
-    jest-util "^22.4.1"
-    jest-validate "^22.4.2"
+    jest-config "^22.4.3"
+    jest-haste-map "^22.4.3"
+    jest-regex-util "^22.4.3"
+    jest-resolve "^22.4.3"
+    jest-util "^22.4.3"
+    jest-validate "^22.4.3"
     json-stable-stringify "^1.0.1"
     micromatch "^2.3.11"
     realpath-native "^1.0.0"
@@ -4533,55 +4527,55 @@ jest-runtime@^22.4.2:
     write-file-atomic "^2.1.0"
     yargs "^10.0.3"
 
-jest-serializer@^22.4.0:
-  version "22.4.0"
-  resolved "https://registry.yarnpkg.com/jest-serializer/-/jest-serializer-22.4.0.tgz#b5d145b98c4b0d2c20ab686609adbb81fe23b566"
+jest-serializer@^22.4.3:
+  version "22.4.3"
+  resolved "https://registry.yarnpkg.com/jest-serializer/-/jest-serializer-22.4.3.tgz#a679b81a7f111e4766235f4f0c46d230ee0f7436"
 
-jest-snapshot@^22.4.0:
-  version "22.4.0"
-  resolved "https://registry.yarnpkg.com/jest-snapshot/-/jest-snapshot-22.4.0.tgz#03d3ce63f8fa7352388afc6a3c8b5ccc3a180ed7"
+jest-snapshot@^22.4.3:
+  version "22.4.3"
+  resolved "https://registry.yarnpkg.com/jest-snapshot/-/jest-snapshot-22.4.3.tgz#b5c9b42846ffb9faccb76b841315ba67887362d2"
   dependencies:
     chalk "^2.0.1"
-    jest-diff "^22.4.0"
-    jest-matcher-utils "^22.4.0"
+    jest-diff "^22.4.3"
+    jest-matcher-utils "^22.4.3"
     mkdirp "^0.5.1"
     natural-compare "^1.4.0"
-    pretty-format "^22.4.0"
+    pretty-format "^22.4.3"
 
-jest-util@^22.4.1:
-  version "22.4.1"
-  resolved "https://registry.yarnpkg.com/jest-util/-/jest-util-22.4.1.tgz#dd17c3bdb067f8e90591563ec0c42bf847dc249f"
+jest-util@^22.4.3:
+  version "22.4.3"
+  resolved "https://registry.yarnpkg.com/jest-util/-/jest-util-22.4.3.tgz#c70fec8eec487c37b10b0809dc064a7ecf6aafac"
   dependencies:
     callsites "^2.0.0"
     chalk "^2.0.1"
     graceful-fs "^4.1.11"
     is-ci "^1.0.10"
-    jest-message-util "^22.4.0"
+    jest-message-util "^22.4.3"
     mkdirp "^0.5.1"
     source-map "^0.6.0"
 
-jest-validate@^22.4.2:
-  version "22.4.2"
-  resolved "https://registry.yarnpkg.com/jest-validate/-/jest-validate-22.4.2.tgz#e789a4e056173bf97fe797a2df2d52105c57d4f4"
+jest-validate@^22.4.3:
+  version "22.4.3"
+  resolved "https://registry.yarnpkg.com/jest-validate/-/jest-validate-22.4.3.tgz#0780954a5a7daaeec8d3c10834b9280865976b30"
   dependencies:
     chalk "^2.0.1"
-    jest-config "^22.4.2"
-    jest-get-type "^22.1.0"
+    jest-config "^22.4.3"
+    jest-get-type "^22.4.3"
     leven "^2.1.0"
-    pretty-format "^22.4.0"
+    pretty-format "^22.4.3"
 
-jest-worker@^22.2.2:
-  version "22.2.2"
-  resolved "https://registry.yarnpkg.com/jest-worker/-/jest-worker-22.2.2.tgz#c1f5dc39976884b81f68ec50cb8532b2cbab3390"
+jest-worker@^22.4.3:
+  version "22.4.3"
+  resolved "https://registry.yarnpkg.com/jest-worker/-/jest-worker-22.4.3.tgz#5c421417cba1c0abf64bf56bd5fb7968d79dd40b"
   dependencies:
     merge-stream "^1.0.1"
 
-jest@^22.1.2:
-  version "22.4.2"
-  resolved "https://registry.yarnpkg.com/jest/-/jest-22.4.2.tgz#34012834a49bf1bdd3bc783850ab44e4499afc20"
+jest@^22.4.3:
+  version "22.4.3"
+  resolved "https://registry.yarnpkg.com/jest/-/jest-22.4.3.tgz#2261f4b117dc46d9a4a1a673d2150958dee92f16"
   dependencies:
     import-local "^1.0.0"
-    jest-cli "^22.4.2"
+    jest-cli "^22.4.3"
 
 "jquery-sparkline@https://github.com/kapusta/jquery.sparkline#2.1.3":
   version "2.1.3"
@@ -4634,13 +4628,20 @@ js-tokens@^3.0.0, js-tokens@^3.0.2:
   version "3.0.2"
   resolved "https://registry.yarnpkg.com/js-tokens/-/js-tokens-3.0.2.tgz#9866df395102130e38f7f996bceb65443209c25b"
 
-js-yaml@^3.5.1, js-yaml@^3.7.0:
+js-yaml@^3.7.0:
   version "3.10.0"
   resolved "https://registry.yarnpkg.com/js-yaml/-/js-yaml-3.10.0.tgz#2e78441646bd4682e963f22b6e92823c309c62dc"
   dependencies:
     argparse "^1.0.7"
     esprima "^4.0.0"
 
+js-yaml@^3.9.1:
+  version "3.11.0"
+  resolved "https://registry.yarnpkg.com/js-yaml/-/js-yaml-3.11.0.tgz#597c1a8bd57152f26d622ce4117851a51f5ebaef"
+  dependencies:
+    argparse "^1.0.7"
+    esprima "^4.0.0"
+
 js-yaml@~3.7.0:
   version "3.7.0"
   resolved "https://registry.yarnpkg.com/js-yaml/-/js-yaml-3.7.0.tgz#5c967ddd837a9bfdca5f2de84253abe8a1c03b80"
@@ -4676,6 +4677,26 @@ jscodeshift@^0.4.0:
     temp "^0.8.1"
     write-file-atomic "^1.2.0"
 
+jscodeshift@^0.5.0:
+  version "0.5.0"
+  resolved "https://registry.yarnpkg.com/jscodeshift/-/jscodeshift-0.5.0.tgz#bdb7b6cc20dd62c16aa728c3fa2d2fe66ca7c748"
+  dependencies:
+    babel-plugin-transform-flow-strip-types "^6.8.0"
+    babel-preset-es2015 "^6.9.0"
+    babel-preset-stage-1 "^6.5.0"
+    babel-register "^6.9.0"
+    babylon "^7.0.0-beta.30"
+    colors "^1.1.2"
+    flow-parser "^0.*"
+    lodash "^4.13.1"
+    micromatch "^2.3.7"
+    neo-async "^2.5.0"
+    node-dir "0.1.8"
+    nomnom "^1.8.1"
+    recast "^0.14.1"
+    temp "^0.8.1"
+    write-file-atomic "^1.2.0"
+
 jsdom@^11.5.1:
   version "11.6.2"
   resolved "https://registry.yarnpkg.com/jsdom/-/jsdom-11.6.2.tgz#25d1ef332d48adf77fc5221fe2619967923f16bb"
@@ -4719,6 +4740,14 @@ jsesc@^2.5.1:
   version "2.5.1"
   resolved "https://registry.yarnpkg.com/jsesc/-/jsesc-2.5.1.tgz#e421a2a8e20d6b0819df28908f782526b96dd1fe"
 
+json-buffer@3.0.0:
+  version "3.0.0"
+  resolved "https://registry.yarnpkg.com/json-buffer/-/json-buffer-3.0.0.tgz#5b1f397afc75d677bde8bcfc0e47e1f9a3d9a898"
+
+json-parse-better-errors@^1.0.1:
+  version "1.0.1"
+  resolved "https://registry.yarnpkg.com/json-parse-better-errors/-/json-parse-better-errors-1.0.1.tgz#50183cd1b2d25275de069e9e71b467ac9eab973a"
+
 json-schema-traverse@^0.3.0:
   version "0.3.1"
   resolved "https://registry.yarnpkg.com/json-schema-traverse/-/json-schema-traverse-0.3.1.tgz#349a6d44c53a51de89b40805c5d5e59b417d3340"
@@ -4727,6 +4756,10 @@ json-schema@0.2.3:
   version "0.2.3"
   resolved "https://registry.yarnpkg.com/json-schema/-/json-schema-0.2.3.tgz#b480c892e59a2f05954ce727bd3f2a4e882f9e13"
 
+json-stable-stringify-without-jsonify@^1.0.1:
+  version "1.0.1"
+  resolved "https://registry.yarnpkg.com/json-stable-stringify-without-jsonify/-/json-stable-stringify-without-jsonify-1.0.1.tgz#9db7b59496ad3f3cfef30a75142d2d930ad72651"
+
 json-stable-stringify@^1.0.0, json-stable-stringify@^1.0.1:
   version "1.0.1"
   resolved "https://registry.yarnpkg.com/json-stable-stringify/-/json-stable-stringify-1.0.1.tgz#9a759d39c5f2ff503fd5300646ed445f88c4f9af"
@@ -4768,13 +4801,13 @@ kew@^0.7.0:
   version "0.7.0"
   resolved "https://registry.yarnpkg.com/kew/-/kew-0.7.0.tgz#79d93d2d33363d6fdd2970b335d9141ad591d79b"
 
-kind-of@^2.0.1:
-  version "2.0.1"
-  resolved "https://registry.yarnpkg.com/kind-of/-/kind-of-2.0.1.tgz#018ec7a4ce7e3a86cb9141be519d24c8faa981b5"
+keyv@3.0.0:
+  version "3.0.0"
+  resolved "https://registry.yarnpkg.com/keyv/-/keyv-3.0.0.tgz#44923ba39e68b12a7cec7df6c3268c031f2ef373"
   dependencies:
-    is-buffer "^1.0.2"
+    json-buffer "3.0.0"
 
-kind-of@^3.0.2, kind-of@^3.0.3, kind-of@^3.2.0, kind-of@^3.2.2:
+kind-of@^3.0.2, kind-of@^3.0.3, kind-of@^3.2.0:
   version "3.2.2"
   resolved "https://registry.yarnpkg.com/kind-of/-/kind-of-3.2.2.tgz#31ea21a734bab9bbb0f32466d893aea51e4a3c64"
   dependencies:
@@ -4800,10 +4833,6 @@ klaw@^1.0.0:
   optionalDependencies:
     graceful-fs "^4.1.9"
 
-lazy-cache@^0.2.3:
-  version "0.2.7"
-  resolved "https://registry.yarnpkg.com/lazy-cache/-/lazy-cache-0.2.7.tgz#7feddf2dcb6edb77d11ef1d117ab5ffdf0ab1b65"
-
 lazy-cache@^1.0.3:
   version "1.0.4"
   resolved "https://registry.yarnpkg.com/lazy-cache/-/lazy-cache-1.0.4.tgz#a1d78fc3a50474cb80845d3b3b6e1da49a446e8e"
@@ -4853,9 +4882,9 @@ listr-silent-renderer@^1.1.1:
   version "1.1.1"
   resolved "https://registry.yarnpkg.com/listr-silent-renderer/-/listr-silent-renderer-1.1.1.tgz#924b5a3757153770bf1a8e3fbf74b8bbf3f9242e"
 
-listr-update-renderer@^0.2.0:
-  version "0.2.0"
-  resolved "https://registry.yarnpkg.com/listr-update-renderer/-/listr-update-renderer-0.2.0.tgz#ca80e1779b4e70266807e8eed1ad6abe398550f9"
+listr-update-renderer@^0.4.0:
+  version "0.4.0"
+  resolved "https://registry.yarnpkg.com/listr-update-renderer/-/listr-update-renderer-0.4.0.tgz#344d980da2ca2e8b145ba305908f32ae3f4cc8a7"
   dependencies:
     chalk "^1.1.3"
     cli-truncate "^0.2.1"
@@ -4875,25 +4904,26 @@ listr-verbose-renderer@^0.4.0:
     date-fns "^1.27.2"
     figures "^1.7.0"
 
-listr@^0.12.0:
-  version "0.12.0"
-  resolved "https://registry.yarnpkg.com/listr/-/listr-0.12.0.tgz#6bce2c0f5603fa49580ea17cd6a00cc0e5fa451a"
+listr@^0.13.0:
+  version "0.13.0"
+  resolved "https://registry.yarnpkg.com/listr/-/listr-0.13.0.tgz#20bb0ba30bae660ee84cc0503df4be3d5623887d"
   dependencies:
     chalk "^1.1.3"
     cli-truncate "^0.2.1"
     figures "^1.7.0"
     indent-string "^2.1.0"
+    is-observable "^0.2.0"
     is-promise "^2.1.0"
     is-stream "^1.1.0"
     listr-silent-renderer "^1.1.1"
-    listr-update-renderer "^0.2.0"
+    listr-update-renderer "^0.4.0"
     listr-verbose-renderer "^0.4.0"
     log-symbols "^1.0.2"
     log-update "^1.0.2"
     ora "^0.2.3"
     p-map "^1.1.1"
-    rxjs "^5.0.0-beta.11"
-    stream-to-observable "^0.1.0"
+    rxjs "^5.4.2"
+    stream-to-observable "^0.2.0"
     strip-ansi "^3.0.1"
 
 load-json-file@^1.0.0:
@@ -4906,13 +4936,13 @@ load-json-file@^1.0.0:
     pinkie-promise "^2.0.0"
     strip-bom "^2.0.0"
 
-load-json-file@^2.0.0:
-  version "2.0.0"
-  resolved "https://registry.yarnpkg.com/load-json-file/-/load-json-file-2.0.0.tgz#7947e42149af80d696cbf797bcaabcfe1fe29ca8"
+load-json-file@^4.0.0:
+  version "4.0.0"
+  resolved "https://registry.yarnpkg.com/load-json-file/-/load-json-file-4.0.0.tgz#2f5f45ab91e33216234fd53adab668eb4ec0993b"
   dependencies:
     graceful-fs "^4.1.2"
-    parse-json "^2.2.0"
-    pify "^2.0.0"
+    parse-json "^4.0.0"
+    pify "^3.0.0"
     strip-bom "^3.0.0"
 
 loader-fs-cache@^1.0.0:
@@ -4926,7 +4956,7 @@ loader-runner@^2.3.0:
   version "2.3.0"
   resolved "https://registry.yarnpkg.com/loader-runner/-/loader-runner-2.3.0.tgz#f482aea82d543e07921700d5a46ef26fdac6b8a2"
 
-loader-utils@^0.2.15, loader-utils@^0.2.5, loader-utils@~0.2.2, loader-utils@~0.2.3, loader-utils@~0.2.5:
+loader-utils@^0.2.5, loader-utils@~0.2.2, loader-utils@~0.2.3, loader-utils@~0.2.5:
   version "0.2.17"
   resolved "https://registry.yarnpkg.com/loader-utils/-/loader-utils-0.2.17.tgz#f86e6374d43205a6e6c60e9196f17c0299bfb348"
   dependencies:
@@ -5131,23 +5161,17 @@ lodash@^4.0.0, lodash@^4.6.0, lodash@~4.17.4:
   version "4.17.4"
   resolved "https://registry.yarnpkg.com/lodash/-/lodash-4.17.4.tgz#78203a4d1c328ae1d86dca6460e369b57f4055ae"
 
-lodash@^4.11.1, lodash@^4.13.1, lodash@^4.14.0, lodash@^4.17.2, lodash@^4.17.4, lodash@^4.2.0, lodash@^4.3.0:
+lodash@^4.13.1, lodash@^4.14.0, lodash@^4.17.2, lodash@^4.17.4, lodash@^4.17.5, lodash@^4.2.0, lodash@^4.3.0:
   version "4.17.5"
   resolved "https://registry.yarnpkg.com/lodash/-/lodash-4.17.5.tgz#99a92d65c0272debe8c96b6057bc8fbfa3bed511"
 
-log-symbols@2.1.0:
-  version "2.1.0"
-  resolved "https://registry.yarnpkg.com/log-symbols/-/log-symbols-2.1.0.tgz#f35fa60e278832b538dc4dddcbb478a45d3e3be6"
-  dependencies:
-    chalk "^2.0.1"
-
-log-symbols@^1.0.1, log-symbols@^1.0.2:
+log-symbols@^1.0.2:
   version "1.0.2"
   resolved "https://registry.yarnpkg.com/log-symbols/-/log-symbols-1.0.2.tgz#376ff7b58ea3086a0f09facc74617eca501e1a18"
   dependencies:
     chalk "^1.0.0"
 
-log-symbols@^2.1.0:
+log-symbols@^2.1.0, log-symbols@^2.2.0:
   version "2.2.0"
   resolved "https://registry.yarnpkg.com/log-symbols/-/log-symbols-2.2.0.tgz#5740e1c5d6f0dfda4ad9323b5332107ef6b4c40a"
   dependencies:
@@ -5181,7 +5205,7 @@ lower-case@^1.1.1:
   version "1.1.4"
   resolved "https://registry.yarnpkg.com/lower-case/-/lower-case-1.1.4.tgz#9a2cabd1b9e8e0ae993a4bf7d5875c39c42e8eac"
 
-lowercase-keys@^1.0.0:
+lowercase-keys@1.0.0, lowercase-keys@^1.0.0:
   version "1.0.0"
   resolved "https://registry.yarnpkg.com/lowercase-keys/-/lowercase-keys-1.0.0.tgz#4e3366b39e7f5457e35f1324bdf6f88d0bfc7306"
 
@@ -5196,7 +5220,7 @@ macaddress@^0.2.8:
   version "0.2.8"
   resolved "https://registry.yarnpkg.com/macaddress/-/macaddress-0.2.8.tgz#5904dc537c39ec6dbefeae902327135fa8511f12"
 
-main-bower-files@2.13.1:
+main-bower-files@^2.13.1:
   version "2.13.1"
   resolved "https://registry.yarnpkg.com/main-bower-files/-/main-bower-files-2.13.1.tgz#7e1bc5c498352ccecd5df087f13d5f31bc057d3e"
   dependencies:
@@ -5208,7 +5232,7 @@ main-bower-files@2.13.1:
     strip-json-comments "^1.0.2"
     vinyl-fs "^2.4.3"
 
-make-dir@^1.0.0:
+make-dir@^1.0.0, make-dir@^1.1.0:
   version "1.2.0"
   resolved "https://registry.yarnpkg.com/make-dir/-/make-dir-1.2.0.tgz#6d6a49eead4aae296c53bbf3a1a008bd6c89469b"
   dependencies:
@@ -5257,7 +5281,7 @@ media-typer@0.3.0:
   version "0.3.0"
   resolved "https://registry.yarnpkg.com/media-typer/-/media-typer-0.3.0.tgz#8710d7af0aa626f8fffa1ce00168545263255748"
 
-mem-fs-editor@^3.0.0:
+mem-fs-editor@^3.0.2:
   version "3.0.2"
   resolved "https://registry.yarnpkg.com/mem-fs-editor/-/mem-fs-editor-3.0.2.tgz#dd0a6eaf2bb8a6b37740067aa549eb530105af9f"
   dependencies:
@@ -5391,12 +5415,6 @@ mimic-response@^1.0.0:
   version "1.0.0"
   resolved "https://registry.yarnpkg.com/mimic-response/-/mimic-response-1.0.0.tgz#df3d3652a73fded6b9b0b24146e6fd052353458e"
 
-min-document@^2.19.0:
-  version "2.19.0"
-  resolved "https://registry.yarnpkg.com/min-document/-/min-document-2.19.0.tgz#7bd282e3f5842ed295bb748cdd9f1ffa2c824685"
-  dependencies:
-    dom-walk "^0.1.0"
-
 minimalistic-assert@^1.0.0:
   version "1.0.0"
   resolved "https://registry.yarnpkg.com/minimalistic-assert/-/minimalistic-assert-1.0.0.tgz#702be2dda6b37f4836bcb3f5db56641b64a1d3d3"
@@ -5492,26 +5510,18 @@ multimatch@^2.0.0:
     arrify "^1.0.0"
     minimatch "^3.0.0"
 
-mute-stream@0.0.5:
-  version "0.0.5"
-  resolved "https://registry.yarnpkg.com/mute-stream/-/mute-stream-0.0.5.tgz#8fbfabb0a98a253d3184331f9e8deb7372fac6c0"
-
-mute-stream@0.0.6:
-  version "0.0.6"
-  resolved "https://registry.yarnpkg.com/mute-stream/-/mute-stream-0.0.6.tgz#48962b19e169fd1dfc240b3f1e7317627bbc47db"
-
 mute-stream@0.0.7:
   version "0.0.7"
   resolved "https://registry.yarnpkg.com/mute-stream/-/mute-stream-0.0.7.tgz#3075ce93bc21b8fab43e1bc4da7e8115ed1e7bab"
 
+nan@^2.10.0:
+  version "2.10.0"
+  resolved "https://registry.yarnpkg.com/nan/-/nan-2.10.0.tgz#96d0cd610ebd58d4b4de9cc0c6828cda99c7548f"
+
 nan@^2.3.0:
   version "2.9.2"
   resolved "https://registry.yarnpkg.com/nan/-/nan-2.9.2.tgz#f564d75f5f8f36a6d9456cca7a6c4fe488ab7866"
 
-nan@^2.3.2:
-  version "2.8.0"
-  resolved "https://registry.yarnpkg.com/nan/-/nan-2.8.0.tgz#ed715f3fe9de02b57a5e6252d90a96675e1f085a"
-
 nanomatch@^1.2.9:
   version "1.2.9"
   resolved "https://registry.yarnpkg.com/nanomatch/-/nanomatch-1.2.9.tgz#879f7150cb2dab7a471259066c104eee6e0fa7c2"
@@ -5554,6 +5564,10 @@ ngtemplate-loader@^2.0.1:
     jsesc "^0.5.0"
     loader-utils "^1.0.2"
 
+nice-try@^1.0.4:
+  version "1.0.4"
+  resolved "https://registry.yarnpkg.com/nice-try/-/nice-try-1.0.4.tgz#d93962f6c52f2c1558c0fbda6d512819f1efe1c4"
+
 no-case@^2.2.0:
   version "2.3.2"
   resolved "https://registry.yarnpkg.com/no-case/-/no-case-2.3.2.tgz#60b813396be39b3f1288a4c1ed5d1e7d28b464ac"
@@ -5647,9 +5661,9 @@ node-pre-gyp@^0.6.39:
     tar "^2.2.1"
     tar-pack "^3.4.0"
 
-node-sass@^4.7.2:
-  version "4.7.2"
-  resolved "https://registry.yarnpkg.com/node-sass/-/node-sass-4.7.2.tgz#9366778ba1469eb01438a9e8592f4262bcb6794e"
+node-sass@^4.8.3:
+  version "4.8.3"
+  resolved "https://registry.yarnpkg.com/node-sass/-/node-sass-4.8.3.tgz#d077cc20a08ac06f661ca44fb6f19cd2ed41debb"
   dependencies:
     async-foreach "^0.1.3"
     chalk "^1.1.1"
@@ -5663,7 +5677,7 @@ node-sass@^4.7.2:
     lodash.mergewith "^4.6.0"
     meow "^3.7.0"
     mkdirp "^0.5.1"
-    nan "^2.3.2"
+    nan "^2.10.0"
     node-gyp "^3.3.1"
     npmlog "^4.0.0"
     request "~2.79.0"
@@ -5700,7 +5714,7 @@ normalize-package-data@^2.3.2, normalize-package-data@^2.3.4:
     semver "2 || 3 || 4 || 5"
     validate-npm-package-license "^3.0.1"
 
-normalize-path@^2.0.0, normalize-path@^2.0.1:
+normalize-path@^2.0.0, normalize-path@^2.0.1, normalize-path@^2.1.1:
   version "2.1.1"
   resolved "https://registry.yarnpkg.com/normalize-path/-/normalize-path-2.1.1.tgz#1ab28b556e198363a8c1a6f7e6fa20137fe6aed9"
   dependencies:
@@ -5710,6 +5724,14 @@ normalize-range@^0.1.2:
   version "0.1.2"
   resolved "https://registry.yarnpkg.com/normalize-range/-/normalize-range-0.1.2.tgz#2d10c06bdfd312ea9777695a4d28439456b75942"
 
+normalize-url@2.0.1:
+  version "2.0.1"
+  resolved "https://registry.yarnpkg.com/normalize-url/-/normalize-url-2.0.1.tgz#835a9da1551fa26f70e92329069a23aa6574d7e6"
+  dependencies:
+    prepend-http "^2.0.0"
+    query-string "^5.0.1"
+    sort-keys "^2.0.0"
+
 normalize-url@^1.4.0:
   version "1.9.1"
   resolved "https://registry.yarnpkg.com/normalize-url/-/normalize-url-1.9.1.tgz#2cc0d66b31ea23036458436e3620d85954c66c3c"
@@ -5882,11 +5904,7 @@ os-locale@^2.0.0:
     lcid "^1.0.0"
     mem "^1.1.0"
 
-os-shim@^0.1.2:
-  version "0.1.3"
-  resolved "https://registry.yarnpkg.com/os-shim/-/os-shim-0.1.3.tgz#6b62c3791cf7909ea35ed46e17658bb417cb3917"
-
-os-tmpdir@^1.0.0, os-tmpdir@^1.0.1, os-tmpdir@~1.0.1, os-tmpdir@~1.0.2:
+os-tmpdir@^1.0.0, os-tmpdir@^1.0.1, os-tmpdir@~1.0.2:
   version "1.0.2"
   resolved "https://registry.yarnpkg.com/os-tmpdir/-/os-tmpdir-1.0.2.tgz#bbe67406c79aa85c5cfec766fe5734555dfa1274"
 
@@ -5916,6 +5934,10 @@ p-cancelable@^0.3.0:
   version "0.3.0"
   resolved "https://registry.yarnpkg.com/p-cancelable/-/p-cancelable-0.3.0.tgz#b9e123800bcebb7ac13a479be195b507b98d30fa"
 
+p-cancelable@^0.4.0:
+  version "0.4.0"
+  resolved "https://registry.yarnpkg.com/p-cancelable/-/p-cancelable-0.4.0.tgz#bcb41d35bf6097fc4367a065b6eb84b9b124eff0"
+
 p-each-series@^1.0.0:
   version "1.0.0"
   resolved "https://registry.yarnpkg.com/p-each-series/-/p-each-series-1.0.0.tgz#930f3d12dd1f50e7434457a22cd6f04ac6ad7f71"
@@ -5926,6 +5948,10 @@ p-finally@^1.0.0:
   version "1.0.0"
   resolved "https://registry.yarnpkg.com/p-finally/-/p-finally-1.0.0.tgz#3fbcfb15b899a44123b34b6dcc18b724336a2cae"
 
+p-is-promise@^1.1.0:
+  version "1.1.0"
+  resolved "https://registry.yarnpkg.com/p-is-promise/-/p-is-promise-1.1.0.tgz#9c9456989e9f6588017b0434d56097675c3da05e"
+
 p-lazy@^1.0.0:
   version "1.0.0"
   resolved "https://registry.yarnpkg.com/p-lazy/-/p-lazy-1.0.0.tgz#ec53c802f2ee3ac28f166cc82d0b2b02de27a835"
@@ -5956,6 +5982,12 @@ p-timeout@^1.1.1:
   dependencies:
     p-finally "^1.0.0"
 
+p-timeout@^2.0.1:
+  version "2.0.1"
+  resolved "https://registry.yarnpkg.com/p-timeout/-/p-timeout-2.0.1.tgz#d8dd1979595d2dc0139e1fe46b8b646cb3cdf038"
+  dependencies:
+    p-finally "^1.0.0"
+
 p-try@^1.0.0:
   version "1.0.0"
   resolved "https://registry.yarnpkg.com/p-try/-/p-try-1.0.0.tgz#cbc79cdbaf8fd4228e13f621f2b1a237c1b207b3"
@@ -5972,7 +6004,7 @@ parallel-transform@^1.1.0:
     inherits "^2.0.3"
     readable-stream "^2.1.5"
 
-parallel-webpack@^2.2.0:
+parallel-webpack@^2.3.0:
   version "2.3.0"
   resolved "https://registry.yarnpkg.com/parallel-webpack/-/parallel-webpack-2.3.0.tgz#a614625e25647cea9655918cb80cf829fa674ff8"
   dependencies:
@@ -6020,6 +6052,13 @@ parse-json@^2.2.0:
   dependencies:
     error-ex "^1.2.0"
 
+parse-json@^4.0.0:
+  version "4.0.0"
+  resolved "https://registry.yarnpkg.com/parse-json/-/parse-json-4.0.0.tgz#be35f5425be1f7f6c747184f98a788cb99477ee0"
+  dependencies:
+    error-ex "^1.3.1"
+    json-parse-better-errors "^1.0.1"
+
 parse-passwd@^1.0.0:
   version "1.0.0"
   resolved "https://registry.yarnpkg.com/parse-passwd/-/parse-passwd-1.0.0.tgz#6d5b934a456993b23d37f40a382d6f1666a8e5c6"
@@ -6062,11 +6101,11 @@ path-is-absolute@^1.0.0, path-is-absolute@^1.0.1:
   version "1.0.1"
   resolved "https://registry.yarnpkg.com/path-is-absolute/-/path-is-absolute-1.0.1.tgz#174b9268735534ffbc7ace6bf53a5a9e1b5c5f5f"
 
-path-is-inside@^1.0.1:
+path-is-inside@^1.0.1, path-is-inside@^1.0.2:
   version "1.0.2"
   resolved "https://registry.yarnpkg.com/path-is-inside/-/path-is-inside-1.0.2.tgz#365417dede44430d1c11af61027facf074bdfc53"
 
-path-key@^2.0.0:
+path-key@^2.0.0, path-key@^2.0.1:
   version "2.0.1"
   resolved "https://registry.yarnpkg.com/path-key/-/path-key-2.0.1.tgz#411cadb574c5a140d3a4b1910d40d80cc9f40b40"
 
@@ -6086,12 +6125,6 @@ path-type@^1.0.0:
     pify "^2.0.0"
     pinkie-promise "^2.0.0"
 
-path-type@^2.0.0:
-  version "2.0.0"
-  resolved "https://registry.yarnpkg.com/path-type/-/path-type-2.0.0.tgz#f012ccb8415b7096fc2daa1054c3d72389594c73"
-  dependencies:
-    pify "^2.0.0"
-
 path-type@^3.0.0:
   version "3.0.0"
   resolved "https://registry.yarnpkg.com/path-type/-/path-type-3.0.0.tgz#cef31dc8e0a1a3bb0d105c0cd97cf3bf47f4e36f"
@@ -6120,7 +6153,7 @@ performance-now@^2.1.0:
   version "2.1.0"
   resolved "https://registry.yarnpkg.com/performance-now/-/performance-now-2.1.0.tgz#6309f4e0e5fa913ec1c69307ae364b4b377c9e7b"
 
-phantomjs-prebuilt@2.1.16:
+phantomjs-prebuilt@2.1.16, phantomjs-prebuilt@^2.1.16:
   version "2.1.16"
   resolved "https://registry.yarnpkg.com/phantomjs-prebuilt/-/phantomjs-prebuilt-2.1.16.tgz#efd212a4a3966d3647684ea8ba788549be2aefef"
   dependencies:
@@ -6168,6 +6201,10 @@ pluralize@^1.2.1:
   version "1.2.1"
   resolved "https://registry.yarnpkg.com/pluralize/-/pluralize-1.2.1.tgz#d1a21483fd22bb41e58a12fa3421823140897c45"
 
+pluralize@^7.0.0:
+  version "7.0.0"
+  resolved "https://registry.yarnpkg.com/pluralize/-/pluralize-7.0.0.tgz#298b89df8b93b0221dbf421ad2b1b1ea23fc6777"
+
 pn@^1.1.0:
   version "1.1.0"
   resolved "https://registry.yarnpkg.com/pn/-/pn-1.1.0.tgz#e2f4cef0e219f463c179ab37463e4e1ecdccbafb"
@@ -6430,6 +6467,10 @@ prepend-http@^1.0.0, prepend-http@^1.0.1:
   version "1.0.4"
   resolved "https://registry.yarnpkg.com/prepend-http/-/prepend-http-1.0.4.tgz#d4f4562b0ce3696e41ac52d0e002e57a635dc6dc"
 
+prepend-http@^2.0.0:
+  version "2.0.0"
+  resolved "https://registry.yarnpkg.com/prepend-http/-/prepend-http-2.0.0.tgz#e92434bfa5ea8c19f41cdfd401d741a3c819d897"
+
 preserve@^0.2.0:
   version "0.2.0"
   resolved "https://registry.yarnpkg.com/preserve/-/preserve-0.2.0.tgz#815ed1f6ebc65926f865b310c0713bcb3315ce4b"
@@ -6442,9 +6483,9 @@ pretty-bytes@^4.0.2:
   version "4.0.2"
   resolved "https://registry.yarnpkg.com/pretty-bytes/-/pretty-bytes-4.0.2.tgz#b2bf82e7350d65c6c33aa95aaa5a4f6327f61cd9"
 
-pretty-format@^22.4.0:
-  version "22.4.0"
-  resolved "https://registry.yarnpkg.com/pretty-format/-/pretty-format-22.4.0.tgz#237b1f7e1c50ed03bc65c03ccc29d7c8bb7beb94"
+pretty-format@^22.4.3:
+  version "22.4.3"
+  resolved "https://registry.yarnpkg.com/pretty-format/-/pretty-format-22.4.3.tgz#f873d780839a9c02e9664c8a082e9ee79eaac16f"
   dependencies:
     ansi-regex "^3.0.0"
     ansi-styles "^3.2.0"
@@ -6465,14 +6506,14 @@ process@^0.11.10:
   version "0.11.10"
   resolved "https://registry.yarnpkg.com/process/-/process-0.11.10.tgz#7332300e840161bda3e69a1d1d91a7d4bc16f182"
 
-process@~0.5.1:
-  version "0.5.2"
-  resolved "https://registry.yarnpkg.com/process/-/process-0.5.2.tgz#1638d8a8e34c2f440a91db95ab9aeb677fc185cf"
-
 progress@^1.1.8:
   version "1.1.8"
   resolved "https://registry.yarnpkg.com/progress/-/progress-1.1.8.tgz#e260c78f6161cdd9b0e56cc3e0a85de17c7a57be"
 
+progress@^2.0.0:
+  version "2.0.0"
+  resolved "https://registry.yarnpkg.com/progress/-/progress-2.0.0.tgz#8a1be366bf8fc23db2bd23f10c6fe920b4389d1f"
+
 promise-inflight@^1.0.1:
   version "1.0.1"
   resolved "https://registry.yarnpkg.com/promise-inflight/-/promise-inflight-1.0.1.tgz#98472870bf228132fcbdd868129bad12c3c029e3"
@@ -6552,6 +6593,14 @@ query-string@^4.1.0:
     object-assign "^4.1.0"
     strict-uri-encode "^1.0.0"
 
+query-string@^5.0.1:
+  version "5.1.1"
+  resolved "https://registry.yarnpkg.com/query-string/-/query-string-5.1.1.tgz#a78c012b71c17e05f2e3fa2319dd330682efb3cb"
+  dependencies:
+    decode-uri-component "^0.2.0"
+    object-assign "^4.1.0"
+    strict-uri-encode "^1.0.0"
+
 querystring-es3@^0.2.0:
   version "0.2.1"
   resolved "https://registry.yarnpkg.com/querystring-es3/-/querystring-es3-0.2.1.tgz#9ec61f79049875707d69414596fd907a4d711e73"
@@ -6606,7 +6655,7 @@ rc@^1.1.7:
     minimist "^1.2.0"
     strip-json-comments "~2.0.1"
 
-read-chunk@^2.0.0:
+read-chunk@^2.1.0:
   version "2.1.0"
   resolved "https://registry.yarnpkg.com/read-chunk/-/read-chunk-2.1.0.tgz#6a04c0928005ed9d42e1a6ac5600e19cbc7ff655"
   dependencies:
@@ -6620,12 +6669,12 @@ read-pkg-up@^1.0.1:
     find-up "^1.0.0"
     read-pkg "^1.0.0"
 
-read-pkg-up@^2.0.0:
-  version "2.0.0"
-  resolved "https://registry.yarnpkg.com/read-pkg-up/-/read-pkg-up-2.0.0.tgz#6b72a8048984e0c41e79510fd5e9fa99b3b549be"
+read-pkg-up@^3.0.0:
+  version "3.0.0"
+  resolved "https://registry.yarnpkg.com/read-pkg-up/-/read-pkg-up-3.0.0.tgz#3ed496685dba0f8fe118d0691dc51f4a1ff96f07"
   dependencies:
     find-up "^2.0.0"
-    read-pkg "^2.0.0"
+    read-pkg "^3.0.0"
 
 read-pkg@^1.0.0:
   version "1.1.0"
@@ -6635,13 +6684,13 @@ read-pkg@^1.0.0:
     normalize-package-data "^2.3.2"
     path-type "^1.0.0"
 
-read-pkg@^2.0.0:
-  version "2.0.0"
-  resolved "https://registry.yarnpkg.com/read-pkg/-/read-pkg-2.0.0.tgz#8ef1c0623c6a6db0dc6713c4bfac46332b2368f8"
+read-pkg@^3.0.0:
+  version "3.0.0"
+  resolved "https://registry.yarnpkg.com/read-pkg/-/read-pkg-3.0.0.tgz#9cbc686978fee65d16c00e2b19c237fcf6e38389"
   dependencies:
-    load-json-file "^2.0.0"
+    load-json-file "^4.0.0"
     normalize-package-data "^2.3.2"
-    path-type "^2.0.0"
+    path-type "^3.0.0"
 
 "readable-stream@1 || 2", readable-stream@^2.0.0, readable-stream@^2.0.1, readable-stream@^2.0.4, readable-stream@^2.0.6, readable-stream@^2.1.4, readable-stream@^2.1.5, readable-stream@^2.2.2:
   version "2.3.4"
@@ -6685,14 +6734,6 @@ readdirp@^2.0.0:
     readable-stream "^2.0.2"
     set-immediate-shim "^1.0.1"
 
-readline2@^1.0.1:
-  version "1.0.1"
-  resolved "https://registry.yarnpkg.com/readline2/-/readline2-1.0.1.tgz#41059608ffc154757b715d9989d199ffbf372e35"
-  dependencies:
-    code-point-at "^1.0.0"
-    is-fullwidth-code-point "^1.0.0"
-    mute-stream "0.0.5"
-
 realpath-native@^1.0.0:
   version "1.0.0"
   resolved "https://registry.yarnpkg.com/realpath-native/-/realpath-native-1.0.0.tgz#7885721a83b43bd5327609f0ddecb2482305fdf0"
@@ -6709,11 +6750,11 @@ recast@^0.12.5:
     private "~0.1.5"
     source-map "~0.6.1"
 
-recast@^0.13.0:
-  version "0.13.2"
-  resolved "https://registry.yarnpkg.com/recast/-/recast-0.13.2.tgz#919e7e856d5154f13284142ed1797753c6756137"
+recast@^0.14.1:
+  version "0.14.7"
+  resolved "https://registry.yarnpkg.com/recast/-/recast-0.14.7.tgz#4f1497c2b5826d42a66e8e3c9d80c512983ff61d"
   dependencies:
-    ast-types "0.10.2"
+    ast-types "0.11.3"
     esprima "~4.0.0"
     private "~0.1.5"
     source-map "~0.6.1"
@@ -6787,6 +6828,10 @@ regex-not@^1.0.0, regex-not@^1.0.2:
     extend-shallow "^3.0.2"
     safe-regex "^1.1.0"
 
+regexpp@^1.0.1:
+  version "1.0.1"
+  resolved "https://registry.yarnpkg.com/regexpp/-/regexpp-1.0.1.tgz#d857c3a741dce075c2848dcb019a0a975b190d43"
+
 regexpu-core@^1.0.0:
   version "1.0.0"
   resolved "https://registry.yarnpkg.com/regexpu-core/-/regexpu-core-1.0.0.tgz#86a763f58ee4d7c2f6b102e4764050de7ed90c6b"
@@ -6950,7 +6995,7 @@ require-main-filename@^1.0.1:
   version "1.0.1"
   resolved "https://registry.yarnpkg.com/require-main-filename/-/require-main-filename-1.0.1.tgz#97f717b69d48784f5f526a6c5aa8ffdda055a4d1"
 
-require-uncached@^1.0.2:
+require-uncached@^1.0.3:
   version "1.0.3"
   resolved "https://registry.yarnpkg.com/require-uncached/-/require-uncached-1.0.3.tgz#4e0d56d6c9662fd31e43011c4b95aa49955421d3"
   dependencies:
@@ -6992,6 +7037,12 @@ resolve@^1.1.6, resolve@^1.3.2:
   dependencies:
     path-parse "^1.0.5"
 
+responselike@1.0.2:
+  version "1.0.2"
+  resolved "https://registry.yarnpkg.com/responselike/-/responselike-1.0.2.tgz#918720ef3b631c5642be068f15ade5a46f4ba1e7"
+  dependencies:
+    lowercase-keys "^1.0.0"
+
 restore-cursor@^1.0.1:
   version "1.0.1"
   resolved "https://registry.yarnpkg.com/restore-cursor/-/restore-cursor-1.0.1.tgz#34661f46886327fed2991479152252df92daa541"
@@ -7016,7 +7067,7 @@ right-align@^0.1.1:
   dependencies:
     align-text "^0.1.1"
 
-rimraf@2, rimraf@^2.2.0, rimraf@^2.2.8, rimraf@^2.4.4, rimraf@^2.5.1, rimraf@^2.5.4, rimraf@^2.6.1, rimraf@^2.6.2:
+rimraf@2, rimraf@^2.2.8, rimraf@^2.4.4, rimraf@^2.5.1, rimraf@^2.5.4, rimraf@^2.6.1, rimraf@^2.6.2:
   version "2.6.2"
   resolved "https://registry.yarnpkg.com/rimraf/-/rimraf-2.6.2.tgz#2ed8150d24a16ea8651e6d6ef0f47c4158ce7a36"
   dependencies:
@@ -7033,12 +7084,6 @@ ripemd160@^2.0.0, ripemd160@^2.0.1:
     hash-base "^2.0.0"
     inherits "^2.0.1"
 
-run-async@^0.1.0:
-  version "0.1.0"
-  resolved "https://registry.yarnpkg.com/run-async/-/run-async-0.1.0.tgz#c8ad4a5e110661e402a7d21b530e009f25f8e389"
-  dependencies:
-    once "^1.3.0"
-
 run-async@^2.0.0, run-async@^2.2.0:
   version "2.3.0"
   resolved "https://registry.yarnpkg.com/run-async/-/run-async-2.3.0.tgz#0371ab4ae0bdd720d4166d7dfda64ff7a445a6c0"
@@ -7061,17 +7106,9 @@ rx-lite@*, rx-lite@^4.0.8:
   version "4.0.8"
   resolved "https://registry.yarnpkg.com/rx-lite/-/rx-lite-4.0.8.tgz#0b1e11af8bc44836f04a6407e92da42467b79444"
 
-rx-lite@^3.1.2:
-  version "3.1.2"
-  resolved "https://registry.yarnpkg.com/rx-lite/-/rx-lite-3.1.2.tgz#19ce502ca572665f3b647b10939f97fd1615f102"
-
-rx@^4.1.0:
-  version "4.1.0"
-  resolved "https://registry.yarnpkg.com/rx/-/rx-4.1.0.tgz#a5f13ff79ef3b740fe30aa803fb09f98805d4782"
-
-rxjs@^5.0.0-beta.11:
-  version "5.5.6"
-  resolved "https://registry.yarnpkg.com/rxjs/-/rxjs-5.5.6.tgz#e31fb96d6fd2ff1fd84bcea8ae9c02d007179c02"
+rxjs@^5.4.2, rxjs@^5.5.2:
+  version "5.5.8"
+  resolved "https://registry.yarnpkg.com/rxjs/-/rxjs-5.5.8.tgz#b2b0809a57614ad6254c03d7446dea0d83ca3791"
   dependencies:
     symbol-observable "1.0.1"
 
@@ -7108,26 +7145,20 @@ sass-graph@^2.2.4:
     scss-tokenizer "^0.2.3"
     yargs "^7.0.0"
 
-sass-loader@^6.0.6:
-  version "6.0.6"
-  resolved "https://registry.yarnpkg.com/sass-loader/-/sass-loader-6.0.6.tgz#e9d5e6c1f155faa32a4b26d7a9b7107c225e40f9"
+sass-loader@^6.0.7:
+  version "6.0.7"
+  resolved "https://registry.yarnpkg.com/sass-loader/-/sass-loader-6.0.7.tgz#dd2fdb3e7eeff4a53f35ba6ac408715488353d00"
   dependencies:
-    async "^2.1.5"
-    clone-deep "^0.3.0"
+    clone-deep "^2.0.1"
     loader-utils "^1.0.1"
     lodash.tail "^4.1.1"
+    neo-async "^2.5.0"
     pify "^3.0.0"
 
 sax@^1.2.4, sax@~1.2.1:
   version "1.2.4"
   resolved "https://registry.yarnpkg.com/sax/-/sax-1.2.4.tgz#2816234e2378bddc4e5354fab5caa895df7100d9"
 
-schema-utils@^0.3.0:
-  version "0.3.0"
-  resolved "https://registry.yarnpkg.com/schema-utils/-/schema-utils-0.3.0.tgz#f5877222ce3e931edae039f17eb3716e7137f8cf"
-  dependencies:
-    ajv "^5.0.0"
-
 schema-utils@^0.4.2, schema-utils@^0.4.5:
   version "0.4.5"
   resolved "https://registry.yarnpkg.com/schema-utils/-/schema-utils-0.4.5.tgz#21836f0608aac17b78f9e3e24daff14a5ca13a3e"
@@ -7152,7 +7183,7 @@ scss-tokenizer@^0.2.3:
     js-base64 "^2.1.8"
     source-map "^0.4.2"
 
-"semver@2 || 3 || 4 || 5", semver@^5.0.1, semver@^5.3.0, semver@^5.4.1:
+"semver@2 || 3 || 4 || 5", semver@^5.0.1, semver@^5.3.0, semver@^5.4.1, semver@^5.5.0:
   version "5.5.0"
   resolved "https://registry.yarnpkg.com/semver/-/semver-5.5.0.tgz#dc4bbc7a6ca9d916dee5d43516f0092b58f7b8ab"
 
@@ -7242,13 +7273,12 @@ sha.js@^2.4.0, sha.js@^2.4.8:
     inherits "^2.0.1"
     safe-buffer "^5.0.1"
 
-shallow-clone@^0.1.2:
-  version "0.1.2"
-  resolved "https://registry.yarnpkg.com/shallow-clone/-/shallow-clone-0.1.2.tgz#5909e874ba77106d73ac414cfec1ffca87d97060"
+shallow-clone@^1.0.0:
+  version "1.0.0"
+  resolved "https://registry.yarnpkg.com/shallow-clone/-/shallow-clone-1.0.0.tgz#4480cd06e882ef68b2ad88a3ea54832e2c48b571"
   dependencies:
     is-extendable "^0.1.1"
-    kind-of "^2.0.1"
-    lazy-cache "^0.2.3"
+    kind-of "^5.0.0"
     mixin-object "^2.0.1"
 
 shaven@^0.8.1:
@@ -7267,9 +7297,9 @@ shebang-regex@^1.0.0:
   version "1.0.0"
   resolved "https://registry.yarnpkg.com/shebang-regex/-/shebang-regex-1.0.0.tgz#da42f49740c0b42db2ca9728571cb190c98efea3"
 
-shelljs@^0.7.0, shelljs@^0.7.5:
-  version "0.7.8"
-  resolved "https://registry.yarnpkg.com/shelljs/-/shelljs-0.7.8.tgz#decbcf874b0d1e5fb72e14b164a9683048e9acb3"
+shelljs@^0.8.0:
+  version "0.8.1"
+  resolved "https://registry.yarnpkg.com/shelljs/-/shelljs-0.8.1.tgz#729e038c413a2254c4078b95ed46e0397154a9f1"
   dependencies:
     glob "^7.0.0"
     interpret "^1.0.0"
@@ -7295,6 +7325,12 @@ slice-ansi@0.0.4:
   version "0.0.4"
   resolved "https://registry.yarnpkg.com/slice-ansi/-/slice-ansi-0.0.4.tgz#edbf8903f66f7ce2f8eafd6ceed65e264c831b35"
 
+slice-ansi@1.0.0:
+  version "1.0.0"
+  resolved "https://registry.yarnpkg.com/slice-ansi/-/slice-ansi-1.0.0.tgz#044f1a49d8842ff307aad6b505ed178bd950134d"
+  dependencies:
+    is-fullwidth-code-point "^2.0.0"
+
 slide@^1.1.5:
   version "1.1.6"
   resolved "https://registry.yarnpkg.com/slide/-/slide-1.1.6.tgz#56eb027d65b4d2dce6cb2e2d32c4d4afc9e1d707"
@@ -7344,6 +7380,12 @@ sort-keys@^1.0.0:
   dependencies:
     is-plain-obj "^1.0.0"
 
+sort-keys@^2.0.0:
+  version "2.0.0"
+  resolved "https://registry.yarnpkg.com/sort-keys/-/sort-keys-2.0.0.tgz#658535584861ec97d730d6cf41822e1f56684128"
+  dependencies:
+    is-plain-obj "^1.0.0"
+
 source-list-map@^2.0.0:
   version "2.0.0"
   resolved "https://registry.yarnpkg.com/source-list-map/-/source-list-map-2.0.0.tgz#aaa47403f7b245a92fbc97ea08f250d6087ed085"
@@ -7394,13 +7436,6 @@ source-map@~0.1.38:
   dependencies:
     amdefine ">=0.0.4"
 
-spawn-sync@^1.0.15:
-  version "1.0.15"
-  resolved "https://registry.yarnpkg.com/spawn-sync/-/spawn-sync-1.0.15.tgz#b00799557eb7fb0c8376c29d44e8a1ea67e57476"
-  dependencies:
-    concat-stream "^1.4.7"
-    os-shim "^0.1.2"
-
 spdx-correct@^3.0.0:
   version "3.0.0"
   resolved "https://registry.yarnpkg.com/spdx-correct/-/spdx-correct-3.0.0.tgz#05a5b4d7153a195bc92c3c425b69f3b2a9524c82"
@@ -7514,9 +7549,11 @@ stream-shift@^1.0.0:
   version "1.0.0"
   resolved "https://registry.yarnpkg.com/stream-shift/-/stream-shift-1.0.0.tgz#d5c752825e5367e786f78e18e445ea223a155952"
 
-stream-to-observable@^0.1.0:
-  version "0.1.0"
-  resolved "https://registry.yarnpkg.com/stream-to-observable/-/stream-to-observable-0.1.0.tgz#45bf1d9f2d7dc09bed81f1c307c430e68b84cffe"
+stream-to-observable@^0.2.0:
+  version "0.2.0"
+  resolved "https://registry.yarnpkg.com/stream-to-observable/-/stream-to-observable-0.2.0.tgz#59d6ea393d87c2c0ddac10aa0d561bc6ba6f0e10"
+  dependencies:
+    any-observable "^0.2.0"
 
 strict-uri-encode@^1.0.0:
   version "1.1.0"
@@ -7631,12 +7668,12 @@ strip-json-comments@~2.0.1:
   version "2.0.1"
   resolved "https://registry.yarnpkg.com/strip-json-comments/-/strip-json-comments-2.0.1.tgz#3c531942e908c2697c0ec344858c286c7ca0a60a"
 
-style-loader@^0.19.1:
-  version "0.19.1"
-  resolved "https://registry.yarnpkg.com/style-loader/-/style-loader-0.19.1.tgz#591ffc80bcefe268b77c5d9ebc0505d772619f85"
+style-loader@^0.20.3:
+  version "0.20.3"
+  resolved "https://registry.yarnpkg.com/style-loader/-/style-loader-0.20.3.tgz#ebef06b89dec491bcb1fdb3452e913a6fd1c10c4"
   dependencies:
-    loader-utils "^1.0.2"
-    schema-utils "^0.3.0"
+    loader-utils "^1.1.0"
+    schema-utils "^0.4.5"
 
 style-loader@^0.8.3:
   version "0.8.3"
@@ -7654,18 +7691,18 @@ supports-color@^3.1.2, supports-color@^3.2.3:
   dependencies:
     has-flag "^1.0.0"
 
-supports-color@^4.4.0:
-  version "4.5.0"
-  resolved "https://registry.yarnpkg.com/supports-color/-/supports-color-4.5.0.tgz#be7a0de484dec5c5cddf8b3d59125044912f635b"
-  dependencies:
-    has-flag "^2.0.0"
-
 supports-color@^5.2.0:
   version "5.2.0"
   resolved "https://registry.yarnpkg.com/supports-color/-/supports-color-5.2.0.tgz#b0d5333b1184dd3666cbe5aa0b45c5ac7ac17a4a"
   dependencies:
     has-flag "^3.0.0"
 
+supports-color@^5.3.0:
+  version "5.3.0"
+  resolved "https://registry.yarnpkg.com/supports-color/-/supports-color-5.3.0.tgz#5b24ac15db80fa927cf5227a4a33fd3c4c7676c0"
+  dependencies:
+    has-flag "^3.0.0"
+
 svgo@^0.7.0:
   version "0.7.2"
   resolved "https://registry.yarnpkg.com/svgo/-/svgo-0.7.2.tgz#9f5772413952135c6fefbf40afe6a4faa88b4bb5"
@@ -7682,24 +7719,24 @@ symbol-observable@1.0.1:
   version "1.0.1"
   resolved "https://registry.yarnpkg.com/symbol-observable/-/symbol-observable-1.0.1.tgz#8340fc4702c3122df5d22288f88283f513d3fdd4"
 
+symbol-observable@^0.2.2:
+  version "0.2.4"
+  resolved "https://registry.yarnpkg.com/symbol-observable/-/symbol-observable-0.2.4.tgz#95a83db26186d6af7e7a18dbd9760a2f86d08f40"
+
 symbol-tree@^3.2.2:
   version "3.2.2"
   resolved "https://registry.yarnpkg.com/symbol-tree/-/symbol-tree-3.2.2.tgz#ae27db38f660a7ae2e1c3b7d1bc290819b8519e6"
 
-table@^3.7.8:
-  version "3.8.3"
-  resolved "https://registry.yarnpkg.com/table/-/table-3.8.3.tgz#2bbc542f0fda9861a755d3947fefd8b3f513855f"
+table@4.0.2:
+  version "4.0.2"
+  resolved "https://registry.yarnpkg.com/table/-/table-4.0.2.tgz#a33447375391e766ad34d3486e6e2aedc84d2e36"
   dependencies:
-    ajv "^4.7.0"
-    ajv-keywords "^1.0.0"
-    chalk "^1.1.1"
-    lodash "^4.0.0"
-    slice-ansi "0.0.4"
-    string-width "^2.0.0"
-
-tapable@^0.2.7:
-  version "0.2.8"
-  resolved "https://registry.yarnpkg.com/tapable/-/tapable-0.2.8.tgz#99372a5c999bf2df160afc0d74bed4f47948cd22"
+    ajv "^5.2.3"
+    ajv-keywords "^2.1.0"
+    chalk "^2.1.0"
+    lodash "^4.17.4"
+    slice-ansi "1.0.0"
+    string-width "^2.1.1"
 
 tapable@^1.0.0:
   version "1.0.0"
@@ -7784,7 +7821,7 @@ through@^2.3.6, through@~2.3.6:
   version "2.3.8"
   resolved "https://registry.yarnpkg.com/through/-/through-2.3.8.tgz#0dd4c9ffaabc357960b1b724115d7e0e86a2e1f5"
 
-timed-out@^4.0.0:
+timed-out@^4.0.0, timed-out@^4.0.1:
   version "4.0.1"
   resolved "https://registry.yarnpkg.com/timed-out/-/timed-out-4.0.1.tgz#f32eacac5a175bea25d7fab565ab3ed8741ef56f"
 
@@ -7794,12 +7831,6 @@ timers-browserify@^2.0.4:
   dependencies:
     setimmediate "^1.0.4"
 
-tmp@^0.0.29:
-  version "0.0.29"
-  resolved "https://registry.yarnpkg.com/tmp/-/tmp-0.0.29.tgz#f25125ff0dd9da3ccb0c2dd371ee1288bb9128c0"
-  dependencies:
-    os-tmpdir "~1.0.1"
-
 tmp@^0.0.33:
   version "0.0.33"
   resolved "https://registry.yarnpkg.com/tmp/-/tmp-0.0.33.tgz#6d34335889768d21b2bcda0aa277ced3b1bfadf9"
@@ -7884,9 +7915,9 @@ tryit@^1.0.1:
   version "1.0.3"
   resolved "https://registry.yarnpkg.com/tryit/-/tryit-1.0.3.tgz#393be730a9446fd1ead6da59a014308f36c289cb"
 
-ts-loader@^4.0.0:
-  version "4.0.0"
-  resolved "https://registry.yarnpkg.com/ts-loader/-/ts-loader-4.0.0.tgz#1d79f777e4f09de88a60697d8d4a96e55164caa9"
+ts-loader@^4.1.0:
+  version "4.1.0"
+  resolved "https://registry.yarnpkg.com/ts-loader/-/ts-loader-4.1.0.tgz#6216e75600941df3270bc4a7125e20aefb2dc5ea"
   dependencies:
     chalk "^2.3.0"
     enhanced-resolve "^4.0.0"
@@ -7966,9 +7997,9 @@ typedarray@^0.0.6:
   version "0.0.6"
   resolved "https://registry.yarnpkg.com/typedarray/-/typedarray-0.0.6.tgz#867ac74e3864187b1d3d47d996a78ec5c8830777"
 
-typescript@^2.7.2:
-  version "2.7.2"
-  resolved "https://registry.yarnpkg.com/typescript/-/typescript-2.7.2.tgz#2d615a1ef4aee4f574425cdff7026edf81919836"
+typescript@^2.8.1:
+  version "2.8.1"
+  resolved "https://registry.yarnpkg.com/typescript/-/typescript-2.8.1.tgz#6160e4f8f195d5ba81d4876f9c0cc1fbc0820624"
 
 uglify-es@^3.3.4:
   version "3.3.9"
@@ -7997,13 +8028,13 @@ uglify-to-browserify@~1.0.0:
   version "1.0.2"
   resolved "https://registry.yarnpkg.com/uglify-to-browserify/-/uglify-to-browserify-1.0.2.tgz#6e0924d6bda6b5afe349e39a6d632850a0f882b7"
 
-uglifyjs-webpack-plugin@^1.1.1, uglifyjs-webpack-plugin@^1.2.2:
-  version "1.2.2"
-  resolved "https://registry.yarnpkg.com/uglifyjs-webpack-plugin/-/uglifyjs-webpack-plugin-1.2.2.tgz#e7516d4367afdb715c3847841eb46f94c45ca2b9"
+uglifyjs-webpack-plugin@^1.2.4:
+  version "1.2.4"
+  resolved "https://registry.yarnpkg.com/uglifyjs-webpack-plugin/-/uglifyjs-webpack-plugin-1.2.4.tgz#5eec941b2e9b8538be0a20fc6eda25b14c7c1043"
   dependencies:
-    cacache "^10.0.1"
+    cacache "^10.0.4"
     find-cache-dir "^1.0.0"
-    schema-utils "^0.4.2"
+    schema-utils "^0.4.5"
     serialize-javascript "^1.4.0"
     source-map "^0.6.1"
     uglify-es "^3.3.4"
@@ -8075,16 +8106,14 @@ unset-value@^1.0.0:
     has-value "^0.3.1"
     isobject "^3.0.0"
 
-untildify@^2.0.0:
-  version "2.1.0"
-  resolved "https://registry.yarnpkg.com/untildify/-/untildify-2.1.0.tgz#17eb2807987f76952e9c0485fc311d06a826a2e0"
-  dependencies:
-    os-homedir "^1.0.0"
-
 untildify@^3.0.2:
   version "3.0.2"
   resolved "https://registry.yarnpkg.com/untildify/-/untildify-3.0.2.tgz#7f1f302055b3fea0f3e81dc78eb36766cb65e3f1"
 
+upath@^1.0.0:
+  version "1.0.4"
+  resolved "https://registry.yarnpkg.com/upath/-/upath-1.0.4.tgz#ee2321ba0a786c50973db043a50b7bcba822361d"
+
 upper-case@^1.1.1:
   version "1.1.3"
   resolved "https://registry.yarnpkg.com/upper-case/-/upper-case-1.1.3.tgz#f6b4501c2ec4cdd26ba78be7222961de77621598"
@@ -8099,6 +8128,12 @@ url-parse-lax@^1.0.0:
   dependencies:
     prepend-http "^1.0.1"
 
+url-parse-lax@^3.0.0:
+  version "3.0.0"
+  resolved "https://registry.yarnpkg.com/url-parse-lax/-/url-parse-lax-3.0.0.tgz#16b5cafc07dbe3676c1b1999177823d6503acb0c"
+  dependencies:
+    prepend-http "^2.0.0"
+
 url-to-options@^1.0.1:
   version "1.0.1"
   resolved "https://registry.yarnpkg.com/url-to-options/-/url-to-options-1.0.1.tgz#1505a03a289a48cbd7a434efbaeec5055f5633a9"
@@ -8110,10 +8145,6 @@ url@^0.11.0:
     punycode "1.3.2"
     querystring "0.2.0"
 
-urlgrey@0.4.4:
-  version "0.4.4"
-  resolved "https://registry.yarnpkg.com/urlgrey/-/urlgrey-0.4.4.tgz#892fe95960805e85519f1cd4389f2cb4cbb7652f"
-
 use@^2.0.0:
   version "2.0.2"
   resolved "https://registry.yarnpkg.com/use/-/use-2.0.2.tgz#ae28a0d72f93bf22422a18a2e379993112dec8e8"
@@ -8126,12 +8157,6 @@ user-home@^1.1.1:
   version "1.1.1"
   resolved "https://registry.yarnpkg.com/user-home/-/user-home-1.1.1.tgz#2b5be23a32b63a7c9deb8d0f28d485724a3df190"
 
-user-home@^2.0.0:
-  version "2.0.0"
-  resolved "https://registry.yarnpkg.com/user-home/-/user-home-2.0.0.tgz#9c70bfd8169bc1dcbf48604e0f04b8b49cde9e9f"
-  dependencies:
-    os-homedir "^1.0.0"
-
 util-deprecate@~1.0.1:
   version "1.0.2"
   resolved "https://registry.yarnpkg.com/util-deprecate/-/util-deprecate-1.0.2.tgz#450d4dc9fa70de732762fbd2d4a28981419a0ccf"
@@ -8157,7 +8182,7 @@ uuid@^3.0.0, uuid@^3.1.0:
   version "3.2.1"
   resolved "https://registry.yarnpkg.com/uuid/-/uuid-3.2.1.tgz#12c528bb9d58d0b9265d9a2f6f0fe8be17ff1f14"
 
-v8-compile-cache@^1.1.0:
+v8-compile-cache@^1.1.2:
   version "1.1.2"
   resolved "https://registry.yarnpkg.com/v8-compile-cache/-/v8-compile-cache-1.1.2.tgz#8d32e4f16974654657e676e0e467a348e89b0dc4"
 
@@ -8271,13 +8296,13 @@ watch@~0.18.0:
     exec-sh "^0.2.0"
     minimist "^1.2.0"
 
-watchpack@^1.4.0:
-  version "1.4.0"
-  resolved "https://registry.yarnpkg.com/watchpack/-/watchpack-1.4.0.tgz#4a1472bcbb952bd0a9bb4036801f954dfb39faac"
+watchpack@^1.5.0:
+  version "1.5.0"
+  resolved "https://registry.yarnpkg.com/watchpack/-/watchpack-1.5.0.tgz#231e783af830a22f8966f65c4c4bacc814072eed"
   dependencies:
-    async "^2.1.2"
-    chokidar "^1.7.0"
+    chokidar "^2.0.2"
     graceful-fs "^4.1.2"
+    neo-async "^2.5.0"
 
 webidl-conversions@^4.0.1, webidl-conversions@^4.0.2:
   version "4.0.2"
@@ -8289,9 +8314,9 @@ webpack-addons@^1.1.5:
   dependencies:
     jscodeshift "^0.4.0"
 
-webpack-bundle-analyzer@^2.9.2:
-  version "2.11.0"
-  resolved "https://registry.yarnpkg.com/webpack-bundle-analyzer/-/webpack-bundle-analyzer-2.11.0.tgz#ed6f6ab59f5b341ffb60849ca707a7fe841c4f86"
+webpack-bundle-analyzer@^2.11.1:
+  version "2.11.1"
+  resolved "https://registry.yarnpkg.com/webpack-bundle-analyzer/-/webpack-bundle-analyzer-2.11.1.tgz#b9fbfb6a32c0a8c1c3237223e90890796b950ab9"
   dependencies:
     acorn "^5.3.0"
     bfj-node4 "^5.2.0"
@@ -8306,69 +8331,35 @@ webpack-bundle-analyzer@^2.9.2:
     opener "^1.4.3"
     ws "^4.0.0"
 
-webpack-cli@^2.0.9:
-  version "2.0.9"
-  resolved "https://registry.yarnpkg.com/webpack-cli/-/webpack-cli-2.0.9.tgz#0310fa04f4cad69714560cc0e4da5c7682eb4d9b"
+webpack-cli@^2.0.13:
+  version "2.0.13"
+  resolved "https://registry.yarnpkg.com/webpack-cli/-/webpack-cli-2.0.13.tgz#6e2bd9ef91345344737217e22e29001ad8537518"
   dependencies:
-    chalk "^2.0.1"
-    codecov "^3.0.0"
-    cross-spawn "^5.1.0"
-    diff "^3.3.0"
-    enhanced-resolve "^3.4.1"
+    chalk "^2.3.2"
+    cross-spawn "^6.0.5"
+    diff "^3.5.0"
+    enhanced-resolve "^4.0.0"
     glob-all "^3.1.0"
-    global "^4.3.2"
     global-modules "^1.0.0"
-    got "^7.1.0"
-    inquirer "^3.2.0"
+    got "^8.2.0"
+    inquirer "^5.1.0"
     interpret "^1.0.4"
-    jscodeshift "^0.4.0"
-    listr "^0.12.0"
+    jscodeshift "^0.5.0"
+    listr "^0.13.0"
     loader-utils "^1.1.0"
-    lodash "^4.17.4"
-    log-symbols "2.1.0"
+    lodash "^4.17.5"
+    log-symbols "^2.2.0"
     mkdirp "^0.5.1"
     p-each-series "^1.0.0"
     p-lazy "^1.0.0"
     prettier "^1.5.3"
-    recast "^0.13.0"
     resolve-cwd "^2.0.0"
-    supports-color "^4.4.0"
-    uglifyjs-webpack-plugin "^1.2.2"
-    v8-compile-cache "^1.1.0"
+    supports-color "^5.3.0"
+    v8-compile-cache "^1.1.2"
     webpack-addons "^1.1.5"
-    webpack-fork-yeoman-generator "^1.1.1"
-    yargs "9.0.1"
+    yargs "^11.0.0"
     yeoman-environment "^2.0.0"
-
-webpack-fork-yeoman-generator@^1.1.1:
-  version "1.1.1"
-  resolved "https://registry.yarnpkg.com/webpack-fork-yeoman-generator/-/webpack-fork-yeoman-generator-1.1.1.tgz#c92b454aba7df9ea392669188aa0330964acf76f"
-  dependencies:
-    async "^2.0.0"
-    chalk "^1.0.0"
-    cli-table "^0.3.1"
-    cross-spawn "^5.0.1"
-    dargs "^5.1.0"
-    dateformat "^2.0.0"
-    debug "^2.1.0"
-    detect-conflict "^1.0.0"
-    error "^7.0.2"
-    find-up "^2.1.0"
-    github-username "^4.0.0"
-    istextorbinary "^2.1.0"
-    lodash "^4.11.1"
-    mem-fs-editor "^3.0.0"
-    minimist "^1.2.0"
-    mkdirp "^0.5.0"
-    pretty-bytes "^4.0.2"
-    read-chunk "^2.0.0"
-    read-pkg-up "^2.0.0"
-    rimraf "^2.2.0"
-    run-async "^2.0.0"
-    shelljs "^0.7.0"
-    text-table "^0.2.0"
-    through2 "^2.0.0"
-    yeoman-environment "^1.1.0"
+    yeoman-generator "^2.0.3"
 
 webpack-md5-hash@^0.0.6:
   version "0.0.6"
@@ -8383,9 +8374,9 @@ webpack-sources@^1.0.1, webpack-sources@^1.1.0:
     source-list-map "^2.0.0"
     source-map "~0.6.1"
 
-webpack@^4.0.1:
-  version "4.0.1"
-  resolved "https://registry.yarnpkg.com/webpack/-/webpack-4.0.1.tgz#768d708beeca4c5f77f6c2d38a240fb6ff50ba5d"
+webpack@^4.3.0:
+  version "4.3.0"
+  resolved "https://registry.yarnpkg.com/webpack/-/webpack-4.3.0.tgz#0b0c1e211311b3995dd25aed47ab46ea658be070"
   dependencies:
     acorn "^5.0.0"
     acorn-dynamic-import "^3.0.0"
@@ -8403,8 +8394,8 @@ webpack@^4.0.1:
     node-libs-browser "^2.0.0"
     schema-utils "^0.4.2"
     tapable "^1.0.0"
-    uglifyjs-webpack-plugin "^1.1.1"
-    watchpack "^1.4.0"
+    uglifyjs-webpack-plugin "^1.2.4"
+    watchpack "^1.5.0"
     webpack-sources "^1.0.1"
 
 whatwg-encoding@^1.0.1, whatwg-encoding@^1.0.3:
@@ -8538,39 +8529,38 @@ yargs-parser@^5.0.0:
   dependencies:
     camelcase "^3.0.0"
 
-yargs-parser@^7.0.0:
-  version "7.0.0"
-  resolved "https://registry.yarnpkg.com/yargs-parser/-/yargs-parser-7.0.0.tgz#8d0ac42f16ea55debd332caf4c4038b3e3f5dfd9"
-  dependencies:
-    camelcase "^4.1.0"
-
 yargs-parser@^8.1.0:
   version "8.1.0"
   resolved "https://registry.yarnpkg.com/yargs-parser/-/yargs-parser-8.1.0.tgz#f1376a33b6629a5d063782944da732631e966950"
   dependencies:
     camelcase "^4.1.0"
 
-yargs@9.0.1:
-  version "9.0.1"
-  resolved "https://registry.yarnpkg.com/yargs/-/yargs-9.0.1.tgz#52acc23feecac34042078ee78c0c007f5085db4c"
+yargs-parser@^9.0.2:
+  version "9.0.2"
+  resolved "https://registry.yarnpkg.com/yargs-parser/-/yargs-parser-9.0.2.tgz#9ccf6a43460fe4ed40a9bb68f48d43b8a68cc077"
   dependencies:
     camelcase "^4.1.0"
-    cliui "^3.2.0"
+
+yargs@^10.0.3:
+  version "10.1.2"
+  resolved "https://registry.yarnpkg.com/yargs/-/yargs-10.1.2.tgz#454d074c2b16a51a43e2fb7807e4f9de69ccb5c5"
+  dependencies:
+    cliui "^4.0.0"
     decamelize "^1.1.1"
+    find-up "^2.1.0"
     get-caller-file "^1.0.1"
     os-locale "^2.0.0"
-    read-pkg-up "^2.0.0"
     require-directory "^2.1.1"
     require-main-filename "^1.0.1"
     set-blocking "^2.0.0"
     string-width "^2.0.0"
     which-module "^2.0.0"
     y18n "^3.2.1"
-    yargs-parser "^7.0.0"
+    yargs-parser "^8.1.0"
 
-yargs@^10.0.3, yargs@^10.1.1:
-  version "10.1.2"
-  resolved "https://registry.yarnpkg.com/yargs/-/yargs-10.1.2.tgz#454d074c2b16a51a43e2fb7807e4f9de69ccb5c5"
+yargs@^11.0.0:
+  version "11.0.0"
+  resolved "https://registry.yarnpkg.com/yargs/-/yargs-11.0.0.tgz#c052931006c5eee74610e5fc0354bedfd08a201b"
   dependencies:
     cliui "^4.0.0"
     decamelize "^1.1.1"
@@ -8583,7 +8573,7 @@ yargs@^10.0.3, yargs@^10.1.1:
     string-width "^2.0.0"
     which-module "^2.0.0"
     y18n "^3.2.1"
-    yargs-parser "^8.1.0"
+    yargs-parser "^9.0.2"
 
 yargs@^7.0.0:
   version "7.1.0"
@@ -8624,24 +8614,7 @@ yauzl@2.4.1:
   dependencies:
     fd-slicer "~1.0.1"
 
-yeoman-environment@^1.1.0:
-  version "1.6.6"
-  resolved "https://registry.yarnpkg.com/yeoman-environment/-/yeoman-environment-1.6.6.tgz#cd85fa67d156060e440d7807d7ef7cf0d2d1d671"
-  dependencies:
-    chalk "^1.0.0"
-    debug "^2.0.0"
-    diff "^2.1.2"
-    escape-string-regexp "^1.0.2"
-    globby "^4.0.0"
-    grouped-queue "^0.3.0"
-    inquirer "^1.0.2"
-    lodash "^4.11.1"
-    log-symbols "^1.0.1"
-    mem-fs "^1.1.0"
-    text-table "^0.2.0"
-    untildify "^2.0.0"
-
-yeoman-environment@^2.0.0:
+yeoman-environment@^2.0.0, yeoman-environment@^2.0.5:
   version "2.0.5"
   resolved "https://registry.yarnpkg.com/yeoman-environment/-/yeoman-environment-2.0.5.tgz#84f22bafa84088971fe99ea85f654a3a3dd2b693"
   dependencies:
@@ -8658,3 +8631,33 @@ yeoman-environment@^2.0.0:
     mem-fs "^1.1.0"
     text-table "^0.2.0"
     untildify "^3.0.2"
+
+yeoman-generator@^2.0.3:
+  version "2.0.3"
+  resolved "https://registry.yarnpkg.com/yeoman-generator/-/yeoman-generator-2.0.3.tgz#19426ed22687ffe05d31526c3f1c2cf67ba768f3"
+  dependencies:
+    async "^2.6.0"
+    chalk "^2.3.0"
+    cli-table "^0.3.1"
+    cross-spawn "^5.1.0"
+    dargs "^5.1.0"
+    dateformat "^3.0.2"
+    debug "^3.1.0"
+    detect-conflict "^1.0.0"
+    error "^7.0.2"
+    find-up "^2.1.0"
+    github-username "^4.0.0"
+    istextorbinary "^2.1.0"
+    lodash "^4.17.4"
+    make-dir "^1.1.0"
+    mem-fs-editor "^3.0.2"
+    minimist "^1.2.0"
+    pretty-bytes "^4.0.2"
+    read-chunk "^2.1.0"
+    read-pkg-up "^3.0.0"
+    rimraf "^2.6.2"
+    run-async "^2.0.0"
+    shelljs "^0.8.0"
+    text-table "^0.2.0"
+    through2 "^2.0.0"
+    yeoman-environment "^2.0.5"
diff --git a/dependencies/pax-exam/pom.xml b/dependencies/pax-exam/pom.xml
index 1ea37f45081..a1ee5c09d11 100644
--- a/dependencies/pax-exam/pom.xml
+++ b/dependencies/pax-exam/pom.xml
@@ -47,7 +47,7 @@
       <groupId>org.ops4j.pax.url</groupId>
       <artifactId>pax-url-aether</artifactId>
       <!-- Make sure this matches the version in Karaf -->
-      <version>2.4.5</version>
+      <version>2.5.4</version>
       <exclusions>
         <exclusion>
           <groupId>commons-logging</groupId>
diff --git a/features/alarm-change-notifier/main-module/src/main/java/org/opennms/plugins/dbnotifier/alarmnotifier/AlarmChangeNotificationClient.java b/features/alarm-change-notifier/main-module/src/main/java/org/opennms/plugins/dbnotifier/alarmnotifier/AlarmChangeNotificationClient.java
index 1385dd3fb09..e4d55c5724b 100644
--- a/features/alarm-change-notifier/main-module/src/main/java/org/opennms/plugins/dbnotifier/alarmnotifier/AlarmChangeNotificationClient.java
+++ b/features/alarm-change-notifier/main-module/src/main/java/org/opennms/plugins/dbnotifier/alarmnotifier/AlarmChangeNotificationClient.java
@@ -61,6 +61,8 @@ public class AlarmChangeNotificationClient implements NotificationClient {
 
 	public static final String EVENT_SOURCE_NAME = "AlarmChangeNotifier";
 
+	protected static final String TYPE_JSON = "json";
+	protected static final String ENCODING_TEXT = "text";
 
 	EventProxy eventProxy = null;
 
@@ -105,8 +107,8 @@ public class AlarmChangeNotificationClient implements NotificationClient {
 							new EventBuilder( AlarmChangeEventConstants.ALARM_DELETED_EVENT, EVENT_SOURCE_NAME));
 
 					//copy in all values as json in params
-					eb.addParam(AlarmChangeEventConstants.OLD_ALARM_VALUES_PARAM,oldJsonObject.toString());
-					eb.addParam(AlarmChangeEventConstants.NEW_ALARM_VALUES_PARAM,newJsonObject.toString());
+					eb.addParam(AlarmChangeEventConstants.OLD_ALARM_VALUES_PARAM,oldJsonObject.toString(), TYPE_JSON, ENCODING_TEXT);
+					eb.addParam(AlarmChangeEventConstants.NEW_ALARM_VALUES_PARAM,newJsonObject.toString(), TYPE_JSON, ENCODING_TEXT);
 
 					sendEvent(eb.getEvent());
 				}
@@ -121,8 +123,8 @@ public class AlarmChangeNotificationClient implements NotificationClient {
 							new EventBuilder( AlarmChangeEventConstants.ALARM_CREATED_EVENT, EVENT_SOURCE_NAME));
 
 					//copy in all values as json in params
-					eb.addParam(AlarmChangeEventConstants.OLD_ALARM_VALUES_PARAM,oldJsonObject.toString());
-					eb.addParam(AlarmChangeEventConstants.NEW_ALARM_VALUES_PARAM,newJsonObject.toString());
+					eb.addParam(AlarmChangeEventConstants.OLD_ALARM_VALUES_PARAM,oldJsonObject.toString(), TYPE_JSON, ENCODING_TEXT);
+					eb.addParam(AlarmChangeEventConstants.NEW_ALARM_VALUES_PARAM,newJsonObject.toString(), TYPE_JSON, ENCODING_TEXT);
 
 					// set initial severity to new alarm severity
 					if (newJsonObject.get("severity")!=null) {
@@ -185,8 +187,8 @@ public class AlarmChangeNotificationClient implements NotificationClient {
 							eb.addParam(AlarmChangeEventConstants.OLDSEVERITY_PARAM,oldseverity);
 
 							//copy in all values as json in params
-							eb.addParam(AlarmChangeEventConstants.OLD_ALARM_VALUES_PARAM,oldJsonObject.toString());
-							eb.addParam(AlarmChangeEventConstants.NEW_ALARM_VALUES_PARAM,newJsonObject.toString());
+							eb.addParam(AlarmChangeEventConstants.OLD_ALARM_VALUES_PARAM,oldJsonObject.toString(), TYPE_JSON, ENCODING_TEXT);
+							eb.addParam(AlarmChangeEventConstants.NEW_ALARM_VALUES_PARAM,newJsonObject.toString(), TYPE_JSON, ENCODING_TEXT);
 
 							sendEvent(eb.getEvent());
 						}
@@ -202,8 +204,8 @@ public class AlarmChangeNotificationClient implements NotificationClient {
 									new EventBuilder(AlarmChangeEventConstants.ALARM_ACKNOWLEDGED_EVENT, EVENT_SOURCE_NAME));
 
 							//copy in all values as json in params
-							eb.addParam(AlarmChangeEventConstants.OLD_ALARM_VALUES_PARAM,oldJsonObject.toString());
-							eb.addParam(AlarmChangeEventConstants.NEW_ALARM_VALUES_PARAM,newJsonObject.toString());
+							eb.addParam(AlarmChangeEventConstants.OLD_ALARM_VALUES_PARAM,oldJsonObject.toString(), TYPE_JSON, ENCODING_TEXT);
+							eb.addParam(AlarmChangeEventConstants.NEW_ALARM_VALUES_PARAM,newJsonObject.toString(), TYPE_JSON, ENCODING_TEXT);
 
 							sendEvent(eb.getEvent());
 
@@ -217,8 +219,8 @@ public class AlarmChangeNotificationClient implements NotificationClient {
 										new EventBuilder(AlarmChangeEventConstants.ALARM_UNACKNOWLEDGED_EVENT, EVENT_SOURCE_NAME));
 
 								//copy in all values as json in params
-								eb.addParam(AlarmChangeEventConstants.OLD_ALARM_VALUES_PARAM,oldJsonObject.toString());
-								eb.addParam(AlarmChangeEventConstants.NEW_ALARM_VALUES_PARAM,newJsonObject.toString());
+								eb.addParam(AlarmChangeEventConstants.OLD_ALARM_VALUES_PARAM,oldJsonObject.toString(), TYPE_JSON, ENCODING_TEXT);
+								eb.addParam(AlarmChangeEventConstants.NEW_ALARM_VALUES_PARAM,newJsonObject.toString(), TYPE_JSON, ENCODING_TEXT);
 
 								sendEvent(eb.getEvent());
 							}
@@ -236,8 +238,8 @@ public class AlarmChangeNotificationClient implements NotificationClient {
 									new EventBuilder(AlarmChangeEventConstants.ALARM_SUPPRESSED_EVENT, EVENT_SOURCE_NAME));
 
 							//copy in all values as json in params
-							eb.addParam(AlarmChangeEventConstants.OLD_ALARM_VALUES_PARAM,oldJsonObject.toString());
-							eb.addParam(AlarmChangeEventConstants.NEW_ALARM_VALUES_PARAM,newJsonObject.toString());
+							eb.addParam(AlarmChangeEventConstants.OLD_ALARM_VALUES_PARAM,oldJsonObject.toString(), TYPE_JSON, ENCODING_TEXT);
+							eb.addParam(AlarmChangeEventConstants.NEW_ALARM_VALUES_PARAM,newJsonObject.toString(), TYPE_JSON, ENCODING_TEXT);
 
 							sendEvent(eb.getEvent());
 
@@ -253,8 +255,8 @@ public class AlarmChangeNotificationClient implements NotificationClient {
 												EVENT_SOURCE_NAME));
 
 								//copy in all values as json in params
-								eb.addParam(AlarmChangeEventConstants.OLD_ALARM_VALUES_PARAM,oldJsonObject.toString());
-								eb.addParam(AlarmChangeEventConstants.NEW_ALARM_VALUES_PARAM,newJsonObject.toString());
+								eb.addParam(AlarmChangeEventConstants.OLD_ALARM_VALUES_PARAM,oldJsonObject.toString(), TYPE_JSON, ENCODING_TEXT);
+								eb.addParam(AlarmChangeEventConstants.NEW_ALARM_VALUES_PARAM,newJsonObject.toString(), TYPE_JSON, ENCODING_TEXT);
 
 								sendEvent(eb.getEvent());
 							}
@@ -284,8 +286,8 @@ public class AlarmChangeNotificationClient implements NotificationClient {
 							eb.addParam(AlarmChangeEventConstants.TTICKETSTATE_PARAM,newtticketstate);
 
 							//copy in all values as json in params
-							eb.addParam(AlarmChangeEventConstants.OLD_ALARM_VALUES_PARAM,oldJsonObject.toString());
-							eb.addParam(AlarmChangeEventConstants.NEW_ALARM_VALUES_PARAM,newJsonObject.toString());
+							eb.addParam(AlarmChangeEventConstants.OLD_ALARM_VALUES_PARAM,oldJsonObject.toString(), TYPE_JSON, ENCODING_TEXT);
+							eb.addParam(AlarmChangeEventConstants.NEW_ALARM_VALUES_PARAM,newJsonObject.toString(), TYPE_JSON, ENCODING_TEXT);
 
 							sendEvent(eb.getEvent());
 						}
@@ -302,8 +304,8 @@ public class AlarmChangeNotificationClient implements NotificationClient {
 							eb.addParam(AlarmChangeEventConstants.STICKYMEMO_PARAM,newstickymemo);
 
 							//copy in all values as json in params
-							eb.addParam(AlarmChangeEventConstants.OLD_ALARM_VALUES_PARAM,oldJsonObject.toString());
-							eb.addParam(AlarmChangeEventConstants.NEW_ALARM_VALUES_PARAM,newJsonObject.toString());
+							eb.addParam(AlarmChangeEventConstants.OLD_ALARM_VALUES_PARAM,oldJsonObject.toString(), TYPE_JSON, ENCODING_TEXT);
+							eb.addParam(AlarmChangeEventConstants.NEW_ALARM_VALUES_PARAM,newJsonObject.toString(), TYPE_JSON, ENCODING_TEXT);
 
 							sendEvent(eb.getEvent());
 						}
@@ -332,8 +334,8 @@ public class AlarmChangeNotificationClient implements NotificationClient {
 									new EventBuilder(AlarmChangeEventConstants.ALARM_CHANGED_EVENT, EVENT_SOURCE_NAME));
 
 							//copy in all values as json in params
-							eb.addParam(AlarmChangeEventConstants.OLD_ALARM_VALUES_PARAM,oldJsonObject.toString());
-							eb.addParam(AlarmChangeEventConstants.NEW_ALARM_VALUES_PARAM,newJsonObject.toString());
+							eb.addParam(AlarmChangeEventConstants.OLD_ALARM_VALUES_PARAM,oldJsonObject.toString(), TYPE_JSON, ENCODING_TEXT);
+							eb.addParam(AlarmChangeEventConstants.NEW_ALARM_VALUES_PARAM,newJsonObject.toString(), TYPE_JSON, ENCODING_TEXT);
 
 							sendEvent(eb.getEvent());
 						}
diff --git a/features/alarm-change-notifier/main-module/src/main/java/org/opennms/plugins/dbnotifier/alarmnotifier/MemosChangeNotificationClient.java b/features/alarm-change-notifier/main-module/src/main/java/org/opennms/plugins/dbnotifier/alarmnotifier/MemosChangeNotificationClient.java
index b30c4a00479..f3edf521c10 100644
--- a/features/alarm-change-notifier/main-module/src/main/java/org/opennms/plugins/dbnotifier/alarmnotifier/MemosChangeNotificationClient.java
+++ b/features/alarm-change-notifier/main-module/src/main/java/org/opennms/plugins/dbnotifier/alarmnotifier/MemosChangeNotificationClient.java
@@ -29,6 +29,9 @@
 package org.opennms.plugins.dbnotifier.alarmnotifier;
 
 
+import static org.opennms.plugins.dbnotifier.alarmnotifier.AlarmChangeNotificationClient.ENCODING_TEXT;
+import static org.opennms.plugins.dbnotifier.alarmnotifier.AlarmChangeNotificationClient.TYPE_JSON;
+
 import java.sql.Timestamp;
 import java.util.Calendar;
 
@@ -110,7 +113,7 @@ public class MemosChangeNotificationClient implements NotificationClient {
 					EventBuilder eb= new EventBuilder( AlarmChangeEventConstants.STICKY_MEMO_EVENT, EVENT_SOURCE_NAME);
 
 					//copy in all values as json in params
-					eb.addParam(AlarmChangeEventConstants.MEMO_VALUES_PARAM,memoJsonObject.toString());
+					eb.addParam(AlarmChangeEventConstants.MEMO_VALUES_PARAM,memoJsonObject.toString(), TYPE_JSON, ENCODING_TEXT);
 					eb.addParam(AlarmChangeEventConstants.MEMO_ALARMID_PARAM, alarmId );
 					eb.addParam(AlarmChangeEventConstants.MEMO_BODY_PARAM, body );
 					eb.addParam(AlarmChangeEventConstants.MEMO_AUTHOR_PARAM, author );
@@ -121,7 +124,7 @@ public class MemosChangeNotificationClient implements NotificationClient {
 					EventBuilder eb= new EventBuilder(AlarmChangeEventConstants.JOURNAL_MEMO_EVENT, EVENT_SOURCE_NAME);
 
 					//copy in all values as json in params
-					eb.addParam(AlarmChangeEventConstants.MEMO_VALUES_PARAM,memoJsonObject.toString());
+					eb.addParam(AlarmChangeEventConstants.MEMO_VALUES_PARAM,memoJsonObject.toString(), TYPE_JSON, ENCODING_TEXT);
 					eb.addParam(AlarmChangeEventConstants.MEMO_ALARMID_PARAM, alarmId );
 					eb.addParam(AlarmChangeEventConstants.MEMO_BODY_PARAM, body );
 					eb.addParam(AlarmChangeEventConstants.MEMO_AUTHOR_PARAM, author );
diff --git a/features/collection/api/src/main/java/org/opennms/netmgt/collection/api/InvalidCollectionAgentException.java b/features/collection/api/src/main/java/org/opennms/netmgt/collection/api/InvalidCollectionAgentException.java
new file mode 100644
index 00000000000..5b43efd3058
--- /dev/null
+++ b/features/collection/api/src/main/java/org/opennms/netmgt/collection/api/InvalidCollectionAgentException.java
@@ -0,0 +1,35 @@
+/*******************************************************************************
+ * This file is part of OpenNMS(R).
+ *
+ * Copyright (C) 2018 The OpenNMS Group, Inc.
+ * OpenNMS(R) is Copyright (C) 1999-2018 The OpenNMS Group, Inc.
+ *
+ * OpenNMS(R) is a registered trademark of The OpenNMS Group, Inc.
+ *
+ * OpenNMS(R) is free software: you can redistribute it and/or modify
+ * it under the terms of the GNU Affero General Public License as published
+ * by the Free Software Foundation, either version 3 of the License,
+ * or (at your option) any later version.
+ *
+ * OpenNMS(R) is distributed in the hope that it will be useful,
+ * but WITHOUT ANY WARRANTY; without even the implied warranty of
+ * MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
+ * GNU Affero General Public License for more details.
+ *
+ * You should have received a copy of the GNU Affero General Public License
+ * along with OpenNMS(R).  If not, see:
+ *      http://www.gnu.org/licenses/
+ *
+ * For more information contact:
+ *     OpenNMS(R) Licensing <license@opennms.org>
+ *     http://www.opennms.org/
+ *     http://www.opennms.com/
+ *******************************************************************************/
+
+package org.opennms.netmgt.collection.api;
+
+public class InvalidCollectionAgentException extends CollectionException {
+    public InvalidCollectionAgentException(String message) {
+        super(message);
+    }
+}
diff --git a/features/collection/shell-commands/src/main/java/org/opennms/netmgt/collection/commands/CollectCommand.java b/features/collection/shell-commands/src/main/java/org/opennms/netmgt/collection/commands/CollectCommand.java
index b64f651d050..52e4db2eb68 100644
--- a/features/collection/shell-commands/src/main/java/org/opennms/netmgt/collection/commands/CollectCommand.java
+++ b/features/collection/shell-commands/src/main/java/org/opennms/netmgt/collection/commands/CollectCommand.java
@@ -53,6 +53,7 @@ import org.opennms.netmgt.collection.api.CollectionInitializationException;
 import org.opennms.netmgt.collection.api.CollectionResource;
 import org.opennms.netmgt.collection.api.CollectionSet;
 import org.opennms.netmgt.collection.api.CollectionStatus;
+import org.opennms.netmgt.collection.api.InvalidCollectionAgentException;
 import org.opennms.netmgt.collection.api.LocationAwareCollectorClient;
 import org.opennms.netmgt.collection.api.ServiceCollector;
 import org.opennms.netmgt.collection.api.ServiceCollectorRegistry;
@@ -134,6 +135,11 @@ public class CollectCommand implements Action {
                 } catch (InterruptedException e) {
                     System.out.println("\nInterrupted.");
                 } catch (ExecutionException e) {
+                    final Throwable cause = e.getCause();
+                    if (cause != null && cause instanceof InvalidCollectionAgentException) {
+                        System.out.printf("The collector requires a valid node and interface. Try specifying a valid node using the --node option.\n", e);
+                        break;
+                    }
                     System.out.printf("\nCollect failed with:", e);
                     e.printStackTrace();
                     System.out.println();
diff --git a/features/events/api/src/main/java/org/opennms/netmgt/xml/event/AlarmData.java b/features/events/api/src/main/java/org/opennms/netmgt/xml/event/AlarmData.java
index 9b9cb934e03..9b519c397d2 100644
--- a/features/events/api/src/main/java/org/opennms/netmgt/xml/event/AlarmData.java
+++ b/features/events/api/src/main/java/org/opennms/netmgt/xml/event/AlarmData.java
@@ -103,7 +103,20 @@ public class AlarmData implements Serializable {
     @XmlElement(name="update-field", required=false)
     @Valid
     private List<UpdateField> m_updateFieldList = new ArrayList<>();
-    
+
+    /**
+     * Field m_impacts
+     */
+    @XmlElement(name = "impacts", required = false)
+    @Valid
+    private List<String> m_impacts = new ArrayList<>();
+
+    /**
+     * Field m_causes
+     */
+    @XmlElement(name = "causes", required = false)
+    @Valid
+    private List<String> m_causes = new ArrayList<>();
 
     public AlarmData() {
         super();
@@ -329,8 +342,25 @@ public class AlarmData implements Serializable {
         m_updateFieldList.addAll(fields);
     }
 
-        @Override
+    public List<String> getImpacts() {
+        return m_impacts;
+    }
+
+    public void setImpacts(List<String> impacts) {
+        this.m_impacts = impacts;
+    }
+
+    public List<String> getCauses() {
+        return m_causes;
+    }
+
+    public void setCauses(List<String> causes) {
+        this.m_causes = causes;
+    }
+
+    @Override
     public String toString() {
     	return new OnmsStringBuilder(this).toString();
     }
+
 }
diff --git a/features/events/api/src/main/java/org/opennms/netmgt/xml/event/Value.java b/features/events/api/src/main/java/org/opennms/netmgt/xml/event/Value.java
index 3256185aa45..9ea13a9c521 100644
--- a/features/events/api/src/main/java/org/opennms/netmgt/xml/event/Value.java
+++ b/features/events/api/src/main/java/org/opennms/netmgt/xml/event/Value.java
@@ -70,7 +70,7 @@ public class Value implements Serializable {
      * Field _type.
      */
 	@XmlAttribute(name="type")
-	@Pattern(regexp="(int|string|Int32|OctetString|Null|ObjectIdentifier|Sequence|IpAddress|Counter32|Gauge32|TimeTicks|Opaque|Counter64)")
+	@Pattern(regexp="(int|string|Int32|OctetString|Null|ObjectIdentifier|Sequence|IpAddress|Counter32|Gauge32|TimeTicks|Opaque|Counter64|json)")
     private java.lang.String _type = "string";
 
     /**
diff --git a/features/kafka/pom.xml b/features/kafka/pom.xml
new file mode 100644
index 00000000000..8fc75b45a84
--- /dev/null
+++ b/features/kafka/pom.xml
@@ -0,0 +1,23 @@
+<?xml version="1.0" encoding="UTF-8"?>
+<project
+  xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"
+  xmlns="http://maven.apache.org/POM/4.0.0"
+  xsi:schemaLocation="http://maven.apache.org/POM/4.0.0 http://maven.apache.org/maven-v4_0_0.xsd"
+>
+  <parent>
+    <groupId>org.opennms</groupId>
+    <artifactId>org.opennms.features</artifactId>
+    <version>22.0.0-SNAPSHOT</version>
+  </parent>
+
+  <modelVersion>4.0.0</modelVersion>
+  <groupId>org.opennms.features</groupId>
+  <artifactId>org.opennms.features.kafka</artifactId>
+  <name>OpenNMS :: Features :: Kafka</name>
+  <packaging>pom</packaging>
+
+  <modules>
+    <module>producer</module>
+  </modules>
+
+</project>
diff --git a/features/kafka/producer/pom.xml b/features/kafka/producer/pom.xml
new file mode 100644
index 00000000000..00ecd1ede8d
--- /dev/null
+++ b/features/kafka/producer/pom.xml
@@ -0,0 +1,173 @@
+<?xml version="1.0" encoding="UTF-8"?>
+<project
+    xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"
+    xmlns="http://maven.apache.org/POM/4.0.0"
+    xsi:schemaLocation="
+        http://maven.apache.org/POM/4.0.0 http://maven.apache.org/maven-v4_0_0.xsd
+">
+
+  <parent>
+    <groupId>org.opennms.features</groupId>
+    <artifactId>org.opennms.features.kafka</artifactId>
+    <version>22.0.0-SNAPSHOT</version>
+  </parent>
+
+  <modelVersion>4.0.0</modelVersion>
+  <groupId>org.opennms.features.kafka</groupId>
+  <artifactId>org.opennms.features.kafka.producer</artifactId>
+
+  <name>OpenNMS :: Features :: Kafka :: Producer</name>
+
+  <packaging>bundle</packaging>
+
+  <build>
+    <plugins>
+      <plugin>
+        <groupId>org.apache.felix</groupId>
+        <artifactId>maven-bundle-plugin</artifactId>
+        <extensions>true</extensions>
+        <configuration>
+          <instructions>
+            <Bundle-RequiredExecutionEnvironment>JavaSE-1.8</Bundle-RequiredExecutionEnvironment>
+            <Karaf-Commands>*</Karaf-Commands>
+          </instructions>
+        </configuration>
+      </plugin>
+    </plugins>
+  </build>
+
+  <dependencies>
+    <dependency>
+      <groupId>org.slf4j</groupId>
+      <artifactId>slf4j-api</artifactId>
+      <scope>provided</scope>
+    </dependency>
+    <dependency>
+      <groupId>org.osgi</groupId>
+      <artifactId>org.osgi.core</artifactId>
+      <scope>provided</scope>
+    </dependency>
+    <dependency>
+      <groupId>org.osgi</groupId>
+      <artifactId>org.osgi.compendium</artifactId>
+      <scope>provided</scope>
+    </dependency>
+    <dependency>
+      <groupId>org.opennms.core</groupId>
+      <artifactId>org.opennms.core.lib</artifactId>
+    </dependency>
+    <dependency>
+      <groupId>org.opennms</groupId>
+      <artifactId>opennms-dao-api</artifactId>
+    </dependency>
+
+    <!-- Kafka -->
+    <dependency>
+      <groupId>org.apache.kafka</groupId>
+      <artifactId>kafka-streams</artifactId>
+      <version>${kafkaStreamsVersion}</version>
+    </dependency>
+    <dependency>
+      <groupId>org.apache.servicemix.bundles</groupId>
+      <artifactId>org.apache.servicemix.bundles.kafka-clients</artifactId>
+      <version>${kafkaStreamsBundleVersion}</version>
+      <exclusions>
+        <exclusion>
+          <artifactId>log4j</artifactId>
+          <groupId>log4j</groupId>
+        </exclusion>
+        <exclusion>
+          <artifactId>slf4j-log4j12</artifactId>
+          <groupId>org.slf4j</groupId>
+        </exclusion>
+      </exclusions>
+    </dependency>
+    <dependency>
+      <groupId> com.google.protobuf</groupId>
+      <artifactId>protobuf-java</artifactId>
+      <version>${protobuf3Version}</version>
+    </dependency>
+    <dependency>
+      <groupId>org.opennms</groupId>
+      <artifactId>opennms-alarm-api</artifactId>
+      <version>${project.version}</version>
+    </dependency>
+    <dependency>
+      <groupId>org.apache.karaf.shell</groupId>
+      <artifactId>org.apache.karaf.shell.core</artifactId>
+    </dependency>
+
+    <!-- Test -->
+    <dependency>
+      <groupId>junit</groupId>
+      <artifactId>junit</artifactId>
+      <scope>test</scope>
+    </dependency>
+    <dependency>
+      <groupId>org.opennms.core.test-api</groupId>
+      <artifactId>org.opennms.core.test-api.xml</artifactId>
+      <scope>test</scope>
+    </dependency>
+    <dependency>
+      <groupId>org.opennms.core.test-api</groupId>
+      <artifactId>org.opennms.core.test-api.camel</artifactId>
+      <scope>test</scope>
+    </dependency>
+    <dependency>
+      <groupId>org.opennms</groupId>
+      <artifactId>opennms-dao</artifactId>
+      <scope>test</scope>
+    </dependency>
+    <dependency>
+      <groupId>org.opennms</groupId>
+      <artifactId>opennms-alarmd</artifactId>
+      <scope>test</scope>
+    </dependency>
+    <dependency>
+      <groupId>org.opennms.core.test-api</groupId>
+      <artifactId>org.opennms.core.test-api.services</artifactId>
+      <scope>test</scope>
+    </dependency>
+    <dependency>
+      <groupId>org.opennms.core</groupId>
+      <artifactId>org.opennms.core.daemon</artifactId>
+      <scope>test</scope>
+    </dependency>
+    <dependency>
+      <groupId>org.opennms</groupId>
+      <artifactId>opennms-services</artifactId>
+      <scope>test</scope>
+    </dependency>
+    <dependency>
+      <groupId>com.jayway.awaitility</groupId>
+      <artifactId>awaitility</artifactId>
+      <scope>test</scope>
+    </dependency>
+    <dependency>
+      <groupId>org.opennms.core.test-api</groupId>
+      <artifactId>org.opennms.core.test-api.kafka</artifactId>
+      <version>${project.version}</version>
+      <scope>test</scope>
+    </dependency>
+    <dependency>
+      <groupId>org.opennms.tests</groupId>
+      <artifactId>org.opennms.tests.mock-elements</artifactId>
+      <scope>test</scope>
+    </dependency>
+    <dependency>
+      <groupId>org.opennms</groupId>
+      <artifactId>opennms-dao-mock</artifactId>
+      <scope>test</scope>
+    </dependency>
+        <dependency>
+      <groupId>org.opennms.core.test-api</groupId>
+      <artifactId>org.opennms.core.test-api.db</artifactId>
+      <scope>test</scope>
+    </dependency>
+    <dependency>
+      <groupId>org.mockito</groupId>
+      <artifactId>mockito-all</artifactId>
+      <scope>test</scope>
+    </dependency>
+  </dependencies>
+</project>
diff --git a/features/kafka/producer/src/main/java/org/opennms/features/kafka/producer/NodeCache.java b/features/kafka/producer/src/main/java/org/opennms/features/kafka/producer/NodeCache.java
new file mode 100644
index 00000000000..46438f296bb
--- /dev/null
+++ b/features/kafka/producer/src/main/java/org/opennms/features/kafka/producer/NodeCache.java
@@ -0,0 +1,85 @@
+/*******************************************************************************
+ * This file is part of OpenNMS(R).
+ *
+ * Copyright (C) 2018 The OpenNMS Group, Inc.
+ * OpenNMS(R) is Copyright (C) 1999-2018 The OpenNMS Group, Inc.
+ *
+ * OpenNMS(R) is a registered trademark of The OpenNMS Group, Inc.
+ *
+ * OpenNMS(R) is free software: you can redistribute it and/or modify
+ * it under the terms of the GNU Affero General Public License as published
+ * by the Free Software Foundation, either version 3 of the License,
+ * or (at your option) any later version.
+ *
+ * OpenNMS(R) is distributed in the hope that it will be useful,
+ * but WITHOUT ANY WARRANTY; without even the implied warranty of
+ * MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
+ * GNU Affero General Public License for more details.
+ *
+ * You should have received a copy of the GNU Affero General Public License
+ * along with OpenNMS(R).  If not, see:
+ *      http://www.gnu.org/licenses/
+ *
+ * For more information contact:
+ *     OpenNMS(R) Licensing <license@opennms.org>
+ *     http://www.opennms.org/
+ *     http://www.opennms.com/
+ *******************************************************************************/
+
+package org.opennms.features.kafka.producer;
+
+import java.util.Map;
+import java.util.Objects;
+import java.util.concurrent.TimeUnit;
+import java.util.function.Consumer;
+
+import org.opennms.netmgt.dao.api.NodeDao;
+import org.opennms.netmgt.model.OnmsNode;
+import org.springframework.transaction.support.TransactionCallback;
+import org.springframework.transaction.support.TransactionOperations;
+
+import com.google.common.collect.Maps;
+
+public class NodeCache {
+
+    private final NodeDao nodeDao;
+
+    private final TransactionOperations transactionOperations;
+
+    private final Map<Long, Long> lastUpdatedByNodeId = Maps.newHashMap();
+
+    private long timeoutInMs = TimeUnit.MINUTES.toMillis(5);
+
+    public NodeCache(NodeDao nodeDao, TransactionOperations transactionOperations) {
+        this.nodeDao = Objects.requireNonNull(nodeDao);
+        this.transactionOperations = Objects.requireNonNull(transactionOperations);
+    }
+
+    public synchronized void triggerIfNeeded(long nodeId, Consumer<OnmsNode> consumer) {
+        final long now = System.currentTimeMillis();
+        final Long lastUpdated = lastUpdatedByNodeId.get(nodeId);
+        if (lastUpdated != null && now - lastUpdated <= timeoutInMs) {
+            // No update required
+            return;
+        }
+
+        transactionOperations.execute((TransactionCallback<Void>) status -> {
+            // Lookup the node
+            final OnmsNode node = nodeDao.get((int)nodeId);
+
+            // Use the timestamp we gather at the beginning of the function, instead
+            // of making another call to System.currentTimeMillis(), even though
+            // some time may have passed since
+            lastUpdatedByNodeId.put(nodeId, now);
+
+            // We got a node, trigger the consumer while holding the transaction
+            // in order to allow relationships to be loaded
+            consumer.accept(node);
+            return null;
+        });
+    }
+
+    public void setTimeoutInMs(long timeoutInMs) {
+        this.timeoutInMs = timeoutInMs;
+    }
+}
diff --git a/features/kafka/producer/src/main/java/org/opennms/features/kafka/producer/OpennmsKafkaProducer.java b/features/kafka/producer/src/main/java/org/opennms/features/kafka/producer/OpennmsKafkaProducer.java
new file mode 100644
index 00000000000..4cdeabbe4c1
--- /dev/null
+++ b/features/kafka/producer/src/main/java/org/opennms/features/kafka/producer/OpennmsKafkaProducer.java
@@ -0,0 +1,359 @@
+/*******************************************************************************
+ * This file is part of OpenNMS(R).
+ *
+ * Copyright (C) 2018 The OpenNMS Group, Inc.
+ * OpenNMS(R) is Copyright (C) 1999-2018 The OpenNMS Group, Inc.
+ *
+ * OpenNMS(R) is a registered trademark of The OpenNMS Group, Inc.
+ *
+ * OpenNMS(R) is free software: you can redistribute it and/or modify
+ * it under the terms of the GNU Affero General Public License as published
+ * by the Free Software Foundation, either version 3 of the License,
+ * or (at your option) any later version.
+ *
+ * OpenNMS(R) is distributed in the hope that it will be useful,
+ * but WITHOUT ANY WARRANTY; without even the implied warranty of
+ * MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
+ * GNU Affero General Public License for more details.
+ *
+ * You should have received a copy of the GNU Affero General Public License
+ * along with OpenNMS(R).  If not, see:
+ *      http://www.gnu.org/licenses/
+ *
+ * For more information contact:
+ *     OpenNMS(R) Licensing <license@opennms.org>
+ *     http://www.opennms.org/
+ *     http://www.opennms.com/
+ *******************************************************************************/
+
+package org.opennms.features.kafka.producer;
+
+import java.io.IOException;
+import java.util.Dictionary;
+import java.util.Enumeration;
+import java.util.Objects;
+import java.util.Properties;
+import java.util.concurrent.Callable;
+import java.util.concurrent.CountDownLatch;
+import java.util.function.Consumer;
+
+import org.apache.kafka.clients.producer.KafkaProducer;
+import org.apache.kafka.clients.producer.ProducerRecord;
+import org.apache.kafka.clients.producer.RecordMetadata;
+import org.apache.kafka.common.serialization.ByteArraySerializer;
+import org.apache.kafka.common.serialization.StringSerializer;
+import org.opennms.features.kafka.producer.model.OpennmsModelProtos;
+import org.opennms.netmgt.alarmd.api.AlarmLifecycleListener;
+import org.opennms.netmgt.alarmd.api.AlarmLifecycleSubscriptionService;
+import org.opennms.netmgt.events.api.EventListener;
+import org.opennms.netmgt.events.api.EventSubscriptionService;
+import org.opennms.netmgt.model.OnmsAlarm;
+import org.opennms.netmgt.xml.event.Event;
+import org.osgi.service.cm.ConfigurationAdmin;
+import org.slf4j.Logger;
+import org.slf4j.LoggerFactory;
+import org.springframework.expression.Expression;
+import org.springframework.expression.ExpressionParser;
+import org.springframework.expression.spel.standard.SpelExpressionParser;
+
+import com.google.common.base.Strings;
+
+public class OpennmsKafkaProducer implements AlarmLifecycleListener, EventListener {
+    private static final Logger LOG = LoggerFactory.getLogger(OpennmsKafkaProducer.class);
+
+    public static final String KAFKA_CLIENT_PID = "org.opennms.features.kafka.producer.client";
+    private static final ExpressionParser SPEL_PARSER = new SpelExpressionParser();
+
+    private final ProtobufMapper protobufMapper;
+    private final NodeCache nodeCache;
+    private final ConfigurationAdmin configAdmin;
+    private final EventSubscriptionService eventSubscriptionService;
+    private final AlarmLifecycleSubscriptionService alarmLifecycleSubscriptionService;
+
+    private String eventTopic;
+    private String alarmTopic;
+    private String nodeTopic;
+
+    private boolean forwardEvents;
+    private boolean forwardAlarms;
+    private boolean forwardNodes;
+    private Expression eventFilterExpression;
+    private Expression alarmFilterExpression;
+
+    private final CountDownLatch forwardedEvent = new CountDownLatch(1);
+    private final CountDownLatch forwardedAlarm = new CountDownLatch(1);
+    private final CountDownLatch forwardedNode = new CountDownLatch(1);
+
+    private KafkaProducer<String, byte[]> producer;
+
+    public OpennmsKafkaProducer(ProtobufMapper protobufMapper, NodeCache nodeCache,
+                                ConfigurationAdmin configAdmin, EventSubscriptionService eventSubscriptionService,
+                                AlarmLifecycleSubscriptionService alarmLifecycleSubscriptionService) {
+        this.protobufMapper = Objects.requireNonNull(protobufMapper);
+        this.nodeCache = Objects.requireNonNull(nodeCache);
+        this.configAdmin = Objects.requireNonNull(configAdmin);
+        this.eventSubscriptionService = Objects.requireNonNull(eventSubscriptionService);
+        this.alarmLifecycleSubscriptionService = Objects.requireNonNull(alarmLifecycleSubscriptionService);
+    }
+
+    public void init() throws IOException {
+        // Create the Kafka producer
+        final Properties producerConfig = new Properties();
+        final Dictionary<String, Object> properties = configAdmin.getConfiguration(KAFKA_CLIENT_PID).getProperties();
+        if (properties != null) {
+            final Enumeration<String> keys = properties.keys();
+            while (keys.hasMoreElements()) {
+                final String key = keys.nextElement();
+                producerConfig.put(key, properties.get(key));
+            }
+        }
+        // Overwrite the serializers, since we rely on these
+        producerConfig.put("key.serializer", StringSerializer.class.getCanonicalName());
+        producerConfig.put("value.serializer", ByteArraySerializer.class.getCanonicalName());
+
+        final ClassLoader currentClassLoader = Thread.currentThread().getContextClassLoader();
+        try {
+            // Class-loader hack for accessing the org.apache.kafka.common.serialization.*
+            Thread.currentThread().setContextClassLoader(null);
+            producer = new KafkaProducer<>(producerConfig);
+        } finally {
+            Thread.currentThread().setContextClassLoader(currentClassLoader);
+        }
+
+        if (forwardEvents) {
+            eventSubscriptionService.addEventListener(this);
+        }
+        if (forwardAlarms) {
+            alarmLifecycleSubscriptionService.addAlarmLifecyleListener(this);
+        }
+    }
+
+    public void destroy() {
+        if (producer != null) {
+            producer.close();
+            producer = null;
+        }
+
+        if (forwardEvents) {
+            eventSubscriptionService.removeEventListener(this);
+        }
+        if (forwardAlarms) {
+            alarmLifecycleSubscriptionService.removeAlarmLifecycleListener(this);
+        }
+    }
+
+    private void forwardEvent(Event event) {
+        boolean shouldForwardEvent = true;
+        // Filtering
+        if (eventFilterExpression != null) {
+            try {
+                shouldForwardEvent = eventFilterExpression.getValue(event, Boolean.class);
+            } catch (Exception e) {
+                LOG.error("Event filter '{}' failed to return a result for event: {}. The event will be forwarded anyways.",
+                        eventFilterExpression.getExpressionString(), event.toStringSimple(), e);
+            }
+        }
+        if (!shouldForwardEvent) {
+            if (LOG.isTraceEnabled()) {
+                LOG.trace("Event {} not forwarded due to event filter: {}",
+                        event.toStringSimple(), eventFilterExpression.getExpressionString());
+            }
+            return;
+        }
+
+        // Node handling
+        if (forwardNodes && event.getNodeid() != null && event.getNodeid() != 0) {
+            maybeUpdateNode(event.getNodeid());
+        }
+
+        // Forward!
+        sendRecord(() -> {
+            final OpennmsModelProtos.Event mappedEvent = protobufMapper.toEvent(event).build();
+            LOG.debug("Sending event with UEI: {}", mappedEvent.getUei());
+            return new ProducerRecord<>(eventTopic, mappedEvent.getUei(), mappedEvent.toByteArray());
+        }, recordMetadata -> {
+            // We've got an ACK from the server that the event was forwarded
+            // Let other threads know when we've successfully forwarded an event
+            forwardedEvent.countDown();
+        });
+    }
+
+    private void updateAlarm(String reductionKey, OnmsAlarm alarm) {
+        // Always push null records, no good way to perform filtering on these
+        if (alarm == null) {
+            // The alarm was deleted, push a null record to the reduction key
+            sendRecord(() -> {
+                LOG.debug("Deleting alarm with reduction key: {}", reductionKey);
+                return new ProducerRecord<>(alarmTopic, reductionKey, null);
+            }, recordMetadata -> {
+                // We've got an ACK from the server that the alarm was forwarded
+                // Let other threads know when we've successfully forwarded an alarm
+                forwardedAlarm.countDown();
+            });
+            return;
+        }
+
+        // Filtering
+        boolean shouldForwardAlarm = true;
+        if (alarmFilterExpression != null) {
+            try {
+                shouldForwardAlarm = alarmFilterExpression.getValue(alarm, Boolean.class);
+            } catch (Exception e) {
+                LOG.error("Alarm filter '{}' failed to return a result for event: {}. The alarm will be forwarded anyways.",
+                        alarmFilterExpression.getExpressionString(), alarm, e);
+            }
+        }
+        if (!shouldForwardAlarm) {
+            if (LOG.isTraceEnabled()) {
+                LOG.trace("Alarm {} not forwarded due to event filter: {}",
+                        alarm, alarmFilterExpression.getExpressionString());
+            }
+            return;
+        }
+
+        // Node handling
+        if (forwardNodes && alarm.getNodeId() != null) {
+            maybeUpdateNode(alarm.getNodeId());
+        }
+
+        // Forward!
+        sendRecord(() -> {
+            final OpennmsModelProtos.Alarm mappedAlarm = protobufMapper.toAlarm(alarm).build();
+            LOG.debug("Sending alarm with reduction key: {}", reductionKey);
+            return new ProducerRecord<>(alarmTopic, reductionKey, mappedAlarm.toByteArray());
+        }, recordMetadata -> {
+            // We've got an ACK from the server that the alarm was forwarded
+            // Let other threads know when we've successfully forwarded an alarm
+            forwardedAlarm.countDown();
+        });
+    }
+
+    private void maybeUpdateNode(long nodeId) {
+        nodeCache.triggerIfNeeded(nodeId, (node) -> {
+            final String nodeCriteria;
+            if (node != null && node.getForeignSource() != null && node.getForeignId() != null) {
+                nodeCriteria = String.format("%s:%s", node.getForeignSource(), node.getForeignId());
+            } else {
+                nodeCriteria = Long.toString(nodeId);
+            }
+
+            if (node == null) {
+                // The node was deleted, push a null record
+                sendRecord(() -> {
+                    LOG.debug("Deleting node with criteria: {}", nodeCriteria);
+                    return new ProducerRecord<>(nodeTopic, nodeCriteria, null);
+                });
+                return;
+            }
+
+            sendRecord(() -> {
+                final OpennmsModelProtos.Node mappedNode = protobufMapper.toNode(node).build();
+                LOG.debug("Sending node with criteria: {}", nodeCriteria);
+                return new ProducerRecord<>(nodeTopic, nodeCriteria, mappedNode.toByteArray());
+            }, recordMetadata -> {
+                // We've got an ACK from the server that the node was forwarded
+                // Let other threads know when we've successfully forwarded a node
+                forwardedNode.countDown();
+            });
+        });
+    }
+
+    private void sendRecord(Callable<ProducerRecord<String,byte[]>> callable) {
+        sendRecord(callable, null);
+    }
+
+    private void sendRecord(Callable<ProducerRecord<String,byte[]>> callable, Consumer<RecordMetadata> callback) {
+        if (producer == null) {
+            return;
+        }
+
+        final ProducerRecord<String,byte[]> record;
+        try {
+            record = callable.call();
+        } catch (Exception e) {
+            // Propagate
+            throw new RuntimeException(e);
+        }
+
+        producer.send(record, (recordMetadata, e) -> {
+            if (e != null) {
+                LOG.warn("Failed to send record to producer: {}.", record, e);
+                return;
+            }
+            if (callback != null) {
+                callback.accept(recordMetadata);
+            }
+        });
+    }
+
+    @Override
+    public void handleNewOrUpdatedAlarm(OnmsAlarm alarm) {
+        updateAlarm(alarm.getReductionKey(), alarm);
+    }
+
+    @Override
+    public void handleDeletedAlarm(int alarmId, String reductionKey) {
+        handleDeletedAlarm(reductionKey);
+    }
+
+    public void handleDeletedAlarm(String reductionKey) {
+        updateAlarm(reductionKey, null);
+    }
+
+    @Override
+    public String getName() {
+        return OpennmsKafkaProducer.class.getName();
+    }
+
+    @Override
+    public void onEvent(Event event) {
+        forwardEvent(event);
+    }
+
+    public void setEventTopic(String eventTopic) {
+        this.eventTopic = eventTopic;
+        forwardEvents = !Strings.isNullOrEmpty(eventTopic);
+    }
+
+    public void setAlarmTopic(String alarmTopic) {
+        this.alarmTopic = alarmTopic;
+        forwardAlarms = !Strings.isNullOrEmpty(alarmTopic);
+    }
+
+    public void setNodeTopic(String nodeTopic) {
+        this.nodeTopic = nodeTopic;
+        forwardNodes = !Strings.isNullOrEmpty(nodeTopic);
+    }
+
+    public void setEventFilter(String eventFilter) {
+        if (Strings.isNullOrEmpty(eventFilter)) {
+            eventFilterExpression = null;
+        } else {
+            eventFilterExpression = SPEL_PARSER.parseExpression(eventFilter);
+        }
+    }
+
+    public void setAlarmFilter(String alarmFilter) {
+        if (Strings.isNullOrEmpty(alarmFilter)) {
+            alarmFilterExpression = null;
+        } else {
+            alarmFilterExpression = SPEL_PARSER.parseExpression(alarmFilter);
+        }
+    }
+
+    public boolean isForwardingAlarms() {
+        return forwardAlarms;
+    }
+
+    public CountDownLatch getEventForwardedLatch() {
+        return forwardedEvent;
+    }
+
+    public CountDownLatch getAlarmForwardedLatch() {
+        return forwardedAlarm;
+    }
+
+    public CountDownLatch getNodeForwardedLatch() {
+        return forwardedNode;
+    }
+}
diff --git a/features/kafka/producer/src/main/java/org/opennms/features/kafka/producer/ProtobufMapper.java b/features/kafka/producer/src/main/java/org/opennms/features/kafka/producer/ProtobufMapper.java
new file mode 100644
index 00000000000..0bf9f3ff699
--- /dev/null
+++ b/features/kafka/producer/src/main/java/org/opennms/features/kafka/producer/ProtobufMapper.java
@@ -0,0 +1,334 @@
+/*******************************************************************************
+ * This file is part of OpenNMS(R).
+ *
+ * Copyright (C) 2018 The OpenNMS Group, Inc.
+ * OpenNMS(R) is Copyright (C) 1999-2018 The OpenNMS Group, Inc.
+ *
+ * OpenNMS(R) is a registered trademark of The OpenNMS Group, Inc.
+ *
+ * OpenNMS(R) is free software: you can redistribute it and/or modify
+ * it under the terms of the GNU Affero General Public License as published
+ * by the Free Software Foundation, either version 3 of the License,
+ * or (at your option) any later version.
+ *
+ * OpenNMS(R) is distributed in the hope that it will be useful,
+ * but WITHOUT ANY WARRANTY; without even the implied warranty of
+ * MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
+ * GNU Affero General Public License for more details.
+ *
+ * You should have received a copy of the GNU Affero General Public License
+ * along with OpenNMS(R).  If not, see:
+ *      http://www.gnu.org/licenses/
+ *
+ * For more information contact:
+ *     OpenNMS(R) Licensing <license@opennms.org>
+ *     http://www.opennms.org/
+ *     http://www.opennms.com/
+ *******************************************************************************/
+
+package org.opennms.features.kafka.producer;
+
+import java.util.Date;
+import java.util.Objects;
+import java.util.function.Consumer;
+
+import org.opennms.core.utils.InetAddressUtils;
+import org.opennms.features.kafka.producer.model.OpennmsModelProtos;
+import org.opennms.netmgt.config.api.EventConfDao;
+import org.opennms.netmgt.model.OnmsAlarm;
+import org.opennms.netmgt.model.OnmsCategory;
+import org.opennms.netmgt.model.OnmsEvent;
+import org.opennms.netmgt.model.OnmsEventParameter;
+import org.opennms.netmgt.model.OnmsIpInterface;
+import org.opennms.netmgt.model.OnmsNode;
+import org.opennms.netmgt.model.OnmsSeverity;
+import org.opennms.netmgt.model.OnmsSnmpInterface;
+import org.opennms.netmgt.model.PrimaryType;
+import org.opennms.netmgt.xml.event.Event;
+
+public class ProtobufMapper {
+
+    private final EventConfDao eventConfDao;
+
+
+    public ProtobufMapper(EventConfDao eventConfDao) {
+        this.eventConfDao = Objects.requireNonNull(eventConfDao);
+    }
+
+    public OpennmsModelProtos.Node.Builder toNode(OnmsNode node) {
+        if (node == null) {
+            return null;
+        }
+
+        final OpennmsModelProtos.Node.Builder builder = OpennmsModelProtos.Node.newBuilder()
+                .setId(node.getId())
+                .setLabel(node.getLabel())
+                .setLocation(node.getLocation().getLocationName());
+        if (node.getForeignSource() != null) {
+            builder.setForeignSource(node.getForeignSource());
+        }
+        if (node.getForeignId() != null) {
+            builder.setForeignId(node.getForeignId());
+        }
+        if (node.getSysContact() != null) {
+            builder.setSysContact(node.getSysContact());
+        }
+        if (node.getSysDescription() != null) {
+            builder.setSysDescription(node.getSysDescription());
+        }
+        if (node.getSysObjectId() != null) {
+            builder.setSysObjectId(node.getSysObjectId());
+        }
+
+        // Add all of the intefaces
+        node.getSnmpInterfaces().forEach(s -> builder.addSnmpInterface(toSnmpInterface(s)));
+        node.getIpInterfaces().forEach(i -> builder.addIpInterface(toIpInterface(i)));
+
+        // Add all of the categories, sorting them by name first
+        node.getCategories()
+                .stream()
+                .map(OnmsCategory::getName)
+                .sorted()
+                .forEach(builder::addCategory);
+
+        setTimeIfNotNull(node.getCreateTime(), builder::setCreateTime);
+
+        return builder;
+    }
+
+    public OpennmsModelProtos.Event.Builder toEvent(Event event) {
+        if (event == null) {
+            return null;
+        }
+        final OpennmsModelProtos.Event.Builder builder = OpennmsModelProtos.Event.newBuilder()
+                .setId(event.getDbid())
+                .setUei(event.getUei())
+                .setSource(event.getSource())
+                .setSeverity(toSeverity(OnmsSeverity.get(event.getSeverity())))
+                .setLabel(eventConfDao.getEventLabel(event.getUei()));
+        if (event.getDescr() != null) {
+            builder.setDescription(event.getDescr());
+        }
+
+        if (event.getLogmsg() != null) {
+            builder.setLogMessage(event.getLogmsg().getContent());
+        }
+        if (event.getNodeid() != null) {
+            // We only include the node id in the node criteria in when forwarding events
+            // since the event does not currently contain the fs:fid or a reference to the node object.
+            builder.setNodeCriteria(OpennmsModelProtos.NodeCriteria.newBuilder()
+                    .setId(event.getNodeid()));
+        }
+
+        setTimeIfNotNull(event.getTime(), builder::setTime);
+
+        return builder;
+    }
+
+    public OpennmsModelProtos.Event.Builder toEvent(OnmsEvent event) {
+        if (event == null) {
+            return null;
+        }
+        final OpennmsModelProtos.Event.Builder builder = OpennmsModelProtos.Event.newBuilder()
+                .setId(event.getId())
+                .setUei(event.getEventUei())
+                .setSource(event.getEventSource())
+                .setSeverity(toSeverity(OnmsSeverity.get(event.getEventSeverity())))
+                .setLabel(eventConfDao.getEventLabel(event.getEventUei()))
+                .setLog("Y".equalsIgnoreCase(event.getEventLog()))
+                .setDisplay("Y".equalsIgnoreCase(event.getEventDisplay()));
+
+        if (event.getEventDescr() != null) {
+            builder.setDescription(event.getEventDescr());
+        }
+        if (event.getEventLogMsg() != null) {
+            builder.setLogMessage(event.getEventLogMsg());
+        }
+        if (event.getNodeId() != null) {
+            builder.setNodeCriteria(toNodeCriteria(event.getNode()));
+        }
+
+        for (OnmsEventParameter param : event.getEventParameters()) {
+            if (param.getName() == null || param.getValue() == null) {
+                continue;
+            }
+            builder.addParameter(OpennmsModelProtos.EventParameter.newBuilder()
+                    .setName(param.getName())
+                    .setValue(param.getValue()));
+        }
+
+        setTimeIfNotNull(event.getEventTime(), builder::setTime);
+        setTimeIfNotNull(event.getEventCreateTime(), builder::setTime);
+
+        return builder;
+    }
+
+    public OpennmsModelProtos.Alarm.Builder toAlarm(OnmsAlarm alarm) {
+        final OpennmsModelProtos.Alarm.Builder builder = OpennmsModelProtos.Alarm.newBuilder()
+                .setId(alarm.getId())
+                .setUei(alarm.getUei())
+                .setCount(alarm.getCounter())
+                .setSeverity(toSeverity(alarm.getSeverity()));
+
+        if (alarm.getReductionKey() != null) {
+            builder.setReductionKey(alarm.getReductionKey());
+        }
+        if (toEvent(alarm.getLastEvent()) != null) {
+            builder.setLastEvent(toEvent(alarm.getLastEvent()));
+        }
+        if (alarm.getLogMsg() != null) {
+            builder.setLogMessage(alarm.getLogMsg());
+        }
+        if (alarm.getDescription() != null) {
+            builder.setDescription(alarm.getDescription());
+        }
+        if (alarm.getIpAddr() != null) {
+            builder.setIpAddress(InetAddressUtils.toIpAddrString(alarm.getIpAddr()));
+        }
+        if (alarm.getIfIndex() != null) {
+            builder.setIfIndex(alarm.getIfIndex());
+        }
+        if (alarm.getOperInstruct() != null) {
+            builder.setOperatorInstructions(alarm.getOperInstruct());
+        }
+        if (alarm.getAckUser() != null) {
+            builder.setAckUser(alarm.getAckUser());
+        }
+        if (alarm.getClearKey() != null) {
+            builder.setClearKey(alarm.getClearKey());
+        }
+        if (alarm.getNodeId() != null) {
+            builder.setNodeCriteria(toNodeCriteria(alarm.getNode()));
+        }
+
+        OpennmsModelProtos.Alarm.Type type = OpennmsModelProtos.Alarm.Type.UNRECOGNIZED;
+        if (alarm.getAlarmType() != null) {
+            if (alarm.getAlarmType() == OnmsAlarm.PROBLEM_TYPE) {
+                type = OpennmsModelProtos.Alarm.Type.PROBLEM_WITH_CLEAR;
+            } else if (alarm.getAlarmType() == OnmsAlarm.RESOLUTION_TYPE) {
+                type = OpennmsModelProtos.Alarm.Type.CLEAR;
+            } else if (alarm.getAlarmType() == OnmsAlarm.PROBLEM_WITHOUT_RESOLUTION_TYPE) {
+                type = OpennmsModelProtos.Alarm.Type.PROBLEM_WITHOUT_CLEAR;
+            }
+        }
+        builder.setType(type);
+
+        if (alarm.getServiceType() != null) {
+            builder.setServiceName(alarm.getServiceType().getName());
+        }
+
+        setTimeIfNotNull(alarm.getFirstEventTime(), builder::setFirstEventTime);
+        setTimeIfNotNull(alarm.getLastEventTime(), builder::setLastEventTime);
+        setTimeIfNotNull(alarm.getAckTime(), builder::setAckTime);
+
+        return builder;
+    }
+
+    public OpennmsModelProtos.NodeCriteria.Builder toNodeCriteria(OnmsNode node) {
+        final OpennmsModelProtos.NodeCriteria.Builder builder = OpennmsModelProtos.NodeCriteria.newBuilder()
+                .setId(node.getId());
+        if (node.getForeignSource() != null) {
+            builder.setForeignSource(node.getForeignSource());
+        }
+        if (node.getForeignId() != null) {
+            builder.setForeignId(node.getForeignId());
+        }
+        return builder;
+    }
+
+    public OpennmsModelProtos.Severity toSeverity(OnmsSeverity sev) {
+        final OpennmsModelProtos.Severity severity;
+        switch(sev) {
+            case INDETERMINATE:
+                severity = OpennmsModelProtos.Severity.INDETERMINATE;
+                break;
+            case CLEARED:
+                severity = OpennmsModelProtos.Severity.CLEARED;
+                break;
+            case NORMAL:
+                severity = OpennmsModelProtos.Severity.NORMAL;
+                break;
+            case WARNING:
+                severity = OpennmsModelProtos.Severity.WARNING;
+                break;
+            case MINOR:
+                severity = OpennmsModelProtos.Severity.MINOR;
+                break;
+            case MAJOR:
+                severity = OpennmsModelProtos.Severity.MAJOR;
+                break;
+            case CRITICAL:
+                severity = OpennmsModelProtos.Severity.CRITICAL;
+                break;
+            default:
+                severity = OpennmsModelProtos.Severity.UNRECOGNIZED;
+        }
+        return severity;
+    }
+
+    public OpennmsModelProtos.IpInterface.Builder toIpInterface(OnmsIpInterface ipInterface) {
+        if (ipInterface == null) {
+            return null;
+        }
+
+        final OpennmsModelProtos.IpInterface.Builder builder = OpennmsModelProtos.IpInterface.newBuilder()
+                .setId(ipInterface.getId())
+                .setIpAddress(InetAddressUtils.toIpAddrString(ipInterface.getIpAddress()));
+        final OnmsSnmpInterface snmpInterface = ipInterface.getSnmpInterface();
+        if (snmpInterface != null && snmpInterface.getIfIndex() != null) {
+            builder.setIfIndex(snmpInterface.getIfIndex());
+        }
+        final PrimaryType primaryType = ipInterface.getIsSnmpPrimary();
+        if (PrimaryType.PRIMARY.equals(primaryType)) {
+            builder.setPrimaryType(OpennmsModelProtos.IpInterface.PrimaryType.PRIMARY);
+        } else if (PrimaryType.SECONDARY.equals(primaryType)) {
+            builder.setPrimaryType(OpennmsModelProtos.IpInterface.PrimaryType.SECONDARY);
+        } else if (PrimaryType.NOT_ELIGIBLE.equals(primaryType)) {
+            builder.setPrimaryType(OpennmsModelProtos.IpInterface.PrimaryType.NOT_ELIGIBLE);
+        }
+        ipInterface.getMonitoredServices().forEach(svc -> builder.addService(svc.getServiceName()));
+
+        return builder;
+    }
+
+    public OpennmsModelProtos.SnmpInterface.Builder toSnmpInterface(OnmsSnmpInterface snmpInterface) {
+        if (snmpInterface == null) {
+            return null;
+        }
+
+        final OpennmsModelProtos.SnmpInterface.Builder builder = OpennmsModelProtos.SnmpInterface.newBuilder()
+                .setId(snmpInterface.getId())
+                .setIfIndex(snmpInterface.getIfIndex());
+        if (snmpInterface.getIfDescr() != null) {
+            builder.setIfDescr(snmpInterface.getIfDescr());
+        }
+        if (snmpInterface.getIfType() != null) {
+            builder.setIfType(snmpInterface.getIfType());
+        }
+        if (snmpInterface.getIfName() != null) {
+            builder.setIfName(snmpInterface.getIfName());
+        }
+        if (snmpInterface.getIfSpeed() != null) {
+            builder.setIfSpeed(snmpInterface.getIfSpeed());
+        }
+        if (snmpInterface.getPhysAddr() != null) {
+            builder.setIfPhysAddress(snmpInterface.getPhysAddr());
+        }
+        if (snmpInterface.getIfAdminStatus() != null) {
+            builder.setIfAdminStatus(snmpInterface.getIfAdminStatus());
+        }
+        if (snmpInterface.getIfOperStatus() != null) {
+            builder.setIfOperStatus(snmpInterface.getIfOperStatus());
+        }
+        if (snmpInterface.getIfAlias() != null) {
+            builder.setIfAlias(snmpInterface.getIfAlias());
+        }
+        return builder;
+    }
+
+    private static void setTimeIfNotNull(Date date, Consumer<Long> setter) {
+        if (date != null) {
+            setter.accept(date.getTime());
+        }
+    }
+}
diff --git a/features/kafka/producer/src/main/java/org/opennms/features/kafka/producer/datasync/AlarmDataStore.java b/features/kafka/producer/src/main/java/org/opennms/features/kafka/producer/datasync/AlarmDataStore.java
new file mode 100644
index 00000000000..1c2fe30c7ec
--- /dev/null
+++ b/features/kafka/producer/src/main/java/org/opennms/features/kafka/producer/datasync/AlarmDataStore.java
@@ -0,0 +1,47 @@
+/*******************************************************************************
+ * This file is part of OpenNMS(R).
+ *
+ * Copyright (C) 2018 The OpenNMS Group, Inc.
+ * OpenNMS(R) is Copyright (C) 1999-2018 The OpenNMS Group, Inc.
+ *
+ * OpenNMS(R) is a registered trademark of The OpenNMS Group, Inc.
+ *
+ * OpenNMS(R) is free software: you can redistribute it and/or modify
+ * it under the terms of the GNU Affero General Public License as published
+ * by the Free Software Foundation, either version 3 of the License,
+ * or (at your option) any later version.
+ *
+ * OpenNMS(R) is distributed in the hope that it will be useful,
+ * but WITHOUT ANY WARRANTY; without even the implied warranty of
+ * MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
+ * GNU Affero General Public License for more details.
+ *
+ * You should have received a copy of the GNU Affero General Public License
+ * along with OpenNMS(R).  If not, see:
+ *      http://www.gnu.org/licenses/
+ *
+ * For more information contact:
+ *     OpenNMS(R) Licensing <license@opennms.org>
+ *     http://www.opennms.org/
+ *     http://www.opennms.com/
+ *******************************************************************************/
+
+package org.opennms.features.kafka.producer.datasync;
+
+import java.util.Map;
+
+import org.opennms.features.kafka.producer.model.OpennmsModelProtos;
+
+public interface AlarmDataStore {
+
+    boolean isEnabled();
+
+    boolean isReady();
+
+    Map<String, OpennmsModelProtos.Alarm> getAlarms();
+
+    OpennmsModelProtos.Alarm getAlarm(String reductionKey);
+
+    AlarmSyncResults synchronizeAlarmsWithDb();
+
+}
diff --git a/features/kafka/producer/src/main/java/org/opennms/features/kafka/producer/datasync/AlarmSyncResults.java b/features/kafka/producer/src/main/java/org/opennms/features/kafka/producer/datasync/AlarmSyncResults.java
new file mode 100644
index 00000000000..ebae237d789
--- /dev/null
+++ b/features/kafka/producer/src/main/java/org/opennms/features/kafka/producer/datasync/AlarmSyncResults.java
@@ -0,0 +1,90 @@
+/*******************************************************************************
+ * This file is part of OpenNMS(R).
+ *
+ * Copyright (C) 2018 The OpenNMS Group, Inc.
+ * OpenNMS(R) is Copyright (C) 1999-2018 The OpenNMS Group, Inc.
+ *
+ * OpenNMS(R) is a registered trademark of The OpenNMS Group, Inc.
+ *
+ * OpenNMS(R) is free software: you can redistribute it and/or modify
+ * it under the terms of the GNU Affero General Public License as published
+ * by the Free Software Foundation, either version 3 of the License,
+ * or (at your option) any later version.
+ *
+ * OpenNMS(R) is distributed in the hope that it will be useful,
+ * but WITHOUT ANY WARRANTY; without even the implied warranty of
+ * MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
+ * GNU Affero General Public License for more details.
+ *
+ * You should have received a copy of the GNU Affero General Public License
+ * along with OpenNMS(R).  If not, see:
+ *      http://www.gnu.org/licenses/
+ *
+ * For more information contact:
+ *     OpenNMS(R) Licensing <license@opennms.org>
+ *     http://www.opennms.org/
+ *     http://www.opennms.com/
+ *******************************************************************************/
+
+package org.opennms.features.kafka.producer.datasync;
+
+import java.util.List;
+import java.util.Map;
+import java.util.Objects;
+import java.util.Set;
+
+import org.opennms.features.kafka.producer.model.OpennmsModelProtos;
+import org.opennms.netmgt.model.OnmsAlarm;
+
+public class AlarmSyncResults {
+    private final Map<String, OpennmsModelProtos.Alarm> alarmsInKtableByReductionKey;
+    private final List<OnmsAlarm> alarmsInDb;
+    private final Map<String, OnmsAlarm> alarmsInDbByReductionKey;
+    private final Set<String> reductionKeysAdded;
+    private final Set<String> reductionKeysDeleted;
+    private final Set<String> reductionKeysUpdated;
+
+    public AlarmSyncResults(Map<String, OpennmsModelProtos.Alarm> alarmsInKtableByReductionKey,
+                            List<OnmsAlarm> alarmsInDb,
+                            Map<String, OnmsAlarm> alarmsInDbByReductionKey,
+                            Set<String> reductionKeysAdded,
+                            Set<String> reductionKeysDeleted,
+                            Set<String> reductionKeysUpdated) {
+        this.alarmsInKtableByReductionKey = Objects.requireNonNull(alarmsInKtableByReductionKey);
+        this.alarmsInDb = Objects.requireNonNull(alarmsInDb);
+        this.alarmsInDbByReductionKey = Objects.requireNonNull(alarmsInDbByReductionKey);
+        this.reductionKeysAdded = Objects.requireNonNull(reductionKeysAdded);
+        this.reductionKeysDeleted = Objects.requireNonNull(reductionKeysDeleted);
+        this.reductionKeysUpdated = Objects.requireNonNull(reductionKeysUpdated);
+    }
+
+    public Map<String, OpennmsModelProtos.Alarm> getAlarmsInKtableByReductionKey() {
+        return alarmsInKtableByReductionKey;
+    }
+
+    public List<OnmsAlarm> getAlarmsInDb() {
+        return alarmsInDb;
+    }
+
+    public Map<String, OnmsAlarm> getAlarmsInDbByReductionKey() {
+        return alarmsInDbByReductionKey;
+    }
+
+    public Set<String> getReductionKeysAdded() {
+        return reductionKeysAdded;
+    }
+
+    public Set<String> getReductionKeysDeleted() {
+        return reductionKeysDeleted;
+    }
+
+    public Set<String> getReductionKeysUpdated() {
+        return reductionKeysUpdated;
+    }
+
+    public int getNumUpdates() {
+        return getReductionKeysAdded().size()
+                + getReductionKeysDeleted().size()
+                + getReductionKeysUpdated().size();
+    }
+}
diff --git a/features/kafka/producer/src/main/java/org/opennms/features/kafka/producer/datasync/KafkaAlarmDataSync.java b/features/kafka/producer/src/main/java/org/opennms/features/kafka/producer/datasync/KafkaAlarmDataSync.java
new file mode 100644
index 00000000000..823e67ab18a
--- /dev/null
+++ b/features/kafka/producer/src/main/java/org/opennms/features/kafka/producer/datasync/KafkaAlarmDataSync.java
@@ -0,0 +1,335 @@
+/*******************************************************************************
+ * This file is part of OpenNMS(R).
+ *
+ * Copyright (C) 2018 The OpenNMS Group, Inc.
+ * OpenNMS(R) is Copyright (C) 1999-2018 The OpenNMS Group, Inc.
+ *
+ * OpenNMS(R) is a registered trademark of The OpenNMS Group, Inc.
+ *
+ * OpenNMS(R) is free software: you can redistribute it and/or modify
+ * it under the terms of the GNU Affero General Public License as published
+ * by the Free Software Foundation, either version 3 of the License,
+ * or (at your option) any later version.
+ *
+ * OpenNMS(R) is distributed in the hope that it will be useful,
+ * but WITHOUT ANY WARRANTY; without even the implied warranty of
+ * MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
+ * GNU Affero General Public License for more details.
+ *
+ * You should have received a copy of the GNU Affero General Public License
+ * along with OpenNMS(R).  If not, see:
+ *      http://www.gnu.org/licenses/
+ *
+ * For more information contact:
+ *     OpenNMS(R) Licensing <license@opennms.org>
+ *     http://www.opennms.org/
+ *     http://www.opennms.com/
+ *******************************************************************************/
+
+package org.opennms.features.kafka.producer.datasync;
+
+import java.io.IOException;
+import java.nio.file.Path;
+import java.nio.file.Paths;
+import java.util.Dictionary;
+import java.util.Enumeration;
+import java.util.LinkedHashMap;
+import java.util.LinkedHashSet;
+import java.util.List;
+import java.util.Map;
+import java.util.Objects;
+import java.util.Properties;
+import java.util.Set;
+import java.util.concurrent.Executors;
+import java.util.concurrent.ScheduledExecutorService;
+import java.util.concurrent.TimeUnit;
+import java.util.concurrent.atomic.AtomicBoolean;
+import java.util.stream.Collectors;
+
+import org.apache.kafka.common.serialization.Serdes;
+import org.apache.kafka.streams.Consumed;
+import org.apache.kafka.streams.KafkaStreams;
+import org.apache.kafka.streams.StreamsBuilder;
+import org.apache.kafka.streams.StreamsConfig;
+import org.apache.kafka.streams.Topology;
+import org.apache.kafka.streams.errors.InvalidStateStoreException;
+import org.apache.kafka.streams.errors.StreamsException;
+import org.apache.kafka.streams.kstream.GlobalKTable;
+import org.apache.kafka.streams.kstream.KStream;
+import org.apache.kafka.streams.kstream.KTable;
+import org.apache.kafka.streams.kstream.Materialized;
+import org.apache.kafka.streams.state.QueryableStoreTypes;
+import org.apache.kafka.streams.state.ReadOnlyKeyValueStore;
+import org.opennms.features.kafka.producer.OpennmsKafkaProducer;
+import org.opennms.features.kafka.producer.ProtobufMapper;
+import org.opennms.features.kafka.producer.model.OpennmsModelProtos;
+import org.opennms.netmgt.dao.api.AlarmDao;
+import org.opennms.netmgt.model.OnmsAlarm;
+import org.osgi.service.cm.ConfigurationAdmin;
+import org.slf4j.Logger;
+import org.slf4j.LoggerFactory;
+import org.springframework.transaction.support.TransactionOperations;
+
+import com.google.common.collect.Sets;
+import com.google.common.util.concurrent.ThreadFactoryBuilder;
+import com.google.protobuf.InvalidProtocolBufferException;
+
+public class KafkaAlarmDataSync implements AlarmDataStore, Runnable {
+
+    private static final Logger LOG = LoggerFactory.getLogger(KafkaAlarmDataSync.class);
+
+    private static final String ALARM_STORE_NAME = "alarm_store";
+    public static final String KAFKA_STREAMS_PID = "org.opennms.features.kafka.producer.streams";
+
+    private final ConfigurationAdmin configAdmin;
+    private final OpennmsKafkaProducer kafkaProducer;
+    private final TransactionOperations transactionOperations;
+    private final AlarmDao alarmDao;
+    private final ProtobufMapper protobufMapper;
+    private final AtomicBoolean closed = new AtomicBoolean(true);
+
+    private String alarmTopic;
+    private long alarmSyncIntervalMs;
+
+    private KafkaStreams streams;
+    private ScheduledExecutorService scheduler;
+    private KTable<String, byte[]> alarmBytesKtable;
+    private KTable<String, OpennmsModelProtos.Alarm> alarmKtable;
+
+    public KafkaAlarmDataSync(ConfigurationAdmin configAdmin, OpennmsKafkaProducer kafkaProducer, AlarmDao alarmDao,
+            ProtobufMapper protobufMapper, TransactionOperations transactionOperations) {
+        this.configAdmin = Objects.requireNonNull(configAdmin);
+        this.kafkaProducer = Objects.requireNonNull(kafkaProducer);
+        this.alarmDao = Objects.requireNonNull(alarmDao);
+        this.protobufMapper = Objects.requireNonNull(protobufMapper);
+        this.transactionOperations = Objects.requireNonNull(transactionOperations);
+    }
+
+    /**
+     * This method initializes the stream client, but doesn't actually start it until
+     * an alarm is forwarded by the producer.
+     *
+     * @throws IOException when an error occurs in loading/parsing the Kafka client/stream configuration
+     */
+    public void init() throws IOException {
+        if (!kafkaProducer.isForwardingAlarms() || alarmSyncIntervalMs <= 0) {
+            LOG.info("Alarm synchronization disabled.");
+            return;
+        }
+
+        final Properties streamProperties = loadStreamsProperties();
+        final StreamsBuilder builder = new StreamsBuilder();
+        final GlobalKTable<String, byte[]> alarmBytesKtable = builder.globalTable(alarmTopic, Consumed.with(Serdes.String(), Serdes.ByteArray()),
+                Materialized.as(ALARM_STORE_NAME));
+
+        final Topology topology = builder.build();
+        final ClassLoader currentClassLoader = Thread.currentThread().getContextClassLoader();
+        try {
+            // Use the class-loader for the KStream class, since the kafka-client bundle
+            // does not import the required classes from the kafka-streams bundle
+            Thread.currentThread().setContextClassLoader(KStream.class.getClassLoader());
+            streams = new KafkaStreams(topology, streamProperties);
+        } finally {
+            Thread.currentThread().setContextClassLoader(currentClassLoader);
+        }
+        streams.setUncaughtExceptionHandler((t, e) -> LOG.error(
+                String.format("Stream error on thread: %s", t.getName()), e));
+
+        // Defer startup to another thread
+        scheduler = Executors.newScheduledThreadPool(1, new ThreadFactoryBuilder()
+                .setNameFormat("kafka-producer-alarm-datasync-%d")
+                .build()
+        );
+        closed.set(false);
+        scheduler.execute(this);
+    }
+
+    @Override
+    public void run() {
+        try {
+            if (kafkaProducer.getAlarmForwardedLatch().await(2, TimeUnit.MINUTES)) {
+                LOG.debug("Triggered: An alarm was successfully forwarded to the topic.");
+            } else {
+                LOG.debug("Triggered: Timeout reached before an alarm was successfully forwarded to the topic.");
+            }
+        } catch (InterruptedException e) {
+            LOG.info("Interrupted while waiting for alarm to be forwarded. Synchronization will not be performed.");
+            return;
+        }
+
+        try {
+            LOG.info("Starting alarm datasync stream.");
+            streams.start();
+            LOG.info("Starting alarm datasync started.");
+        } catch (StreamsException | IllegalStateException e) {
+            LOG.error("Failed to start alarm datasync stream. Synchronization will not be performed.", e);
+        }
+
+        LOG.info("Waiting for alarm data store to be ready.");
+        while (!closed.get()) {
+            if (isReady()) {
+                break;
+            }
+
+            try {
+                Thread.sleep(100);
+            } catch (InterruptedException e) {
+                LOG.info("Interrupted while waiting for store to be ready. Synchronization will not be performed.");
+                return;
+            }
+        }
+        LOG.info("Alarm data store is ready!");
+
+        LOG.info("Scheduling periodic alarm synchronization every {}ms", alarmSyncIntervalMs);
+        // Schedule sync after initial delay of 1 minute or the sync interval, whichever is shorter
+        scheduler.scheduleWithFixedDelay(this::doSynchronizeAlarmsWithDb, Math.min(TimeUnit.MINUTES.toMillis(1), alarmSyncIntervalMs),
+                alarmSyncIntervalMs, TimeUnit.MILLISECONDS);
+    }
+
+    public void destroy() {
+        closed.set(true);
+        if (scheduler != null) {
+            scheduler.shutdown();
+        }
+        if (streams != null) {
+            streams.close(2, TimeUnit.MINUTES);
+        }
+    }
+
+    private void doSynchronizeAlarmsWithDb() {
+        LOG.debug("Performing alarm synchronization with ktable.");
+        try {
+            final AlarmSyncResults results = synchronizeAlarmsWithDb();
+            if (LOG.isDebugEnabled()) {
+                LOG.debug("Done performing alarm synchronization with the ktable. Executed {} updates.",
+                        results.getReductionKeysAdded().size()
+                                + results.getReductionKeysDeleted().size()
+                                + results.getReductionKeysUpdated().size());
+                LOG.debug("Reduction keys added to ktable: {}", results.getReductionKeysAdded());
+                LOG.debug("Reduction keys deleted from the ktable: {}", results.getReductionKeysDeleted());
+                LOG.debug("Reduction keys updated in the ktable: {}", results.getReductionKeysAdded());
+            }
+        } catch (Exception e) {
+            LOG.error("An error occurred while performing alarm synchronization with the ktable. Will try again after {} ms.",
+                    alarmSyncIntervalMs, e);
+        }
+    }
+
+    @Override
+    public synchronized AlarmSyncResults synchronizeAlarmsWithDb() {
+        // Retrieve the map of alarms by reduction key from the ktable
+        final Map<String, OpennmsModelProtos.Alarm> alarmsInKtableByReductionKey = getAlarms();
+
+        // Perform the synchronization in a single transaction context
+        return transactionOperations.execute(status -> {
+            final Set<String> reductionKeysInKtable = alarmsInKtableByReductionKey.keySet();
+
+            final List<OnmsAlarm> alarmsInDb = alarmDao.findAll();
+            final Map<String, OnmsAlarm> alarmsInDbByReductionKey = alarmsInDb.stream()
+                    .collect(Collectors.toMap(OnmsAlarm::getReductionKey, a -> a));
+            final Set<String> reductionKeysInDb = alarmsInDbByReductionKey.keySet();
+
+            // Push deletes for keys that are in the ktable, but not in the database
+            final Set<String> reductionKeysNotInDb = Sets.difference(reductionKeysInKtable, reductionKeysInDb);
+            reductionKeysNotInDb.forEach(kafkaProducer::handleDeletedAlarm);
+
+            // Push new entries for keys that are in the database, but not in the ktable
+            final Set<String> reductionKeysNotInKtable = Sets.difference(reductionKeysInDb, reductionKeysInKtable);
+            reductionKeysNotInKtable.forEach(rkey -> kafkaProducer.handleNewOrUpdatedAlarm(alarmsInDbByReductionKey.get(rkey)));
+
+            // Handle Updates
+            final Set<String> reductionKeysUpdated = new LinkedHashSet<>();
+            final Set<String> commonReductionKeys = Sets.intersection(reductionKeysInKtable, reductionKeysInDb);
+            commonReductionKeys.forEach(rkey -> {
+                final OnmsAlarm dbAlarm = alarmsInDbByReductionKey.get(rkey);
+                final OpennmsModelProtos.Alarm mappedDbAlarm = protobufMapper.toAlarm(dbAlarm).build();
+                final OpennmsModelProtos.Alarm alarmFromKtable = alarmsInKtableByReductionKey.get(rkey);
+                if (!Objects.equals(mappedDbAlarm, alarmFromKtable)) {
+                    kafkaProducer.handleNewOrUpdatedAlarm(dbAlarm);
+                    reductionKeysUpdated.add(rkey);
+                }
+            });
+            return new AlarmSyncResults(alarmsInKtableByReductionKey, alarmsInDb, alarmsInDbByReductionKey,
+                    reductionKeysNotInKtable, reductionKeysNotInDb, reductionKeysUpdated);
+        });
+    }
+
+    private Properties loadStreamsProperties() throws IOException {
+        final Properties streamsProperties = new Properties();
+        // Default values
+        streamsProperties.put(StreamsConfig.APPLICATION_ID_CONFIG, "alarm-datasync");
+        Path kafkaDir = Paths.get(System.getProperty("karaf.data"), "kafka");
+        streamsProperties.put(StreamsConfig.STATE_DIR_CONFIG, kafkaDir.toString());
+        // Copy kafka server info from client properties
+        final Dictionary<String, Object> clientProperties = configAdmin.getConfiguration(OpennmsKafkaProducer.KAFKA_CLIENT_PID).getProperties();
+        if (clientProperties != null) {
+            streamsProperties.put(StreamsConfig.BOOTSTRAP_SERVERS_CONFIG, clientProperties.get(StreamsConfig.BOOTSTRAP_SERVERS_CONFIG));
+        }
+        // Add all of the stream properties, overriding the bootstrap servers if set
+        final Dictionary<String, Object> properties = configAdmin.getConfiguration(KAFKA_STREAMS_PID).getProperties();
+        if (properties != null) {
+            final Enumeration<String> keys = properties.keys();
+            while (keys.hasMoreElements()) {
+                final String key = keys.nextElement();
+                streamsProperties.put(key, properties.get(key));
+            }
+        }
+        // Override the deserializers unconditionally
+        streamsProperties.put(StreamsConfig.DEFAULT_KEY_SERDE_CLASS_CONFIG, Serdes.String().getClass());
+        streamsProperties.put(StreamsConfig.DEFAULT_VALUE_SERDE_CLASS_CONFIG, Serdes.ByteArray().getClass());
+        return streamsProperties;
+    }
+
+    public void setAlarmTopic(String alarmTopic) {
+        this.alarmTopic = alarmTopic;
+    }
+
+    public void setAlarmSyncIntervalMs(long intervalMs) {
+        alarmSyncIntervalMs = intervalMs;
+    }
+
+    private ReadOnlyKeyValueStore<String, byte[]> getAlarmTableNow() throws InvalidStateStoreException {
+        return streams.store(ALARM_STORE_NAME, QueryableStoreTypes.keyValueStore());
+    }
+
+    @Override
+    public boolean isEnabled() {
+        return !kafkaProducer.isForwardingAlarms() || alarmSyncIntervalMs <= 0;
+    }
+
+    @Override
+    public boolean isReady() {
+        try {
+            getAlarmTableNow();
+            return true;
+        } catch (InvalidStateStoreException ignored) {
+            // Store is not yet ready for querying
+            return false;
+        }
+    }
+
+    @Override
+    public Map<String, OpennmsModelProtos.Alarm> getAlarms() {
+        final Map<String, OpennmsModelProtos.Alarm> alarmsByReductionKey = new LinkedHashMap<>();
+        getAlarmTableNow().all().forEachRemaining(kv -> {
+            try {
+                alarmsByReductionKey.put(kv.key, kv.value != null ? OpennmsModelProtos.Alarm.parseFrom(kv.value) : null);
+            } catch (InvalidProtocolBufferException e) {
+                LOG.error("Failed to parse alarm for bytes at reduction key '{}'. Alarm will be empty in map.", kv.key);
+                alarmsByReductionKey.put(kv.key, null);
+            }
+        });
+        return alarmsByReductionKey;
+    }
+
+    @Override
+    public OpennmsModelProtos.Alarm getAlarm(String reductionKey) {
+        final byte[] alarmBytes = getAlarmTableNow().get(reductionKey);
+        try {
+            return OpennmsModelProtos.Alarm.parseFrom(alarmBytes);
+        } catch (InvalidProtocolBufferException e) {
+            throw new RuntimeException("Failed to parse alarm for bytes at reduction key " + reductionKey, e);
+        }
+    }
+
+}
diff --git a/features/kafka/producer/src/main/java/org/opennms/features/kafka/producer/model/OpennmsModelProtos.java b/features/kafka/producer/src/main/java/org/opennms/features/kafka/producer/model/OpennmsModelProtos.java
new file mode 100644
index 00000000000..f368a181173
--- /dev/null
+++ b/features/kafka/producer/src/main/java/org/opennms/features/kafka/producer/model/OpennmsModelProtos.java
@@ -0,0 +1,11363 @@
+/*******************************************************************************
+ * This file is part of OpenNMS(R).
+ *
+ * Copyright (C) 2018 The OpenNMS Group, Inc.
+ * OpenNMS(R) is Copyright (C) 1999-2018 The OpenNMS Group, Inc.
+ *
+ * OpenNMS(R) is a registered trademark of The OpenNMS Group, Inc.
+ *
+ * OpenNMS(R) is free software: you can redistribute it and/or modify
+ * it under the terms of the GNU Affero General Public License as published
+ * by the Free Software Foundation, either version 3 of the License,
+ * or (at your option) any later version.
+ *
+ * OpenNMS(R) is distributed in the hope that it will be useful,
+ * but WITHOUT ANY WARRANTY; without even the implied warranty of
+ * MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
+ * GNU Affero General Public License for more details.
+ *
+ * You should have received a copy of the GNU Affero General Public License
+ * along with OpenNMS(R).  If not, see:
+ *      http://www.gnu.org/licenses/
+ *
+ * For more information contact:
+ *     OpenNMS(R) Licensing <license@opennms.org>
+ *     http://www.opennms.org/
+ *     http://www.opennms.com/
+ *******************************************************************************/
+
+// Generated by the protocol buffer compiler.  DO NOT EDIT!
+// source: opennms.proto
+
+package org.opennms.features.kafka.producer.model;
+
+public final class OpennmsModelProtos {
+  private OpennmsModelProtos() {}
+  public static void registerAllExtensions(
+      com.google.protobuf.ExtensionRegistryLite registry) {
+  }
+
+  public static void registerAllExtensions(
+      com.google.protobuf.ExtensionRegistry registry) {
+    registerAllExtensions(
+        (com.google.protobuf.ExtensionRegistryLite) registry);
+  }
+  /**
+   * <pre>
+   * The values differ from the standard codes in OpenNMS
+   * since proto3 enforces us to start at 0
+   * </pre>
+   *
+   * Protobuf enum {@code Severity}
+   */
+  public enum Severity
+      implements com.google.protobuf.ProtocolMessageEnum {
+    /**
+     * <code>INDETERMINATE = 0;</code>
+     */
+    INDETERMINATE(0),
+    /**
+     * <code>CLEARED = 1;</code>
+     */
+    CLEARED(1),
+    /**
+     * <code>NORMAL = 2;</code>
+     */
+    NORMAL(2),
+    /**
+     * <code>WARNING = 3;</code>
+     */
+    WARNING(3),
+    /**
+     * <code>MINOR = 4;</code>
+     */
+    MINOR(4),
+    /**
+     * <code>MAJOR = 5;</code>
+     */
+    MAJOR(5),
+    /**
+     * <code>CRITICAL = 6;</code>
+     */
+    CRITICAL(6),
+    UNRECOGNIZED(-1),
+    ;
+
+    /**
+     * <code>INDETERMINATE = 0;</code>
+     */
+    public static final int INDETERMINATE_VALUE = 0;
+    /**
+     * <code>CLEARED = 1;</code>
+     */
+    public static final int CLEARED_VALUE = 1;
+    /**
+     * <code>NORMAL = 2;</code>
+     */
+    public static final int NORMAL_VALUE = 2;
+    /**
+     * <code>WARNING = 3;</code>
+     */
+    public static final int WARNING_VALUE = 3;
+    /**
+     * <code>MINOR = 4;</code>
+     */
+    public static final int MINOR_VALUE = 4;
+    /**
+     * <code>MAJOR = 5;</code>
+     */
+    public static final int MAJOR_VALUE = 5;
+    /**
+     * <code>CRITICAL = 6;</code>
+     */
+    public static final int CRITICAL_VALUE = 6;
+
+
+    public final int getNumber() {
+      if (this == UNRECOGNIZED) {
+        throw new java.lang.IllegalArgumentException(
+            "Can't get the number of an unknown enum value.");
+      }
+      return value;
+    }
+
+    /**
+     * @deprecated Use {@link #forNumber(int)} instead.
+     */
+    @java.lang.Deprecated
+    public static Severity valueOf(int value) {
+      return forNumber(value);
+    }
+
+    public static Severity forNumber(int value) {
+      switch (value) {
+        case 0: return INDETERMINATE;
+        case 1: return CLEARED;
+        case 2: return NORMAL;
+        case 3: return WARNING;
+        case 4: return MINOR;
+        case 5: return MAJOR;
+        case 6: return CRITICAL;
+        default: return null;
+      }
+    }
+
+    public static com.google.protobuf.Internal.EnumLiteMap<Severity>
+        internalGetValueMap() {
+      return internalValueMap;
+    }
+    private static final com.google.protobuf.Internal.EnumLiteMap<
+        Severity> internalValueMap =
+          new com.google.protobuf.Internal.EnumLiteMap<Severity>() {
+            public Severity findValueByNumber(int number) {
+              return Severity.forNumber(number);
+            }
+          };
+
+    public final com.google.protobuf.Descriptors.EnumValueDescriptor
+        getValueDescriptor() {
+      return getDescriptor().getValues().get(ordinal());
+    }
+    public final com.google.protobuf.Descriptors.EnumDescriptor
+        getDescriptorForType() {
+      return getDescriptor();
+    }
+    public static final com.google.protobuf.Descriptors.EnumDescriptor
+        getDescriptor() {
+      return org.opennms.features.kafka.producer.model.OpennmsModelProtos.getDescriptor().getEnumTypes().get(0);
+    }
+
+    private static final Severity[] VALUES = values();
+
+    public static Severity valueOf(
+        com.google.protobuf.Descriptors.EnumValueDescriptor desc) {
+      if (desc.getType() != getDescriptor()) {
+        throw new java.lang.IllegalArgumentException(
+          "EnumValueDescriptor is not for this type.");
+      }
+      if (desc.getIndex() == -1) {
+        return UNRECOGNIZED;
+      }
+      return VALUES[desc.getIndex()];
+    }
+
+    private final int value;
+
+    private Severity(int value) {
+      this.value = value;
+    }
+
+    // @@protoc_insertion_point(enum_scope:Severity)
+  }
+
+  public interface NodeCriteriaOrBuilder extends
+      // @@protoc_insertion_point(interface_extends:NodeCriteria)
+      com.google.protobuf.MessageOrBuilder {
+
+    /**
+     * <code>uint64 id = 1;</code>
+     */
+    long getId();
+
+    /**
+     * <code>string foreign_source = 2;</code>
+     */
+    java.lang.String getForeignSource();
+    /**
+     * <code>string foreign_source = 2;</code>
+     */
+    com.google.protobuf.ByteString
+        getForeignSourceBytes();
+
+    /**
+     * <code>string foreign_id = 3;</code>
+     */
+    java.lang.String getForeignId();
+    /**
+     * <code>string foreign_id = 3;</code>
+     */
+    com.google.protobuf.ByteString
+        getForeignIdBytes();
+  }
+  /**
+   * Protobuf type {@code NodeCriteria}
+   */
+  public  static final class NodeCriteria extends
+      com.google.protobuf.GeneratedMessageV3 implements
+      // @@protoc_insertion_point(message_implements:NodeCriteria)
+      NodeCriteriaOrBuilder {
+  private static final long serialVersionUID = 0L;
+    // Use NodeCriteria.newBuilder() to construct.
+    private NodeCriteria(com.google.protobuf.GeneratedMessageV3.Builder<?> builder) {
+      super(builder);
+    }
+    private NodeCriteria() {
+      id_ = 0L;
+      foreignSource_ = "";
+      foreignId_ = "";
+    }
+
+    @java.lang.Override
+    public final com.google.protobuf.UnknownFieldSet
+    getUnknownFields() {
+      return this.unknownFields;
+    }
+    private NodeCriteria(
+        com.google.protobuf.CodedInputStream input,
+        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
+        throws com.google.protobuf.InvalidProtocolBufferException {
+      this();
+      if (extensionRegistry == null) {
+        throw new java.lang.NullPointerException();
+      }
+      int mutable_bitField0_ = 0;
+      com.google.protobuf.UnknownFieldSet.Builder unknownFields =
+          com.google.protobuf.UnknownFieldSet.newBuilder();
+      try {
+        boolean done = false;
+        while (!done) {
+          int tag = input.readTag();
+          switch (tag) {
+            case 0:
+              done = true;
+              break;
+            default: {
+              if (!parseUnknownFieldProto3(
+                  input, unknownFields, extensionRegistry, tag)) {
+                done = true;
+              }
+              break;
+            }
+            case 8: {
+
+              id_ = input.readUInt64();
+              break;
+            }
+            case 18: {
+              java.lang.String s = input.readStringRequireUtf8();
+
+              foreignSource_ = s;
+              break;
+            }
+            case 26: {
+              java.lang.String s = input.readStringRequireUtf8();
+
+              foreignId_ = s;
+              break;
+            }
+          }
+        }
+      } catch (com.google.protobuf.InvalidProtocolBufferException e) {
+        throw e.setUnfinishedMessage(this);
+      } catch (java.io.IOException e) {
+        throw new com.google.protobuf.InvalidProtocolBufferException(
+            e).setUnfinishedMessage(this);
+      } finally {
+        this.unknownFields = unknownFields.build();
+        makeExtensionsImmutable();
+      }
+    }
+    public static final com.google.protobuf.Descriptors.Descriptor
+        getDescriptor() {
+      return org.opennms.features.kafka.producer.model.OpennmsModelProtos.internal_static_NodeCriteria_descriptor;
+    }
+
+    protected com.google.protobuf.GeneratedMessageV3.FieldAccessorTable
+        internalGetFieldAccessorTable() {
+      return org.opennms.features.kafka.producer.model.OpennmsModelProtos.internal_static_NodeCriteria_fieldAccessorTable
+          .ensureFieldAccessorsInitialized(
+              org.opennms.features.kafka.producer.model.OpennmsModelProtos.NodeCriteria.class, org.opennms.features.kafka.producer.model.OpennmsModelProtos.NodeCriteria.Builder.class);
+    }
+
+    public static final int ID_FIELD_NUMBER = 1;
+    private long id_;
+    /**
+     * <code>uint64 id = 1;</code>
+     */
+    public long getId() {
+      return id_;
+    }
+
+    public static final int FOREIGN_SOURCE_FIELD_NUMBER = 2;
+    private volatile java.lang.Object foreignSource_;
+    /**
+     * <code>string foreign_source = 2;</code>
+     */
+    public java.lang.String getForeignSource() {
+      java.lang.Object ref = foreignSource_;
+      if (ref instanceof java.lang.String) {
+        return (java.lang.String) ref;
+      } else {
+        com.google.protobuf.ByteString bs = 
+            (com.google.protobuf.ByteString) ref;
+        java.lang.String s = bs.toStringUtf8();
+        foreignSource_ = s;
+        return s;
+      }
+    }
+    /**
+     * <code>string foreign_source = 2;</code>
+     */
+    public com.google.protobuf.ByteString
+        getForeignSourceBytes() {
+      java.lang.Object ref = foreignSource_;
+      if (ref instanceof java.lang.String) {
+        com.google.protobuf.ByteString b = 
+            com.google.protobuf.ByteString.copyFromUtf8(
+                (java.lang.String) ref);
+        foreignSource_ = b;
+        return b;
+      } else {
+        return (com.google.protobuf.ByteString) ref;
+      }
+    }
+
+    public static final int FOREIGN_ID_FIELD_NUMBER = 3;
+    private volatile java.lang.Object foreignId_;
+    /**
+     * <code>string foreign_id = 3;</code>
+     */
+    public java.lang.String getForeignId() {
+      java.lang.Object ref = foreignId_;
+      if (ref instanceof java.lang.String) {
+        return (java.lang.String) ref;
+      } else {
+        com.google.protobuf.ByteString bs = 
+            (com.google.protobuf.ByteString) ref;
+        java.lang.String s = bs.toStringUtf8();
+        foreignId_ = s;
+        return s;
+      }
+    }
+    /**
+     * <code>string foreign_id = 3;</code>
+     */
+    public com.google.protobuf.ByteString
+        getForeignIdBytes() {
+      java.lang.Object ref = foreignId_;
+      if (ref instanceof java.lang.String) {
+        com.google.protobuf.ByteString b = 
+            com.google.protobuf.ByteString.copyFromUtf8(
+                (java.lang.String) ref);
+        foreignId_ = b;
+        return b;
+      } else {
+        return (com.google.protobuf.ByteString) ref;
+      }
+    }
+
+    private byte memoizedIsInitialized = -1;
+    public final boolean isInitialized() {
+      byte isInitialized = memoizedIsInitialized;
+      if (isInitialized == 1) return true;
+      if (isInitialized == 0) return false;
+
+      memoizedIsInitialized = 1;
+      return true;
+    }
+
+    public void writeTo(com.google.protobuf.CodedOutputStream output)
+                        throws java.io.IOException {
+      if (id_ != 0L) {
+        output.writeUInt64(1, id_);
+      }
+      if (!getForeignSourceBytes().isEmpty()) {
+        com.google.protobuf.GeneratedMessageV3.writeString(output, 2, foreignSource_);
+      }
+      if (!getForeignIdBytes().isEmpty()) {
+        com.google.protobuf.GeneratedMessageV3.writeString(output, 3, foreignId_);
+      }
+      unknownFields.writeTo(output);
+    }
+
+    public int getSerializedSize() {
+      int size = memoizedSize;
+      if (size != -1) return size;
+
+      size = 0;
+      if (id_ != 0L) {
+        size += com.google.protobuf.CodedOutputStream
+          .computeUInt64Size(1, id_);
+      }
+      if (!getForeignSourceBytes().isEmpty()) {
+        size += com.google.protobuf.GeneratedMessageV3.computeStringSize(2, foreignSource_);
+      }
+      if (!getForeignIdBytes().isEmpty()) {
+        size += com.google.protobuf.GeneratedMessageV3.computeStringSize(3, foreignId_);
+      }
+      size += unknownFields.getSerializedSize();
+      memoizedSize = size;
+      return size;
+    }
+
+    @java.lang.Override
+    public boolean equals(final java.lang.Object obj) {
+      if (obj == this) {
+       return true;
+      }
+      if (!(obj instanceof org.opennms.features.kafka.producer.model.OpennmsModelProtos.NodeCriteria)) {
+        return super.equals(obj);
+      }
+      org.opennms.features.kafka.producer.model.OpennmsModelProtos.NodeCriteria other = (org.opennms.features.kafka.producer.model.OpennmsModelProtos.NodeCriteria) obj;
+
+      boolean result = true;
+      result = result && (getId()
+          == other.getId());
+      result = result && getForeignSource()
+          .equals(other.getForeignSource());
+      result = result && getForeignId()
+          .equals(other.getForeignId());
+      result = result && unknownFields.equals(other.unknownFields);
+      return result;
+    }
+
+    @java.lang.Override
+    public int hashCode() {
+      if (memoizedHashCode != 0) {
+        return memoizedHashCode;
+      }
+      int hash = 41;
+      hash = (19 * hash) + getDescriptor().hashCode();
+      hash = (37 * hash) + ID_FIELD_NUMBER;
+      hash = (53 * hash) + com.google.protobuf.Internal.hashLong(
+          getId());
+      hash = (37 * hash) + FOREIGN_SOURCE_FIELD_NUMBER;
+      hash = (53 * hash) + getForeignSource().hashCode();
+      hash = (37 * hash) + FOREIGN_ID_FIELD_NUMBER;
+      hash = (53 * hash) + getForeignId().hashCode();
+      hash = (29 * hash) + unknownFields.hashCode();
+      memoizedHashCode = hash;
+      return hash;
+    }
+
+    public static org.opennms.features.kafka.producer.model.OpennmsModelProtos.NodeCriteria parseFrom(
+        java.nio.ByteBuffer data)
+        throws com.google.protobuf.InvalidProtocolBufferException {
+      return PARSER.parseFrom(data);
+    }
+    public static org.opennms.features.kafka.producer.model.OpennmsModelProtos.NodeCriteria parseFrom(
+        java.nio.ByteBuffer data,
+        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
+        throws com.google.protobuf.InvalidProtocolBufferException {
+      return PARSER.parseFrom(data, extensionRegistry);
+    }
+    public static org.opennms.features.kafka.producer.model.OpennmsModelProtos.NodeCriteria parseFrom(
+        com.google.protobuf.ByteString data)
+        throws com.google.protobuf.InvalidProtocolBufferException {
+      return PARSER.parseFrom(data);
+    }
+    public static org.opennms.features.kafka.producer.model.OpennmsModelProtos.NodeCriteria parseFrom(
+        com.google.protobuf.ByteString data,
+        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
+        throws com.google.protobuf.InvalidProtocolBufferException {
+      return PARSER.parseFrom(data, extensionRegistry);
+    }
+    public static org.opennms.features.kafka.producer.model.OpennmsModelProtos.NodeCriteria parseFrom(byte[] data)
+        throws com.google.protobuf.InvalidProtocolBufferException {
+      return PARSER.parseFrom(data);
+    }
+    public static org.opennms.features.kafka.producer.model.OpennmsModelProtos.NodeCriteria parseFrom(
+        byte[] data,
+        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
+        throws com.google.protobuf.InvalidProtocolBufferException {
+      return PARSER.parseFrom(data, extensionRegistry);
+    }
+    public static org.opennms.features.kafka.producer.model.OpennmsModelProtos.NodeCriteria parseFrom(java.io.InputStream input)
+        throws java.io.IOException {
+      return com.google.protobuf.GeneratedMessageV3
+          .parseWithIOException(PARSER, input);
+    }
+    public static org.opennms.features.kafka.producer.model.OpennmsModelProtos.NodeCriteria parseFrom(
+        java.io.InputStream input,
+        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
+        throws java.io.IOException {
+      return com.google.protobuf.GeneratedMessageV3
+          .parseWithIOException(PARSER, input, extensionRegistry);
+    }
+    public static org.opennms.features.kafka.producer.model.OpennmsModelProtos.NodeCriteria parseDelimitedFrom(java.io.InputStream input)
+        throws java.io.IOException {
+      return com.google.protobuf.GeneratedMessageV3
+          .parseDelimitedWithIOException(PARSER, input);
+    }
+    public static org.opennms.features.kafka.producer.model.OpennmsModelProtos.NodeCriteria parseDelimitedFrom(
+        java.io.InputStream input,
+        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
+        throws java.io.IOException {
+      return com.google.protobuf.GeneratedMessageV3
+          .parseDelimitedWithIOException(PARSER, input, extensionRegistry);
+    }
+    public static org.opennms.features.kafka.producer.model.OpennmsModelProtos.NodeCriteria parseFrom(
+        com.google.protobuf.CodedInputStream input)
+        throws java.io.IOException {
+      return com.google.protobuf.GeneratedMessageV3
+          .parseWithIOException(PARSER, input);
+    }
+    public static org.opennms.features.kafka.producer.model.OpennmsModelProtos.NodeCriteria parseFrom(
+        com.google.protobuf.CodedInputStream input,
+        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
+        throws java.io.IOException {
+      return com.google.protobuf.GeneratedMessageV3
+          .parseWithIOException(PARSER, input, extensionRegistry);
+    }
+
+    public Builder newBuilderForType() { return newBuilder(); }
+    public static Builder newBuilder() {
+      return DEFAULT_INSTANCE.toBuilder();
+    }
+    public static Builder newBuilder(org.opennms.features.kafka.producer.model.OpennmsModelProtos.NodeCriteria prototype) {
+      return DEFAULT_INSTANCE.toBuilder().mergeFrom(prototype);
+    }
+    public Builder toBuilder() {
+      return this == DEFAULT_INSTANCE
+          ? new Builder() : new Builder().mergeFrom(this);
+    }
+
+    @java.lang.Override
+    protected Builder newBuilderForType(
+        com.google.protobuf.GeneratedMessageV3.BuilderParent parent) {
+      Builder builder = new Builder(parent);
+      return builder;
+    }
+    /**
+     * Protobuf type {@code NodeCriteria}
+     */
+    public static final class Builder extends
+        com.google.protobuf.GeneratedMessageV3.Builder<Builder> implements
+        // @@protoc_insertion_point(builder_implements:NodeCriteria)
+        org.opennms.features.kafka.producer.model.OpennmsModelProtos.NodeCriteriaOrBuilder {
+      public static final com.google.protobuf.Descriptors.Descriptor
+          getDescriptor() {
+        return org.opennms.features.kafka.producer.model.OpennmsModelProtos.internal_static_NodeCriteria_descriptor;
+      }
+
+      protected com.google.protobuf.GeneratedMessageV3.FieldAccessorTable
+          internalGetFieldAccessorTable() {
+        return org.opennms.features.kafka.producer.model.OpennmsModelProtos.internal_static_NodeCriteria_fieldAccessorTable
+            .ensureFieldAccessorsInitialized(
+                org.opennms.features.kafka.producer.model.OpennmsModelProtos.NodeCriteria.class, org.opennms.features.kafka.producer.model.OpennmsModelProtos.NodeCriteria.Builder.class);
+      }
+
+      // Construct using org.opennms.features.kafka.producer.model.OpennmsModelProtos.NodeCriteria.newBuilder()
+      private Builder() {
+        maybeForceBuilderInitialization();
+      }
+
+      private Builder(
+          com.google.protobuf.GeneratedMessageV3.BuilderParent parent) {
+        super(parent);
+        maybeForceBuilderInitialization();
+      }
+      private void maybeForceBuilderInitialization() {
+        if (com.google.protobuf.GeneratedMessageV3
+                .alwaysUseFieldBuilders) {
+        }
+      }
+      public Builder clear() {
+        super.clear();
+        id_ = 0L;
+
+        foreignSource_ = "";
+
+        foreignId_ = "";
+
+        return this;
+      }
+
+      public com.google.protobuf.Descriptors.Descriptor
+          getDescriptorForType() {
+        return org.opennms.features.kafka.producer.model.OpennmsModelProtos.internal_static_NodeCriteria_descriptor;
+      }
+
+      public org.opennms.features.kafka.producer.model.OpennmsModelProtos.NodeCriteria getDefaultInstanceForType() {
+        return org.opennms.features.kafka.producer.model.OpennmsModelProtos.NodeCriteria.getDefaultInstance();
+      }
+
+      public org.opennms.features.kafka.producer.model.OpennmsModelProtos.NodeCriteria build() {
+        org.opennms.features.kafka.producer.model.OpennmsModelProtos.NodeCriteria result = buildPartial();
+        if (!result.isInitialized()) {
+          throw newUninitializedMessageException(result);
+        }
+        return result;
+      }
+
+      public org.opennms.features.kafka.producer.model.OpennmsModelProtos.NodeCriteria buildPartial() {
+        org.opennms.features.kafka.producer.model.OpennmsModelProtos.NodeCriteria result = new org.opennms.features.kafka.producer.model.OpennmsModelProtos.NodeCriteria(this);
+        result.id_ = id_;
+        result.foreignSource_ = foreignSource_;
+        result.foreignId_ = foreignId_;
+        onBuilt();
+        return result;
+      }
+
+      public Builder clone() {
+        return (Builder) super.clone();
+      }
+      public Builder setField(
+          com.google.protobuf.Descriptors.FieldDescriptor field,
+          java.lang.Object value) {
+        return (Builder) super.setField(field, value);
+      }
+      public Builder clearField(
+          com.google.protobuf.Descriptors.FieldDescriptor field) {
+        return (Builder) super.clearField(field);
+      }
+      public Builder clearOneof(
+          com.google.protobuf.Descriptors.OneofDescriptor oneof) {
+        return (Builder) super.clearOneof(oneof);
+      }
+      public Builder setRepeatedField(
+          com.google.protobuf.Descriptors.FieldDescriptor field,
+          int index, java.lang.Object value) {
+        return (Builder) super.setRepeatedField(field, index, value);
+      }
+      public Builder addRepeatedField(
+          com.google.protobuf.Descriptors.FieldDescriptor field,
+          java.lang.Object value) {
+        return (Builder) super.addRepeatedField(field, value);
+      }
+      public Builder mergeFrom(com.google.protobuf.Message other) {
+        if (other instanceof org.opennms.features.kafka.producer.model.OpennmsModelProtos.NodeCriteria) {
+          return mergeFrom((org.opennms.features.kafka.producer.model.OpennmsModelProtos.NodeCriteria)other);
+        } else {
+          super.mergeFrom(other);
+          return this;
+        }
+      }
+
+      public Builder mergeFrom(org.opennms.features.kafka.producer.model.OpennmsModelProtos.NodeCriteria other) {
+        if (other == org.opennms.features.kafka.producer.model.OpennmsModelProtos.NodeCriteria.getDefaultInstance()) return this;
+        if (other.getId() != 0L) {
+          setId(other.getId());
+        }
+        if (!other.getForeignSource().isEmpty()) {
+          foreignSource_ = other.foreignSource_;
+          onChanged();
+        }
+        if (!other.getForeignId().isEmpty()) {
+          foreignId_ = other.foreignId_;
+          onChanged();
+        }
+        this.mergeUnknownFields(other.unknownFields);
+        onChanged();
+        return this;
+      }
+
+      public final boolean isInitialized() {
+        return true;
+      }
+
+      public Builder mergeFrom(
+          com.google.protobuf.CodedInputStream input,
+          com.google.protobuf.ExtensionRegistryLite extensionRegistry)
+          throws java.io.IOException {
+        org.opennms.features.kafka.producer.model.OpennmsModelProtos.NodeCriteria parsedMessage = null;
+        try {
+          parsedMessage = PARSER.parsePartialFrom(input, extensionRegistry);
+        } catch (com.google.protobuf.InvalidProtocolBufferException e) {
+          parsedMessage = (org.opennms.features.kafka.producer.model.OpennmsModelProtos.NodeCriteria) e.getUnfinishedMessage();
+          throw e.unwrapIOException();
+        } finally {
+          if (parsedMessage != null) {
+            mergeFrom(parsedMessage);
+          }
+        }
+        return this;
+      }
+
+      private long id_ ;
+      /**
+       * <code>uint64 id = 1;</code>
+       */
+      public long getId() {
+        return id_;
+      }
+      /**
+       * <code>uint64 id = 1;</code>
+       */
+      public Builder setId(long value) {
+        
+        id_ = value;
+        onChanged();
+        return this;
+      }
+      /**
+       * <code>uint64 id = 1;</code>
+       */
+      public Builder clearId() {
+        
+        id_ = 0L;
+        onChanged();
+        return this;
+      }
+
+      private java.lang.Object foreignSource_ = "";
+      /**
+       * <code>string foreign_source = 2;</code>
+       */
+      public java.lang.String getForeignSource() {
+        java.lang.Object ref = foreignSource_;
+        if (!(ref instanceof java.lang.String)) {
+          com.google.protobuf.ByteString bs =
+              (com.google.protobuf.ByteString) ref;
+          java.lang.String s = bs.toStringUtf8();
+          foreignSource_ = s;
+          return s;
+        } else {
+          return (java.lang.String) ref;
+        }
+      }
+      /**
+       * <code>string foreign_source = 2;</code>
+       */
+      public com.google.protobuf.ByteString
+          getForeignSourceBytes() {
+        java.lang.Object ref = foreignSource_;
+        if (ref instanceof String) {
+          com.google.protobuf.ByteString b = 
+              com.google.protobuf.ByteString.copyFromUtf8(
+                  (java.lang.String) ref);
+          foreignSource_ = b;
+          return b;
+        } else {
+          return (com.google.protobuf.ByteString) ref;
+        }
+      }
+      /**
+       * <code>string foreign_source = 2;</code>
+       */
+      public Builder setForeignSource(
+          java.lang.String value) {
+        if (value == null) {
+    throw new NullPointerException();
+  }
+  
+        foreignSource_ = value;
+        onChanged();
+        return this;
+      }
+      /**
+       * <code>string foreign_source = 2;</code>
+       */
+      public Builder clearForeignSource() {
+        
+        foreignSource_ = getDefaultInstance().getForeignSource();
+        onChanged();
+        return this;
+      }
+      /**
+       * <code>string foreign_source = 2;</code>
+       */
+      public Builder setForeignSourceBytes(
+          com.google.protobuf.ByteString value) {
+        if (value == null) {
+    throw new NullPointerException();
+  }
+  checkByteStringIsUtf8(value);
+        
+        foreignSource_ = value;
+        onChanged();
+        return this;
+      }
+
+      private java.lang.Object foreignId_ = "";
+      /**
+       * <code>string foreign_id = 3;</code>
+       */
+      public java.lang.String getForeignId() {
+        java.lang.Object ref = foreignId_;
+        if (!(ref instanceof java.lang.String)) {
+          com.google.protobuf.ByteString bs =
+              (com.google.protobuf.ByteString) ref;
+          java.lang.String s = bs.toStringUtf8();
+          foreignId_ = s;
+          return s;
+        } else {
+          return (java.lang.String) ref;
+        }
+      }
+      /**
+       * <code>string foreign_id = 3;</code>
+       */
+      public com.google.protobuf.ByteString
+          getForeignIdBytes() {
+        java.lang.Object ref = foreignId_;
+        if (ref instanceof String) {
+          com.google.protobuf.ByteString b = 
+              com.google.protobuf.ByteString.copyFromUtf8(
+                  (java.lang.String) ref);
+          foreignId_ = b;
+          return b;
+        } else {
+          return (com.google.protobuf.ByteString) ref;
+        }
+      }
+      /**
+       * <code>string foreign_id = 3;</code>
+       */
+      public Builder setForeignId(
+          java.lang.String value) {
+        if (value == null) {
+    throw new NullPointerException();
+  }
+  
+        foreignId_ = value;
+        onChanged();
+        return this;
+      }
+      /**
+       * <code>string foreign_id = 3;</code>
+       */
+      public Builder clearForeignId() {
+        
+        foreignId_ = getDefaultInstance().getForeignId();
+        onChanged();
+        return this;
+      }
+      /**
+       * <code>string foreign_id = 3;</code>
+       */
+      public Builder setForeignIdBytes(
+          com.google.protobuf.ByteString value) {
+        if (value == null) {
+    throw new NullPointerException();
+  }
+  checkByteStringIsUtf8(value);
+        
+        foreignId_ = value;
+        onChanged();
+        return this;
+      }
+      public final Builder setUnknownFields(
+          final com.google.protobuf.UnknownFieldSet unknownFields) {
+        return super.setUnknownFieldsProto3(unknownFields);
+      }
+
+      public final Builder mergeUnknownFields(
+          final com.google.protobuf.UnknownFieldSet unknownFields) {
+        return super.mergeUnknownFields(unknownFields);
+      }
+
+
+      // @@protoc_insertion_point(builder_scope:NodeCriteria)
+    }
+
+    // @@protoc_insertion_point(class_scope:NodeCriteria)
+    private static final org.opennms.features.kafka.producer.model.OpennmsModelProtos.NodeCriteria DEFAULT_INSTANCE;
+    static {
+      DEFAULT_INSTANCE = new org.opennms.features.kafka.producer.model.OpennmsModelProtos.NodeCriteria();
+    }
+
+    public static org.opennms.features.kafka.producer.model.OpennmsModelProtos.NodeCriteria getDefaultInstance() {
+      return DEFAULT_INSTANCE;
+    }
+
+    private static final com.google.protobuf.Parser<NodeCriteria>
+        PARSER = new com.google.protobuf.AbstractParser<NodeCriteria>() {
+      public NodeCriteria parsePartialFrom(
+          com.google.protobuf.CodedInputStream input,
+          com.google.protobuf.ExtensionRegistryLite extensionRegistry)
+          throws com.google.protobuf.InvalidProtocolBufferException {
+        return new NodeCriteria(input, extensionRegistry);
+      }
+    };
+
+    public static com.google.protobuf.Parser<NodeCriteria> parser() {
+      return PARSER;
+    }
+
+    @java.lang.Override
+    public com.google.protobuf.Parser<NodeCriteria> getParserForType() {
+      return PARSER;
+    }
+
+    public org.opennms.features.kafka.producer.model.OpennmsModelProtos.NodeCriteria getDefaultInstanceForType() {
+      return DEFAULT_INSTANCE;
+    }
+
+  }
+
+  public interface EventParameterOrBuilder extends
+      // @@protoc_insertion_point(interface_extends:EventParameter)
+      com.google.protobuf.MessageOrBuilder {
+
+    /**
+     * <code>string name = 1;</code>
+     */
+    java.lang.String getName();
+    /**
+     * <code>string name = 1;</code>
+     */
+    com.google.protobuf.ByteString
+        getNameBytes();
+
+    /**
+     * <code>string value = 2;</code>
+     */
+    java.lang.String getValue();
+    /**
+     * <code>string value = 2;</code>
+     */
+    com.google.protobuf.ByteString
+        getValueBytes();
+
+    /**
+     * <code>string type = 3;</code>
+     */
+    java.lang.String getType();
+    /**
+     * <code>string type = 3;</code>
+     */
+    com.google.protobuf.ByteString
+        getTypeBytes();
+  }
+  /**
+   * Protobuf type {@code EventParameter}
+   */
+  public  static final class EventParameter extends
+      com.google.protobuf.GeneratedMessageV3 implements
+      // @@protoc_insertion_point(message_implements:EventParameter)
+      EventParameterOrBuilder {
+  private static final long serialVersionUID = 0L;
+    // Use EventParameter.newBuilder() to construct.
+    private EventParameter(com.google.protobuf.GeneratedMessageV3.Builder<?> builder) {
+      super(builder);
+    }
+    private EventParameter() {
+      name_ = "";
+      value_ = "";
+      type_ = "";
+    }
+
+    @java.lang.Override
+    public final com.google.protobuf.UnknownFieldSet
+    getUnknownFields() {
+      return this.unknownFields;
+    }
+    private EventParameter(
+        com.google.protobuf.CodedInputStream input,
+        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
+        throws com.google.protobuf.InvalidProtocolBufferException {
+      this();
+      if (extensionRegistry == null) {
+        throw new java.lang.NullPointerException();
+      }
+      int mutable_bitField0_ = 0;
+      com.google.protobuf.UnknownFieldSet.Builder unknownFields =
+          com.google.protobuf.UnknownFieldSet.newBuilder();
+      try {
+        boolean done = false;
+        while (!done) {
+          int tag = input.readTag();
+          switch (tag) {
+            case 0:
+              done = true;
+              break;
+            default: {
+              if (!parseUnknownFieldProto3(
+                  input, unknownFields, extensionRegistry, tag)) {
+                done = true;
+              }
+              break;
+            }
+            case 10: {
+              java.lang.String s = input.readStringRequireUtf8();
+
+              name_ = s;
+              break;
+            }
+            case 18: {
+              java.lang.String s = input.readStringRequireUtf8();
+
+              value_ = s;
+              break;
+            }
+            case 26: {
+              java.lang.String s = input.readStringRequireUtf8();
+
+              type_ = s;
+              break;
+            }
+          }
+        }
+      } catch (com.google.protobuf.InvalidProtocolBufferException e) {
+        throw e.setUnfinishedMessage(this);
+      } catch (java.io.IOException e) {
+        throw new com.google.protobuf.InvalidProtocolBufferException(
+            e).setUnfinishedMessage(this);
+      } finally {
+        this.unknownFields = unknownFields.build();
+        makeExtensionsImmutable();
+      }
+    }
+    public static final com.google.protobuf.Descriptors.Descriptor
+        getDescriptor() {
+      return org.opennms.features.kafka.producer.model.OpennmsModelProtos.internal_static_EventParameter_descriptor;
+    }
+
+    protected com.google.protobuf.GeneratedMessageV3.FieldAccessorTable
+        internalGetFieldAccessorTable() {
+      return org.opennms.features.kafka.producer.model.OpennmsModelProtos.internal_static_EventParameter_fieldAccessorTable
+          .ensureFieldAccessorsInitialized(
+              org.opennms.features.kafka.producer.model.OpennmsModelProtos.EventParameter.class, org.opennms.features.kafka.producer.model.OpennmsModelProtos.EventParameter.Builder.class);
+    }
+
+    public static final int NAME_FIELD_NUMBER = 1;
+    private volatile java.lang.Object name_;
+    /**
+     * <code>string name = 1;</code>
+     */
+    public java.lang.String getName() {
+      java.lang.Object ref = name_;
+      if (ref instanceof java.lang.String) {
+        return (java.lang.String) ref;
+      } else {
+        com.google.protobuf.ByteString bs = 
+            (com.google.protobuf.ByteString) ref;
+        java.lang.String s = bs.toStringUtf8();
+        name_ = s;
+        return s;
+      }
+    }
+    /**
+     * <code>string name = 1;</code>
+     */
+    public com.google.protobuf.ByteString
+        getNameBytes() {
+      java.lang.Object ref = name_;
+      if (ref instanceof java.lang.String) {
+        com.google.protobuf.ByteString b = 
+            com.google.protobuf.ByteString.copyFromUtf8(
+                (java.lang.String) ref);
+        name_ = b;
+        return b;
+      } else {
+        return (com.google.protobuf.ByteString) ref;
+      }
+    }
+
+    public static final int VALUE_FIELD_NUMBER = 2;
+    private volatile java.lang.Object value_;
+    /**
+     * <code>string value = 2;</code>
+     */
+    public java.lang.String getValue() {
+      java.lang.Object ref = value_;
+      if (ref instanceof java.lang.String) {
+        return (java.lang.String) ref;
+      } else {
+        com.google.protobuf.ByteString bs = 
+            (com.google.protobuf.ByteString) ref;
+        java.lang.String s = bs.toStringUtf8();
+        value_ = s;
+        return s;
+      }
+    }
+    /**
+     * <code>string value = 2;</code>
+     */
+    public com.google.protobuf.ByteString
+        getValueBytes() {
+      java.lang.Object ref = value_;
+      if (ref instanceof java.lang.String) {
+        com.google.protobuf.ByteString b = 
+            com.google.protobuf.ByteString.copyFromUtf8(
+                (java.lang.String) ref);
+        value_ = b;
+        return b;
+      } else {
+        return (com.google.protobuf.ByteString) ref;
+      }
+    }
+
+    public static final int TYPE_FIELD_NUMBER = 3;
+    private volatile java.lang.Object type_;
+    /**
+     * <code>string type = 3;</code>
+     */
+    public java.lang.String getType() {
+      java.lang.Object ref = type_;
+      if (ref instanceof java.lang.String) {
+        return (java.lang.String) ref;
+      } else {
+        com.google.protobuf.ByteString bs = 
+            (com.google.protobuf.ByteString) ref;
+        java.lang.String s = bs.toStringUtf8();
+        type_ = s;
+        return s;
+      }
+    }
+    /**
+     * <code>string type = 3;</code>
+     */
+    public com.google.protobuf.ByteString
+        getTypeBytes() {
+      java.lang.Object ref = type_;
+      if (ref instanceof java.lang.String) {
+        com.google.protobuf.ByteString b = 
+            com.google.protobuf.ByteString.copyFromUtf8(
+                (java.lang.String) ref);
+        type_ = b;
+        return b;
+      } else {
+        return (com.google.protobuf.ByteString) ref;
+      }
+    }
+
+    private byte memoizedIsInitialized = -1;
+    public final boolean isInitialized() {
+      byte isInitialized = memoizedIsInitialized;
+      if (isInitialized == 1) return true;
+      if (isInitialized == 0) return false;
+
+      memoizedIsInitialized = 1;
+      return true;
+    }
+
+    public void writeTo(com.google.protobuf.CodedOutputStream output)
+                        throws java.io.IOException {
+      if (!getNameBytes().isEmpty()) {
+        com.google.protobuf.GeneratedMessageV3.writeString(output, 1, name_);
+      }
+      if (!getValueBytes().isEmpty()) {
+        com.google.protobuf.GeneratedMessageV3.writeString(output, 2, value_);
+      }
+      if (!getTypeBytes().isEmpty()) {
+        com.google.protobuf.GeneratedMessageV3.writeString(output, 3, type_);
+      }
+      unknownFields.writeTo(output);
+    }
+
+    public int getSerializedSize() {
+      int size = memoizedSize;
+      if (size != -1) return size;
+
+      size = 0;
+      if (!getNameBytes().isEmpty()) {
+        size += com.google.protobuf.GeneratedMessageV3.computeStringSize(1, name_);
+      }
+      if (!getValueBytes().isEmpty()) {
+        size += com.google.protobuf.GeneratedMessageV3.computeStringSize(2, value_);
+      }
+      if (!getTypeBytes().isEmpty()) {
+        size += com.google.protobuf.GeneratedMessageV3.computeStringSize(3, type_);
+      }
+      size += unknownFields.getSerializedSize();
+      memoizedSize = size;
+      return size;
+    }
+
+    @java.lang.Override
+    public boolean equals(final java.lang.Object obj) {
+      if (obj == this) {
+       return true;
+      }
+      if (!(obj instanceof org.opennms.features.kafka.producer.model.OpennmsModelProtos.EventParameter)) {
+        return super.equals(obj);
+      }
+      org.opennms.features.kafka.producer.model.OpennmsModelProtos.EventParameter other = (org.opennms.features.kafka.producer.model.OpennmsModelProtos.EventParameter) obj;
+
+      boolean result = true;
+      result = result && getName()
+          .equals(other.getName());
+      result = result && getValue()
+          .equals(other.getValue());
+      result = result && getType()
+          .equals(other.getType());
+      result = result && unknownFields.equals(other.unknownFields);
+      return result;
+    }
+
+    @java.lang.Override
+    public int hashCode() {
+      if (memoizedHashCode != 0) {
+        return memoizedHashCode;
+      }
+      int hash = 41;
+      hash = (19 * hash) + getDescriptor().hashCode();
+      hash = (37 * hash) + NAME_FIELD_NUMBER;
+      hash = (53 * hash) + getName().hashCode();
+      hash = (37 * hash) + VALUE_FIELD_NUMBER;
+      hash = (53 * hash) + getValue().hashCode();
+      hash = (37 * hash) + TYPE_FIELD_NUMBER;
+      hash = (53 * hash) + getType().hashCode();
+      hash = (29 * hash) + unknownFields.hashCode();
+      memoizedHashCode = hash;
+      return hash;
+    }
+
+    public static org.opennms.features.kafka.producer.model.OpennmsModelProtos.EventParameter parseFrom(
+        java.nio.ByteBuffer data)
+        throws com.google.protobuf.InvalidProtocolBufferException {
+      return PARSER.parseFrom(data);
+    }
+    public static org.opennms.features.kafka.producer.model.OpennmsModelProtos.EventParameter parseFrom(
+        java.nio.ByteBuffer data,
+        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
+        throws com.google.protobuf.InvalidProtocolBufferException {
+      return PARSER.parseFrom(data, extensionRegistry);
+    }
+    public static org.opennms.features.kafka.producer.model.OpennmsModelProtos.EventParameter parseFrom(
+        com.google.protobuf.ByteString data)
+        throws com.google.protobuf.InvalidProtocolBufferException {
+      return PARSER.parseFrom(data);
+    }
+    public static org.opennms.features.kafka.producer.model.OpennmsModelProtos.EventParameter parseFrom(
+        com.google.protobuf.ByteString data,
+        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
+        throws com.google.protobuf.InvalidProtocolBufferException {
+      return PARSER.parseFrom(data, extensionRegistry);
+    }
+    public static org.opennms.features.kafka.producer.model.OpennmsModelProtos.EventParameter parseFrom(byte[] data)
+        throws com.google.protobuf.InvalidProtocolBufferException {
+      return PARSER.parseFrom(data);
+    }
+    public static org.opennms.features.kafka.producer.model.OpennmsModelProtos.EventParameter parseFrom(
+        byte[] data,
+        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
+        throws com.google.protobuf.InvalidProtocolBufferException {
+      return PARSER.parseFrom(data, extensionRegistry);
+    }
+    public static org.opennms.features.kafka.producer.model.OpennmsModelProtos.EventParameter parseFrom(java.io.InputStream input)
+        throws java.io.IOException {
+      return com.google.protobuf.GeneratedMessageV3
+          .parseWithIOException(PARSER, input);
+    }
+    public static org.opennms.features.kafka.producer.model.OpennmsModelProtos.EventParameter parseFrom(
+        java.io.InputStream input,
+        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
+        throws java.io.IOException {
+      return com.google.protobuf.GeneratedMessageV3
+          .parseWithIOException(PARSER, input, extensionRegistry);
+    }
+    public static org.opennms.features.kafka.producer.model.OpennmsModelProtos.EventParameter parseDelimitedFrom(java.io.InputStream input)
+        throws java.io.IOException {
+      return com.google.protobuf.GeneratedMessageV3
+          .parseDelimitedWithIOException(PARSER, input);
+    }
+    public static org.opennms.features.kafka.producer.model.OpennmsModelProtos.EventParameter parseDelimitedFrom(
+        java.io.InputStream input,
+        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
+        throws java.io.IOException {
+      return com.google.protobuf.GeneratedMessageV3
+          .parseDelimitedWithIOException(PARSER, input, extensionRegistry);
+    }
+    public static org.opennms.features.kafka.producer.model.OpennmsModelProtos.EventParameter parseFrom(
+        com.google.protobuf.CodedInputStream input)
+        throws java.io.IOException {
+      return com.google.protobuf.GeneratedMessageV3
+          .parseWithIOException(PARSER, input);
+    }
+    public static org.opennms.features.kafka.producer.model.OpennmsModelProtos.EventParameter parseFrom(
+        com.google.protobuf.CodedInputStream input,
+        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
+        throws java.io.IOException {
+      return com.google.protobuf.GeneratedMessageV3
+          .parseWithIOException(PARSER, input, extensionRegistry);
+    }
+
+    public Builder newBuilderForType() { return newBuilder(); }
+    public static Builder newBuilder() {
+      return DEFAULT_INSTANCE.toBuilder();
+    }
+    public static Builder newBuilder(org.opennms.features.kafka.producer.model.OpennmsModelProtos.EventParameter prototype) {
+      return DEFAULT_INSTANCE.toBuilder().mergeFrom(prototype);
+    }
+    public Builder toBuilder() {
+      return this == DEFAULT_INSTANCE
+          ? new Builder() : new Builder().mergeFrom(this);
+    }
+
+    @java.lang.Override
+    protected Builder newBuilderForType(
+        com.google.protobuf.GeneratedMessageV3.BuilderParent parent) {
+      Builder builder = new Builder(parent);
+      return builder;
+    }
+    /**
+     * Protobuf type {@code EventParameter}
+     */
+    public static final class Builder extends
+        com.google.protobuf.GeneratedMessageV3.Builder<Builder> implements
+        // @@protoc_insertion_point(builder_implements:EventParameter)
+        org.opennms.features.kafka.producer.model.OpennmsModelProtos.EventParameterOrBuilder {
+      public static final com.google.protobuf.Descriptors.Descriptor
+          getDescriptor() {
+        return org.opennms.features.kafka.producer.model.OpennmsModelProtos.internal_static_EventParameter_descriptor;
+      }
+
+      protected com.google.protobuf.GeneratedMessageV3.FieldAccessorTable
+          internalGetFieldAccessorTable() {
+        return org.opennms.features.kafka.producer.model.OpennmsModelProtos.internal_static_EventParameter_fieldAccessorTable
+            .ensureFieldAccessorsInitialized(
+                org.opennms.features.kafka.producer.model.OpennmsModelProtos.EventParameter.class, org.opennms.features.kafka.producer.model.OpennmsModelProtos.EventParameter.Builder.class);
+      }
+
+      // Construct using org.opennms.features.kafka.producer.model.OpennmsModelProtos.EventParameter.newBuilder()
+      private Builder() {
+        maybeForceBuilderInitialization();
+      }
+
+      private Builder(
+          com.google.protobuf.GeneratedMessageV3.BuilderParent parent) {
+        super(parent);
+        maybeForceBuilderInitialization();
+      }
+      private void maybeForceBuilderInitialization() {
+        if (com.google.protobuf.GeneratedMessageV3
+                .alwaysUseFieldBuilders) {
+        }
+      }
+      public Builder clear() {
+        super.clear();
+        name_ = "";
+
+        value_ = "";
+
+        type_ = "";
+
+        return this;
+      }
+
+      public com.google.protobuf.Descriptors.Descriptor
+          getDescriptorForType() {
+        return org.opennms.features.kafka.producer.model.OpennmsModelProtos.internal_static_EventParameter_descriptor;
+      }
+
+      public org.opennms.features.kafka.producer.model.OpennmsModelProtos.EventParameter getDefaultInstanceForType() {
+        return org.opennms.features.kafka.producer.model.OpennmsModelProtos.EventParameter.getDefaultInstance();
+      }
+
+      public org.opennms.features.kafka.producer.model.OpennmsModelProtos.EventParameter build() {
+        org.opennms.features.kafka.producer.model.OpennmsModelProtos.EventParameter result = buildPartial();
+        if (!result.isInitialized()) {
+          throw newUninitializedMessageException(result);
+        }
+        return result;
+      }
+
+      public org.opennms.features.kafka.producer.model.OpennmsModelProtos.EventParameter buildPartial() {
+        org.opennms.features.kafka.producer.model.OpennmsModelProtos.EventParameter result = new org.opennms.features.kafka.producer.model.OpennmsModelProtos.EventParameter(this);
+        result.name_ = name_;
+        result.value_ = value_;
+        result.type_ = type_;
+        onBuilt();
+        return result;
+      }
+
+      public Builder clone() {
+        return (Builder) super.clone();
+      }
+      public Builder setField(
+          com.google.protobuf.Descriptors.FieldDescriptor field,
+          java.lang.Object value) {
+        return (Builder) super.setField(field, value);
+      }
+      public Builder clearField(
+          com.google.protobuf.Descriptors.FieldDescriptor field) {
+        return (Builder) super.clearField(field);
+      }
+      public Builder clearOneof(
+          com.google.protobuf.Descriptors.OneofDescriptor oneof) {
+        return (Builder) super.clearOneof(oneof);
+      }
+      public Builder setRepeatedField(
+          com.google.protobuf.Descriptors.FieldDescriptor field,
+          int index, java.lang.Object value) {
+        return (Builder) super.setRepeatedField(field, index, value);
+      }
+      public Builder addRepeatedField(
+          com.google.protobuf.Descriptors.FieldDescriptor field,
+          java.lang.Object value) {
+        return (Builder) super.addRepeatedField(field, value);
+      }
+      public Builder mergeFrom(com.google.protobuf.Message other) {
+        if (other instanceof org.opennms.features.kafka.producer.model.OpennmsModelProtos.EventParameter) {
+          return mergeFrom((org.opennms.features.kafka.producer.model.OpennmsModelProtos.EventParameter)other);
+        } else {
+          super.mergeFrom(other);
+          return this;
+        }
+      }
+
+      public Builder mergeFrom(org.opennms.features.kafka.producer.model.OpennmsModelProtos.EventParameter other) {
+        if (other == org.opennms.features.kafka.producer.model.OpennmsModelProtos.EventParameter.getDefaultInstance()) return this;
+        if (!other.getName().isEmpty()) {
+          name_ = other.name_;
+          onChanged();
+        }
+        if (!other.getValue().isEmpty()) {
+          value_ = other.value_;
+          onChanged();
+        }
+        if (!other.getType().isEmpty()) {
+          type_ = other.type_;
+          onChanged();
+        }
+        this.mergeUnknownFields(other.unknownFields);
+        onChanged();
+        return this;
+      }
+
+      public final boolean isInitialized() {
+        return true;
+      }
+
+      public Builder mergeFrom(
+          com.google.protobuf.CodedInputStream input,
+          com.google.protobuf.ExtensionRegistryLite extensionRegistry)
+          throws java.io.IOException {
+        org.opennms.features.kafka.producer.model.OpennmsModelProtos.EventParameter parsedMessage = null;
+        try {
+          parsedMessage = PARSER.parsePartialFrom(input, extensionRegistry);
+        } catch (com.google.protobuf.InvalidProtocolBufferException e) {
+          parsedMessage = (org.opennms.features.kafka.producer.model.OpennmsModelProtos.EventParameter) e.getUnfinishedMessage();
+          throw e.unwrapIOException();
+        } finally {
+          if (parsedMessage != null) {
+            mergeFrom(parsedMessage);
+          }
+        }
+        return this;
+      }
+
+      private java.lang.Object name_ = "";
+      /**
+       * <code>string name = 1;</code>
+       */
+      public java.lang.String getName() {
+        java.lang.Object ref = name_;
+        if (!(ref instanceof java.lang.String)) {
+          com.google.protobuf.ByteString bs =
+              (com.google.protobuf.ByteString) ref;
+          java.lang.String s = bs.toStringUtf8();
+          name_ = s;
+          return s;
+        } else {
+          return (java.lang.String) ref;
+        }
+      }
+      /**
+       * <code>string name = 1;</code>
+       */
+      public com.google.protobuf.ByteString
+          getNameBytes() {
+        java.lang.Object ref = name_;
+        if (ref instanceof String) {
+          com.google.protobuf.ByteString b = 
+              com.google.protobuf.ByteString.copyFromUtf8(
+                  (java.lang.String) ref);
+          name_ = b;
+          return b;
+        } else {
+          return (com.google.protobuf.ByteString) ref;
+        }
+      }
+      /**
+       * <code>string name = 1;</code>
+       */
+      public Builder setName(
+          java.lang.String value) {
+        if (value == null) {
+    throw new NullPointerException();
+  }
+  
+        name_ = value;
+        onChanged();
+        return this;
+      }
+      /**
+       * <code>string name = 1;</code>
+       */
+      public Builder clearName() {
+        
+        name_ = getDefaultInstance().getName();
+        onChanged();
+        return this;
+      }
+      /**
+       * <code>string name = 1;</code>
+       */
+      public Builder setNameBytes(
+          com.google.protobuf.ByteString value) {
+        if (value == null) {
+    throw new NullPointerException();
+  }
+  checkByteStringIsUtf8(value);
+        
+        name_ = value;
+        onChanged();
+        return this;
+      }
+
+      private java.lang.Object value_ = "";
+      /**
+       * <code>string value = 2;</code>
+       */
+      public java.lang.String getValue() {
+        java.lang.Object ref = value_;
+        if (!(ref instanceof java.lang.String)) {
+          com.google.protobuf.ByteString bs =
+              (com.google.protobuf.ByteString) ref;
+          java.lang.String s = bs.toStringUtf8();
+          value_ = s;
+          return s;
+        } else {
+          return (java.lang.String) ref;
+        }
+      }
+      /**
+       * <code>string value = 2;</code>
+       */
+      public com.google.protobuf.ByteString
+          getValueBytes() {
+        java.lang.Object ref = value_;
+        if (ref instanceof String) {
+          com.google.protobuf.ByteString b = 
+              com.google.protobuf.ByteString.copyFromUtf8(
+                  (java.lang.String) ref);
+          value_ = b;
+          return b;
+        } else {
+          return (com.google.protobuf.ByteString) ref;
+        }
+      }
+      /**
+       * <code>string value = 2;</code>
+       */
+      public Builder setValue(
+          java.lang.String value) {
+        if (value == null) {
+    throw new NullPointerException();
+  }
+  
+        value_ = value;
+        onChanged();
+        return this;
+      }
+      /**
+       * <code>string value = 2;</code>
+       */
+      public Builder clearValue() {
+        
+        value_ = getDefaultInstance().getValue();
+        onChanged();
+        return this;
+      }
+      /**
+       * <code>string value = 2;</code>
+       */
+      public Builder setValueBytes(
+          com.google.protobuf.ByteString value) {
+        if (value == null) {
+    throw new NullPointerException();
+  }
+  checkByteStringIsUtf8(value);
+        
+        value_ = value;
+        onChanged();
+        return this;
+      }
+
+      private java.lang.Object type_ = "";
+      /**
+       * <code>string type = 3;</code>
+       */
+      public java.lang.String getType() {
+        java.lang.Object ref = type_;
+        if (!(ref instanceof java.lang.String)) {
+          com.google.protobuf.ByteString bs =
+              (com.google.protobuf.ByteString) ref;
+          java.lang.String s = bs.toStringUtf8();
+          type_ = s;
+          return s;
+        } else {
+          return (java.lang.String) ref;
+        }
+      }
+      /**
+       * <code>string type = 3;</code>
+       */
+      public com.google.protobuf.ByteString
+          getTypeBytes() {
+        java.lang.Object ref = type_;
+        if (ref instanceof String) {
+          com.google.protobuf.ByteString b = 
+              com.google.protobuf.ByteString.copyFromUtf8(
+                  (java.lang.String) ref);
+          type_ = b;
+          return b;
+        } else {
+          return (com.google.protobuf.ByteString) ref;
+        }
+      }
+      /**
+       * <code>string type = 3;</code>
+       */
+      public Builder setType(
+          java.lang.String value) {
+        if (value == null) {
+    throw new NullPointerException();
+  }
+  
+        type_ = value;
+        onChanged();
+        return this;
+      }
+      /**
+       * <code>string type = 3;</code>
+       */
+      public Builder clearType() {
+        
+        type_ = getDefaultInstance().getType();
+        onChanged();
+        return this;
+      }
+      /**
+       * <code>string type = 3;</code>
+       */
+      public Builder setTypeBytes(
+          com.google.protobuf.ByteString value) {
+        if (value == null) {
+    throw new NullPointerException();
+  }
+  checkByteStringIsUtf8(value);
+        
+        type_ = value;
+        onChanged();
+        return this;
+      }
+      public final Builder setUnknownFields(
+          final com.google.protobuf.UnknownFieldSet unknownFields) {
+        return super.setUnknownFieldsProto3(unknownFields);
+      }
+
+      public final Builder mergeUnknownFields(
+          final com.google.protobuf.UnknownFieldSet unknownFields) {
+        return super.mergeUnknownFields(unknownFields);
+      }
+
+
+      // @@protoc_insertion_point(builder_scope:EventParameter)
+    }
+
+    // @@protoc_insertion_point(class_scope:EventParameter)
+    private static final org.opennms.features.kafka.producer.model.OpennmsModelProtos.EventParameter DEFAULT_INSTANCE;
+    static {
+      DEFAULT_INSTANCE = new org.opennms.features.kafka.producer.model.OpennmsModelProtos.EventParameter();
+    }
+
+    public static org.opennms.features.kafka.producer.model.OpennmsModelProtos.EventParameter getDefaultInstance() {
+      return DEFAULT_INSTANCE;
+    }
+
+    private static final com.google.protobuf.Parser<EventParameter>
+        PARSER = new com.google.protobuf.AbstractParser<EventParameter>() {
+      public EventParameter parsePartialFrom(
+          com.google.protobuf.CodedInputStream input,
+          com.google.protobuf.ExtensionRegistryLite extensionRegistry)
+          throws com.google.protobuf.InvalidProtocolBufferException {
+        return new EventParameter(input, extensionRegistry);
+      }
+    };
+
+    public static com.google.protobuf.Parser<EventParameter> parser() {
+      return PARSER;
+    }
+
+    @java.lang.Override
+    public com.google.protobuf.Parser<EventParameter> getParserForType() {
+      return PARSER;
+    }
+
+    public org.opennms.features.kafka.producer.model.OpennmsModelProtos.EventParameter getDefaultInstanceForType() {
+      return DEFAULT_INSTANCE;
+    }
+
+  }
+
+  public interface EventOrBuilder extends
+      // @@protoc_insertion_point(interface_extends:Event)
+      com.google.protobuf.MessageOrBuilder {
+
+    /**
+     * <code>uint64 id = 1;</code>
+     */
+    long getId();
+
+    /**
+     * <code>string uei = 2;</code>
+     */
+    java.lang.String getUei();
+    /**
+     * <code>string uei = 2;</code>
+     */
+    com.google.protobuf.ByteString
+        getUeiBytes();
+
+    /**
+     * <code>string label = 3;</code>
+     */
+    java.lang.String getLabel();
+    /**
+     * <code>string label = 3;</code>
+     */
+    com.google.protobuf.ByteString
+        getLabelBytes();
+
+    /**
+     * <code>uint64 time = 4;</code>
+     */
+    long getTime();
+
+    /**
+     * <code>string source = 5;</code>
+     */
+    java.lang.String getSource();
+    /**
+     * <code>string source = 5;</code>
+     */
+    com.google.protobuf.ByteString
+        getSourceBytes();
+
+    /**
+     * <code>repeated .EventParameter parameter = 6;</code>
+     */
+    java.util.List<org.opennms.features.kafka.producer.model.OpennmsModelProtos.EventParameter> 
+        getParameterList();
+    /**
+     * <code>repeated .EventParameter parameter = 6;</code>
+     */
+    org.opennms.features.kafka.producer.model.OpennmsModelProtos.EventParameter getParameter(int index);
+    /**
+     * <code>repeated .EventParameter parameter = 6;</code>
+     */
+    int getParameterCount();
+    /**
+     * <code>repeated .EventParameter parameter = 6;</code>
+     */
+    java.util.List<? extends org.opennms.features.kafka.producer.model.OpennmsModelProtos.EventParameterOrBuilder> 
+        getParameterOrBuilderList();
+    /**
+     * <code>repeated .EventParameter parameter = 6;</code>
+     */
+    org.opennms.features.kafka.producer.model.OpennmsModelProtos.EventParameterOrBuilder getParameterOrBuilder(
+        int index);
+
+    /**
+     * <code>uint64 create_time = 7;</code>
+     */
+    long getCreateTime();
+
+    /**
+     * <code>string description = 8;</code>
+     */
+    java.lang.String getDescription();
+    /**
+     * <code>string description = 8;</code>
+     */
+    com.google.protobuf.ByteString
+        getDescriptionBytes();
+
+    /**
+     * <code>string log_message = 9;</code>
+     */
+    java.lang.String getLogMessage();
+    /**
+     * <code>string log_message = 9;</code>
+     */
+    com.google.protobuf.ByteString
+        getLogMessageBytes();
+
+    /**
+     * <code>.Severity severity = 10;</code>
+     */
+    int getSeverityValue();
+    /**
+     * <code>.Severity severity = 10;</code>
+     */
+    org.opennms.features.kafka.producer.model.OpennmsModelProtos.Severity getSeverity();
+
+    /**
+     * <code>bool log = 11;</code>
+     */
+    boolean getLog();
+
+    /**
+     * <code>bool display = 12;</code>
+     */
+    boolean getDisplay();
+
+    /**
+     * <code>.NodeCriteria node_criteria = 13;</code>
+     */
+    boolean hasNodeCriteria();
+    /**
+     * <code>.NodeCriteria node_criteria = 13;</code>
+     */
+    org.opennms.features.kafka.producer.model.OpennmsModelProtos.NodeCriteria getNodeCriteria();
+    /**
+     * <code>.NodeCriteria node_criteria = 13;</code>
+     */
+    org.opennms.features.kafka.producer.model.OpennmsModelProtos.NodeCriteriaOrBuilder getNodeCriteriaOrBuilder();
+  }
+  /**
+   * Protobuf type {@code Event}
+   */
+  public  static final class Event extends
+      com.google.protobuf.GeneratedMessageV3 implements
+      // @@protoc_insertion_point(message_implements:Event)
+      EventOrBuilder {
+  private static final long serialVersionUID = 0L;
+    // Use Event.newBuilder() to construct.
+    private Event(com.google.protobuf.GeneratedMessageV3.Builder<?> builder) {
+      super(builder);
+    }
+    private Event() {
+      id_ = 0L;
+      uei_ = "";
+      label_ = "";
+      time_ = 0L;
+      source_ = "";
+      parameter_ = java.util.Collections.emptyList();
+      createTime_ = 0L;
+      description_ = "";
+      logMessage_ = "";
+      severity_ = 0;
+      log_ = false;
+      display_ = false;
+    }
+
+    @java.lang.Override
+    public final com.google.protobuf.UnknownFieldSet
+    getUnknownFields() {
+      return this.unknownFields;
+    }
+    private Event(
+        com.google.protobuf.CodedInputStream input,
+        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
+        throws com.google.protobuf.InvalidProtocolBufferException {
+      this();
+      if (extensionRegistry == null) {
+        throw new java.lang.NullPointerException();
+      }
+      int mutable_bitField0_ = 0;
+      com.google.protobuf.UnknownFieldSet.Builder unknownFields =
+          com.google.protobuf.UnknownFieldSet.newBuilder();
+      try {
+        boolean done = false;
+        while (!done) {
+          int tag = input.readTag();
+          switch (tag) {
+            case 0:
+              done = true;
+              break;
+            default: {
+              if (!parseUnknownFieldProto3(
+                  input, unknownFields, extensionRegistry, tag)) {
+                done = true;
+              }
+              break;
+            }
+            case 8: {
+
+              id_ = input.readUInt64();
+              break;
+            }
+            case 18: {
+              java.lang.String s = input.readStringRequireUtf8();
+
+              uei_ = s;
+              break;
+            }
+            case 26: {
+              java.lang.String s = input.readStringRequireUtf8();
+
+              label_ = s;
+              break;
+            }
+            case 32: {
+
+              time_ = input.readUInt64();
+              break;
+            }
+            case 42: {
+              java.lang.String s = input.readStringRequireUtf8();
+
+              source_ = s;
+              break;
+            }
+            case 50: {
+              if (!((mutable_bitField0_ & 0x00000020) == 0x00000020)) {
+                parameter_ = new java.util.ArrayList<org.opennms.features.kafka.producer.model.OpennmsModelProtos.EventParameter>();
+                mutable_bitField0_ |= 0x00000020;
+              }
+              parameter_.add(
+                  input.readMessage(org.opennms.features.kafka.producer.model.OpennmsModelProtos.EventParameter.parser(), extensionRegistry));
+              break;
+            }
+            case 56: {
+
+              createTime_ = input.readUInt64();
+              break;
+            }
+            case 66: {
+              java.lang.String s = input.readStringRequireUtf8();
+
+              description_ = s;
+              break;
+            }
+            case 74: {
+              java.lang.String s = input.readStringRequireUtf8();
+
+              logMessage_ = s;
+              break;
+            }
+            case 80: {
+              int rawValue = input.readEnum();
+
+              severity_ = rawValue;
+              break;
+            }
+            case 88: {
+
+              log_ = input.readBool();
+              break;
+            }
+            case 96: {
+
+              display_ = input.readBool();
+              break;
+            }
+            case 106: {
+              org.opennms.features.kafka.producer.model.OpennmsModelProtos.NodeCriteria.Builder subBuilder = null;
+              if (nodeCriteria_ != null) {
+                subBuilder = nodeCriteria_.toBuilder();
+              }
+              nodeCriteria_ = input.readMessage(org.opennms.features.kafka.producer.model.OpennmsModelProtos.NodeCriteria.parser(), extensionRegistry);
+              if (subBuilder != null) {
+                subBuilder.mergeFrom(nodeCriteria_);
+                nodeCriteria_ = subBuilder.buildPartial();
+              }
+
+              break;
+            }
+          }
+        }
+      } catch (com.google.protobuf.InvalidProtocolBufferException e) {
+        throw e.setUnfinishedMessage(this);
+      } catch (java.io.IOException e) {
+        throw new com.google.protobuf.InvalidProtocolBufferException(
+            e).setUnfinishedMessage(this);
+      } finally {
+        if (((mutable_bitField0_ & 0x00000020) == 0x00000020)) {
+          parameter_ = java.util.Collections.unmodifiableList(parameter_);
+        }
+        this.unknownFields = unknownFields.build();
+        makeExtensionsImmutable();
+      }
+    }
+    public static final com.google.protobuf.Descriptors.Descriptor
+        getDescriptor() {
+      return org.opennms.features.kafka.producer.model.OpennmsModelProtos.internal_static_Event_descriptor;
+    }
+
+    protected com.google.protobuf.GeneratedMessageV3.FieldAccessorTable
+        internalGetFieldAccessorTable() {
+      return org.opennms.features.kafka.producer.model.OpennmsModelProtos.internal_static_Event_fieldAccessorTable
+          .ensureFieldAccessorsInitialized(
+              org.opennms.features.kafka.producer.model.OpennmsModelProtos.Event.class, org.opennms.features.kafka.producer.model.OpennmsModelProtos.Event.Builder.class);
+    }
+
+    private int bitField0_;
+    public static final int ID_FIELD_NUMBER = 1;
+    private long id_;
+    /**
+     * <code>uint64 id = 1;</code>
+     */
+    public long getId() {
+      return id_;
+    }
+
+    public static final int UEI_FIELD_NUMBER = 2;
+    private volatile java.lang.Object uei_;
+    /**
+     * <code>string uei = 2;</code>
+     */
+    public java.lang.String getUei() {
+      java.lang.Object ref = uei_;
+      if (ref instanceof java.lang.String) {
+        return (java.lang.String) ref;
+      } else {
+        com.google.protobuf.ByteString bs = 
+            (com.google.protobuf.ByteString) ref;
+        java.lang.String s = bs.toStringUtf8();
+        uei_ = s;
+        return s;
+      }
+    }
+    /**
+     * <code>string uei = 2;</code>
+     */
+    public com.google.protobuf.ByteString
+        getUeiBytes() {
+      java.lang.Object ref = uei_;
+      if (ref instanceof java.lang.String) {
+        com.google.protobuf.ByteString b = 
+            com.google.protobuf.ByteString.copyFromUtf8(
+                (java.lang.String) ref);
+        uei_ = b;
+        return b;
+      } else {
+        return (com.google.protobuf.ByteString) ref;
+      }
+    }
+
+    public static final int LABEL_FIELD_NUMBER = 3;
+    private volatile java.lang.Object label_;
+    /**
+     * <code>string label = 3;</code>
+     */
+    public java.lang.String getLabel() {
+      java.lang.Object ref = label_;
+      if (ref instanceof java.lang.String) {
+        return (java.lang.String) ref;
+      } else {
+        com.google.protobuf.ByteString bs = 
+            (com.google.protobuf.ByteString) ref;
+        java.lang.String s = bs.toStringUtf8();
+        label_ = s;
+        return s;
+      }
+    }
+    /**
+     * <code>string label = 3;</code>
+     */
+    public com.google.protobuf.ByteString
+        getLabelBytes() {
+      java.lang.Object ref = label_;
+      if (ref instanceof java.lang.String) {
+        com.google.protobuf.ByteString b = 
+            com.google.protobuf.ByteString.copyFromUtf8(
+                (java.lang.String) ref);
+        label_ = b;
+        return b;
+      } else {
+        return (com.google.protobuf.ByteString) ref;
+      }
+    }
+
+    public static final int TIME_FIELD_NUMBER = 4;
+    private long time_;
+    /**
+     * <code>uint64 time = 4;</code>
+     */
+    public long getTime() {
+      return time_;
+    }
+
+    public static final int SOURCE_FIELD_NUMBER = 5;
+    private volatile java.lang.Object source_;
+    /**
+     * <code>string source = 5;</code>
+     */
+    public java.lang.String getSource() {
+      java.lang.Object ref = source_;
+      if (ref instanceof java.lang.String) {
+        return (java.lang.String) ref;
+      } else {
+        com.google.protobuf.ByteString bs = 
+            (com.google.protobuf.ByteString) ref;
+        java.lang.String s = bs.toStringUtf8();
+        source_ = s;
+        return s;
+      }
+    }
+    /**
+     * <code>string source = 5;</code>
+     */
+    public com.google.protobuf.ByteString
+        getSourceBytes() {
+      java.lang.Object ref = source_;
+      if (ref instanceof java.lang.String) {
+        com.google.protobuf.ByteString b = 
+            com.google.protobuf.ByteString.copyFromUtf8(
+                (java.lang.String) ref);
+        source_ = b;
+        return b;
+      } else {
+        return (com.google.protobuf.ByteString) ref;
+      }
+    }
+
+    public static final int PARAMETER_FIELD_NUMBER = 6;
+    private java.util.List<org.opennms.features.kafka.producer.model.OpennmsModelProtos.EventParameter> parameter_;
+    /**
+     * <code>repeated .EventParameter parameter = 6;</code>
+     */
+    public java.util.List<org.opennms.features.kafka.producer.model.OpennmsModelProtos.EventParameter> getParameterList() {
+      return parameter_;
+    }
+    /**
+     * <code>repeated .EventParameter parameter = 6;</code>
+     */
+    public java.util.List<? extends org.opennms.features.kafka.producer.model.OpennmsModelProtos.EventParameterOrBuilder> 
+        getParameterOrBuilderList() {
+      return parameter_;
+    }
+    /**
+     * <code>repeated .EventParameter parameter = 6;</code>
+     */
+    public int getParameterCount() {
+      return parameter_.size();
+    }
+    /**
+     * <code>repeated .EventParameter parameter = 6;</code>
+     */
+    public org.opennms.features.kafka.producer.model.OpennmsModelProtos.EventParameter getParameter(int index) {
+      return parameter_.get(index);
+    }
+    /**
+     * <code>repeated .EventParameter parameter = 6;</code>
+     */
+    public org.opennms.features.kafka.producer.model.OpennmsModelProtos.EventParameterOrBuilder getParameterOrBuilder(
+        int index) {
+      return parameter_.get(index);
+    }
+
+    public static final int CREATE_TIME_FIELD_NUMBER = 7;
+    private long createTime_;
+    /**
+     * <code>uint64 create_time = 7;</code>
+     */
+    public long getCreateTime() {
+      return createTime_;
+    }
+
+    public static final int DESCRIPTION_FIELD_NUMBER = 8;
+    private volatile java.lang.Object description_;
+    /**
+     * <code>string description = 8;</code>
+     */
+    public java.lang.String getDescription() {
+      java.lang.Object ref = description_;
+      if (ref instanceof java.lang.String) {
+        return (java.lang.String) ref;
+      } else {
+        com.google.protobuf.ByteString bs = 
+            (com.google.protobuf.ByteString) ref;
+        java.lang.String s = bs.toStringUtf8();
+        description_ = s;
+        return s;
+      }
+    }
+    /**
+     * <code>string description = 8;</code>
+     */
+    public com.google.protobuf.ByteString
+        getDescriptionBytes() {
+      java.lang.Object ref = description_;
+      if (ref instanceof java.lang.String) {
+        com.google.protobuf.ByteString b = 
+            com.google.protobuf.ByteString.copyFromUtf8(
+                (java.lang.String) ref);
+        description_ = b;
+        return b;
+      } else {
+        return (com.google.protobuf.ByteString) ref;
+      }
+    }
+
+    public static final int LOG_MESSAGE_FIELD_NUMBER = 9;
+    private volatile java.lang.Object logMessage_;
+    /**
+     * <code>string log_message = 9;</code>
+     */
+    public java.lang.String getLogMessage() {
+      java.lang.Object ref = logMessage_;
+      if (ref instanceof java.lang.String) {
+        return (java.lang.String) ref;
+      } else {
+        com.google.protobuf.ByteString bs = 
+            (com.google.protobuf.ByteString) ref;
+        java.lang.String s = bs.toStringUtf8();
+        logMessage_ = s;
+        return s;
+      }
+    }
+    /**
+     * <code>string log_message = 9;</code>
+     */
+    public com.google.protobuf.ByteString
+        getLogMessageBytes() {
+      java.lang.Object ref = logMessage_;
+      if (ref instanceof java.lang.String) {
+        com.google.protobuf.ByteString b = 
+            com.google.protobuf.ByteString.copyFromUtf8(
+                (java.lang.String) ref);
+        logMessage_ = b;
+        return b;
+      } else {
+        return (com.google.protobuf.ByteString) ref;
+      }
+    }
+
+    public static final int SEVERITY_FIELD_NUMBER = 10;
+    private int severity_;
+    /**
+     * <code>.Severity severity = 10;</code>
+     */
+    public int getSeverityValue() {
+      return severity_;
+    }
+    /**
+     * <code>.Severity severity = 10;</code>
+     */
+    public org.opennms.features.kafka.producer.model.OpennmsModelProtos.Severity getSeverity() {
+      org.opennms.features.kafka.producer.model.OpennmsModelProtos.Severity result = org.opennms.features.kafka.producer.model.OpennmsModelProtos.Severity.valueOf(severity_);
+      return result == null ? org.opennms.features.kafka.producer.model.OpennmsModelProtos.Severity.UNRECOGNIZED : result;
+    }
+
+    public static final int LOG_FIELD_NUMBER = 11;
+    private boolean log_;
+    /**
+     * <code>bool log = 11;</code>
+     */
+    public boolean getLog() {
+      return log_;
+    }
+
+    public static final int DISPLAY_FIELD_NUMBER = 12;
+    private boolean display_;
+    /**
+     * <code>bool display = 12;</code>
+     */
+    public boolean getDisplay() {
+      return display_;
+    }
+
+    public static final int NODE_CRITERIA_FIELD_NUMBER = 13;
+    private org.opennms.features.kafka.producer.model.OpennmsModelProtos.NodeCriteria nodeCriteria_;
+    /**
+     * <code>.NodeCriteria node_criteria = 13;</code>
+     */
+    public boolean hasNodeCriteria() {
+      return nodeCriteria_ != null;
+    }
+    /**
+     * <code>.NodeCriteria node_criteria = 13;</code>
+     */
+    public org.opennms.features.kafka.producer.model.OpennmsModelProtos.NodeCriteria getNodeCriteria() {
+      return nodeCriteria_ == null ? org.opennms.features.kafka.producer.model.OpennmsModelProtos.NodeCriteria.getDefaultInstance() : nodeCriteria_;
+    }
+    /**
+     * <code>.NodeCriteria node_criteria = 13;</code>
+     */
+    public org.opennms.features.kafka.producer.model.OpennmsModelProtos.NodeCriteriaOrBuilder getNodeCriteriaOrBuilder() {
+      return getNodeCriteria();
+    }
+
+    private byte memoizedIsInitialized = -1;
+    public final boolean isInitialized() {
+      byte isInitialized = memoizedIsInitialized;
+      if (isInitialized == 1) return true;
+      if (isInitialized == 0) return false;
+
+      memoizedIsInitialized = 1;
+      return true;
+    }
+
+    public void writeTo(com.google.protobuf.CodedOutputStream output)
+                        throws java.io.IOException {
+      if (id_ != 0L) {
+        output.writeUInt64(1, id_);
+      }
+      if (!getUeiBytes().isEmpty()) {
+        com.google.protobuf.GeneratedMessageV3.writeString(output, 2, uei_);
+      }
+      if (!getLabelBytes().isEmpty()) {
+        com.google.protobuf.GeneratedMessageV3.writeString(output, 3, label_);
+      }
+      if (time_ != 0L) {
+        output.writeUInt64(4, time_);
+      }
+      if (!getSourceBytes().isEmpty()) {
+        com.google.protobuf.GeneratedMessageV3.writeString(output, 5, source_);
+      }
+      for (int i = 0; i < parameter_.size(); i++) {
+        output.writeMessage(6, parameter_.get(i));
+      }
+      if (createTime_ != 0L) {
+        output.writeUInt64(7, createTime_);
+      }
+      if (!getDescriptionBytes().isEmpty()) {
+        com.google.protobuf.GeneratedMessageV3.writeString(output, 8, description_);
+      }
+      if (!getLogMessageBytes().isEmpty()) {
+        com.google.protobuf.GeneratedMessageV3.writeString(output, 9, logMessage_);
+      }
+      if (severity_ != org.opennms.features.kafka.producer.model.OpennmsModelProtos.Severity.INDETERMINATE.getNumber()) {
+        output.writeEnum(10, severity_);
+      }
+      if (log_ != false) {
+        output.writeBool(11, log_);
+      }
+      if (display_ != false) {
+        output.writeBool(12, display_);
+      }
+      if (nodeCriteria_ != null) {
+        output.writeMessage(13, getNodeCriteria());
+      }
+      unknownFields.writeTo(output);
+    }
+
+    public int getSerializedSize() {
+      int size = memoizedSize;
+      if (size != -1) return size;
+
+      size = 0;
+      if (id_ != 0L) {
+        size += com.google.protobuf.CodedOutputStream
+          .computeUInt64Size(1, id_);
+      }
+      if (!getUeiBytes().isEmpty()) {
+        size += com.google.protobuf.GeneratedMessageV3.computeStringSize(2, uei_);
+      }
+      if (!getLabelBytes().isEmpty()) {
+        size += com.google.protobuf.GeneratedMessageV3.computeStringSize(3, label_);
+      }
+      if (time_ != 0L) {
+        size += com.google.protobuf.CodedOutputStream
+          .computeUInt64Size(4, time_);
+      }
+      if (!getSourceBytes().isEmpty()) {
+        size += com.google.protobuf.GeneratedMessageV3.computeStringSize(5, source_);
+      }
+      for (int i = 0; i < parameter_.size(); i++) {
+        size += com.google.protobuf.CodedOutputStream
+          .computeMessageSize(6, parameter_.get(i));
+      }
+      if (createTime_ != 0L) {
+        size += com.google.protobuf.CodedOutputStream
+          .computeUInt64Size(7, createTime_);
+      }
+      if (!getDescriptionBytes().isEmpty()) {
+        size += com.google.protobuf.GeneratedMessageV3.computeStringSize(8, description_);
+      }
+      if (!getLogMessageBytes().isEmpty()) {
+        size += com.google.protobuf.GeneratedMessageV3.computeStringSize(9, logMessage_);
+      }
+      if (severity_ != org.opennms.features.kafka.producer.model.OpennmsModelProtos.Severity.INDETERMINATE.getNumber()) {
+        size += com.google.protobuf.CodedOutputStream
+          .computeEnumSize(10, severity_);
+      }
+      if (log_ != false) {
+        size += com.google.protobuf.CodedOutputStream
+          .computeBoolSize(11, log_);
+      }
+      if (display_ != false) {
+        size += com.google.protobuf.CodedOutputStream
+          .computeBoolSize(12, display_);
+      }
+      if (nodeCriteria_ != null) {
+        size += com.google.protobuf.CodedOutputStream
+          .computeMessageSize(13, getNodeCriteria());
+      }
+      size += unknownFields.getSerializedSize();
+      memoizedSize = size;
+      return size;
+    }
+
+    @java.lang.Override
+    public boolean equals(final java.lang.Object obj) {
+      if (obj == this) {
+       return true;
+      }
+      if (!(obj instanceof org.opennms.features.kafka.producer.model.OpennmsModelProtos.Event)) {
+        return super.equals(obj);
+      }
+      org.opennms.features.kafka.producer.model.OpennmsModelProtos.Event other = (org.opennms.features.kafka.producer.model.OpennmsModelProtos.Event) obj;
+
+      boolean result = true;
+      result = result && (getId()
+          == other.getId());
+      result = result && getUei()
+          .equals(other.getUei());
+      result = result && getLabel()
+          .equals(other.getLabel());
+      result = result && (getTime()
+          == other.getTime());
+      result = result && getSource()
+          .equals(other.getSource());
+      result = result && getParameterList()
+          .equals(other.getParameterList());
+      result = result && (getCreateTime()
+          == other.getCreateTime());
+      result = result && getDescription()
+          .equals(other.getDescription());
+      result = result && getLogMessage()
+          .equals(other.getLogMessage());
+      result = result && severity_ == other.severity_;
+      result = result && (getLog()
+          == other.getLog());
+      result = result && (getDisplay()
+          == other.getDisplay());
+      result = result && (hasNodeCriteria() == other.hasNodeCriteria());
+      if (hasNodeCriteria()) {
+        result = result && getNodeCriteria()
+            .equals(other.getNodeCriteria());
+      }
+      result = result && unknownFields.equals(other.unknownFields);
+      return result;
+    }
+
+    @java.lang.Override
+    public int hashCode() {
+      if (memoizedHashCode != 0) {
+        return memoizedHashCode;
+      }
+      int hash = 41;
+      hash = (19 * hash) + getDescriptor().hashCode();
+      hash = (37 * hash) + ID_FIELD_NUMBER;
+      hash = (53 * hash) + com.google.protobuf.Internal.hashLong(
+          getId());
+      hash = (37 * hash) + UEI_FIELD_NUMBER;
+      hash = (53 * hash) + getUei().hashCode();
+      hash = (37 * hash) + LABEL_FIELD_NUMBER;
+      hash = (53 * hash) + getLabel().hashCode();
+      hash = (37 * hash) + TIME_FIELD_NUMBER;
+      hash = (53 * hash) + com.google.protobuf.Internal.hashLong(
+          getTime());
+      hash = (37 * hash) + SOURCE_FIELD_NUMBER;
+      hash = (53 * hash) + getSource().hashCode();
+      if (getParameterCount() > 0) {
+        hash = (37 * hash) + PARAMETER_FIELD_NUMBER;
+        hash = (53 * hash) + getParameterList().hashCode();
+      }
+      hash = (37 * hash) + CREATE_TIME_FIELD_NUMBER;
+      hash = (53 * hash) + com.google.protobuf.Internal.hashLong(
+          getCreateTime());
+      hash = (37 * hash) + DESCRIPTION_FIELD_NUMBER;
+      hash = (53 * hash) + getDescription().hashCode();
+      hash = (37 * hash) + LOG_MESSAGE_FIELD_NUMBER;
+      hash = (53 * hash) + getLogMessage().hashCode();
+      hash = (37 * hash) + SEVERITY_FIELD_NUMBER;
+      hash = (53 * hash) + severity_;
+      hash = (37 * hash) + LOG_FIELD_NUMBER;
+      hash = (53 * hash) + com.google.protobuf.Internal.hashBoolean(
+          getLog());
+      hash = (37 * hash) + DISPLAY_FIELD_NUMBER;
+      hash = (53 * hash) + com.google.protobuf.Internal.hashBoolean(
+          getDisplay());
+      if (hasNodeCriteria()) {
+        hash = (37 * hash) + NODE_CRITERIA_FIELD_NUMBER;
+        hash = (53 * hash) + getNodeCriteria().hashCode();
+      }
+      hash = (29 * hash) + unknownFields.hashCode();
+      memoizedHashCode = hash;
+      return hash;
+    }
+
+    public static org.opennms.features.kafka.producer.model.OpennmsModelProtos.Event parseFrom(
+        java.nio.ByteBuffer data)
+        throws com.google.protobuf.InvalidProtocolBufferException {
+      return PARSER.parseFrom(data);
+    }
+    public static org.opennms.features.kafka.producer.model.OpennmsModelProtos.Event parseFrom(
+        java.nio.ByteBuffer data,
+        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
+        throws com.google.protobuf.InvalidProtocolBufferException {
+      return PARSER.parseFrom(data, extensionRegistry);
+    }
+    public static org.opennms.features.kafka.producer.model.OpennmsModelProtos.Event parseFrom(
+        com.google.protobuf.ByteString data)
+        throws com.google.protobuf.InvalidProtocolBufferException {
+      return PARSER.parseFrom(data);
+    }
+    public static org.opennms.features.kafka.producer.model.OpennmsModelProtos.Event parseFrom(
+        com.google.protobuf.ByteString data,
+        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
+        throws com.google.protobuf.InvalidProtocolBufferException {
+      return PARSER.parseFrom(data, extensionRegistry);
+    }
+    public static org.opennms.features.kafka.producer.model.OpennmsModelProtos.Event parseFrom(byte[] data)
+        throws com.google.protobuf.InvalidProtocolBufferException {
+      return PARSER.parseFrom(data);
+    }
+    public static org.opennms.features.kafka.producer.model.OpennmsModelProtos.Event parseFrom(
+        byte[] data,
+        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
+        throws com.google.protobuf.InvalidProtocolBufferException {
+      return PARSER.parseFrom(data, extensionRegistry);
+    }
+    public static org.opennms.features.kafka.producer.model.OpennmsModelProtos.Event parseFrom(java.io.InputStream input)
+        throws java.io.IOException {
+      return com.google.protobuf.GeneratedMessageV3
+          .parseWithIOException(PARSER, input);
+    }
+    public static org.opennms.features.kafka.producer.model.OpennmsModelProtos.Event parseFrom(
+        java.io.InputStream input,
+        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
+        throws java.io.IOException {
+      return com.google.protobuf.GeneratedMessageV3
+          .parseWithIOException(PARSER, input, extensionRegistry);
+    }
+    public static org.opennms.features.kafka.producer.model.OpennmsModelProtos.Event parseDelimitedFrom(java.io.InputStream input)
+        throws java.io.IOException {
+      return com.google.protobuf.GeneratedMessageV3
+          .parseDelimitedWithIOException(PARSER, input);
+    }
+    public static org.opennms.features.kafka.producer.model.OpennmsModelProtos.Event parseDelimitedFrom(
+        java.io.InputStream input,
+        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
+        throws java.io.IOException {
+      return com.google.protobuf.GeneratedMessageV3
+          .parseDelimitedWithIOException(PARSER, input, extensionRegistry);
+    }
+    public static org.opennms.features.kafka.producer.model.OpennmsModelProtos.Event parseFrom(
+        com.google.protobuf.CodedInputStream input)
+        throws java.io.IOException {
+      return com.google.protobuf.GeneratedMessageV3
+          .parseWithIOException(PARSER, input);
+    }
+    public static org.opennms.features.kafka.producer.model.OpennmsModelProtos.Event parseFrom(
+        com.google.protobuf.CodedInputStream input,
+        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
+        throws java.io.IOException {
+      return com.google.protobuf.GeneratedMessageV3
+          .parseWithIOException(PARSER, input, extensionRegistry);
+    }
+
+    public Builder newBuilderForType() { return newBuilder(); }
+    public static Builder newBuilder() {
+      return DEFAULT_INSTANCE.toBuilder();
+    }
+    public static Builder newBuilder(org.opennms.features.kafka.producer.model.OpennmsModelProtos.Event prototype) {
+      return DEFAULT_INSTANCE.toBuilder().mergeFrom(prototype);
+    }
+    public Builder toBuilder() {
+      return this == DEFAULT_INSTANCE
+          ? new Builder() : new Builder().mergeFrom(this);
+    }
+
+    @java.lang.Override
+    protected Builder newBuilderForType(
+        com.google.protobuf.GeneratedMessageV3.BuilderParent parent) {
+      Builder builder = new Builder(parent);
+      return builder;
+    }
+    /**
+     * Protobuf type {@code Event}
+     */
+    public static final class Builder extends
+        com.google.protobuf.GeneratedMessageV3.Builder<Builder> implements
+        // @@protoc_insertion_point(builder_implements:Event)
+        org.opennms.features.kafka.producer.model.OpennmsModelProtos.EventOrBuilder {
+      public static final com.google.protobuf.Descriptors.Descriptor
+          getDescriptor() {
+        return org.opennms.features.kafka.producer.model.OpennmsModelProtos.internal_static_Event_descriptor;
+      }
+
+      protected com.google.protobuf.GeneratedMessageV3.FieldAccessorTable
+          internalGetFieldAccessorTable() {
+        return org.opennms.features.kafka.producer.model.OpennmsModelProtos.internal_static_Event_fieldAccessorTable
+            .ensureFieldAccessorsInitialized(
+                org.opennms.features.kafka.producer.model.OpennmsModelProtos.Event.class, org.opennms.features.kafka.producer.model.OpennmsModelProtos.Event.Builder.class);
+      }
+
+      // Construct using org.opennms.features.kafka.producer.model.OpennmsModelProtos.Event.newBuilder()
+      private Builder() {
+        maybeForceBuilderInitialization();
+      }
+
+      private Builder(
+          com.google.protobuf.GeneratedMessageV3.BuilderParent parent) {
+        super(parent);
+        maybeForceBuilderInitialization();
+      }
+      private void maybeForceBuilderInitialization() {
+        if (com.google.protobuf.GeneratedMessageV3
+                .alwaysUseFieldBuilders) {
+          getParameterFieldBuilder();
+        }
+      }
+      public Builder clear() {
+        super.clear();
+        id_ = 0L;
+
+        uei_ = "";
+
+        label_ = "";
+
+        time_ = 0L;
+
+        source_ = "";
+
+        if (parameterBuilder_ == null) {
+          parameter_ = java.util.Collections.emptyList();
+          bitField0_ = (bitField0_ & ~0x00000020);
+        } else {
+          parameterBuilder_.clear();
+        }
+        createTime_ = 0L;
+
+        description_ = "";
+
+        logMessage_ = "";
+
+        severity_ = 0;
+
+        log_ = false;
+
+        display_ = false;
+
+        if (nodeCriteriaBuilder_ == null) {
+          nodeCriteria_ = null;
+        } else {
+          nodeCriteria_ = null;
+          nodeCriteriaBuilder_ = null;
+        }
+        return this;
+      }
+
+      public com.google.protobuf.Descriptors.Descriptor
+          getDescriptorForType() {
+        return org.opennms.features.kafka.producer.model.OpennmsModelProtos.internal_static_Event_descriptor;
+      }
+
+      public org.opennms.features.kafka.producer.model.OpennmsModelProtos.Event getDefaultInstanceForType() {
+        return org.opennms.features.kafka.producer.model.OpennmsModelProtos.Event.getDefaultInstance();
+      }
+
+      public org.opennms.features.kafka.producer.model.OpennmsModelProtos.Event build() {
+        org.opennms.features.kafka.producer.model.OpennmsModelProtos.Event result = buildPartial();
+        if (!result.isInitialized()) {
+          throw newUninitializedMessageException(result);
+        }
+        return result;
+      }
+
+      public org.opennms.features.kafka.producer.model.OpennmsModelProtos.Event buildPartial() {
+        org.opennms.features.kafka.producer.model.OpennmsModelProtos.Event result = new org.opennms.features.kafka.producer.model.OpennmsModelProtos.Event(this);
+        int from_bitField0_ = bitField0_;
+        int to_bitField0_ = 0;
+        result.id_ = id_;
+        result.uei_ = uei_;
+        result.label_ = label_;
+        result.time_ = time_;
+        result.source_ = source_;
+        if (parameterBuilder_ == null) {
+          if (((bitField0_ & 0x00000020) == 0x00000020)) {
+            parameter_ = java.util.Collections.unmodifiableList(parameter_);
+            bitField0_ = (bitField0_ & ~0x00000020);
+          }
+          result.parameter_ = parameter_;
+        } else {
+          result.parameter_ = parameterBuilder_.build();
+        }
+        result.createTime_ = createTime_;
+        result.description_ = description_;
+        result.logMessage_ = logMessage_;
+        result.severity_ = severity_;
+        result.log_ = log_;
+        result.display_ = display_;
+        if (nodeCriteriaBuilder_ == null) {
+          result.nodeCriteria_ = nodeCriteria_;
+        } else {
+          result.nodeCriteria_ = nodeCriteriaBuilder_.build();
+        }
+        result.bitField0_ = to_bitField0_;
+        onBuilt();
+        return result;
+      }
+
+      public Builder clone() {
+        return (Builder) super.clone();
+      }
+      public Builder setField(
+          com.google.protobuf.Descriptors.FieldDescriptor field,
+          java.lang.Object value) {
+        return (Builder) super.setField(field, value);
+      }
+      public Builder clearField(
+          com.google.protobuf.Descriptors.FieldDescriptor field) {
+        return (Builder) super.clearField(field);
+      }
+      public Builder clearOneof(
+          com.google.protobuf.Descriptors.OneofDescriptor oneof) {
+        return (Builder) super.clearOneof(oneof);
+      }
+      public Builder setRepeatedField(
+          com.google.protobuf.Descriptors.FieldDescriptor field,
+          int index, java.lang.Object value) {
+        return (Builder) super.setRepeatedField(field, index, value);
+      }
+      public Builder addRepeatedField(
+          com.google.protobuf.Descriptors.FieldDescriptor field,
+          java.lang.Object value) {
+        return (Builder) super.addRepeatedField(field, value);
+      }
+      public Builder mergeFrom(com.google.protobuf.Message other) {
+        if (other instanceof org.opennms.features.kafka.producer.model.OpennmsModelProtos.Event) {
+          return mergeFrom((org.opennms.features.kafka.producer.model.OpennmsModelProtos.Event)other);
+        } else {
+          super.mergeFrom(other);
+          return this;
+        }
+      }
+
+      public Builder mergeFrom(org.opennms.features.kafka.producer.model.OpennmsModelProtos.Event other) {
+        if (other == org.opennms.features.kafka.producer.model.OpennmsModelProtos.Event.getDefaultInstance()) return this;
+        if (other.getId() != 0L) {
+          setId(other.getId());
+        }
+        if (!other.getUei().isEmpty()) {
+          uei_ = other.uei_;
+          onChanged();
+        }
+        if (!other.getLabel().isEmpty()) {
+          label_ = other.label_;
+          onChanged();
+        }
+        if (other.getTime() != 0L) {
+          setTime(other.getTime());
+        }
+        if (!other.getSource().isEmpty()) {
+          source_ = other.source_;
+          onChanged();
+        }
+        if (parameterBuilder_ == null) {
+          if (!other.parameter_.isEmpty()) {
+            if (parameter_.isEmpty()) {
+              parameter_ = other.parameter_;
+              bitField0_ = (bitField0_ & ~0x00000020);
+            } else {
+              ensureParameterIsMutable();
+              parameter_.addAll(other.parameter_);
+            }
+            onChanged();
+          }
+        } else {
+          if (!other.parameter_.isEmpty()) {
+            if (parameterBuilder_.isEmpty()) {
+              parameterBuilder_.dispose();
+              parameterBuilder_ = null;
+              parameter_ = other.parameter_;
+              bitField0_ = (bitField0_ & ~0x00000020);
+              parameterBuilder_ = 
+                com.google.protobuf.GeneratedMessageV3.alwaysUseFieldBuilders ?
+                   getParameterFieldBuilder() : null;
+            } else {
+              parameterBuilder_.addAllMessages(other.parameter_);
+            }
+          }
+        }
+        if (other.getCreateTime() != 0L) {
+          setCreateTime(other.getCreateTime());
+        }
+        if (!other.getDescription().isEmpty()) {
+          description_ = other.description_;
+          onChanged();
+        }
+        if (!other.getLogMessage().isEmpty()) {
+          logMessage_ = other.logMessage_;
+          onChanged();
+        }
+        if (other.severity_ != 0) {
+          setSeverityValue(other.getSeverityValue());
+        }
+        if (other.getLog() != false) {
+          setLog(other.getLog());
+        }
+        if (other.getDisplay() != false) {
+          setDisplay(other.getDisplay());
+        }
+        if (other.hasNodeCriteria()) {
+          mergeNodeCriteria(other.getNodeCriteria());
+        }
+        this.mergeUnknownFields(other.unknownFields);
+        onChanged();
+        return this;
+      }
+
+      public final boolean isInitialized() {
+        return true;
+      }
+
+      public Builder mergeFrom(
+          com.google.protobuf.CodedInputStream input,
+          com.google.protobuf.ExtensionRegistryLite extensionRegistry)
+          throws java.io.IOException {
+        org.opennms.features.kafka.producer.model.OpennmsModelProtos.Event parsedMessage = null;
+        try {
+          parsedMessage = PARSER.parsePartialFrom(input, extensionRegistry);
+        } catch (com.google.protobuf.InvalidProtocolBufferException e) {
+          parsedMessage = (org.opennms.features.kafka.producer.model.OpennmsModelProtos.Event) e.getUnfinishedMessage();
+          throw e.unwrapIOException();
+        } finally {
+          if (parsedMessage != null) {
+            mergeFrom(parsedMessage);
+          }
+        }
+        return this;
+      }
+      private int bitField0_;
+
+      private long id_ ;
+      /**
+       * <code>uint64 id = 1;</code>
+       */
+      public long getId() {
+        return id_;
+      }
+      /**
+       * <code>uint64 id = 1;</code>
+       */
+      public Builder setId(long value) {
+        
+        id_ = value;
+        onChanged();
+        return this;
+      }
+      /**
+       * <code>uint64 id = 1;</code>
+       */
+      public Builder clearId() {
+        
+        id_ = 0L;
+        onChanged();
+        return this;
+      }
+
+      private java.lang.Object uei_ = "";
+      /**
+       * <code>string uei = 2;</code>
+       */
+      public java.lang.String getUei() {
+        java.lang.Object ref = uei_;
+        if (!(ref instanceof java.lang.String)) {
+          com.google.protobuf.ByteString bs =
+              (com.google.protobuf.ByteString) ref;
+          java.lang.String s = bs.toStringUtf8();
+          uei_ = s;
+          return s;
+        } else {
+          return (java.lang.String) ref;
+        }
+      }
+      /**
+       * <code>string uei = 2;</code>
+       */
+      public com.google.protobuf.ByteString
+          getUeiBytes() {
+        java.lang.Object ref = uei_;
+        if (ref instanceof String) {
+          com.google.protobuf.ByteString b = 
+              com.google.protobuf.ByteString.copyFromUtf8(
+                  (java.lang.String) ref);
+          uei_ = b;
+          return b;
+        } else {
+          return (com.google.protobuf.ByteString) ref;
+        }
+      }
+      /**
+       * <code>string uei = 2;</code>
+       */
+      public Builder setUei(
+          java.lang.String value) {
+        if (value == null) {
+    throw new NullPointerException();
+  }
+  
+        uei_ = value;
+        onChanged();
+        return this;
+      }
+      /**
+       * <code>string uei = 2;</code>
+       */
+      public Builder clearUei() {
+        
+        uei_ = getDefaultInstance().getUei();
+        onChanged();
+        return this;
+      }
+      /**
+       * <code>string uei = 2;</code>
+       */
+      public Builder setUeiBytes(
+          com.google.protobuf.ByteString value) {
+        if (value == null) {
+    throw new NullPointerException();
+  }
+  checkByteStringIsUtf8(value);
+        
+        uei_ = value;
+        onChanged();
+        return this;
+      }
+
+      private java.lang.Object label_ = "";
+      /**
+       * <code>string label = 3;</code>
+       */
+      public java.lang.String getLabel() {
+        java.lang.Object ref = label_;
+        if (!(ref instanceof java.lang.String)) {
+          com.google.protobuf.ByteString bs =
+              (com.google.protobuf.ByteString) ref;
+          java.lang.String s = bs.toStringUtf8();
+          label_ = s;
+          return s;
+        } else {
+          return (java.lang.String) ref;
+        }
+      }
+      /**
+       * <code>string label = 3;</code>
+       */
+      public com.google.protobuf.ByteString
+          getLabelBytes() {
+        java.lang.Object ref = label_;
+        if (ref instanceof String) {
+          com.google.protobuf.ByteString b = 
+              com.google.protobuf.ByteString.copyFromUtf8(
+                  (java.lang.String) ref);
+          label_ = b;
+          return b;
+        } else {
+          return (com.google.protobuf.ByteString) ref;
+        }
+      }
+      /**
+       * <code>string label = 3;</code>
+       */
+      public Builder setLabel(
+          java.lang.String value) {
+        if (value == null) {
+    throw new NullPointerException();
+  }
+  
+        label_ = value;
+        onChanged();
+        return this;
+      }
+      /**
+       * <code>string label = 3;</code>
+       */
+      public Builder clearLabel() {
+        
+        label_ = getDefaultInstance().getLabel();
+        onChanged();
+        return this;
+      }
+      /**
+       * <code>string label = 3;</code>
+       */
+      public Builder setLabelBytes(
+          com.google.protobuf.ByteString value) {
+        if (value == null) {
+    throw new NullPointerException();
+  }
+  checkByteStringIsUtf8(value);
+        
+        label_ = value;
+        onChanged();
+        return this;
+      }
+
+      private long time_ ;
+      /**
+       * <code>uint64 time = 4;</code>
+       */
+      public long getTime() {
+        return time_;
+      }
+      /**
+       * <code>uint64 time = 4;</code>
+       */
+      public Builder setTime(long value) {
+        
+        time_ = value;
+        onChanged();
+        return this;
+      }
+      /**
+       * <code>uint64 time = 4;</code>
+       */
+      public Builder clearTime() {
+        
+        time_ = 0L;
+        onChanged();
+        return this;
+      }
+
+      private java.lang.Object source_ = "";
+      /**
+       * <code>string source = 5;</code>
+       */
+      public java.lang.String getSource() {
+        java.lang.Object ref = source_;
+        if (!(ref instanceof java.lang.String)) {
+          com.google.protobuf.ByteString bs =
+              (com.google.protobuf.ByteString) ref;
+          java.lang.String s = bs.toStringUtf8();
+          source_ = s;
+          return s;
+        } else {
+          return (java.lang.String) ref;
+        }
+      }
+      /**
+       * <code>string source = 5;</code>
+       */
+      public com.google.protobuf.ByteString
+          getSourceBytes() {
+        java.lang.Object ref = source_;
+        if (ref instanceof String) {
+          com.google.protobuf.ByteString b = 
+              com.google.protobuf.ByteString.copyFromUtf8(
+                  (java.lang.String) ref);
+          source_ = b;
+          return b;
+        } else {
+          return (com.google.protobuf.ByteString) ref;
+        }
+      }
+      /**
+       * <code>string source = 5;</code>
+       */
+      public Builder setSource(
+          java.lang.String value) {
+        if (value == null) {
+    throw new NullPointerException();
+  }
+  
+        source_ = value;
+        onChanged();
+        return this;
+      }
+      /**
+       * <code>string source = 5;</code>
+       */
+      public Builder clearSource() {
+        
+        source_ = getDefaultInstance().getSource();
+        onChanged();
+        return this;
+      }
+      /**
+       * <code>string source = 5;</code>
+       */
+      public Builder setSourceBytes(
+          com.google.protobuf.ByteString value) {
+        if (value == null) {
+    throw new NullPointerException();
+  }
+  checkByteStringIsUtf8(value);
+        
+        source_ = value;
+        onChanged();
+        return this;
+      }
+
+      private java.util.List<org.opennms.features.kafka.producer.model.OpennmsModelProtos.EventParameter> parameter_ =
+        java.util.Collections.emptyList();
+      private void ensureParameterIsMutable() {
+        if (!((bitField0_ & 0x00000020) == 0x00000020)) {
+          parameter_ = new java.util.ArrayList<org.opennms.features.kafka.producer.model.OpennmsModelProtos.EventParameter>(parameter_);
+          bitField0_ |= 0x00000020;
+         }
+      }
+
+      private com.google.protobuf.RepeatedFieldBuilderV3<
+          org.opennms.features.kafka.producer.model.OpennmsModelProtos.EventParameter, org.opennms.features.kafka.producer.model.OpennmsModelProtos.EventParameter.Builder, org.opennms.features.kafka.producer.model.OpennmsModelProtos.EventParameterOrBuilder> parameterBuilder_;
+
+      /**
+       * <code>repeated .EventParameter parameter = 6;</code>
+       */
+      public java.util.List<org.opennms.features.kafka.producer.model.OpennmsModelProtos.EventParameter> getParameterList() {
+        if (parameterBuilder_ == null) {
+          return java.util.Collections.unmodifiableList(parameter_);
+        } else {
+          return parameterBuilder_.getMessageList();
+        }
+      }
+      /**
+       * <code>repeated .EventParameter parameter = 6;</code>
+       */
+      public int getParameterCount() {
+        if (parameterBuilder_ == null) {
+          return parameter_.size();
+        } else {
+          return parameterBuilder_.getCount();
+        }
+      }
+      /**
+       * <code>repeated .EventParameter parameter = 6;</code>
+       */
+      public org.opennms.features.kafka.producer.model.OpennmsModelProtos.EventParameter getParameter(int index) {
+        if (parameterBuilder_ == null) {
+          return parameter_.get(index);
+        } else {
+          return parameterBuilder_.getMessage(index);
+        }
+      }
+      /**
+       * <code>repeated .EventParameter parameter = 6;</code>
+       */
+      public Builder setParameter(
+          int index, org.opennms.features.kafka.producer.model.OpennmsModelProtos.EventParameter value) {
+        if (parameterBuilder_ == null) {
+          if (value == null) {
+            throw new NullPointerException();
+          }
+          ensureParameterIsMutable();
+          parameter_.set(index, value);
+          onChanged();
+        } else {
+          parameterBuilder_.setMessage(index, value);
+        }
+        return this;
+      }
+      /**
+       * <code>repeated .EventParameter parameter = 6;</code>
+       */
+      public Builder setParameter(
+          int index, org.opennms.features.kafka.producer.model.OpennmsModelProtos.EventParameter.Builder builderForValue) {
+        if (parameterBuilder_ == null) {
+          ensureParameterIsMutable();
+          parameter_.set(index, builderForValue.build());
+          onChanged();
+        } else {
+          parameterBuilder_.setMessage(index, builderForValue.build());
+        }
+        return this;
+      }
+      /**
+       * <code>repeated .EventParameter parameter = 6;</code>
+       */
+      public Builder addParameter(org.opennms.features.kafka.producer.model.OpennmsModelProtos.EventParameter value) {
+        if (parameterBuilder_ == null) {
+          if (value == null) {
+            throw new NullPointerException();
+          }
+          ensureParameterIsMutable();
+          parameter_.add(value);
+          onChanged();
+        } else {
+          parameterBuilder_.addMessage(value);
+        }
+        return this;
+      }
+      /**
+       * <code>repeated .EventParameter parameter = 6;</code>
+       */
+      public Builder addParameter(
+          int index, org.opennms.features.kafka.producer.model.OpennmsModelProtos.EventParameter value) {
+        if (parameterBuilder_ == null) {
+          if (value == null) {
+            throw new NullPointerException();
+          }
+          ensureParameterIsMutable();
+          parameter_.add(index, value);
+          onChanged();
+        } else {
+          parameterBuilder_.addMessage(index, value);
+        }
+        return this;
+      }
+      /**
+       * <code>repeated .EventParameter parameter = 6;</code>
+       */
+      public Builder addParameter(
+          org.opennms.features.kafka.producer.model.OpennmsModelProtos.EventParameter.Builder builderForValue) {
+        if (parameterBuilder_ == null) {
+          ensureParameterIsMutable();
+          parameter_.add(builderForValue.build());
+          onChanged();
+        } else {
+          parameterBuilder_.addMessage(builderForValue.build());
+        }
+        return this;
+      }
+      /**
+       * <code>repeated .EventParameter parameter = 6;</code>
+       */
+      public Builder addParameter(
+          int index, org.opennms.features.kafka.producer.model.OpennmsModelProtos.EventParameter.Builder builderForValue) {
+        if (parameterBuilder_ == null) {
+          ensureParameterIsMutable();
+          parameter_.add(index, builderForValue.build());
+          onChanged();
+        } else {
+          parameterBuilder_.addMessage(index, builderForValue.build());
+        }
+        return this;
+      }
+      /**
+       * <code>repeated .EventParameter parameter = 6;</code>
+       */
+      public Builder addAllParameter(
+          java.lang.Iterable<? extends org.opennms.features.kafka.producer.model.OpennmsModelProtos.EventParameter> values) {
+        if (parameterBuilder_ == null) {
+          ensureParameterIsMutable();
+          com.google.protobuf.AbstractMessageLite.Builder.addAll(
+              values, parameter_);
+          onChanged();
+        } else {
+          parameterBuilder_.addAllMessages(values);
+        }
+        return this;
+      }
+      /**
+       * <code>repeated .EventParameter parameter = 6;</code>
+       */
+      public Builder clearParameter() {
+        if (parameterBuilder_ == null) {
+          parameter_ = java.util.Collections.emptyList();
+          bitField0_ = (bitField0_ & ~0x00000020);
+          onChanged();
+        } else {
+          parameterBuilder_.clear();
+        }
+        return this;
+      }
+      /**
+       * <code>repeated .EventParameter parameter = 6;</code>
+       */
+      public Builder removeParameter(int index) {
+        if (parameterBuilder_ == null) {
+          ensureParameterIsMutable();
+          parameter_.remove(index);
+          onChanged();
+        } else {
+          parameterBuilder_.remove(index);
+        }
+        return this;
+      }
+      /**
+       * <code>repeated .EventParameter parameter = 6;</code>
+       */
+      public org.opennms.features.kafka.producer.model.OpennmsModelProtos.EventParameter.Builder getParameterBuilder(
+          int index) {
+        return getParameterFieldBuilder().getBuilder(index);
+      }
+      /**
+       * <code>repeated .EventParameter parameter = 6;</code>
+       */
+      public org.opennms.features.kafka.producer.model.OpennmsModelProtos.EventParameterOrBuilder getParameterOrBuilder(
+          int index) {
+        if (parameterBuilder_ == null) {
+          return parameter_.get(index);  } else {
+          return parameterBuilder_.getMessageOrBuilder(index);
+        }
+      }
+      /**
+       * <code>repeated .EventParameter parameter = 6;</code>
+       */
+      public java.util.List<? extends org.opennms.features.kafka.producer.model.OpennmsModelProtos.EventParameterOrBuilder> 
+           getParameterOrBuilderList() {
+        if (parameterBuilder_ != null) {
+          return parameterBuilder_.getMessageOrBuilderList();
+        } else {
+          return java.util.Collections.unmodifiableList(parameter_);
+        }
+      }
+      /**
+       * <code>repeated .EventParameter parameter = 6;</code>
+       */
+      public org.opennms.features.kafka.producer.model.OpennmsModelProtos.EventParameter.Builder addParameterBuilder() {
+        return getParameterFieldBuilder().addBuilder(
+            org.opennms.features.kafka.producer.model.OpennmsModelProtos.EventParameter.getDefaultInstance());
+      }
+      /**
+       * <code>repeated .EventParameter parameter = 6;</code>
+       */
+      public org.opennms.features.kafka.producer.model.OpennmsModelProtos.EventParameter.Builder addParameterBuilder(
+          int index) {
+        return getParameterFieldBuilder().addBuilder(
+            index, org.opennms.features.kafka.producer.model.OpennmsModelProtos.EventParameter.getDefaultInstance());
+      }
+      /**
+       * <code>repeated .EventParameter parameter = 6;</code>
+       */
+      public java.util.List<org.opennms.features.kafka.producer.model.OpennmsModelProtos.EventParameter.Builder> 
+           getParameterBuilderList() {
+        return getParameterFieldBuilder().getBuilderList();
+      }
+      private com.google.protobuf.RepeatedFieldBuilderV3<
+          org.opennms.features.kafka.producer.model.OpennmsModelProtos.EventParameter, org.opennms.features.kafka.producer.model.OpennmsModelProtos.EventParameter.Builder, org.opennms.features.kafka.producer.model.OpennmsModelProtos.EventParameterOrBuilder> 
+          getParameterFieldBuilder() {
+        if (parameterBuilder_ == null) {
+          parameterBuilder_ = new com.google.protobuf.RepeatedFieldBuilderV3<
+              org.opennms.features.kafka.producer.model.OpennmsModelProtos.EventParameter, org.opennms.features.kafka.producer.model.OpennmsModelProtos.EventParameter.Builder, org.opennms.features.kafka.producer.model.OpennmsModelProtos.EventParameterOrBuilder>(
+                  parameter_,
+                  ((bitField0_ & 0x00000020) == 0x00000020),
+                  getParentForChildren(),
+                  isClean());
+          parameter_ = null;
+        }
+        return parameterBuilder_;
+      }
+
+      private long createTime_ ;
+      /**
+       * <code>uint64 create_time = 7;</code>
+       */
+      public long getCreateTime() {
+        return createTime_;
+      }
+      /**
+       * <code>uint64 create_time = 7;</code>
+       */
+      public Builder setCreateTime(long value) {
+        
+        createTime_ = value;
+        onChanged();
+        return this;
+      }
+      /**
+       * <code>uint64 create_time = 7;</code>
+       */
+      public Builder clearCreateTime() {
+        
+        createTime_ = 0L;
+        onChanged();
+        return this;
+      }
+
+      private java.lang.Object description_ = "";
+      /**
+       * <code>string description = 8;</code>
+       */
+      public java.lang.String getDescription() {
+        java.lang.Object ref = description_;
+        if (!(ref instanceof java.lang.String)) {
+          com.google.protobuf.ByteString bs =
+              (com.google.protobuf.ByteString) ref;
+          java.lang.String s = bs.toStringUtf8();
+          description_ = s;
+          return s;
+        } else {
+          return (java.lang.String) ref;
+        }
+      }
+      /**
+       * <code>string description = 8;</code>
+       */
+      public com.google.protobuf.ByteString
+          getDescriptionBytes() {
+        java.lang.Object ref = description_;
+        if (ref instanceof String) {
+          com.google.protobuf.ByteString b = 
+              com.google.protobuf.ByteString.copyFromUtf8(
+                  (java.lang.String) ref);
+          description_ = b;
+          return b;
+        } else {
+          return (com.google.protobuf.ByteString) ref;
+        }
+      }
+      /**
+       * <code>string description = 8;</code>
+       */
+      public Builder setDescription(
+          java.lang.String value) {
+        if (value == null) {
+    throw new NullPointerException();
+  }
+  
+        description_ = value;
+        onChanged();
+        return this;
+      }
+      /**
+       * <code>string description = 8;</code>
+       */
+      public Builder clearDescription() {
+        
+        description_ = getDefaultInstance().getDescription();
+        onChanged();
+        return this;
+      }
+      /**
+       * <code>string description = 8;</code>
+       */
+      public Builder setDescriptionBytes(
+          com.google.protobuf.ByteString value) {
+        if (value == null) {
+    throw new NullPointerException();
+  }
+  checkByteStringIsUtf8(value);
+        
+        description_ = value;
+        onChanged();
+        return this;
+      }
+
+      private java.lang.Object logMessage_ = "";
+      /**
+       * <code>string log_message = 9;</code>
+       */
+      public java.lang.String getLogMessage() {
+        java.lang.Object ref = logMessage_;
+        if (!(ref instanceof java.lang.String)) {
+          com.google.protobuf.ByteString bs =
+              (com.google.protobuf.ByteString) ref;
+          java.lang.String s = bs.toStringUtf8();
+          logMessage_ = s;
+          return s;
+        } else {
+          return (java.lang.String) ref;
+        }
+      }
+      /**
+       * <code>string log_message = 9;</code>
+       */
+      public com.google.protobuf.ByteString
+          getLogMessageBytes() {
+        java.lang.Object ref = logMessage_;
+        if (ref instanceof String) {
+          com.google.protobuf.ByteString b = 
+              com.google.protobuf.ByteString.copyFromUtf8(
+                  (java.lang.String) ref);
+          logMessage_ = b;
+          return b;
+        } else {
+          return (com.google.protobuf.ByteString) ref;
+        }
+      }
+      /**
+       * <code>string log_message = 9;</code>
+       */
+      public Builder setLogMessage(
+          java.lang.String value) {
+        if (value == null) {
+    throw new NullPointerException();
+  }
+  
+        logMessage_ = value;
+        onChanged();
+        return this;
+      }
+      /**
+       * <code>string log_message = 9;</code>
+       */
+      public Builder clearLogMessage() {
+        
+        logMessage_ = getDefaultInstance().getLogMessage();
+        onChanged();
+        return this;
+      }
+      /**
+       * <code>string log_message = 9;</code>
+       */
+      public Builder setLogMessageBytes(
+          com.google.protobuf.ByteString value) {
+        if (value == null) {
+    throw new NullPointerException();
+  }
+  checkByteStringIsUtf8(value);
+        
+        logMessage_ = value;
+        onChanged();
+        return this;
+      }
+
+      private int severity_ = 0;
+      /**
+       * <code>.Severity severity = 10;</code>
+       */
+      public int getSeverityValue() {
+        return severity_;
+      }
+      /**
+       * <code>.Severity severity = 10;</code>
+       */
+      public Builder setSeverityValue(int value) {
+        severity_ = value;
+        onChanged();
+        return this;
+      }
+      /**
+       * <code>.Severity severity = 10;</code>
+       */
+      public org.opennms.features.kafka.producer.model.OpennmsModelProtos.Severity getSeverity() {
+        org.opennms.features.kafka.producer.model.OpennmsModelProtos.Severity result = org.opennms.features.kafka.producer.model.OpennmsModelProtos.Severity.valueOf(severity_);
+        return result == null ? org.opennms.features.kafka.producer.model.OpennmsModelProtos.Severity.UNRECOGNIZED : result;
+      }
+      /**
+       * <code>.Severity severity = 10;</code>
+       */
+      public Builder setSeverity(org.opennms.features.kafka.producer.model.OpennmsModelProtos.Severity value) {
+        if (value == null) {
+          throw new NullPointerException();
+        }
+        
+        severity_ = value.getNumber();
+        onChanged();
+        return this;
+      }
+      /**
+       * <code>.Severity severity = 10;</code>
+       */
+      public Builder clearSeverity() {
+        
+        severity_ = 0;
+        onChanged();
+        return this;
+      }
+
+      private boolean log_ ;
+      /**
+       * <code>bool log = 11;</code>
+       */
+      public boolean getLog() {
+        return log_;
+      }
+      /**
+       * <code>bool log = 11;</code>
+       */
+      public Builder setLog(boolean value) {
+        
+        log_ = value;
+        onChanged();
+        return this;
+      }
+      /**
+       * <code>bool log = 11;</code>
+       */
+      public Builder clearLog() {
+        
+        log_ = false;
+        onChanged();
+        return this;
+      }
+
+      private boolean display_ ;
+      /**
+       * <code>bool display = 12;</code>
+       */
+      public boolean getDisplay() {
+        return display_;
+      }
+      /**
+       * <code>bool display = 12;</code>
+       */
+      public Builder setDisplay(boolean value) {
+        
+        display_ = value;
+        onChanged();
+        return this;
+      }
+      /**
+       * <code>bool display = 12;</code>
+       */
+      public Builder clearDisplay() {
+        
+        display_ = false;
+        onChanged();
+        return this;
+      }
+
+      private org.opennms.features.kafka.producer.model.OpennmsModelProtos.NodeCriteria nodeCriteria_ = null;
+      private com.google.protobuf.SingleFieldBuilderV3<
+          org.opennms.features.kafka.producer.model.OpennmsModelProtos.NodeCriteria, org.opennms.features.kafka.producer.model.OpennmsModelProtos.NodeCriteria.Builder, org.opennms.features.kafka.producer.model.OpennmsModelProtos.NodeCriteriaOrBuilder> nodeCriteriaBuilder_;
+      /**
+       * <code>.NodeCriteria node_criteria = 13;</code>
+       */
+      public boolean hasNodeCriteria() {
+        return nodeCriteriaBuilder_ != null || nodeCriteria_ != null;
+      }
+      /**
+       * <code>.NodeCriteria node_criteria = 13;</code>
+       */
+      public org.opennms.features.kafka.producer.model.OpennmsModelProtos.NodeCriteria getNodeCriteria() {
+        if (nodeCriteriaBuilder_ == null) {
+          return nodeCriteria_ == null ? org.opennms.features.kafka.producer.model.OpennmsModelProtos.NodeCriteria.getDefaultInstance() : nodeCriteria_;
+        } else {
+          return nodeCriteriaBuilder_.getMessage();
+        }
+      }
+      /**
+       * <code>.NodeCriteria node_criteria = 13;</code>
+       */
+      public Builder setNodeCriteria(org.opennms.features.kafka.producer.model.OpennmsModelProtos.NodeCriteria value) {
+        if (nodeCriteriaBuilder_ == null) {
+          if (value == null) {
+            throw new NullPointerException();
+          }
+          nodeCriteria_ = value;
+          onChanged();
+        } else {
+          nodeCriteriaBuilder_.setMessage(value);
+        }
+
+        return this;
+      }
+      /**
+       * <code>.NodeCriteria node_criteria = 13;</code>
+       */
+      public Builder setNodeCriteria(
+          org.opennms.features.kafka.producer.model.OpennmsModelProtos.NodeCriteria.Builder builderForValue) {
+        if (nodeCriteriaBuilder_ == null) {
+          nodeCriteria_ = builderForValue.build();
+          onChanged();
+        } else {
+          nodeCriteriaBuilder_.setMessage(builderForValue.build());
+        }
+
+        return this;
+      }
+      /**
+       * <code>.NodeCriteria node_criteria = 13;</code>
+       */
+      public Builder mergeNodeCriteria(org.opennms.features.kafka.producer.model.OpennmsModelProtos.NodeCriteria value) {
+        if (nodeCriteriaBuilder_ == null) {
+          if (nodeCriteria_ != null) {
+            nodeCriteria_ =
+              org.opennms.features.kafka.producer.model.OpennmsModelProtos.NodeCriteria.newBuilder(nodeCriteria_).mergeFrom(value).buildPartial();
+          } else {
+            nodeCriteria_ = value;
+          }
+          onChanged();
+        } else {
+          nodeCriteriaBuilder_.mergeFrom(value);
+        }
+
+        return this;
+      }
+      /**
+       * <code>.NodeCriteria node_criteria = 13;</code>
+       */
+      public Builder clearNodeCriteria() {
+        if (nodeCriteriaBuilder_ == null) {
+          nodeCriteria_ = null;
+          onChanged();
+        } else {
+          nodeCriteria_ = null;
+          nodeCriteriaBuilder_ = null;
+        }
+
+        return this;
+      }
+      /**
+       * <code>.NodeCriteria node_criteria = 13;</code>
+       */
+      public org.opennms.features.kafka.producer.model.OpennmsModelProtos.NodeCriteria.Builder getNodeCriteriaBuilder() {
+        
+        onChanged();
+        return getNodeCriteriaFieldBuilder().getBuilder();
+      }
+      /**
+       * <code>.NodeCriteria node_criteria = 13;</code>
+       */
+      public org.opennms.features.kafka.producer.model.OpennmsModelProtos.NodeCriteriaOrBuilder getNodeCriteriaOrBuilder() {
+        if (nodeCriteriaBuilder_ != null) {
+          return nodeCriteriaBuilder_.getMessageOrBuilder();
+        } else {
+          return nodeCriteria_ == null ?
+              org.opennms.features.kafka.producer.model.OpennmsModelProtos.NodeCriteria.getDefaultInstance() : nodeCriteria_;
+        }
+      }
+      /**
+       * <code>.NodeCriteria node_criteria = 13;</code>
+       */
+      private com.google.protobuf.SingleFieldBuilderV3<
+          org.opennms.features.kafka.producer.model.OpennmsModelProtos.NodeCriteria, org.opennms.features.kafka.producer.model.OpennmsModelProtos.NodeCriteria.Builder, org.opennms.features.kafka.producer.model.OpennmsModelProtos.NodeCriteriaOrBuilder> 
+          getNodeCriteriaFieldBuilder() {
+        if (nodeCriteriaBuilder_ == null) {
+          nodeCriteriaBuilder_ = new com.google.protobuf.SingleFieldBuilderV3<
+              org.opennms.features.kafka.producer.model.OpennmsModelProtos.NodeCriteria, org.opennms.features.kafka.producer.model.OpennmsModelProtos.NodeCriteria.Builder, org.opennms.features.kafka.producer.model.OpennmsModelProtos.NodeCriteriaOrBuilder>(
+                  getNodeCriteria(),
+                  getParentForChildren(),
+                  isClean());
+          nodeCriteria_ = null;
+        }
+        return nodeCriteriaBuilder_;
+      }
+      public final Builder setUnknownFields(
+          final com.google.protobuf.UnknownFieldSet unknownFields) {
+        return super.setUnknownFieldsProto3(unknownFields);
+      }
+
+      public final Builder mergeUnknownFields(
+          final com.google.protobuf.UnknownFieldSet unknownFields) {
+        return super.mergeUnknownFields(unknownFields);
+      }
+
+
+      // @@protoc_insertion_point(builder_scope:Event)
+    }
+
+    // @@protoc_insertion_point(class_scope:Event)
+    private static final org.opennms.features.kafka.producer.model.OpennmsModelProtos.Event DEFAULT_INSTANCE;
+    static {
+      DEFAULT_INSTANCE = new org.opennms.features.kafka.producer.model.OpennmsModelProtos.Event();
+    }
+
+    public static org.opennms.features.kafka.producer.model.OpennmsModelProtos.Event getDefaultInstance() {
+      return DEFAULT_INSTANCE;
+    }
+
+    private static final com.google.protobuf.Parser<Event>
+        PARSER = new com.google.protobuf.AbstractParser<Event>() {
+      public Event parsePartialFrom(
+          com.google.protobuf.CodedInputStream input,
+          com.google.protobuf.ExtensionRegistryLite extensionRegistry)
+          throws com.google.protobuf.InvalidProtocolBufferException {
+        return new Event(input, extensionRegistry);
+      }
+    };
+
+    public static com.google.protobuf.Parser<Event> parser() {
+      return PARSER;
+    }
+
+    @java.lang.Override
+    public com.google.protobuf.Parser<Event> getParserForType() {
+      return PARSER;
+    }
+
+    public org.opennms.features.kafka.producer.model.OpennmsModelProtos.Event getDefaultInstanceForType() {
+      return DEFAULT_INSTANCE;
+    }
+
+  }
+
+  public interface AlarmOrBuilder extends
+      // @@protoc_insertion_point(interface_extends:Alarm)
+      com.google.protobuf.MessageOrBuilder {
+
+    /**
+     * <code>uint64 id = 1;</code>
+     */
+    long getId();
+
+    /**
+     * <code>string uei = 2;</code>
+     */
+    java.lang.String getUei();
+    /**
+     * <code>string uei = 2;</code>
+     */
+    com.google.protobuf.ByteString
+        getUeiBytes();
+
+    /**
+     * <code>.NodeCriteria node_criteria = 3;</code>
+     */
+    boolean hasNodeCriteria();
+    /**
+     * <code>.NodeCriteria node_criteria = 3;</code>
+     */
+    org.opennms.features.kafka.producer.model.OpennmsModelProtos.NodeCriteria getNodeCriteria();
+    /**
+     * <code>.NodeCriteria node_criteria = 3;</code>
+     */
+    org.opennms.features.kafka.producer.model.OpennmsModelProtos.NodeCriteriaOrBuilder getNodeCriteriaOrBuilder();
+
+    /**
+     * <code>string ip_address = 4;</code>
+     */
+    java.lang.String getIpAddress();
+    /**
+     * <code>string ip_address = 4;</code>
+     */
+    com.google.protobuf.ByteString
+        getIpAddressBytes();
+
+    /**
+     * <code>string service_name = 5;</code>
+     */
+    java.lang.String getServiceName();
+    /**
+     * <code>string service_name = 5;</code>
+     */
+    com.google.protobuf.ByteString
+        getServiceNameBytes();
+
+    /**
+     * <code>string reduction_key = 6;</code>
+     */
+    java.lang.String getReductionKey();
+    /**
+     * <code>string reduction_key = 6;</code>
+     */
+    com.google.protobuf.ByteString
+        getReductionKeyBytes();
+
+    /**
+     * <code>.Alarm.Type type = 7;</code>
+     */
+    int getTypeValue();
+    /**
+     * <code>.Alarm.Type type = 7;</code>
+     */
+    org.opennms.features.kafka.producer.model.OpennmsModelProtos.Alarm.Type getType();
+
+    /**
+     * <code>uint64 count = 8;</code>
+     */
+    long getCount();
+
+    /**
+     * <code>.Severity severity = 9;</code>
+     */
+    int getSeverityValue();
+    /**
+     * <code>.Severity severity = 9;</code>
+     */
+    org.opennms.features.kafka.producer.model.OpennmsModelProtos.Severity getSeverity();
+
+    /**
+     * <code>uint64 first_event_time = 10;</code>
+     */
+    long getFirstEventTime();
+
+    /**
+     * <code>string description = 11;</code>
+     */
+    java.lang.String getDescription();
+    /**
+     * <code>string description = 11;</code>
+     */
+    com.google.protobuf.ByteString
+        getDescriptionBytes();
+
+    /**
+     * <code>string log_message = 12;</code>
+     */
+    java.lang.String getLogMessage();
+    /**
+     * <code>string log_message = 12;</code>
+     */
+    com.google.protobuf.ByteString
+        getLogMessageBytes();
+
+    /**
+     * <code>string ack_user = 13;</code>
+     */
+    java.lang.String getAckUser();
+    /**
+     * <code>string ack_user = 13;</code>
+     */
+    com.google.protobuf.ByteString
+        getAckUserBytes();
+
+    /**
+     * <code>uint64 ack_time = 14;</code>
+     */
+    long getAckTime();
+
+    /**
+     * <code>.Event last_event = 15;</code>
+     */
+    boolean hasLastEvent();
+    /**
+     * <code>.Event last_event = 15;</code>
+     */
+    org.opennms.features.kafka.producer.model.OpennmsModelProtos.Event getLastEvent();
+    /**
+     * <code>.Event last_event = 15;</code>
+     */
+    org.opennms.features.kafka.producer.model.OpennmsModelProtos.EventOrBuilder getLastEventOrBuilder();
+
+    /**
+     * <code>uint64 last_event_time = 16;</code>
+     */
+    long getLastEventTime();
+
+    /**
+     * <code>uint32 if_index = 17;</code>
+     */
+    int getIfIndex();
+
+    /**
+     * <code>string operator_instructions = 18;</code>
+     */
+    java.lang.String getOperatorInstructions();
+    /**
+     * <code>string operator_instructions = 18;</code>
+     */
+    com.google.protobuf.ByteString
+        getOperatorInstructionsBytes();
+
+    /**
+     * <code>string clear_key = 19;</code>
+     */
+    java.lang.String getClearKey();
+    /**
+     * <code>string clear_key = 19;</code>
+     */
+    com.google.protobuf.ByteString
+        getClearKeyBytes();
+  }
+  /**
+   * Protobuf type {@code Alarm}
+   */
+  public  static final class Alarm extends
+      com.google.protobuf.GeneratedMessageV3 implements
+      // @@protoc_insertion_point(message_implements:Alarm)
+      AlarmOrBuilder {
+  private static final long serialVersionUID = 0L;
+    // Use Alarm.newBuilder() to construct.
+    private Alarm(com.google.protobuf.GeneratedMessageV3.Builder<?> builder) {
+      super(builder);
+    }
+    private Alarm() {
+      id_ = 0L;
+      uei_ = "";
+      ipAddress_ = "";
+      serviceName_ = "";
+      reductionKey_ = "";
+      type_ = 0;
+      count_ = 0L;
+      severity_ = 0;
+      firstEventTime_ = 0L;
+      description_ = "";
+      logMessage_ = "";
+      ackUser_ = "";
+      ackTime_ = 0L;
+      lastEventTime_ = 0L;
+      ifIndex_ = 0;
+      operatorInstructions_ = "";
+      clearKey_ = "";
+    }
+
+    @java.lang.Override
+    public final com.google.protobuf.UnknownFieldSet
+    getUnknownFields() {
+      return this.unknownFields;
+    }
+    private Alarm(
+        com.google.protobuf.CodedInputStream input,
+        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
+        throws com.google.protobuf.InvalidProtocolBufferException {
+      this();
+      if (extensionRegistry == null) {
+        throw new java.lang.NullPointerException();
+      }
+      int mutable_bitField0_ = 0;
+      com.google.protobuf.UnknownFieldSet.Builder unknownFields =
+          com.google.protobuf.UnknownFieldSet.newBuilder();
+      try {
+        boolean done = false;
+        while (!done) {
+          int tag = input.readTag();
+          switch (tag) {
+            case 0:
+              done = true;
+              break;
+            default: {
+              if (!parseUnknownFieldProto3(
+                  input, unknownFields, extensionRegistry, tag)) {
+                done = true;
+              }
+              break;
+            }
+            case 8: {
+
+              id_ = input.readUInt64();
+              break;
+            }
+            case 18: {
+              java.lang.String s = input.readStringRequireUtf8();
+
+              uei_ = s;
+              break;
+            }
+            case 26: {
+              org.opennms.features.kafka.producer.model.OpennmsModelProtos.NodeCriteria.Builder subBuilder = null;
+              if (nodeCriteria_ != null) {
+                subBuilder = nodeCriteria_.toBuilder();
+              }
+              nodeCriteria_ = input.readMessage(org.opennms.features.kafka.producer.model.OpennmsModelProtos.NodeCriteria.parser(), extensionRegistry);
+              if (subBuilder != null) {
+                subBuilder.mergeFrom(nodeCriteria_);
+                nodeCriteria_ = subBuilder.buildPartial();
+              }
+
+              break;
+            }
+            case 34: {
+              java.lang.String s = input.readStringRequireUtf8();
+
+              ipAddress_ = s;
+              break;
+            }
+            case 42: {
+              java.lang.String s = input.readStringRequireUtf8();
+
+              serviceName_ = s;
+              break;
+            }
+            case 50: {
+              java.lang.String s = input.readStringRequireUtf8();
+
+              reductionKey_ = s;
+              break;
+            }
+            case 56: {
+              int rawValue = input.readEnum();
+
+              type_ = rawValue;
+              break;
+            }
+            case 64: {
+
+              count_ = input.readUInt64();
+              break;
+            }
+            case 72: {
+              int rawValue = input.readEnum();
+
+              severity_ = rawValue;
+              break;
+            }
+            case 80: {
+
+              firstEventTime_ = input.readUInt64();
+              break;
+            }
+            case 90: {
+              java.lang.String s = input.readStringRequireUtf8();
+
+              description_ = s;
+              break;
+            }
+            case 98: {
+              java.lang.String s = input.readStringRequireUtf8();
+
+              logMessage_ = s;
+              break;
+            }
+            case 106: {
+              java.lang.String s = input.readStringRequireUtf8();
+
+              ackUser_ = s;
+              break;
+            }
+            case 112: {
+
+              ackTime_ = input.readUInt64();
+              break;
+            }
+            case 122: {
+              org.opennms.features.kafka.producer.model.OpennmsModelProtos.Event.Builder subBuilder = null;
+              if (lastEvent_ != null) {
+                subBuilder = lastEvent_.toBuilder();
+              }
+              lastEvent_ = input.readMessage(org.opennms.features.kafka.producer.model.OpennmsModelProtos.Event.parser(), extensionRegistry);
+              if (subBuilder != null) {
+                subBuilder.mergeFrom(lastEvent_);
+                lastEvent_ = subBuilder.buildPartial();
+              }
+
+              break;
+            }
+            case 128: {
+
+              lastEventTime_ = input.readUInt64();
+              break;
+            }
+            case 136: {
+
+              ifIndex_ = input.readUInt32();
+              break;
+            }
+            case 146: {
+              java.lang.String s = input.readStringRequireUtf8();
+
+              operatorInstructions_ = s;
+              break;
+            }
+            case 154: {
+              java.lang.String s = input.readStringRequireUtf8();
+
+              clearKey_ = s;
+              break;
+            }
+          }
+        }
+      } catch (com.google.protobuf.InvalidProtocolBufferException e) {
+        throw e.setUnfinishedMessage(this);
+      } catch (java.io.IOException e) {
+        throw new com.google.protobuf.InvalidProtocolBufferException(
+            e).setUnfinishedMessage(this);
+      } finally {
+        this.unknownFields = unknownFields.build();
+        makeExtensionsImmutable();
+      }
+    }
+    public static final com.google.protobuf.Descriptors.Descriptor
+        getDescriptor() {
+      return org.opennms.features.kafka.producer.model.OpennmsModelProtos.internal_static_Alarm_descriptor;
+    }
+
+    protected com.google.protobuf.GeneratedMessageV3.FieldAccessorTable
+        internalGetFieldAccessorTable() {
+      return org.opennms.features.kafka.producer.model.OpennmsModelProtos.internal_static_Alarm_fieldAccessorTable
+          .ensureFieldAccessorsInitialized(
+              org.opennms.features.kafka.producer.model.OpennmsModelProtos.Alarm.class, org.opennms.features.kafka.producer.model.OpennmsModelProtos.Alarm.Builder.class);
+    }
+
+    /**
+     * Protobuf enum {@code Alarm.Type}
+     */
+    public enum Type
+        implements com.google.protobuf.ProtocolMessageEnum {
+      /**
+       * <code>PROBLEM_WITH_CLEAR = 0;</code>
+       */
+      PROBLEM_WITH_CLEAR(0),
+      /**
+       * <code>CLEAR = 1;</code>
+       */
+      CLEAR(1),
+      /**
+       * <code>PROBLEM_WITHOUT_CLEAR = 2;</code>
+       */
+      PROBLEM_WITHOUT_CLEAR(2),
+      UNRECOGNIZED(-1),
+      ;
+
+      /**
+       * <code>PROBLEM_WITH_CLEAR = 0;</code>
+       */
+      public static final int PROBLEM_WITH_CLEAR_VALUE = 0;
+      /**
+       * <code>CLEAR = 1;</code>
+       */
+      public static final int CLEAR_VALUE = 1;
+      /**
+       * <code>PROBLEM_WITHOUT_CLEAR = 2;</code>
+       */
+      public static final int PROBLEM_WITHOUT_CLEAR_VALUE = 2;
+
+
+      public final int getNumber() {
+        if (this == UNRECOGNIZED) {
+          throw new java.lang.IllegalArgumentException(
+              "Can't get the number of an unknown enum value.");
+        }
+        return value;
+      }
+
+      /**
+       * @deprecated Use {@link #forNumber(int)} instead.
+       */
+      @java.lang.Deprecated
+      public static Type valueOf(int value) {
+        return forNumber(value);
+      }
+
+      public static Type forNumber(int value) {
+        switch (value) {
+          case 0: return PROBLEM_WITH_CLEAR;
+          case 1: return CLEAR;
+          case 2: return PROBLEM_WITHOUT_CLEAR;
+          default: return null;
+        }
+      }
+
+      public static com.google.protobuf.Internal.EnumLiteMap<Type>
+          internalGetValueMap() {
+        return internalValueMap;
+      }
+      private static final com.google.protobuf.Internal.EnumLiteMap<
+          Type> internalValueMap =
+            new com.google.protobuf.Internal.EnumLiteMap<Type>() {
+              public Type findValueByNumber(int number) {
+                return Type.forNumber(number);
+              }
+            };
+
+      public final com.google.protobuf.Descriptors.EnumValueDescriptor
+          getValueDescriptor() {
+        return getDescriptor().getValues().get(ordinal());
+      }
+      public final com.google.protobuf.Descriptors.EnumDescriptor
+          getDescriptorForType() {
+        return getDescriptor();
+      }
+      public static final com.google.protobuf.Descriptors.EnumDescriptor
+          getDescriptor() {
+        return org.opennms.features.kafka.producer.model.OpennmsModelProtos.Alarm.getDescriptor().getEnumTypes().get(0);
+      }
+
+      private static final Type[] VALUES = values();
+
+      public static Type valueOf(
+          com.google.protobuf.Descriptors.EnumValueDescriptor desc) {
+        if (desc.getType() != getDescriptor()) {
+          throw new java.lang.IllegalArgumentException(
+            "EnumValueDescriptor is not for this type.");
+        }
+        if (desc.getIndex() == -1) {
+          return UNRECOGNIZED;
+        }
+        return VALUES[desc.getIndex()];
+      }
+
+      private final int value;
+
+      private Type(int value) {
+        this.value = value;
+      }
+
+      // @@protoc_insertion_point(enum_scope:Alarm.Type)
+    }
+
+    public static final int ID_FIELD_NUMBER = 1;
+    private long id_;
+    /**
+     * <code>uint64 id = 1;</code>
+     */
+    public long getId() {
+      return id_;
+    }
+
+    public static final int UEI_FIELD_NUMBER = 2;
+    private volatile java.lang.Object uei_;
+    /**
+     * <code>string uei = 2;</code>
+     */
+    public java.lang.String getUei() {
+      java.lang.Object ref = uei_;
+      if (ref instanceof java.lang.String) {
+        return (java.lang.String) ref;
+      } else {
+        com.google.protobuf.ByteString bs = 
+            (com.google.protobuf.ByteString) ref;
+        java.lang.String s = bs.toStringUtf8();
+        uei_ = s;
+        return s;
+      }
+    }
+    /**
+     * <code>string uei = 2;</code>
+     */
+    public com.google.protobuf.ByteString
+        getUeiBytes() {
+      java.lang.Object ref = uei_;
+      if (ref instanceof java.lang.String) {
+        com.google.protobuf.ByteString b = 
+            com.google.protobuf.ByteString.copyFromUtf8(
+                (java.lang.String) ref);
+        uei_ = b;
+        return b;
+      } else {
+        return (com.google.protobuf.ByteString) ref;
+      }
+    }
+
+    public static final int NODE_CRITERIA_FIELD_NUMBER = 3;
+    private org.opennms.features.kafka.producer.model.OpennmsModelProtos.NodeCriteria nodeCriteria_;
+    /**
+     * <code>.NodeCriteria node_criteria = 3;</code>
+     */
+    public boolean hasNodeCriteria() {
+      return nodeCriteria_ != null;
+    }
+    /**
+     * <code>.NodeCriteria node_criteria = 3;</code>
+     */
+    public org.opennms.features.kafka.producer.model.OpennmsModelProtos.NodeCriteria getNodeCriteria() {
+      return nodeCriteria_ == null ? org.opennms.features.kafka.producer.model.OpennmsModelProtos.NodeCriteria.getDefaultInstance() : nodeCriteria_;
+    }
+    /**
+     * <code>.NodeCriteria node_criteria = 3;</code>
+     */
+    public org.opennms.features.kafka.producer.model.OpennmsModelProtos.NodeCriteriaOrBuilder getNodeCriteriaOrBuilder() {
+      return getNodeCriteria();
+    }
+
+    public static final int IP_ADDRESS_FIELD_NUMBER = 4;
+    private volatile java.lang.Object ipAddress_;
+    /**
+     * <code>string ip_address = 4;</code>
+     */
+    public java.lang.String getIpAddress() {
+      java.lang.Object ref = ipAddress_;
+      if (ref instanceof java.lang.String) {
+        return (java.lang.String) ref;
+      } else {
+        com.google.protobuf.ByteString bs = 
+            (com.google.protobuf.ByteString) ref;
+        java.lang.String s = bs.toStringUtf8();
+        ipAddress_ = s;
+        return s;
+      }
+    }
+    /**
+     * <code>string ip_address = 4;</code>
+     */
+    public com.google.protobuf.ByteString
+        getIpAddressBytes() {
+      java.lang.Object ref = ipAddress_;
+      if (ref instanceof java.lang.String) {
+        com.google.protobuf.ByteString b = 
+            com.google.protobuf.ByteString.copyFromUtf8(
+                (java.lang.String) ref);
+        ipAddress_ = b;
+        return b;
+      } else {
+        return (com.google.protobuf.ByteString) ref;
+      }
+    }
+
+    public static final int SERVICE_NAME_FIELD_NUMBER = 5;
+    private volatile java.lang.Object serviceName_;
+    /**
+     * <code>string service_name = 5;</code>
+     */
+    public java.lang.String getServiceName() {
+      java.lang.Object ref = serviceName_;
+      if (ref instanceof java.lang.String) {
+        return (java.lang.String) ref;
+      } else {
+        com.google.protobuf.ByteString bs = 
+            (com.google.protobuf.ByteString) ref;
+        java.lang.String s = bs.toStringUtf8();
+        serviceName_ = s;
+        return s;
+      }
+    }
+    /**
+     * <code>string service_name = 5;</code>
+     */
+    public com.google.protobuf.ByteString
+        getServiceNameBytes() {
+      java.lang.Object ref = serviceName_;
+      if (ref instanceof java.lang.String) {
+        com.google.protobuf.ByteString b = 
+            com.google.protobuf.ByteString.copyFromUtf8(
+                (java.lang.String) ref);
+        serviceName_ = b;
+        return b;
+      } else {
+        return (com.google.protobuf.ByteString) ref;
+      }
+    }
+
+    public static final int REDUCTION_KEY_FIELD_NUMBER = 6;
+    private volatile java.lang.Object reductionKey_;
+    /**
+     * <code>string reduction_key = 6;</code>
+     */
+    public java.lang.String getReductionKey() {
+      java.lang.Object ref = reductionKey_;
+      if (ref instanceof java.lang.String) {
+        return (java.lang.String) ref;
+      } else {
+        com.google.protobuf.ByteString bs = 
+            (com.google.protobuf.ByteString) ref;
+        java.lang.String s = bs.toStringUtf8();
+        reductionKey_ = s;
+        return s;
+      }
+    }
+    /**
+     * <code>string reduction_key = 6;</code>
+     */
+    public com.google.protobuf.ByteString
+        getReductionKeyBytes() {
+      java.lang.Object ref = reductionKey_;
+      if (ref instanceof java.lang.String) {
+        com.google.protobuf.ByteString b = 
+            com.google.protobuf.ByteString.copyFromUtf8(
+                (java.lang.String) ref);
+        reductionKey_ = b;
+        return b;
+      } else {
+        return (com.google.protobuf.ByteString) ref;
+      }
+    }
+
+    public static final int TYPE_FIELD_NUMBER = 7;
+    private int type_;
+    /**
+     * <code>.Alarm.Type type = 7;</code>
+     */
+    public int getTypeValue() {
+      return type_;
+    }
+    /**
+     * <code>.Alarm.Type type = 7;</code>
+     */
+    public org.opennms.features.kafka.producer.model.OpennmsModelProtos.Alarm.Type getType() {
+      org.opennms.features.kafka.producer.model.OpennmsModelProtos.Alarm.Type result = org.opennms.features.kafka.producer.model.OpennmsModelProtos.Alarm.Type.valueOf(type_);
+      return result == null ? org.opennms.features.kafka.producer.model.OpennmsModelProtos.Alarm.Type.UNRECOGNIZED : result;
+    }
+
+    public static final int COUNT_FIELD_NUMBER = 8;
+    private long count_;
+    /**
+     * <code>uint64 count = 8;</code>
+     */
+    public long getCount() {
+      return count_;
+    }
+
+    public static final int SEVERITY_FIELD_NUMBER = 9;
+    private int severity_;
+    /**
+     * <code>.Severity severity = 9;</code>
+     */
+    public int getSeverityValue() {
+      return severity_;
+    }
+    /**
+     * <code>.Severity severity = 9;</code>
+     */
+    public org.opennms.features.kafka.producer.model.OpennmsModelProtos.Severity getSeverity() {
+      org.opennms.features.kafka.producer.model.OpennmsModelProtos.Severity result = org.opennms.features.kafka.producer.model.OpennmsModelProtos.Severity.valueOf(severity_);
+      return result == null ? org.opennms.features.kafka.producer.model.OpennmsModelProtos.Severity.UNRECOGNIZED : result;
+    }
+
+    public static final int FIRST_EVENT_TIME_FIELD_NUMBER = 10;
+    private long firstEventTime_;
+    /**
+     * <code>uint64 first_event_time = 10;</code>
+     */
+    public long getFirstEventTime() {
+      return firstEventTime_;
+    }
+
+    public static final int DESCRIPTION_FIELD_NUMBER = 11;
+    private volatile java.lang.Object description_;
+    /**
+     * <code>string description = 11;</code>
+     */
+    public java.lang.String getDescription() {
+      java.lang.Object ref = description_;
+      if (ref instanceof java.lang.String) {
+        return (java.lang.String) ref;
+      } else {
+        com.google.protobuf.ByteString bs = 
+            (com.google.protobuf.ByteString) ref;
+        java.lang.String s = bs.toStringUtf8();
+        description_ = s;
+        return s;
+      }
+    }
+    /**
+     * <code>string description = 11;</code>
+     */
+    public com.google.protobuf.ByteString
+        getDescriptionBytes() {
+      java.lang.Object ref = description_;
+      if (ref instanceof java.lang.String) {
+        com.google.protobuf.ByteString b = 
+            com.google.protobuf.ByteString.copyFromUtf8(
+                (java.lang.String) ref);
+        description_ = b;
+        return b;
+      } else {
+        return (com.google.protobuf.ByteString) ref;
+      }
+    }
+
+    public static final int LOG_MESSAGE_FIELD_NUMBER = 12;
+    private volatile java.lang.Object logMessage_;
+    /**
+     * <code>string log_message = 12;</code>
+     */
+    public java.lang.String getLogMessage() {
+      java.lang.Object ref = logMessage_;
+      if (ref instanceof java.lang.String) {
+        return (java.lang.String) ref;
+      } else {
+        com.google.protobuf.ByteString bs = 
+            (com.google.protobuf.ByteString) ref;
+        java.lang.String s = bs.toStringUtf8();
+        logMessage_ = s;
+        return s;
+      }
+    }
+    /**
+     * <code>string log_message = 12;</code>
+     */
+    public com.google.protobuf.ByteString
+        getLogMessageBytes() {
+      java.lang.Object ref = logMessage_;
+      if (ref instanceof java.lang.String) {
+        com.google.protobuf.ByteString b = 
+            com.google.protobuf.ByteString.copyFromUtf8(
+                (java.lang.String) ref);
+        logMessage_ = b;
+        return b;
+      } else {
+        return (com.google.protobuf.ByteString) ref;
+      }
+    }
+
+    public static final int ACK_USER_FIELD_NUMBER = 13;
+    private volatile java.lang.Object ackUser_;
+    /**
+     * <code>string ack_user = 13;</code>
+     */
+    public java.lang.String getAckUser() {
+      java.lang.Object ref = ackUser_;
+      if (ref instanceof java.lang.String) {
+        return (java.lang.String) ref;
+      } else {
+        com.google.protobuf.ByteString bs = 
+            (com.google.protobuf.ByteString) ref;
+        java.lang.String s = bs.toStringUtf8();
+        ackUser_ = s;
+        return s;
+      }
+    }
+    /**
+     * <code>string ack_user = 13;</code>
+     */
+    public com.google.protobuf.ByteString
+        getAckUserBytes() {
+      java.lang.Object ref = ackUser_;
+      if (ref instanceof java.lang.String) {
+        com.google.protobuf.ByteString b = 
+            com.google.protobuf.ByteString.copyFromUtf8(
+                (java.lang.String) ref);
+        ackUser_ = b;
+        return b;
+      } else {
+        return (com.google.protobuf.ByteString) ref;
+      }
+    }
+
+    public static final int ACK_TIME_FIELD_NUMBER = 14;
+    private long ackTime_;
+    /**
+     * <code>uint64 ack_time = 14;</code>
+     */
+    public long getAckTime() {
+      return ackTime_;
+    }
+
+    public static final int LAST_EVENT_FIELD_NUMBER = 15;
+    private org.opennms.features.kafka.producer.model.OpennmsModelProtos.Event lastEvent_;
+    /**
+     * <code>.Event last_event = 15;</code>
+     */
+    public boolean hasLastEvent() {
+      return lastEvent_ != null;
+    }
+    /**
+     * <code>.Event last_event = 15;</code>
+     */
+    public org.opennms.features.kafka.producer.model.OpennmsModelProtos.Event getLastEvent() {
+      return lastEvent_ == null ? org.opennms.features.kafka.producer.model.OpennmsModelProtos.Event.getDefaultInstance() : lastEvent_;
+    }
+    /**
+     * <code>.Event last_event = 15;</code>
+     */
+    public org.opennms.features.kafka.producer.model.OpennmsModelProtos.EventOrBuilder getLastEventOrBuilder() {
+      return getLastEvent();
+    }
+
+    public static final int LAST_EVENT_TIME_FIELD_NUMBER = 16;
+    private long lastEventTime_;
+    /**
+     * <code>uint64 last_event_time = 16;</code>
+     */
+    public long getLastEventTime() {
+      return lastEventTime_;
+    }
+
+    public static final int IF_INDEX_FIELD_NUMBER = 17;
+    private int ifIndex_;
+    /**
+     * <code>uint32 if_index = 17;</code>
+     */
+    public int getIfIndex() {
+      return ifIndex_;
+    }
+
+    public static final int OPERATOR_INSTRUCTIONS_FIELD_NUMBER = 18;
+    private volatile java.lang.Object operatorInstructions_;
+    /**
+     * <code>string operator_instructions = 18;</code>
+     */
+    public java.lang.String getOperatorInstructions() {
+      java.lang.Object ref = operatorInstructions_;
+      if (ref instanceof java.lang.String) {
+        return (java.lang.String) ref;
+      } else {
+        com.google.protobuf.ByteString bs = 
+            (com.google.protobuf.ByteString) ref;
+        java.lang.String s = bs.toStringUtf8();
+        operatorInstructions_ = s;
+        return s;
+      }
+    }
+    /**
+     * <code>string operator_instructions = 18;</code>
+     */
+    public com.google.protobuf.ByteString
+        getOperatorInstructionsBytes() {
+      java.lang.Object ref = operatorInstructions_;
+      if (ref instanceof java.lang.String) {
+        com.google.protobuf.ByteString b = 
+            com.google.protobuf.ByteString.copyFromUtf8(
+                (java.lang.String) ref);
+        operatorInstructions_ = b;
+        return b;
+      } else {
+        return (com.google.protobuf.ByteString) ref;
+      }
+    }
+
+    public static final int CLEAR_KEY_FIELD_NUMBER = 19;
+    private volatile java.lang.Object clearKey_;
+    /**
+     * <code>string clear_key = 19;</code>
+     */
+    public java.lang.String getClearKey() {
+      java.lang.Object ref = clearKey_;
+      if (ref instanceof java.lang.String) {
+        return (java.lang.String) ref;
+      } else {
+        com.google.protobuf.ByteString bs = 
+            (com.google.protobuf.ByteString) ref;
+        java.lang.String s = bs.toStringUtf8();
+        clearKey_ = s;
+        return s;
+      }
+    }
+    /**
+     * <code>string clear_key = 19;</code>
+     */
+    public com.google.protobuf.ByteString
+        getClearKeyBytes() {
+      java.lang.Object ref = clearKey_;
+      if (ref instanceof java.lang.String) {
+        com.google.protobuf.ByteString b = 
+            com.google.protobuf.ByteString.copyFromUtf8(
+                (java.lang.String) ref);
+        clearKey_ = b;
+        return b;
+      } else {
+        return (com.google.protobuf.ByteString) ref;
+      }
+    }
+
+    private byte memoizedIsInitialized = -1;
+    public final boolean isInitialized() {
+      byte isInitialized = memoizedIsInitialized;
+      if (isInitialized == 1) return true;
+      if (isInitialized == 0) return false;
+
+      memoizedIsInitialized = 1;
+      return true;
+    }
+
+    public void writeTo(com.google.protobuf.CodedOutputStream output)
+                        throws java.io.IOException {
+      if (id_ != 0L) {
+        output.writeUInt64(1, id_);
+      }
+      if (!getUeiBytes().isEmpty()) {
+        com.google.protobuf.GeneratedMessageV3.writeString(output, 2, uei_);
+      }
+      if (nodeCriteria_ != null) {
+        output.writeMessage(3, getNodeCriteria());
+      }
+      if (!getIpAddressBytes().isEmpty()) {
+        com.google.protobuf.GeneratedMessageV3.writeString(output, 4, ipAddress_);
+      }
+      if (!getServiceNameBytes().isEmpty()) {
+        com.google.protobuf.GeneratedMessageV3.writeString(output, 5, serviceName_);
+      }
+      if (!getReductionKeyBytes().isEmpty()) {
+        com.google.protobuf.GeneratedMessageV3.writeString(output, 6, reductionKey_);
+      }
+      if (type_ != org.opennms.features.kafka.producer.model.OpennmsModelProtos.Alarm.Type.PROBLEM_WITH_CLEAR.getNumber()) {
+        output.writeEnum(7, type_);
+      }
+      if (count_ != 0L) {
+        output.writeUInt64(8, count_);
+      }
+      if (severity_ != org.opennms.features.kafka.producer.model.OpennmsModelProtos.Severity.INDETERMINATE.getNumber()) {
+        output.writeEnum(9, severity_);
+      }
+      if (firstEventTime_ != 0L) {
+        output.writeUInt64(10, firstEventTime_);
+      }
+      if (!getDescriptionBytes().isEmpty()) {
+        com.google.protobuf.GeneratedMessageV3.writeString(output, 11, description_);
+      }
+      if (!getLogMessageBytes().isEmpty()) {
+        com.google.protobuf.GeneratedMessageV3.writeString(output, 12, logMessage_);
+      }
+      if (!getAckUserBytes().isEmpty()) {
+        com.google.protobuf.GeneratedMessageV3.writeString(output, 13, ackUser_);
+      }
+      if (ackTime_ != 0L) {
+        output.writeUInt64(14, ackTime_);
+      }
+      if (lastEvent_ != null) {
+        output.writeMessage(15, getLastEvent());
+      }
+      if (lastEventTime_ != 0L) {
+        output.writeUInt64(16, lastEventTime_);
+      }
+      if (ifIndex_ != 0) {
+        output.writeUInt32(17, ifIndex_);
+      }
+      if (!getOperatorInstructionsBytes().isEmpty()) {
+        com.google.protobuf.GeneratedMessageV3.writeString(output, 18, operatorInstructions_);
+      }
+      if (!getClearKeyBytes().isEmpty()) {
+        com.google.protobuf.GeneratedMessageV3.writeString(output, 19, clearKey_);
+      }
+      unknownFields.writeTo(output);
+    }
+
+    public int getSerializedSize() {
+      int size = memoizedSize;
+      if (size != -1) return size;
+
+      size = 0;
+      if (id_ != 0L) {
+        size += com.google.protobuf.CodedOutputStream
+          .computeUInt64Size(1, id_);
+      }
+      if (!getUeiBytes().isEmpty()) {
+        size += com.google.protobuf.GeneratedMessageV3.computeStringSize(2, uei_);
+      }
+      if (nodeCriteria_ != null) {
+        size += com.google.protobuf.CodedOutputStream
+          .computeMessageSize(3, getNodeCriteria());
+      }
+      if (!getIpAddressBytes().isEmpty()) {
+        size += com.google.protobuf.GeneratedMessageV3.computeStringSize(4, ipAddress_);
+      }
+      if (!getServiceNameBytes().isEmpty()) {
+        size += com.google.protobuf.GeneratedMessageV3.computeStringSize(5, serviceName_);
+      }
+      if (!getReductionKeyBytes().isEmpty()) {
+        size += com.google.protobuf.GeneratedMessageV3.computeStringSize(6, reductionKey_);
+      }
+      if (type_ != org.opennms.features.kafka.producer.model.OpennmsModelProtos.Alarm.Type.PROBLEM_WITH_CLEAR.getNumber()) {
+        size += com.google.protobuf.CodedOutputStream
+          .computeEnumSize(7, type_);
+      }
+      if (count_ != 0L) {
+        size += com.google.protobuf.CodedOutputStream
+          .computeUInt64Size(8, count_);
+      }
+      if (severity_ != org.opennms.features.kafka.producer.model.OpennmsModelProtos.Severity.INDETERMINATE.getNumber()) {
+        size += com.google.protobuf.CodedOutputStream
+          .computeEnumSize(9, severity_);
+      }
+      if (firstEventTime_ != 0L) {
+        size += com.google.protobuf.CodedOutputStream
+          .computeUInt64Size(10, firstEventTime_);
+      }
+      if (!getDescriptionBytes().isEmpty()) {
+        size += com.google.protobuf.GeneratedMessageV3.computeStringSize(11, description_);
+      }
+      if (!getLogMessageBytes().isEmpty()) {
+        size += com.google.protobuf.GeneratedMessageV3.computeStringSize(12, logMessage_);
+      }
+      if (!getAckUserBytes().isEmpty()) {
+        size += com.google.protobuf.GeneratedMessageV3.computeStringSize(13, ackUser_);
+      }
+      if (ackTime_ != 0L) {
+        size += com.google.protobuf.CodedOutputStream
+          .computeUInt64Size(14, ackTime_);
+      }
+      if (lastEvent_ != null) {
+        size += com.google.protobuf.CodedOutputStream
+          .computeMessageSize(15, getLastEvent());
+      }
+      if (lastEventTime_ != 0L) {
+        size += com.google.protobuf.CodedOutputStream
+          .computeUInt64Size(16, lastEventTime_);
+      }
+      if (ifIndex_ != 0) {
+        size += com.google.protobuf.CodedOutputStream
+          .computeUInt32Size(17, ifIndex_);
+      }
+      if (!getOperatorInstructionsBytes().isEmpty()) {
+        size += com.google.protobuf.GeneratedMessageV3.computeStringSize(18, operatorInstructions_);
+      }
+      if (!getClearKeyBytes().isEmpty()) {
+        size += com.google.protobuf.GeneratedMessageV3.computeStringSize(19, clearKey_);
+      }
+      size += unknownFields.getSerializedSize();
+      memoizedSize = size;
+      return size;
+    }
+
+    @java.lang.Override
+    public boolean equals(final java.lang.Object obj) {
+      if (obj == this) {
+       return true;
+      }
+      if (!(obj instanceof org.opennms.features.kafka.producer.model.OpennmsModelProtos.Alarm)) {
+        return super.equals(obj);
+      }
+      org.opennms.features.kafka.producer.model.OpennmsModelProtos.Alarm other = (org.opennms.features.kafka.producer.model.OpennmsModelProtos.Alarm) obj;
+
+      boolean result = true;
+      result = result && (getId()
+          == other.getId());
+      result = result && getUei()
+          .equals(other.getUei());
+      result = result && (hasNodeCriteria() == other.hasNodeCriteria());
+      if (hasNodeCriteria()) {
+        result = result && getNodeCriteria()
+            .equals(other.getNodeCriteria());
+      }
+      result = result && getIpAddress()
+          .equals(other.getIpAddress());
+      result = result && getServiceName()
+          .equals(other.getServiceName());
+      result = result && getReductionKey()
+          .equals(other.getReductionKey());
+      result = result && type_ == other.type_;
+      result = result && (getCount()
+          == other.getCount());
+      result = result && severity_ == other.severity_;
+      result = result && (getFirstEventTime()
+          == other.getFirstEventTime());
+      result = result && getDescription()
+          .equals(other.getDescription());
+      result = result && getLogMessage()
+          .equals(other.getLogMessage());
+      result = result && getAckUser()
+          .equals(other.getAckUser());
+      result = result && (getAckTime()
+          == other.getAckTime());
+      result = result && (hasLastEvent() == other.hasLastEvent());
+      if (hasLastEvent()) {
+        result = result && getLastEvent()
+            .equals(other.getLastEvent());
+      }
+      result = result && (getLastEventTime()
+          == other.getLastEventTime());
+      result = result && (getIfIndex()
+          == other.getIfIndex());
+      result = result && getOperatorInstructions()
+          .equals(other.getOperatorInstructions());
+      result = result && getClearKey()
+          .equals(other.getClearKey());
+      result = result && unknownFields.equals(other.unknownFields);
+      return result;
+    }
+
+    @java.lang.Override
+    public int hashCode() {
+      if (memoizedHashCode != 0) {
+        return memoizedHashCode;
+      }
+      int hash = 41;
+      hash = (19 * hash) + getDescriptor().hashCode();
+      hash = (37 * hash) + ID_FIELD_NUMBER;
+      hash = (53 * hash) + com.google.protobuf.Internal.hashLong(
+          getId());
+      hash = (37 * hash) + UEI_FIELD_NUMBER;
+      hash = (53 * hash) + getUei().hashCode();
+      if (hasNodeCriteria()) {
+        hash = (37 * hash) + NODE_CRITERIA_FIELD_NUMBER;
+        hash = (53 * hash) + getNodeCriteria().hashCode();
+      }
+      hash = (37 * hash) + IP_ADDRESS_FIELD_NUMBER;
+      hash = (53 * hash) + getIpAddress().hashCode();
+      hash = (37 * hash) + SERVICE_NAME_FIELD_NUMBER;
+      hash = (53 * hash) + getServiceName().hashCode();
+      hash = (37 * hash) + REDUCTION_KEY_FIELD_NUMBER;
+      hash = (53 * hash) + getReductionKey().hashCode();
+      hash = (37 * hash) + TYPE_FIELD_NUMBER;
+      hash = (53 * hash) + type_;
+      hash = (37 * hash) + COUNT_FIELD_NUMBER;
+      hash = (53 * hash) + com.google.protobuf.Internal.hashLong(
+          getCount());
+      hash = (37 * hash) + SEVERITY_FIELD_NUMBER;
+      hash = (53 * hash) + severity_;
+      hash = (37 * hash) + FIRST_EVENT_TIME_FIELD_NUMBER;
+      hash = (53 * hash) + com.google.protobuf.Internal.hashLong(
+          getFirstEventTime());
+      hash = (37 * hash) + DESCRIPTION_FIELD_NUMBER;
+      hash = (53 * hash) + getDescription().hashCode();
+      hash = (37 * hash) + LOG_MESSAGE_FIELD_NUMBER;
+      hash = (53 * hash) + getLogMessage().hashCode();
+      hash = (37 * hash) + ACK_USER_FIELD_NUMBER;
+      hash = (53 * hash) + getAckUser().hashCode();
+      hash = (37 * hash) + ACK_TIME_FIELD_NUMBER;
+      hash = (53 * hash) + com.google.protobuf.Internal.hashLong(
+          getAckTime());
+      if (hasLastEvent()) {
+        hash = (37 * hash) + LAST_EVENT_FIELD_NUMBER;
+        hash = (53 * hash) + getLastEvent().hashCode();
+      }
+      hash = (37 * hash) + LAST_EVENT_TIME_FIELD_NUMBER;
+      hash = (53 * hash) + com.google.protobuf.Internal.hashLong(
+          getLastEventTime());
+      hash = (37 * hash) + IF_INDEX_FIELD_NUMBER;
+      hash = (53 * hash) + getIfIndex();
+      hash = (37 * hash) + OPERATOR_INSTRUCTIONS_FIELD_NUMBER;
+      hash = (53 * hash) + getOperatorInstructions().hashCode();
+      hash = (37 * hash) + CLEAR_KEY_FIELD_NUMBER;
+      hash = (53 * hash) + getClearKey().hashCode();
+      hash = (29 * hash) + unknownFields.hashCode();
+      memoizedHashCode = hash;
+      return hash;
+    }
+
+    public static org.opennms.features.kafka.producer.model.OpennmsModelProtos.Alarm parseFrom(
+        java.nio.ByteBuffer data)
+        throws com.google.protobuf.InvalidProtocolBufferException {
+      return PARSER.parseFrom(data);
+    }
+    public static org.opennms.features.kafka.producer.model.OpennmsModelProtos.Alarm parseFrom(
+        java.nio.ByteBuffer data,
+        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
+        throws com.google.protobuf.InvalidProtocolBufferException {
+      return PARSER.parseFrom(data, extensionRegistry);
+    }
+    public static org.opennms.features.kafka.producer.model.OpennmsModelProtos.Alarm parseFrom(
+        com.google.protobuf.ByteString data)
+        throws com.google.protobuf.InvalidProtocolBufferException {
+      return PARSER.parseFrom(data);
+    }
+    public static org.opennms.features.kafka.producer.model.OpennmsModelProtos.Alarm parseFrom(
+        com.google.protobuf.ByteString data,
+        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
+        throws com.google.protobuf.InvalidProtocolBufferException {
+      return PARSER.parseFrom(data, extensionRegistry);
+    }
+    public static org.opennms.features.kafka.producer.model.OpennmsModelProtos.Alarm parseFrom(byte[] data)
+        throws com.google.protobuf.InvalidProtocolBufferException {
+      return PARSER.parseFrom(data);
+    }
+    public static org.opennms.features.kafka.producer.model.OpennmsModelProtos.Alarm parseFrom(
+        byte[] data,
+        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
+        throws com.google.protobuf.InvalidProtocolBufferException {
+      return PARSER.parseFrom(data, extensionRegistry);
+    }
+    public static org.opennms.features.kafka.producer.model.OpennmsModelProtos.Alarm parseFrom(java.io.InputStream input)
+        throws java.io.IOException {
+      return com.google.protobuf.GeneratedMessageV3
+          .parseWithIOException(PARSER, input);
+    }
+    public static org.opennms.features.kafka.producer.model.OpennmsModelProtos.Alarm parseFrom(
+        java.io.InputStream input,
+        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
+        throws java.io.IOException {
+      return com.google.protobuf.GeneratedMessageV3
+          .parseWithIOException(PARSER, input, extensionRegistry);
+    }
+    public static org.opennms.features.kafka.producer.model.OpennmsModelProtos.Alarm parseDelimitedFrom(java.io.InputStream input)
+        throws java.io.IOException {
+      return com.google.protobuf.GeneratedMessageV3
+          .parseDelimitedWithIOException(PARSER, input);
+    }
+    public static org.opennms.features.kafka.producer.model.OpennmsModelProtos.Alarm parseDelimitedFrom(
+        java.io.InputStream input,
+        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
+        throws java.io.IOException {
+      return com.google.protobuf.GeneratedMessageV3
+          .parseDelimitedWithIOException(PARSER, input, extensionRegistry);
+    }
+    public static org.opennms.features.kafka.producer.model.OpennmsModelProtos.Alarm parseFrom(
+        com.google.protobuf.CodedInputStream input)
+        throws java.io.IOException {
+      return com.google.protobuf.GeneratedMessageV3
+          .parseWithIOException(PARSER, input);
+    }
+    public static org.opennms.features.kafka.producer.model.OpennmsModelProtos.Alarm parseFrom(
+        com.google.protobuf.CodedInputStream input,
+        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
+        throws java.io.IOException {
+      return com.google.protobuf.GeneratedMessageV3
+          .parseWithIOException(PARSER, input, extensionRegistry);
+    }
+
+    public Builder newBuilderForType() { return newBuilder(); }
+    public static Builder newBuilder() {
+      return DEFAULT_INSTANCE.toBuilder();
+    }
+    public static Builder newBuilder(org.opennms.features.kafka.producer.model.OpennmsModelProtos.Alarm prototype) {
+      return DEFAULT_INSTANCE.toBuilder().mergeFrom(prototype);
+    }
+    public Builder toBuilder() {
+      return this == DEFAULT_INSTANCE
+          ? new Builder() : new Builder().mergeFrom(this);
+    }
+
+    @java.lang.Override
+    protected Builder newBuilderForType(
+        com.google.protobuf.GeneratedMessageV3.BuilderParent parent) {
+      Builder builder = new Builder(parent);
+      return builder;
+    }
+    /**
+     * Protobuf type {@code Alarm}
+     */
+    public static final class Builder extends
+        com.google.protobuf.GeneratedMessageV3.Builder<Builder> implements
+        // @@protoc_insertion_point(builder_implements:Alarm)
+        org.opennms.features.kafka.producer.model.OpennmsModelProtos.AlarmOrBuilder {
+      public static final com.google.protobuf.Descriptors.Descriptor
+          getDescriptor() {
+        return org.opennms.features.kafka.producer.model.OpennmsModelProtos.internal_static_Alarm_descriptor;
+      }
+
+      protected com.google.protobuf.GeneratedMessageV3.FieldAccessorTable
+          internalGetFieldAccessorTable() {
+        return org.opennms.features.kafka.producer.model.OpennmsModelProtos.internal_static_Alarm_fieldAccessorTable
+            .ensureFieldAccessorsInitialized(
+                org.opennms.features.kafka.producer.model.OpennmsModelProtos.Alarm.class, org.opennms.features.kafka.producer.model.OpennmsModelProtos.Alarm.Builder.class);
+      }
+
+      // Construct using org.opennms.features.kafka.producer.model.OpennmsModelProtos.Alarm.newBuilder()
+      private Builder() {
+        maybeForceBuilderInitialization();
+      }
+
+      private Builder(
+          com.google.protobuf.GeneratedMessageV3.BuilderParent parent) {
+        super(parent);
+        maybeForceBuilderInitialization();
+      }
+      private void maybeForceBuilderInitialization() {
+        if (com.google.protobuf.GeneratedMessageV3
+                .alwaysUseFieldBuilders) {
+        }
+      }
+      public Builder clear() {
+        super.clear();
+        id_ = 0L;
+
+        uei_ = "";
+
+        if (nodeCriteriaBuilder_ == null) {
+          nodeCriteria_ = null;
+        } else {
+          nodeCriteria_ = null;
+          nodeCriteriaBuilder_ = null;
+        }
+        ipAddress_ = "";
+
+        serviceName_ = "";
+
+        reductionKey_ = "";
+
+        type_ = 0;
+
+        count_ = 0L;
+
+        severity_ = 0;
+
+        firstEventTime_ = 0L;
+
+        description_ = "";
+
+        logMessage_ = "";
+
+        ackUser_ = "";
+
+        ackTime_ = 0L;
+
+        if (lastEventBuilder_ == null) {
+          lastEvent_ = null;
+        } else {
+          lastEvent_ = null;
+          lastEventBuilder_ = null;
+        }
+        lastEventTime_ = 0L;
+
+        ifIndex_ = 0;
+
+        operatorInstructions_ = "";
+
+        clearKey_ = "";
+
+        return this;
+      }
+
+      public com.google.protobuf.Descriptors.Descriptor
+          getDescriptorForType() {
+        return org.opennms.features.kafka.producer.model.OpennmsModelProtos.internal_static_Alarm_descriptor;
+      }
+
+      public org.opennms.features.kafka.producer.model.OpennmsModelProtos.Alarm getDefaultInstanceForType() {
+        return org.opennms.features.kafka.producer.model.OpennmsModelProtos.Alarm.getDefaultInstance();
+      }
+
+      public org.opennms.features.kafka.producer.model.OpennmsModelProtos.Alarm build() {
+        org.opennms.features.kafka.producer.model.OpennmsModelProtos.Alarm result = buildPartial();
+        if (!result.isInitialized()) {
+          throw newUninitializedMessageException(result);
+        }
+        return result;
+      }
+
+      public org.opennms.features.kafka.producer.model.OpennmsModelProtos.Alarm buildPartial() {
+        org.opennms.features.kafka.producer.model.OpennmsModelProtos.Alarm result = new org.opennms.features.kafka.producer.model.OpennmsModelProtos.Alarm(this);
+        result.id_ = id_;
+        result.uei_ = uei_;
+        if (nodeCriteriaBuilder_ == null) {
+          result.nodeCriteria_ = nodeCriteria_;
+        } else {
+          result.nodeCriteria_ = nodeCriteriaBuilder_.build();
+        }
+        result.ipAddress_ = ipAddress_;
+        result.serviceName_ = serviceName_;
+        result.reductionKey_ = reductionKey_;
+        result.type_ = type_;
+        result.count_ = count_;
+        result.severity_ = severity_;
+        result.firstEventTime_ = firstEventTime_;
+        result.description_ = description_;
+        result.logMessage_ = logMessage_;
+        result.ackUser_ = ackUser_;
+        result.ackTime_ = ackTime_;
+        if (lastEventBuilder_ == null) {
+          result.lastEvent_ = lastEvent_;
+        } else {
+          result.lastEvent_ = lastEventBuilder_.build();
+        }
+        result.lastEventTime_ = lastEventTime_;
+        result.ifIndex_ = ifIndex_;
+        result.operatorInstructions_ = operatorInstructions_;
+        result.clearKey_ = clearKey_;
+        onBuilt();
+        return result;
+      }
+
+      public Builder clone() {
+        return (Builder) super.clone();
+      }
+      public Builder setField(
+          com.google.protobuf.Descriptors.FieldDescriptor field,
+          java.lang.Object value) {
+        return (Builder) super.setField(field, value);
+      }
+      public Builder clearField(
+          com.google.protobuf.Descriptors.FieldDescriptor field) {
+        return (Builder) super.clearField(field);
+      }
+      public Builder clearOneof(
+          com.google.protobuf.Descriptors.OneofDescriptor oneof) {
+        return (Builder) super.clearOneof(oneof);
+      }
+      public Builder setRepeatedField(
+          com.google.protobuf.Descriptors.FieldDescriptor field,
+          int index, java.lang.Object value) {
+        return (Builder) super.setRepeatedField(field, index, value);
+      }
+      public Builder addRepeatedField(
+          com.google.protobuf.Descriptors.FieldDescriptor field,
+          java.lang.Object value) {
+        return (Builder) super.addRepeatedField(field, value);
+      }
+      public Builder mergeFrom(com.google.protobuf.Message other) {
+        if (other instanceof org.opennms.features.kafka.producer.model.OpennmsModelProtos.Alarm) {
+          return mergeFrom((org.opennms.features.kafka.producer.model.OpennmsModelProtos.Alarm)other);
+        } else {
+          super.mergeFrom(other);
+          return this;
+        }
+      }
+
+      public Builder mergeFrom(org.opennms.features.kafka.producer.model.OpennmsModelProtos.Alarm other) {
+        if (other == org.opennms.features.kafka.producer.model.OpennmsModelProtos.Alarm.getDefaultInstance()) return this;
+        if (other.getId() != 0L) {
+          setId(other.getId());
+        }
+        if (!other.getUei().isEmpty()) {
+          uei_ = other.uei_;
+          onChanged();
+        }
+        if (other.hasNodeCriteria()) {
+          mergeNodeCriteria(other.getNodeCriteria());
+        }
+        if (!other.getIpAddress().isEmpty()) {
+          ipAddress_ = other.ipAddress_;
+          onChanged();
+        }
+        if (!other.getServiceName().isEmpty()) {
+          serviceName_ = other.serviceName_;
+          onChanged();
+        }
+        if (!other.getReductionKey().isEmpty()) {
+          reductionKey_ = other.reductionKey_;
+          onChanged();
+        }
+        if (other.type_ != 0) {
+          setTypeValue(other.getTypeValue());
+        }
+        if (other.getCount() != 0L) {
+          setCount(other.getCount());
+        }
+        if (other.severity_ != 0) {
+          setSeverityValue(other.getSeverityValue());
+        }
+        if (other.getFirstEventTime() != 0L) {
+          setFirstEventTime(other.getFirstEventTime());
+        }
+        if (!other.getDescription().isEmpty()) {
+          description_ = other.description_;
+          onChanged();
+        }
+        if (!other.getLogMessage().isEmpty()) {
+          logMessage_ = other.logMessage_;
+          onChanged();
+        }
+        if (!other.getAckUser().isEmpty()) {
+          ackUser_ = other.ackUser_;
+          onChanged();
+        }
+        if (other.getAckTime() != 0L) {
+          setAckTime(other.getAckTime());
+        }
+        if (other.hasLastEvent()) {
+          mergeLastEvent(other.getLastEvent());
+        }
+        if (other.getLastEventTime() != 0L) {
+          setLastEventTime(other.getLastEventTime());
+        }
+        if (other.getIfIndex() != 0) {
+          setIfIndex(other.getIfIndex());
+        }
+        if (!other.getOperatorInstructions().isEmpty()) {
+          operatorInstructions_ = other.operatorInstructions_;
+          onChanged();
+        }
+        if (!other.getClearKey().isEmpty()) {
+          clearKey_ = other.clearKey_;
+          onChanged();
+        }
+        this.mergeUnknownFields(other.unknownFields);
+        onChanged();
+        return this;
+      }
+
+      public final boolean isInitialized() {
+        return true;
+      }
+
+      public Builder mergeFrom(
+          com.google.protobuf.CodedInputStream input,
+          com.google.protobuf.ExtensionRegistryLite extensionRegistry)
+          throws java.io.IOException {
+        org.opennms.features.kafka.producer.model.OpennmsModelProtos.Alarm parsedMessage = null;
+        try {
+          parsedMessage = PARSER.parsePartialFrom(input, extensionRegistry);
+        } catch (com.google.protobuf.InvalidProtocolBufferException e) {
+          parsedMessage = (org.opennms.features.kafka.producer.model.OpennmsModelProtos.Alarm) e.getUnfinishedMessage();
+          throw e.unwrapIOException();
+        } finally {
+          if (parsedMessage != null) {
+            mergeFrom(parsedMessage);
+          }
+        }
+        return this;
+      }
+
+      private long id_ ;
+      /**
+       * <code>uint64 id = 1;</code>
+       */
+      public long getId() {
+        return id_;
+      }
+      /**
+       * <code>uint64 id = 1;</code>
+       */
+      public Builder setId(long value) {
+        
+        id_ = value;
+        onChanged();
+        return this;
+      }
+      /**
+       * <code>uint64 id = 1;</code>
+       */
+      public Builder clearId() {
+        
+        id_ = 0L;
+        onChanged();
+        return this;
+      }
+
+      private java.lang.Object uei_ = "";
+      /**
+       * <code>string uei = 2;</code>
+       */
+      public java.lang.String getUei() {
+        java.lang.Object ref = uei_;
+        if (!(ref instanceof java.lang.String)) {
+          com.google.protobuf.ByteString bs =
+              (com.google.protobuf.ByteString) ref;
+          java.lang.String s = bs.toStringUtf8();
+          uei_ = s;
+          return s;
+        } else {
+          return (java.lang.String) ref;
+        }
+      }
+      /**
+       * <code>string uei = 2;</code>
+       */
+      public com.google.protobuf.ByteString
+          getUeiBytes() {
+        java.lang.Object ref = uei_;
+        if (ref instanceof String) {
+          com.google.protobuf.ByteString b = 
+              com.google.protobuf.ByteString.copyFromUtf8(
+                  (java.lang.String) ref);
+          uei_ = b;
+          return b;
+        } else {
+          return (com.google.protobuf.ByteString) ref;
+        }
+      }
+      /**
+       * <code>string uei = 2;</code>
+       */
+      public Builder setUei(
+          java.lang.String value) {
+        if (value == null) {
+    throw new NullPointerException();
+  }
+  
+        uei_ = value;
+        onChanged();
+        return this;
+      }
+      /**
+       * <code>string uei = 2;</code>
+       */
+      public Builder clearUei() {
+        
+        uei_ = getDefaultInstance().getUei();
+        onChanged();
+        return this;
+      }
+      /**
+       * <code>string uei = 2;</code>
+       */
+      public Builder setUeiBytes(
+          com.google.protobuf.ByteString value) {
+        if (value == null) {
+    throw new NullPointerException();
+  }
+  checkByteStringIsUtf8(value);
+        
+        uei_ = value;
+        onChanged();
+        return this;
+      }
+
+      private org.opennms.features.kafka.producer.model.OpennmsModelProtos.NodeCriteria nodeCriteria_ = null;
+      private com.google.protobuf.SingleFieldBuilderV3<
+          org.opennms.features.kafka.producer.model.OpennmsModelProtos.NodeCriteria, org.opennms.features.kafka.producer.model.OpennmsModelProtos.NodeCriteria.Builder, org.opennms.features.kafka.producer.model.OpennmsModelProtos.NodeCriteriaOrBuilder> nodeCriteriaBuilder_;
+      /**
+       * <code>.NodeCriteria node_criteria = 3;</code>
+       */
+      public boolean hasNodeCriteria() {
+        return nodeCriteriaBuilder_ != null || nodeCriteria_ != null;
+      }
+      /**
+       * <code>.NodeCriteria node_criteria = 3;</code>
+       */
+      public org.opennms.features.kafka.producer.model.OpennmsModelProtos.NodeCriteria getNodeCriteria() {
+        if (nodeCriteriaBuilder_ == null) {
+          return nodeCriteria_ == null ? org.opennms.features.kafka.producer.model.OpennmsModelProtos.NodeCriteria.getDefaultInstance() : nodeCriteria_;
+        } else {
+          return nodeCriteriaBuilder_.getMessage();
+        }
+      }
+      /**
+       * <code>.NodeCriteria node_criteria = 3;</code>
+       */
+      public Builder setNodeCriteria(org.opennms.features.kafka.producer.model.OpennmsModelProtos.NodeCriteria value) {
+        if (nodeCriteriaBuilder_ == null) {
+          if (value == null) {
+            throw new NullPointerException();
+          }
+          nodeCriteria_ = value;
+          onChanged();
+        } else {
+          nodeCriteriaBuilder_.setMessage(value);
+        }
+
+        return this;
+      }
+      /**
+       * <code>.NodeCriteria node_criteria = 3;</code>
+       */
+      public Builder setNodeCriteria(
+          org.opennms.features.kafka.producer.model.OpennmsModelProtos.NodeCriteria.Builder builderForValue) {
+        if (nodeCriteriaBuilder_ == null) {
+          nodeCriteria_ = builderForValue.build();
+          onChanged();
+        } else {
+          nodeCriteriaBuilder_.setMessage(builderForValue.build());
+        }
+
+        return this;
+      }
+      /**
+       * <code>.NodeCriteria node_criteria = 3;</code>
+       */
+      public Builder mergeNodeCriteria(org.opennms.features.kafka.producer.model.OpennmsModelProtos.NodeCriteria value) {
+        if (nodeCriteriaBuilder_ == null) {
+          if (nodeCriteria_ != null) {
+            nodeCriteria_ =
+              org.opennms.features.kafka.producer.model.OpennmsModelProtos.NodeCriteria.newBuilder(nodeCriteria_).mergeFrom(value).buildPartial();
+          } else {
+            nodeCriteria_ = value;
+          }
+          onChanged();
+        } else {
+          nodeCriteriaBuilder_.mergeFrom(value);
+        }
+
+        return this;
+      }
+      /**
+       * <code>.NodeCriteria node_criteria = 3;</code>
+       */
+      public Builder clearNodeCriteria() {
+        if (nodeCriteriaBuilder_ == null) {
+          nodeCriteria_ = null;
+          onChanged();
+        } else {
+          nodeCriteria_ = null;
+          nodeCriteriaBuilder_ = null;
+        }
+
+        return this;
+      }
+      /**
+       * <code>.NodeCriteria node_criteria = 3;</code>
+       */
+      public org.opennms.features.kafka.producer.model.OpennmsModelProtos.NodeCriteria.Builder getNodeCriteriaBuilder() {
+        
+        onChanged();
+        return getNodeCriteriaFieldBuilder().getBuilder();
+      }
+      /**
+       * <code>.NodeCriteria node_criteria = 3;</code>
+       */
+      public org.opennms.features.kafka.producer.model.OpennmsModelProtos.NodeCriteriaOrBuilder getNodeCriteriaOrBuilder() {
+        if (nodeCriteriaBuilder_ != null) {
+          return nodeCriteriaBuilder_.getMessageOrBuilder();
+        } else {
+          return nodeCriteria_ == null ?
+              org.opennms.features.kafka.producer.model.OpennmsModelProtos.NodeCriteria.getDefaultInstance() : nodeCriteria_;
+        }
+      }
+      /**
+       * <code>.NodeCriteria node_criteria = 3;</code>
+       */
+      private com.google.protobuf.SingleFieldBuilderV3<
+          org.opennms.features.kafka.producer.model.OpennmsModelProtos.NodeCriteria, org.opennms.features.kafka.producer.model.OpennmsModelProtos.NodeCriteria.Builder, org.opennms.features.kafka.producer.model.OpennmsModelProtos.NodeCriteriaOrBuilder> 
+          getNodeCriteriaFieldBuilder() {
+        if (nodeCriteriaBuilder_ == null) {
+          nodeCriteriaBuilder_ = new com.google.protobuf.SingleFieldBuilderV3<
+              org.opennms.features.kafka.producer.model.OpennmsModelProtos.NodeCriteria, org.opennms.features.kafka.producer.model.OpennmsModelProtos.NodeCriteria.Builder, org.opennms.features.kafka.producer.model.OpennmsModelProtos.NodeCriteriaOrBuilder>(
+                  getNodeCriteria(),
+                  getParentForChildren(),
+                  isClean());
+          nodeCriteria_ = null;
+        }
+        return nodeCriteriaBuilder_;
+      }
+
+      private java.lang.Object ipAddress_ = "";
+      /**
+       * <code>string ip_address = 4;</code>
+       */
+      public java.lang.String getIpAddress() {
+        java.lang.Object ref = ipAddress_;
+        if (!(ref instanceof java.lang.String)) {
+          com.google.protobuf.ByteString bs =
+              (com.google.protobuf.ByteString) ref;
+          java.lang.String s = bs.toStringUtf8();
+          ipAddress_ = s;
+          return s;
+        } else {
+          return (java.lang.String) ref;
+        }
+      }
+      /**
+       * <code>string ip_address = 4;</code>
+       */
+      public com.google.protobuf.ByteString
+          getIpAddressBytes() {
+        java.lang.Object ref = ipAddress_;
+        if (ref instanceof String) {
+          com.google.protobuf.ByteString b = 
+              com.google.protobuf.ByteString.copyFromUtf8(
+                  (java.lang.String) ref);
+          ipAddress_ = b;
+          return b;
+        } else {
+          return (com.google.protobuf.ByteString) ref;
+        }
+      }
+      /**
+       * <code>string ip_address = 4;</code>
+       */
+      public Builder setIpAddress(
+          java.lang.String value) {
+        if (value == null) {
+    throw new NullPointerException();
+  }
+  
+        ipAddress_ = value;
+        onChanged();
+        return this;
+      }
+      /**
+       * <code>string ip_address = 4;</code>
+       */
+      public Builder clearIpAddress() {
+        
+        ipAddress_ = getDefaultInstance().getIpAddress();
+        onChanged();
+        return this;
+      }
+      /**
+       * <code>string ip_address = 4;</code>
+       */
+      public Builder setIpAddressBytes(
+          com.google.protobuf.ByteString value) {
+        if (value == null) {
+    throw new NullPointerException();
+  }
+  checkByteStringIsUtf8(value);
+        
+        ipAddress_ = value;
+        onChanged();
+        return this;
+      }
+
+      private java.lang.Object serviceName_ = "";
+      /**
+       * <code>string service_name = 5;</code>
+       */
+      public java.lang.String getServiceName() {
+        java.lang.Object ref = serviceName_;
+        if (!(ref instanceof java.lang.String)) {
+          com.google.protobuf.ByteString bs =
+              (com.google.protobuf.ByteString) ref;
+          java.lang.String s = bs.toStringUtf8();
+          serviceName_ = s;
+          return s;
+        } else {
+          return (java.lang.String) ref;
+        }
+      }
+      /**
+       * <code>string service_name = 5;</code>
+       */
+      public com.google.protobuf.ByteString
+          getServiceNameBytes() {
+        java.lang.Object ref = serviceName_;
+        if (ref instanceof String) {
+          com.google.protobuf.ByteString b = 
+              com.google.protobuf.ByteString.copyFromUtf8(
+                  (java.lang.String) ref);
+          serviceName_ = b;
+          return b;
+        } else {
+          return (com.google.protobuf.ByteString) ref;
+        }
+      }
+      /**
+       * <code>string service_name = 5;</code>
+       */
+      public Builder setServiceName(
+          java.lang.String value) {
+        if (value == null) {
+    throw new NullPointerException();
+  }
+  
+        serviceName_ = value;
+        onChanged();
+        return this;
+      }
+      /**
+       * <code>string service_name = 5;</code>
+       */
+      public Builder clearServiceName() {
+        
+        serviceName_ = getDefaultInstance().getServiceName();
+        onChanged();
+        return this;
+      }
+      /**
+       * <code>string service_name = 5;</code>
+       */
+      public Builder setServiceNameBytes(
+          com.google.protobuf.ByteString value) {
+        if (value == null) {
+    throw new NullPointerException();
+  }
+  checkByteStringIsUtf8(value);
+        
+        serviceName_ = value;
+        onChanged();
+        return this;
+      }
+
+      private java.lang.Object reductionKey_ = "";
+      /**
+       * <code>string reduction_key = 6;</code>
+       */
+      public java.lang.String getReductionKey() {
+        java.lang.Object ref = reductionKey_;
+        if (!(ref instanceof java.lang.String)) {
+          com.google.protobuf.ByteString bs =
+              (com.google.protobuf.ByteString) ref;
+          java.lang.String s = bs.toStringUtf8();
+          reductionKey_ = s;
+          return s;
+        } else {
+          return (java.lang.String) ref;
+        }
+      }
+      /**
+       * <code>string reduction_key = 6;</code>
+       */
+      public com.google.protobuf.ByteString
+          getReductionKeyBytes() {
+        java.lang.Object ref = reductionKey_;
+        if (ref instanceof String) {
+          com.google.protobuf.ByteString b = 
+              com.google.protobuf.ByteString.copyFromUtf8(
+                  (java.lang.String) ref);
+          reductionKey_ = b;
+          return b;
+        } else {
+          return (com.google.protobuf.ByteString) ref;
+        }
+      }
+      /**
+       * <code>string reduction_key = 6;</code>
+       */
+      public Builder setReductionKey(
+          java.lang.String value) {
+        if (value == null) {
+    throw new NullPointerException();
+  }
+  
+        reductionKey_ = value;
+        onChanged();
+        return this;
+      }
+      /**
+       * <code>string reduction_key = 6;</code>
+       */
+      public Builder clearReductionKey() {
+        
+        reductionKey_ = getDefaultInstance().getReductionKey();
+        onChanged();
+        return this;
+      }
+      /**
+       * <code>string reduction_key = 6;</code>
+       */
+      public Builder setReductionKeyBytes(
+          com.google.protobuf.ByteString value) {
+        if (value == null) {
+    throw new NullPointerException();
+  }
+  checkByteStringIsUtf8(value);
+        
+        reductionKey_ = value;
+        onChanged();
+        return this;
+      }
+
+      private int type_ = 0;
+      /**
+       * <code>.Alarm.Type type = 7;</code>
+       */
+      public int getTypeValue() {
+        return type_;
+      }
+      /**
+       * <code>.Alarm.Type type = 7;</code>
+       */
+      public Builder setTypeValue(int value) {
+        type_ = value;
+        onChanged();
+        return this;
+      }
+      /**
+       * <code>.Alarm.Type type = 7;</code>
+       */
+      public org.opennms.features.kafka.producer.model.OpennmsModelProtos.Alarm.Type getType() {
+        org.opennms.features.kafka.producer.model.OpennmsModelProtos.Alarm.Type result = org.opennms.features.kafka.producer.model.OpennmsModelProtos.Alarm.Type.valueOf(type_);
+        return result == null ? org.opennms.features.kafka.producer.model.OpennmsModelProtos.Alarm.Type.UNRECOGNIZED : result;
+      }
+      /**
+       * <code>.Alarm.Type type = 7;</code>
+       */
+      public Builder setType(org.opennms.features.kafka.producer.model.OpennmsModelProtos.Alarm.Type value) {
+        if (value == null) {
+          throw new NullPointerException();
+        }
+        
+        type_ = value.getNumber();
+        onChanged();
+        return this;
+      }
+      /**
+       * <code>.Alarm.Type type = 7;</code>
+       */
+      public Builder clearType() {
+        
+        type_ = 0;
+        onChanged();
+        return this;
+      }
+
+      private long count_ ;
+      /**
+       * <code>uint64 count = 8;</code>
+       */
+      public long getCount() {
+        return count_;
+      }
+      /**
+       * <code>uint64 count = 8;</code>
+       */
+      public Builder setCount(long value) {
+        
+        count_ = value;
+        onChanged();
+        return this;
+      }
+      /**
+       * <code>uint64 count = 8;</code>
+       */
+      public Builder clearCount() {
+        
+        count_ = 0L;
+        onChanged();
+        return this;
+      }
+
+      private int severity_ = 0;
+      /**
+       * <code>.Severity severity = 9;</code>
+       */
+      public int getSeverityValue() {
+        return severity_;
+      }
+      /**
+       * <code>.Severity severity = 9;</code>
+       */
+      public Builder setSeverityValue(int value) {
+        severity_ = value;
+        onChanged();
+        return this;
+      }
+      /**
+       * <code>.Severity severity = 9;</code>
+       */
+      public org.opennms.features.kafka.producer.model.OpennmsModelProtos.Severity getSeverity() {
+        org.opennms.features.kafka.producer.model.OpennmsModelProtos.Severity result = org.opennms.features.kafka.producer.model.OpennmsModelProtos.Severity.valueOf(severity_);
+        return result == null ? org.opennms.features.kafka.producer.model.OpennmsModelProtos.Severity.UNRECOGNIZED : result;
+      }
+      /**
+       * <code>.Severity severity = 9;</code>
+       */
+      public Builder setSeverity(org.opennms.features.kafka.producer.model.OpennmsModelProtos.Severity value) {
+        if (value == null) {
+          throw new NullPointerException();
+        }
+        
+        severity_ = value.getNumber();
+        onChanged();
+        return this;
+      }
+      /**
+       * <code>.Severity severity = 9;</code>
+       */
+      public Builder clearSeverity() {
+        
+        severity_ = 0;
+        onChanged();
+        return this;
+      }
+
+      private long firstEventTime_ ;
+      /**
+       * <code>uint64 first_event_time = 10;</code>
+       */
+      public long getFirstEventTime() {
+        return firstEventTime_;
+      }
+      /**
+       * <code>uint64 first_event_time = 10;</code>
+       */
+      public Builder setFirstEventTime(long value) {
+        
+        firstEventTime_ = value;
+        onChanged();
+        return this;
+      }
+      /**
+       * <code>uint64 first_event_time = 10;</code>
+       */
+      public Builder clearFirstEventTime() {
+        
+        firstEventTime_ = 0L;
+        onChanged();
+        return this;
+      }
+
+      private java.lang.Object description_ = "";
+      /**
+       * <code>string description = 11;</code>
+       */
+      public java.lang.String getDescription() {
+        java.lang.Object ref = description_;
+        if (!(ref instanceof java.lang.String)) {
+          com.google.protobuf.ByteString bs =
+              (com.google.protobuf.ByteString) ref;
+          java.lang.String s = bs.toStringUtf8();
+          description_ = s;
+          return s;
+        } else {
+          return (java.lang.String) ref;
+        }
+      }
+      /**
+       * <code>string description = 11;</code>
+       */
+      public com.google.protobuf.ByteString
+          getDescriptionBytes() {
+        java.lang.Object ref = description_;
+        if (ref instanceof String) {
+          com.google.protobuf.ByteString b = 
+              com.google.protobuf.ByteString.copyFromUtf8(
+                  (java.lang.String) ref);
+          description_ = b;
+          return b;
+        } else {
+          return (com.google.protobuf.ByteString) ref;
+        }
+      }
+      /**
+       * <code>string description = 11;</code>
+       */
+      public Builder setDescription(
+          java.lang.String value) {
+        if (value == null) {
+    throw new NullPointerException();
+  }
+  
+        description_ = value;
+        onChanged();
+        return this;
+      }
+      /**
+       * <code>string description = 11;</code>
+       */
+      public Builder clearDescription() {
+        
+        description_ = getDefaultInstance().getDescription();
+        onChanged();
+        return this;
+      }
+      /**
+       * <code>string description = 11;</code>
+       */
+      public Builder setDescriptionBytes(
+          com.google.protobuf.ByteString value) {
+        if (value == null) {
+    throw new NullPointerException();
+  }
+  checkByteStringIsUtf8(value);
+        
+        description_ = value;
+        onChanged();
+        return this;
+      }
+
+      private java.lang.Object logMessage_ = "";
+      /**
+       * <code>string log_message = 12;</code>
+       */
+      public java.lang.String getLogMessage() {
+        java.lang.Object ref = logMessage_;
+        if (!(ref instanceof java.lang.String)) {
+          com.google.protobuf.ByteString bs =
+              (com.google.protobuf.ByteString) ref;
+          java.lang.String s = bs.toStringUtf8();
+          logMessage_ = s;
+          return s;
+        } else {
+          return (java.lang.String) ref;
+        }
+      }
+      /**
+       * <code>string log_message = 12;</code>
+       */
+      public com.google.protobuf.ByteString
+          getLogMessageBytes() {
+        java.lang.Object ref = logMessage_;
+        if (ref instanceof String) {
+          com.google.protobuf.ByteString b = 
+              com.google.protobuf.ByteString.copyFromUtf8(
+                  (java.lang.String) ref);
+          logMessage_ = b;
+          return b;
+        } else {
+          return (com.google.protobuf.ByteString) ref;
+        }
+      }
+      /**
+       * <code>string log_message = 12;</code>
+       */
+      public Builder setLogMessage(
+          java.lang.String value) {
+        if (value == null) {
+    throw new NullPointerException();
+  }
+  
+        logMessage_ = value;
+        onChanged();
+        return this;
+      }
+      /**
+       * <code>string log_message = 12;</code>
+       */
+      public Builder clearLogMessage() {
+        
+        logMessage_ = getDefaultInstance().getLogMessage();
+        onChanged();
+        return this;
+      }
+      /**
+       * <code>string log_message = 12;</code>
+       */
+      public Builder setLogMessageBytes(
+          com.google.protobuf.ByteString value) {
+        if (value == null) {
+    throw new NullPointerException();
+  }
+  checkByteStringIsUtf8(value);
+        
+        logMessage_ = value;
+        onChanged();
+        return this;
+      }
+
+      private java.lang.Object ackUser_ = "";
+      /**
+       * <code>string ack_user = 13;</code>
+       */
+      public java.lang.String getAckUser() {
+        java.lang.Object ref = ackUser_;
+        if (!(ref instanceof java.lang.String)) {
+          com.google.protobuf.ByteString bs =
+              (com.google.protobuf.ByteString) ref;
+          java.lang.String s = bs.toStringUtf8();
+          ackUser_ = s;
+          return s;
+        } else {
+          return (java.lang.String) ref;
+        }
+      }
+      /**
+       * <code>string ack_user = 13;</code>
+       */
+      public com.google.protobuf.ByteString
+          getAckUserBytes() {
+        java.lang.Object ref = ackUser_;
+        if (ref instanceof String) {
+          com.google.protobuf.ByteString b = 
+              com.google.protobuf.ByteString.copyFromUtf8(
+                  (java.lang.String) ref);
+          ackUser_ = b;
+          return b;
+        } else {
+          return (com.google.protobuf.ByteString) ref;
+        }
+      }
+      /**
+       * <code>string ack_user = 13;</code>
+       */
+      public Builder setAckUser(
+          java.lang.String value) {
+        if (value == null) {
+    throw new NullPointerException();
+  }
+  
+        ackUser_ = value;
+        onChanged();
+        return this;
+      }
+      /**
+       * <code>string ack_user = 13;</code>
+       */
+      public Builder clearAckUser() {
+        
+        ackUser_ = getDefaultInstance().getAckUser();
+        onChanged();
+        return this;
+      }
+      /**
+       * <code>string ack_user = 13;</code>
+       */
+      public Builder setAckUserBytes(
+          com.google.protobuf.ByteString value) {
+        if (value == null) {
+    throw new NullPointerException();
+  }
+  checkByteStringIsUtf8(value);
+        
+        ackUser_ = value;
+        onChanged();
+        return this;
+      }
+
+      private long ackTime_ ;
+      /**
+       * <code>uint64 ack_time = 14;</code>
+       */
+      public long getAckTime() {
+        return ackTime_;
+      }
+      /**
+       * <code>uint64 ack_time = 14;</code>
+       */
+      public Builder setAckTime(long value) {
+        
+        ackTime_ = value;
+        onChanged();
+        return this;
+      }
+      /**
+       * <code>uint64 ack_time = 14;</code>
+       */
+      public Builder clearAckTime() {
+        
+        ackTime_ = 0L;
+        onChanged();
+        return this;
+      }
+
+      private org.opennms.features.kafka.producer.model.OpennmsModelProtos.Event lastEvent_ = null;
+      private com.google.protobuf.SingleFieldBuilderV3<
+          org.opennms.features.kafka.producer.model.OpennmsModelProtos.Event, org.opennms.features.kafka.producer.model.OpennmsModelProtos.Event.Builder, org.opennms.features.kafka.producer.model.OpennmsModelProtos.EventOrBuilder> lastEventBuilder_;
+      /**
+       * <code>.Event last_event = 15;</code>
+       */
+      public boolean hasLastEvent() {
+        return lastEventBuilder_ != null || lastEvent_ != null;
+      }
+      /**
+       * <code>.Event last_event = 15;</code>
+       */
+      public org.opennms.features.kafka.producer.model.OpennmsModelProtos.Event getLastEvent() {
+        if (lastEventBuilder_ == null) {
+          return lastEvent_ == null ? org.opennms.features.kafka.producer.model.OpennmsModelProtos.Event.getDefaultInstance() : lastEvent_;
+        } else {
+          return lastEventBuilder_.getMessage();
+        }
+      }
+      /**
+       * <code>.Event last_event = 15;</code>
+       */
+      public Builder setLastEvent(org.opennms.features.kafka.producer.model.OpennmsModelProtos.Event value) {
+        if (lastEventBuilder_ == null) {
+          if (value == null) {
+            throw new NullPointerException();
+          }
+          lastEvent_ = value;
+          onChanged();
+        } else {
+          lastEventBuilder_.setMessage(value);
+        }
+
+        return this;
+      }
+      /**
+       * <code>.Event last_event = 15;</code>
+       */
+      public Builder setLastEvent(
+          org.opennms.features.kafka.producer.model.OpennmsModelProtos.Event.Builder builderForValue) {
+        if (lastEventBuilder_ == null) {
+          lastEvent_ = builderForValue.build();
+          onChanged();
+        } else {
+          lastEventBuilder_.setMessage(builderForValue.build());
+        }
+
+        return this;
+      }
+      /**
+       * <code>.Event last_event = 15;</code>
+       */
+      public Builder mergeLastEvent(org.opennms.features.kafka.producer.model.OpennmsModelProtos.Event value) {
+        if (lastEventBuilder_ == null) {
+          if (lastEvent_ != null) {
+            lastEvent_ =
+              org.opennms.features.kafka.producer.model.OpennmsModelProtos.Event.newBuilder(lastEvent_).mergeFrom(value).buildPartial();
+          } else {
+            lastEvent_ = value;
+          }
+          onChanged();
+        } else {
+          lastEventBuilder_.mergeFrom(value);
+        }
+
+        return this;
+      }
+      /**
+       * <code>.Event last_event = 15;</code>
+       */
+      public Builder clearLastEvent() {
+        if (lastEventBuilder_ == null) {
+          lastEvent_ = null;
+          onChanged();
+        } else {
+          lastEvent_ = null;
+          lastEventBuilder_ = null;
+        }
+
+        return this;
+      }
+      /**
+       * <code>.Event last_event = 15;</code>
+       */
+      public org.opennms.features.kafka.producer.model.OpennmsModelProtos.Event.Builder getLastEventBuilder() {
+        
+        onChanged();
+        return getLastEventFieldBuilder().getBuilder();
+      }
+      /**
+       * <code>.Event last_event = 15;</code>
+       */
+      public org.opennms.features.kafka.producer.model.OpennmsModelProtos.EventOrBuilder getLastEventOrBuilder() {
+        if (lastEventBuilder_ != null) {
+          return lastEventBuilder_.getMessageOrBuilder();
+        } else {
+          return lastEvent_ == null ?
+              org.opennms.features.kafka.producer.model.OpennmsModelProtos.Event.getDefaultInstance() : lastEvent_;
+        }
+      }
+      /**
+       * <code>.Event last_event = 15;</code>
+       */
+      private com.google.protobuf.SingleFieldBuilderV3<
+          org.opennms.features.kafka.producer.model.OpennmsModelProtos.Event, org.opennms.features.kafka.producer.model.OpennmsModelProtos.Event.Builder, org.opennms.features.kafka.producer.model.OpennmsModelProtos.EventOrBuilder> 
+          getLastEventFieldBuilder() {
+        if (lastEventBuilder_ == null) {
+          lastEventBuilder_ = new com.google.protobuf.SingleFieldBuilderV3<
+              org.opennms.features.kafka.producer.model.OpennmsModelProtos.Event, org.opennms.features.kafka.producer.model.OpennmsModelProtos.Event.Builder, org.opennms.features.kafka.producer.model.OpennmsModelProtos.EventOrBuilder>(
+                  getLastEvent(),
+                  getParentForChildren(),
+                  isClean());
+          lastEvent_ = null;
+        }
+        return lastEventBuilder_;
+      }
+
+      private long lastEventTime_ ;
+      /**
+       * <code>uint64 last_event_time = 16;</code>
+       */
+      public long getLastEventTime() {
+        return lastEventTime_;
+      }
+      /**
+       * <code>uint64 last_event_time = 16;</code>
+       */
+      public Builder setLastEventTime(long value) {
+        
+        lastEventTime_ = value;
+        onChanged();
+        return this;
+      }
+      /**
+       * <code>uint64 last_event_time = 16;</code>
+       */
+      public Builder clearLastEventTime() {
+        
+        lastEventTime_ = 0L;
+        onChanged();
+        return this;
+      }
+
+      private int ifIndex_ ;
+      /**
+       * <code>uint32 if_index = 17;</code>
+       */
+      public int getIfIndex() {
+        return ifIndex_;
+      }
+      /**
+       * <code>uint32 if_index = 17;</code>
+       */
+      public Builder setIfIndex(int value) {
+        
+        ifIndex_ = value;
+        onChanged();
+        return this;
+      }
+      /**
+       * <code>uint32 if_index = 17;</code>
+       */
+      public Builder clearIfIndex() {
+        
+        ifIndex_ = 0;
+        onChanged();
+        return this;
+      }
+
+      private java.lang.Object operatorInstructions_ = "";
+      /**
+       * <code>string operator_instructions = 18;</code>
+       */
+      public java.lang.String getOperatorInstructions() {
+        java.lang.Object ref = operatorInstructions_;
+        if (!(ref instanceof java.lang.String)) {
+          com.google.protobuf.ByteString bs =
+              (com.google.protobuf.ByteString) ref;
+          java.lang.String s = bs.toStringUtf8();
+          operatorInstructions_ = s;
+          return s;
+        } else {
+          return (java.lang.String) ref;
+        }
+      }
+      /**
+       * <code>string operator_instructions = 18;</code>
+       */
+      public com.google.protobuf.ByteString
+          getOperatorInstructionsBytes() {
+        java.lang.Object ref = operatorInstructions_;
+        if (ref instanceof String) {
+          com.google.protobuf.ByteString b = 
+              com.google.protobuf.ByteString.copyFromUtf8(
+                  (java.lang.String) ref);
+          operatorInstructions_ = b;
+          return b;
+        } else {
+          return (com.google.protobuf.ByteString) ref;
+        }
+      }
+      /**
+       * <code>string operator_instructions = 18;</code>
+       */
+      public Builder setOperatorInstructions(
+          java.lang.String value) {
+        if (value == null) {
+    throw new NullPointerException();
+  }
+  
+        operatorInstructions_ = value;
+        onChanged();
+        return this;
+      }
+      /**
+       * <code>string operator_instructions = 18;</code>
+       */
+      public Builder clearOperatorInstructions() {
+        
+        operatorInstructions_ = getDefaultInstance().getOperatorInstructions();
+        onChanged();
+        return this;
+      }
+      /**
+       * <code>string operator_instructions = 18;</code>
+       */
+      public Builder setOperatorInstructionsBytes(
+          com.google.protobuf.ByteString value) {
+        if (value == null) {
+    throw new NullPointerException();
+  }
+  checkByteStringIsUtf8(value);
+        
+        operatorInstructions_ = value;
+        onChanged();
+        return this;
+      }
+
+      private java.lang.Object clearKey_ = "";
+      /**
+       * <code>string clear_key = 19;</code>
+       */
+      public java.lang.String getClearKey() {
+        java.lang.Object ref = clearKey_;
+        if (!(ref instanceof java.lang.String)) {
+          com.google.protobuf.ByteString bs =
+              (com.google.protobuf.ByteString) ref;
+          java.lang.String s = bs.toStringUtf8();
+          clearKey_ = s;
+          return s;
+        } else {
+          return (java.lang.String) ref;
+        }
+      }
+      /**
+       * <code>string clear_key = 19;</code>
+       */
+      public com.google.protobuf.ByteString
+          getClearKeyBytes() {
+        java.lang.Object ref = clearKey_;
+        if (ref instanceof String) {
+          com.google.protobuf.ByteString b = 
+              com.google.protobuf.ByteString.copyFromUtf8(
+                  (java.lang.String) ref);
+          clearKey_ = b;
+          return b;
+        } else {
+          return (com.google.protobuf.ByteString) ref;
+        }
+      }
+      /**
+       * <code>string clear_key = 19;</code>
+       */
+      public Builder setClearKey(
+          java.lang.String value) {
+        if (value == null) {
+    throw new NullPointerException();
+  }
+  
+        clearKey_ = value;
+        onChanged();
+        return this;
+      }
+      /**
+       * <code>string clear_key = 19;</code>
+       */
+      public Builder clearClearKey() {
+        
+        clearKey_ = getDefaultInstance().getClearKey();
+        onChanged();
+        return this;
+      }
+      /**
+       * <code>string clear_key = 19;</code>
+       */
+      public Builder setClearKeyBytes(
+          com.google.protobuf.ByteString value) {
+        if (value == null) {
+    throw new NullPointerException();
+  }
+  checkByteStringIsUtf8(value);
+        
+        clearKey_ = value;
+        onChanged();
+        return this;
+      }
+      public final Builder setUnknownFields(
+          final com.google.protobuf.UnknownFieldSet unknownFields) {
+        return super.setUnknownFieldsProto3(unknownFields);
+      }
+
+      public final Builder mergeUnknownFields(
+          final com.google.protobuf.UnknownFieldSet unknownFields) {
+        return super.mergeUnknownFields(unknownFields);
+      }
+
+
+      // @@protoc_insertion_point(builder_scope:Alarm)
+    }
+
+    // @@protoc_insertion_point(class_scope:Alarm)
+    private static final org.opennms.features.kafka.producer.model.OpennmsModelProtos.Alarm DEFAULT_INSTANCE;
+    static {
+      DEFAULT_INSTANCE = new org.opennms.features.kafka.producer.model.OpennmsModelProtos.Alarm();
+    }
+
+    public static org.opennms.features.kafka.producer.model.OpennmsModelProtos.Alarm getDefaultInstance() {
+      return DEFAULT_INSTANCE;
+    }
+
+    private static final com.google.protobuf.Parser<Alarm>
+        PARSER = new com.google.protobuf.AbstractParser<Alarm>() {
+      public Alarm parsePartialFrom(
+          com.google.protobuf.CodedInputStream input,
+          com.google.protobuf.ExtensionRegistryLite extensionRegistry)
+          throws com.google.protobuf.InvalidProtocolBufferException {
+        return new Alarm(input, extensionRegistry);
+      }
+    };
+
+    public static com.google.protobuf.Parser<Alarm> parser() {
+      return PARSER;
+    }
+
+    @java.lang.Override
+    public com.google.protobuf.Parser<Alarm> getParserForType() {
+      return PARSER;
+    }
+
+    public org.opennms.features.kafka.producer.model.OpennmsModelProtos.Alarm getDefaultInstanceForType() {
+      return DEFAULT_INSTANCE;
+    }
+
+  }
+
+  public interface IpInterfaceOrBuilder extends
+      // @@protoc_insertion_point(interface_extends:IpInterface)
+      com.google.protobuf.MessageOrBuilder {
+
+    /**
+     * <code>uint64 id = 1;</code>
+     */
+    long getId();
+
+    /**
+     * <code>string ip_address = 2;</code>
+     */
+    java.lang.String getIpAddress();
+    /**
+     * <code>string ip_address = 2;</code>
+     */
+    com.google.protobuf.ByteString
+        getIpAddressBytes();
+
+    /**
+     * <code>uint32 if_index = 3;</code>
+     */
+    int getIfIndex();
+
+    /**
+     * <code>.IpInterface.PrimaryType primary_type = 4;</code>
+     */
+    int getPrimaryTypeValue();
+    /**
+     * <code>.IpInterface.PrimaryType primary_type = 4;</code>
+     */
+    org.opennms.features.kafka.producer.model.OpennmsModelProtos.IpInterface.PrimaryType getPrimaryType();
+
+    /**
+     * <code>repeated string service = 5;</code>
+     */
+    java.util.List<java.lang.String>
+        getServiceList();
+    /**
+     * <code>repeated string service = 5;</code>
+     */
+    int getServiceCount();
+    /**
+     * <code>repeated string service = 5;</code>
+     */
+    java.lang.String getService(int index);
+    /**
+     * <code>repeated string service = 5;</code>
+     */
+    com.google.protobuf.ByteString
+        getServiceBytes(int index);
+  }
+  /**
+   * Protobuf type {@code IpInterface}
+   */
+  public  static final class IpInterface extends
+      com.google.protobuf.GeneratedMessageV3 implements
+      // @@protoc_insertion_point(message_implements:IpInterface)
+      IpInterfaceOrBuilder {
+  private static final long serialVersionUID = 0L;
+    // Use IpInterface.newBuilder() to construct.
+    private IpInterface(com.google.protobuf.GeneratedMessageV3.Builder<?> builder) {
+      super(builder);
+    }
+    private IpInterface() {
+      id_ = 0L;
+      ipAddress_ = "";
+      ifIndex_ = 0;
+      primaryType_ = 0;
+      service_ = com.google.protobuf.LazyStringArrayList.EMPTY;
+    }
+
+    @java.lang.Override
+    public final com.google.protobuf.UnknownFieldSet
+    getUnknownFields() {
+      return this.unknownFields;
+    }
+    private IpInterface(
+        com.google.protobuf.CodedInputStream input,
+        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
+        throws com.google.protobuf.InvalidProtocolBufferException {
+      this();
+      if (extensionRegistry == null) {
+        throw new java.lang.NullPointerException();
+      }
+      int mutable_bitField0_ = 0;
+      com.google.protobuf.UnknownFieldSet.Builder unknownFields =
+          com.google.protobuf.UnknownFieldSet.newBuilder();
+      try {
+        boolean done = false;
+        while (!done) {
+          int tag = input.readTag();
+          switch (tag) {
+            case 0:
+              done = true;
+              break;
+            default: {
+              if (!parseUnknownFieldProto3(
+                  input, unknownFields, extensionRegistry, tag)) {
+                done = true;
+              }
+              break;
+            }
+            case 8: {
+
+              id_ = input.readUInt64();
+              break;
+            }
+            case 18: {
+              java.lang.String s = input.readStringRequireUtf8();
+
+              ipAddress_ = s;
+              break;
+            }
+            case 24: {
+
+              ifIndex_ = input.readUInt32();
+              break;
+            }
+            case 32: {
+              int rawValue = input.readEnum();
+
+              primaryType_ = rawValue;
+              break;
+            }
+            case 42: {
+              java.lang.String s = input.readStringRequireUtf8();
+              if (!((mutable_bitField0_ & 0x00000010) == 0x00000010)) {
+                service_ = new com.google.protobuf.LazyStringArrayList();
+                mutable_bitField0_ |= 0x00000010;
+              }
+              service_.add(s);
+              break;
+            }
+          }
+        }
+      } catch (com.google.protobuf.InvalidProtocolBufferException e) {
+        throw e.setUnfinishedMessage(this);
+      } catch (java.io.IOException e) {
+        throw new com.google.protobuf.InvalidProtocolBufferException(
+            e).setUnfinishedMessage(this);
+      } finally {
+        if (((mutable_bitField0_ & 0x00000010) == 0x00000010)) {
+          service_ = service_.getUnmodifiableView();
+        }
+        this.unknownFields = unknownFields.build();
+        makeExtensionsImmutable();
+      }
+    }
+    public static final com.google.protobuf.Descriptors.Descriptor
+        getDescriptor() {
+      return org.opennms.features.kafka.producer.model.OpennmsModelProtos.internal_static_IpInterface_descriptor;
+    }
+
+    protected com.google.protobuf.GeneratedMessageV3.FieldAccessorTable
+        internalGetFieldAccessorTable() {
+      return org.opennms.features.kafka.producer.model.OpennmsModelProtos.internal_static_IpInterface_fieldAccessorTable
+          .ensureFieldAccessorsInitialized(
+              org.opennms.features.kafka.producer.model.OpennmsModelProtos.IpInterface.class, org.opennms.features.kafka.producer.model.OpennmsModelProtos.IpInterface.Builder.class);
+    }
+
+    /**
+     * Protobuf enum {@code IpInterface.PrimaryType}
+     */
+    public enum PrimaryType
+        implements com.google.protobuf.ProtocolMessageEnum {
+      /**
+       * <code>PRIMARY = 0;</code>
+       */
+      PRIMARY(0),
+      /**
+       * <code>SECONDARY = 1;</code>
+       */
+      SECONDARY(1),
+      /**
+       * <code>NOT_ELIGIBLE = 2;</code>
+       */
+      NOT_ELIGIBLE(2),
+      UNRECOGNIZED(-1),
+      ;
+
+      /**
+       * <code>PRIMARY = 0;</code>
+       */
+      public static final int PRIMARY_VALUE = 0;
+      /**
+       * <code>SECONDARY = 1;</code>
+       */
+      public static final int SECONDARY_VALUE = 1;
+      /**
+       * <code>NOT_ELIGIBLE = 2;</code>
+       */
+      public static final int NOT_ELIGIBLE_VALUE = 2;
+
+
+      public final int getNumber() {
+        if (this == UNRECOGNIZED) {
+          throw new java.lang.IllegalArgumentException(
+              "Can't get the number of an unknown enum value.");
+        }
+        return value;
+      }
+
+      /**
+       * @deprecated Use {@link #forNumber(int)} instead.
+       */
+      @java.lang.Deprecated
+      public static PrimaryType valueOf(int value) {
+        return forNumber(value);
+      }
+
+      public static PrimaryType forNumber(int value) {
+        switch (value) {
+          case 0: return PRIMARY;
+          case 1: return SECONDARY;
+          case 2: return NOT_ELIGIBLE;
+          default: return null;
+        }
+      }
+
+      public static com.google.protobuf.Internal.EnumLiteMap<PrimaryType>
+          internalGetValueMap() {
+        return internalValueMap;
+      }
+      private static final com.google.protobuf.Internal.EnumLiteMap<
+          PrimaryType> internalValueMap =
+            new com.google.protobuf.Internal.EnumLiteMap<PrimaryType>() {
+              public PrimaryType findValueByNumber(int number) {
+                return PrimaryType.forNumber(number);
+              }
+            };
+
+      public final com.google.protobuf.Descriptors.EnumValueDescriptor
+          getValueDescriptor() {
+        return getDescriptor().getValues().get(ordinal());
+      }
+      public final com.google.protobuf.Descriptors.EnumDescriptor
+          getDescriptorForType() {
+        return getDescriptor();
+      }
+      public static final com.google.protobuf.Descriptors.EnumDescriptor
+          getDescriptor() {
+        return org.opennms.features.kafka.producer.model.OpennmsModelProtos.IpInterface.getDescriptor().getEnumTypes().get(0);
+      }
+
+      private static final PrimaryType[] VALUES = values();
+
+      public static PrimaryType valueOf(
+          com.google.protobuf.Descriptors.EnumValueDescriptor desc) {
+        if (desc.getType() != getDescriptor()) {
+          throw new java.lang.IllegalArgumentException(
+            "EnumValueDescriptor is not for this type.");
+        }
+        if (desc.getIndex() == -1) {
+          return UNRECOGNIZED;
+        }
+        return VALUES[desc.getIndex()];
+      }
+
+      private final int value;
+
+      private PrimaryType(int value) {
+        this.value = value;
+      }
+
+      // @@protoc_insertion_point(enum_scope:IpInterface.PrimaryType)
+    }
+
+    private int bitField0_;
+    public static final int ID_FIELD_NUMBER = 1;
+    private long id_;
+    /**
+     * <code>uint64 id = 1;</code>
+     */
+    public long getId() {
+      return id_;
+    }
+
+    public static final int IP_ADDRESS_FIELD_NUMBER = 2;
+    private volatile java.lang.Object ipAddress_;
+    /**
+     * <code>string ip_address = 2;</code>
+     */
+    public java.lang.String getIpAddress() {
+      java.lang.Object ref = ipAddress_;
+      if (ref instanceof java.lang.String) {
+        return (java.lang.String) ref;
+      } else {
+        com.google.protobuf.ByteString bs = 
+            (com.google.protobuf.ByteString) ref;
+        java.lang.String s = bs.toStringUtf8();
+        ipAddress_ = s;
+        return s;
+      }
+    }
+    /**
+     * <code>string ip_address = 2;</code>
+     */
+    public com.google.protobuf.ByteString
+        getIpAddressBytes() {
+      java.lang.Object ref = ipAddress_;
+      if (ref instanceof java.lang.String) {
+        com.google.protobuf.ByteString b = 
+            com.google.protobuf.ByteString.copyFromUtf8(
+                (java.lang.String) ref);
+        ipAddress_ = b;
+        return b;
+      } else {
+        return (com.google.protobuf.ByteString) ref;
+      }
+    }
+
+    public static final int IF_INDEX_FIELD_NUMBER = 3;
+    private int ifIndex_;
+    /**
+     * <code>uint32 if_index = 3;</code>
+     */
+    public int getIfIndex() {
+      return ifIndex_;
+    }
+
+    public static final int PRIMARY_TYPE_FIELD_NUMBER = 4;
+    private int primaryType_;
+    /**
+     * <code>.IpInterface.PrimaryType primary_type = 4;</code>
+     */
+    public int getPrimaryTypeValue() {
+      return primaryType_;
+    }
+    /**
+     * <code>.IpInterface.PrimaryType primary_type = 4;</code>
+     */
+    public org.opennms.features.kafka.producer.model.OpennmsModelProtos.IpInterface.PrimaryType getPrimaryType() {
+      org.opennms.features.kafka.producer.model.OpennmsModelProtos.IpInterface.PrimaryType result = org.opennms.features.kafka.producer.model.OpennmsModelProtos.IpInterface.PrimaryType.valueOf(primaryType_);
+      return result == null ? org.opennms.features.kafka.producer.model.OpennmsModelProtos.IpInterface.PrimaryType.UNRECOGNIZED : result;
+    }
+
+    public static final int SERVICE_FIELD_NUMBER = 5;
+    private com.google.protobuf.LazyStringList service_;
+    /**
+     * <code>repeated string service = 5;</code>
+     */
+    public com.google.protobuf.ProtocolStringList
+        getServiceList() {
+      return service_;
+    }
+    /**
+     * <code>repeated string service = 5;</code>
+     */
+    public int getServiceCount() {
+      return service_.size();
+    }
+    /**
+     * <code>repeated string service = 5;</code>
+     */
+    public java.lang.String getService(int index) {
+      return service_.get(index);
+    }
+    /**
+     * <code>repeated string service = 5;</code>
+     */
+    public com.google.protobuf.ByteString
+        getServiceBytes(int index) {
+      return service_.getByteString(index);
+    }
+
+    private byte memoizedIsInitialized = -1;
+    public final boolean isInitialized() {
+      byte isInitialized = memoizedIsInitialized;
+      if (isInitialized == 1) return true;
+      if (isInitialized == 0) return false;
+
+      memoizedIsInitialized = 1;
+      return true;
+    }
+
+    public void writeTo(com.google.protobuf.CodedOutputStream output)
+                        throws java.io.IOException {
+      if (id_ != 0L) {
+        output.writeUInt64(1, id_);
+      }
+      if (!getIpAddressBytes().isEmpty()) {
+        com.google.protobuf.GeneratedMessageV3.writeString(output, 2, ipAddress_);
+      }
+      if (ifIndex_ != 0) {
+        output.writeUInt32(3, ifIndex_);
+      }
+      if (primaryType_ != org.opennms.features.kafka.producer.model.OpennmsModelProtos.IpInterface.PrimaryType.PRIMARY.getNumber()) {
+        output.writeEnum(4, primaryType_);
+      }
+      for (int i = 0; i < service_.size(); i++) {
+        com.google.protobuf.GeneratedMessageV3.writeString(output, 5, service_.getRaw(i));
+      }
+      unknownFields.writeTo(output);
+    }
+
+    public int getSerializedSize() {
+      int size = memoizedSize;
+      if (size != -1) return size;
+
+      size = 0;
+      if (id_ != 0L) {
+        size += com.google.protobuf.CodedOutputStream
+          .computeUInt64Size(1, id_);
+      }
+      if (!getIpAddressBytes().isEmpty()) {
+        size += com.google.protobuf.GeneratedMessageV3.computeStringSize(2, ipAddress_);
+      }
+      if (ifIndex_ != 0) {
+        size += com.google.protobuf.CodedOutputStream
+          .computeUInt32Size(3, ifIndex_);
+      }
+      if (primaryType_ != org.opennms.features.kafka.producer.model.OpennmsModelProtos.IpInterface.PrimaryType.PRIMARY.getNumber()) {
+        size += com.google.protobuf.CodedOutputStream
+          .computeEnumSize(4, primaryType_);
+      }
+      {
+        int dataSize = 0;
+        for (int i = 0; i < service_.size(); i++) {
+          dataSize += computeStringSizeNoTag(service_.getRaw(i));
+        }
+        size += dataSize;
+        size += 1 * getServiceList().size();
+      }
+      size += unknownFields.getSerializedSize();
+      memoizedSize = size;
+      return size;
+    }
+
+    @java.lang.Override
+    public boolean equals(final java.lang.Object obj) {
+      if (obj == this) {
+       return true;
+      }
+      if (!(obj instanceof org.opennms.features.kafka.producer.model.OpennmsModelProtos.IpInterface)) {
+        return super.equals(obj);
+      }
+      org.opennms.features.kafka.producer.model.OpennmsModelProtos.IpInterface other = (org.opennms.features.kafka.producer.model.OpennmsModelProtos.IpInterface) obj;
+
+      boolean result = true;
+      result = result && (getId()
+          == other.getId());
+      result = result && getIpAddress()
+          .equals(other.getIpAddress());
+      result = result && (getIfIndex()
+          == other.getIfIndex());
+      result = result && primaryType_ == other.primaryType_;
+      result = result && getServiceList()
+          .equals(other.getServiceList());
+      result = result && unknownFields.equals(other.unknownFields);
+      return result;
+    }
+
+    @java.lang.Override
+    public int hashCode() {
+      if (memoizedHashCode != 0) {
+        return memoizedHashCode;
+      }
+      int hash = 41;
+      hash = (19 * hash) + getDescriptor().hashCode();
+      hash = (37 * hash) + ID_FIELD_NUMBER;
+      hash = (53 * hash) + com.google.protobuf.Internal.hashLong(
+          getId());
+      hash = (37 * hash) + IP_ADDRESS_FIELD_NUMBER;
+      hash = (53 * hash) + getIpAddress().hashCode();
+      hash = (37 * hash) + IF_INDEX_FIELD_NUMBER;
+      hash = (53 * hash) + getIfIndex();
+      hash = (37 * hash) + PRIMARY_TYPE_FIELD_NUMBER;
+      hash = (53 * hash) + primaryType_;
+      if (getServiceCount() > 0) {
+        hash = (37 * hash) + SERVICE_FIELD_NUMBER;
+        hash = (53 * hash) + getServiceList().hashCode();
+      }
+      hash = (29 * hash) + unknownFields.hashCode();
+      memoizedHashCode = hash;
+      return hash;
+    }
+
+    public static org.opennms.features.kafka.producer.model.OpennmsModelProtos.IpInterface parseFrom(
+        java.nio.ByteBuffer data)
+        throws com.google.protobuf.InvalidProtocolBufferException {
+      return PARSER.parseFrom(data);
+    }
+    public static org.opennms.features.kafka.producer.model.OpennmsModelProtos.IpInterface parseFrom(
+        java.nio.ByteBuffer data,
+        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
+        throws com.google.protobuf.InvalidProtocolBufferException {
+      return PARSER.parseFrom(data, extensionRegistry);
+    }
+    public static org.opennms.features.kafka.producer.model.OpennmsModelProtos.IpInterface parseFrom(
+        com.google.protobuf.ByteString data)
+        throws com.google.protobuf.InvalidProtocolBufferException {
+      return PARSER.parseFrom(data);
+    }
+    public static org.opennms.features.kafka.producer.model.OpennmsModelProtos.IpInterface parseFrom(
+        com.google.protobuf.ByteString data,
+        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
+        throws com.google.protobuf.InvalidProtocolBufferException {
+      return PARSER.parseFrom(data, extensionRegistry);
+    }
+    public static org.opennms.features.kafka.producer.model.OpennmsModelProtos.IpInterface parseFrom(byte[] data)
+        throws com.google.protobuf.InvalidProtocolBufferException {
+      return PARSER.parseFrom(data);
+    }
+    public static org.opennms.features.kafka.producer.model.OpennmsModelProtos.IpInterface parseFrom(
+        byte[] data,
+        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
+        throws com.google.protobuf.InvalidProtocolBufferException {
+      return PARSER.parseFrom(data, extensionRegistry);
+    }
+    public static org.opennms.features.kafka.producer.model.OpennmsModelProtos.IpInterface parseFrom(java.io.InputStream input)
+        throws java.io.IOException {
+      return com.google.protobuf.GeneratedMessageV3
+          .parseWithIOException(PARSER, input);
+    }
+    public static org.opennms.features.kafka.producer.model.OpennmsModelProtos.IpInterface parseFrom(
+        java.io.InputStream input,
+        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
+        throws java.io.IOException {
+      return com.google.protobuf.GeneratedMessageV3
+          .parseWithIOException(PARSER, input, extensionRegistry);
+    }
+    public static org.opennms.features.kafka.producer.model.OpennmsModelProtos.IpInterface parseDelimitedFrom(java.io.InputStream input)
+        throws java.io.IOException {
+      return com.google.protobuf.GeneratedMessageV3
+          .parseDelimitedWithIOException(PARSER, input);
+    }
+    public static org.opennms.features.kafka.producer.model.OpennmsModelProtos.IpInterface parseDelimitedFrom(
+        java.io.InputStream input,
+        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
+        throws java.io.IOException {
+      return com.google.protobuf.GeneratedMessageV3
+          .parseDelimitedWithIOException(PARSER, input, extensionRegistry);
+    }
+    public static org.opennms.features.kafka.producer.model.OpennmsModelProtos.IpInterface parseFrom(
+        com.google.protobuf.CodedInputStream input)
+        throws java.io.IOException {
+      return com.google.protobuf.GeneratedMessageV3
+          .parseWithIOException(PARSER, input);
+    }
+    public static org.opennms.features.kafka.producer.model.OpennmsModelProtos.IpInterface parseFrom(
+        com.google.protobuf.CodedInputStream input,
+        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
+        throws java.io.IOException {
+      return com.google.protobuf.GeneratedMessageV3
+          .parseWithIOException(PARSER, input, extensionRegistry);
+    }
+
+    public Builder newBuilderForType() { return newBuilder(); }
+    public static Builder newBuilder() {
+      return DEFAULT_INSTANCE.toBuilder();
+    }
+    public static Builder newBuilder(org.opennms.features.kafka.producer.model.OpennmsModelProtos.IpInterface prototype) {
+      return DEFAULT_INSTANCE.toBuilder().mergeFrom(prototype);
+    }
+    public Builder toBuilder() {
+      return this == DEFAULT_INSTANCE
+          ? new Builder() : new Builder().mergeFrom(this);
+    }
+
+    @java.lang.Override
+    protected Builder newBuilderForType(
+        com.google.protobuf.GeneratedMessageV3.BuilderParent parent) {
+      Builder builder = new Builder(parent);
+      return builder;
+    }
+    /**
+     * Protobuf type {@code IpInterface}
+     */
+    public static final class Builder extends
+        com.google.protobuf.GeneratedMessageV3.Builder<Builder> implements
+        // @@protoc_insertion_point(builder_implements:IpInterface)
+        org.opennms.features.kafka.producer.model.OpennmsModelProtos.IpInterfaceOrBuilder {
+      public static final com.google.protobuf.Descriptors.Descriptor
+          getDescriptor() {
+        return org.opennms.features.kafka.producer.model.OpennmsModelProtos.internal_static_IpInterface_descriptor;
+      }
+
+      protected com.google.protobuf.GeneratedMessageV3.FieldAccessorTable
+          internalGetFieldAccessorTable() {
+        return org.opennms.features.kafka.producer.model.OpennmsModelProtos.internal_static_IpInterface_fieldAccessorTable
+            .ensureFieldAccessorsInitialized(
+                org.opennms.features.kafka.producer.model.OpennmsModelProtos.IpInterface.class, org.opennms.features.kafka.producer.model.OpennmsModelProtos.IpInterface.Builder.class);
+      }
+
+      // Construct using org.opennms.features.kafka.producer.model.OpennmsModelProtos.IpInterface.newBuilder()
+      private Builder() {
+        maybeForceBuilderInitialization();
+      }
+
+      private Builder(
+          com.google.protobuf.GeneratedMessageV3.BuilderParent parent) {
+        super(parent);
+        maybeForceBuilderInitialization();
+      }
+      private void maybeForceBuilderInitialization() {
+        if (com.google.protobuf.GeneratedMessageV3
+                .alwaysUseFieldBuilders) {
+        }
+      }
+      public Builder clear() {
+        super.clear();
+        id_ = 0L;
+
+        ipAddress_ = "";
+
+        ifIndex_ = 0;
+
+        primaryType_ = 0;
+
+        service_ = com.google.protobuf.LazyStringArrayList.EMPTY;
+        bitField0_ = (bitField0_ & ~0x00000010);
+        return this;
+      }
+
+      public com.google.protobuf.Descriptors.Descriptor
+          getDescriptorForType() {
+        return org.opennms.features.kafka.producer.model.OpennmsModelProtos.internal_static_IpInterface_descriptor;
+      }
+
+      public org.opennms.features.kafka.producer.model.OpennmsModelProtos.IpInterface getDefaultInstanceForType() {
+        return org.opennms.features.kafka.producer.model.OpennmsModelProtos.IpInterface.getDefaultInstance();
+      }
+
+      public org.opennms.features.kafka.producer.model.OpennmsModelProtos.IpInterface build() {
+        org.opennms.features.kafka.producer.model.OpennmsModelProtos.IpInterface result = buildPartial();
+        if (!result.isInitialized()) {
+          throw newUninitializedMessageException(result);
+        }
+        return result;
+      }
+
+      public org.opennms.features.kafka.producer.model.OpennmsModelProtos.IpInterface buildPartial() {
+        org.opennms.features.kafka.producer.model.OpennmsModelProtos.IpInterface result = new org.opennms.features.kafka.producer.model.OpennmsModelProtos.IpInterface(this);
+        int from_bitField0_ = bitField0_;
+        int to_bitField0_ = 0;
+        result.id_ = id_;
+        result.ipAddress_ = ipAddress_;
+        result.ifIndex_ = ifIndex_;
+        result.primaryType_ = primaryType_;
+        if (((bitField0_ & 0x00000010) == 0x00000010)) {
+          service_ = service_.getUnmodifiableView();
+          bitField0_ = (bitField0_ & ~0x00000010);
+        }
+        result.service_ = service_;
+        result.bitField0_ = to_bitField0_;
+        onBuilt();
+        return result;
+      }
+
+      public Builder clone() {
+        return (Builder) super.clone();
+      }
+      public Builder setField(
+          com.google.protobuf.Descriptors.FieldDescriptor field,
+          java.lang.Object value) {
+        return (Builder) super.setField(field, value);
+      }
+      public Builder clearField(
+          com.google.protobuf.Descriptors.FieldDescriptor field) {
+        return (Builder) super.clearField(field);
+      }
+      public Builder clearOneof(
+          com.google.protobuf.Descriptors.OneofDescriptor oneof) {
+        return (Builder) super.clearOneof(oneof);
+      }
+      public Builder setRepeatedField(
+          com.google.protobuf.Descriptors.FieldDescriptor field,
+          int index, java.lang.Object value) {
+        return (Builder) super.setRepeatedField(field, index, value);
+      }
+      public Builder addRepeatedField(
+          com.google.protobuf.Descriptors.FieldDescriptor field,
+          java.lang.Object value) {
+        return (Builder) super.addRepeatedField(field, value);
+      }
+      public Builder mergeFrom(com.google.protobuf.Message other) {
+        if (other instanceof org.opennms.features.kafka.producer.model.OpennmsModelProtos.IpInterface) {
+          return mergeFrom((org.opennms.features.kafka.producer.model.OpennmsModelProtos.IpInterface)other);
+        } else {
+          super.mergeFrom(other);
+          return this;
+        }
+      }
+
+      public Builder mergeFrom(org.opennms.features.kafka.producer.model.OpennmsModelProtos.IpInterface other) {
+        if (other == org.opennms.features.kafka.producer.model.OpennmsModelProtos.IpInterface.getDefaultInstance()) return this;
+        if (other.getId() != 0L) {
+          setId(other.getId());
+        }
+        if (!other.getIpAddress().isEmpty()) {
+          ipAddress_ = other.ipAddress_;
+          onChanged();
+        }
+        if (other.getIfIndex() != 0) {
+          setIfIndex(other.getIfIndex());
+        }
+        if (other.primaryType_ != 0) {
+          setPrimaryTypeValue(other.getPrimaryTypeValue());
+        }
+        if (!other.service_.isEmpty()) {
+          if (service_.isEmpty()) {
+            service_ = other.service_;
+            bitField0_ = (bitField0_ & ~0x00000010);
+          } else {
+            ensureServiceIsMutable();
+            service_.addAll(other.service_);
+          }
+          onChanged();
+        }
+        this.mergeUnknownFields(other.unknownFields);
+        onChanged();
+        return this;
+      }
+
+      public final boolean isInitialized() {
+        return true;
+      }
+
+      public Builder mergeFrom(
+          com.google.protobuf.CodedInputStream input,
+          com.google.protobuf.ExtensionRegistryLite extensionRegistry)
+          throws java.io.IOException {
+        org.opennms.features.kafka.producer.model.OpennmsModelProtos.IpInterface parsedMessage = null;
+        try {
+          parsedMessage = PARSER.parsePartialFrom(input, extensionRegistry);
+        } catch (com.google.protobuf.InvalidProtocolBufferException e) {
+          parsedMessage = (org.opennms.features.kafka.producer.model.OpennmsModelProtos.IpInterface) e.getUnfinishedMessage();
+          throw e.unwrapIOException();
+        } finally {
+          if (parsedMessage != null) {
+            mergeFrom(parsedMessage);
+          }
+        }
+        return this;
+      }
+      private int bitField0_;
+
+      private long id_ ;
+      /**
+       * <code>uint64 id = 1;</code>
+       */
+      public long getId() {
+        return id_;
+      }
+      /**
+       * <code>uint64 id = 1;</code>
+       */
+      public Builder setId(long value) {
+        
+        id_ = value;
+        onChanged();
+        return this;
+      }
+      /**
+       * <code>uint64 id = 1;</code>
+       */
+      public Builder clearId() {
+        
+        id_ = 0L;
+        onChanged();
+        return this;
+      }
+
+      private java.lang.Object ipAddress_ = "";
+      /**
+       * <code>string ip_address = 2;</code>
+       */
+      public java.lang.String getIpAddress() {
+        java.lang.Object ref = ipAddress_;
+        if (!(ref instanceof java.lang.String)) {
+          com.google.protobuf.ByteString bs =
+              (com.google.protobuf.ByteString) ref;
+          java.lang.String s = bs.toStringUtf8();
+          ipAddress_ = s;
+          return s;
+        } else {
+          return (java.lang.String) ref;
+        }
+      }
+      /**
+       * <code>string ip_address = 2;</code>
+       */
+      public com.google.protobuf.ByteString
+          getIpAddressBytes() {
+        java.lang.Object ref = ipAddress_;
+        if (ref instanceof String) {
+          com.google.protobuf.ByteString b = 
+              com.google.protobuf.ByteString.copyFromUtf8(
+                  (java.lang.String) ref);
+          ipAddress_ = b;
+          return b;
+        } else {
+          return (com.google.protobuf.ByteString) ref;
+        }
+      }
+      /**
+       * <code>string ip_address = 2;</code>
+       */
+      public Builder setIpAddress(
+          java.lang.String value) {
+        if (value == null) {
+    throw new NullPointerException();
+  }
+  
+        ipAddress_ = value;
+        onChanged();
+        return this;
+      }
+      /**
+       * <code>string ip_address = 2;</code>
+       */
+      public Builder clearIpAddress() {
+        
+        ipAddress_ = getDefaultInstance().getIpAddress();
+        onChanged();
+        return this;
+      }
+      /**
+       * <code>string ip_address = 2;</code>
+       */
+      public Builder setIpAddressBytes(
+          com.google.protobuf.ByteString value) {
+        if (value == null) {
+    throw new NullPointerException();
+  }
+  checkByteStringIsUtf8(value);
+        
+        ipAddress_ = value;
+        onChanged();
+        return this;
+      }
+
+      private int ifIndex_ ;
+      /**
+       * <code>uint32 if_index = 3;</code>
+       */
+      public int getIfIndex() {
+        return ifIndex_;
+      }
+      /**
+       * <code>uint32 if_index = 3;</code>
+       */
+      public Builder setIfIndex(int value) {
+        
+        ifIndex_ = value;
+        onChanged();
+        return this;
+      }
+      /**
+       * <code>uint32 if_index = 3;</code>
+       */
+      public Builder clearIfIndex() {
+        
+        ifIndex_ = 0;
+        onChanged();
+        return this;
+      }
+
+      private int primaryType_ = 0;
+      /**
+       * <code>.IpInterface.PrimaryType primary_type = 4;</code>
+       */
+      public int getPrimaryTypeValue() {
+        return primaryType_;
+      }
+      /**
+       * <code>.IpInterface.PrimaryType primary_type = 4;</code>
+       */
+      public Builder setPrimaryTypeValue(int value) {
+        primaryType_ = value;
+        onChanged();
+        return this;
+      }
+      /**
+       * <code>.IpInterface.PrimaryType primary_type = 4;</code>
+       */
+      public org.opennms.features.kafka.producer.model.OpennmsModelProtos.IpInterface.PrimaryType getPrimaryType() {
+        org.opennms.features.kafka.producer.model.OpennmsModelProtos.IpInterface.PrimaryType result = org.opennms.features.kafka.producer.model.OpennmsModelProtos.IpInterface.PrimaryType.valueOf(primaryType_);
+        return result == null ? org.opennms.features.kafka.producer.model.OpennmsModelProtos.IpInterface.PrimaryType.UNRECOGNIZED : result;
+      }
+      /**
+       * <code>.IpInterface.PrimaryType primary_type = 4;</code>
+       */
+      public Builder setPrimaryType(org.opennms.features.kafka.producer.model.OpennmsModelProtos.IpInterface.PrimaryType value) {
+        if (value == null) {
+          throw new NullPointerException();
+        }
+        
+        primaryType_ = value.getNumber();
+        onChanged();
+        return this;
+      }
+      /**
+       * <code>.IpInterface.PrimaryType primary_type = 4;</code>
+       */
+      public Builder clearPrimaryType() {
+        
+        primaryType_ = 0;
+        onChanged();
+        return this;
+      }
+
+      private com.google.protobuf.LazyStringList service_ = com.google.protobuf.LazyStringArrayList.EMPTY;
+      private void ensureServiceIsMutable() {
+        if (!((bitField0_ & 0x00000010) == 0x00000010)) {
+          service_ = new com.google.protobuf.LazyStringArrayList(service_);
+          bitField0_ |= 0x00000010;
+         }
+      }
+      /**
+       * <code>repeated string service = 5;</code>
+       */
+      public com.google.protobuf.ProtocolStringList
+          getServiceList() {
+        return service_.getUnmodifiableView();
+      }
+      /**
+       * <code>repeated string service = 5;</code>
+       */
+      public int getServiceCount() {
+        return service_.size();
+      }
+      /**
+       * <code>repeated string service = 5;</code>
+       */
+      public java.lang.String getService(int index) {
+        return service_.get(index);
+      }
+      /**
+       * <code>repeated string service = 5;</code>
+       */
+      public com.google.protobuf.ByteString
+          getServiceBytes(int index) {
+        return service_.getByteString(index);
+      }
+      /**
+       * <code>repeated string service = 5;</code>
+       */
+      public Builder setService(
+          int index, java.lang.String value) {
+        if (value == null) {
+    throw new NullPointerException();
+  }
+  ensureServiceIsMutable();
+        service_.set(index, value);
+        onChanged();
+        return this;
+      }
+      /**
+       * <code>repeated string service = 5;</code>
+       */
+      public Builder addService(
+          java.lang.String value) {
+        if (value == null) {
+    throw new NullPointerException();
+  }
+  ensureServiceIsMutable();
+        service_.add(value);
+        onChanged();
+        return this;
+      }
+      /**
+       * <code>repeated string service = 5;</code>
+       */
+      public Builder addAllService(
+          java.lang.Iterable<java.lang.String> values) {
+        ensureServiceIsMutable();
+        com.google.protobuf.AbstractMessageLite.Builder.addAll(
+            values, service_);
+        onChanged();
+        return this;
+      }
+      /**
+       * <code>repeated string service = 5;</code>
+       */
+      public Builder clearService() {
+        service_ = com.google.protobuf.LazyStringArrayList.EMPTY;
+        bitField0_ = (bitField0_ & ~0x00000010);
+        onChanged();
+        return this;
+      }
+      /**
+       * <code>repeated string service = 5;</code>
+       */
+      public Builder addServiceBytes(
+          com.google.protobuf.ByteString value) {
+        if (value == null) {
+    throw new NullPointerException();
+  }
+  checkByteStringIsUtf8(value);
+        ensureServiceIsMutable();
+        service_.add(value);
+        onChanged();
+        return this;
+      }
+      public final Builder setUnknownFields(
+          final com.google.protobuf.UnknownFieldSet unknownFields) {
+        return super.setUnknownFieldsProto3(unknownFields);
+      }
+
+      public final Builder mergeUnknownFields(
+          final com.google.protobuf.UnknownFieldSet unknownFields) {
+        return super.mergeUnknownFields(unknownFields);
+      }
+
+
+      // @@protoc_insertion_point(builder_scope:IpInterface)
+    }
+
+    // @@protoc_insertion_point(class_scope:IpInterface)
+    private static final org.opennms.features.kafka.producer.model.OpennmsModelProtos.IpInterface DEFAULT_INSTANCE;
+    static {
+      DEFAULT_INSTANCE = new org.opennms.features.kafka.producer.model.OpennmsModelProtos.IpInterface();
+    }
+
+    public static org.opennms.features.kafka.producer.model.OpennmsModelProtos.IpInterface getDefaultInstance() {
+      return DEFAULT_INSTANCE;
+    }
+
+    private static final com.google.protobuf.Parser<IpInterface>
+        PARSER = new com.google.protobuf.AbstractParser<IpInterface>() {
+      public IpInterface parsePartialFrom(
+          com.google.protobuf.CodedInputStream input,
+          com.google.protobuf.ExtensionRegistryLite extensionRegistry)
+          throws com.google.protobuf.InvalidProtocolBufferException {
+        return new IpInterface(input, extensionRegistry);
+      }
+    };
+
+    public static com.google.protobuf.Parser<IpInterface> parser() {
+      return PARSER;
+    }
+
+    @java.lang.Override
+    public com.google.protobuf.Parser<IpInterface> getParserForType() {
+      return PARSER;
+    }
+
+    public org.opennms.features.kafka.producer.model.OpennmsModelProtos.IpInterface getDefaultInstanceForType() {
+      return DEFAULT_INSTANCE;
+    }
+
+  }
+
+  public interface SnmpInterfaceOrBuilder extends
+      // @@protoc_insertion_point(interface_extends:SnmpInterface)
+      com.google.protobuf.MessageOrBuilder {
+
+    /**
+     * <code>uint64 id = 1;</code>
+     */
+    long getId();
+
+    /**
+     * <code>uint32 if_index = 2;</code>
+     */
+    int getIfIndex();
+
+    /**
+     * <code>string if_descr = 3;</code>
+     */
+    java.lang.String getIfDescr();
+    /**
+     * <code>string if_descr = 3;</code>
+     */
+    com.google.protobuf.ByteString
+        getIfDescrBytes();
+
+    /**
+     * <code>uint32 if_type = 4;</code>
+     */
+    int getIfType();
+
+    /**
+     * <code>string if_name = 5;</code>
+     */
+    java.lang.String getIfName();
+    /**
+     * <code>string if_name = 5;</code>
+     */
+    com.google.protobuf.ByteString
+        getIfNameBytes();
+
+    /**
+     * <code>uint64 if_speed = 6;</code>
+     */
+    long getIfSpeed();
+
+    /**
+     * <code>string if_phys_address = 7;</code>
+     */
+    java.lang.String getIfPhysAddress();
+    /**
+     * <code>string if_phys_address = 7;</code>
+     */
+    com.google.protobuf.ByteString
+        getIfPhysAddressBytes();
+
+    /**
+     * <code>uint32 if_admin_status = 8;</code>
+     */
+    int getIfAdminStatus();
+
+    /**
+     * <code>uint32 if_oper_status = 9;</code>
+     */
+    int getIfOperStatus();
+
+    /**
+     * <code>string if_alias = 10;</code>
+     */
+    java.lang.String getIfAlias();
+    /**
+     * <code>string if_alias = 10;</code>
+     */
+    com.google.protobuf.ByteString
+        getIfAliasBytes();
+  }
+  /**
+   * Protobuf type {@code SnmpInterface}
+   */
+  public  static final class SnmpInterface extends
+      com.google.protobuf.GeneratedMessageV3 implements
+      // @@protoc_insertion_point(message_implements:SnmpInterface)
+      SnmpInterfaceOrBuilder {
+  private static final long serialVersionUID = 0L;
+    // Use SnmpInterface.newBuilder() to construct.
+    private SnmpInterface(com.google.protobuf.GeneratedMessageV3.Builder<?> builder) {
+      super(builder);
+    }
+    private SnmpInterface() {
+      id_ = 0L;
+      ifIndex_ = 0;
+      ifDescr_ = "";
+      ifType_ = 0;
+      ifName_ = "";
+      ifSpeed_ = 0L;
+      ifPhysAddress_ = "";
+      ifAdminStatus_ = 0;
+      ifOperStatus_ = 0;
+      ifAlias_ = "";
+    }
+
+    @java.lang.Override
+    public final com.google.protobuf.UnknownFieldSet
+    getUnknownFields() {
+      return this.unknownFields;
+    }
+    private SnmpInterface(
+        com.google.protobuf.CodedInputStream input,
+        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
+        throws com.google.protobuf.InvalidProtocolBufferException {
+      this();
+      if (extensionRegistry == null) {
+        throw new java.lang.NullPointerException();
+      }
+      int mutable_bitField0_ = 0;
+      com.google.protobuf.UnknownFieldSet.Builder unknownFields =
+          com.google.protobuf.UnknownFieldSet.newBuilder();
+      try {
+        boolean done = false;
+        while (!done) {
+          int tag = input.readTag();
+          switch (tag) {
+            case 0:
+              done = true;
+              break;
+            default: {
+              if (!parseUnknownFieldProto3(
+                  input, unknownFields, extensionRegistry, tag)) {
+                done = true;
+              }
+              break;
+            }
+            case 8: {
+
+              id_ = input.readUInt64();
+              break;
+            }
+            case 16: {
+
+              ifIndex_ = input.readUInt32();
+              break;
+            }
+            case 26: {
+              java.lang.String s = input.readStringRequireUtf8();
+
+              ifDescr_ = s;
+              break;
+            }
+            case 32: {
+
+              ifType_ = input.readUInt32();
+              break;
+            }
+            case 42: {
+              java.lang.String s = input.readStringRequireUtf8();
+
+              ifName_ = s;
+              break;
+            }
+            case 48: {
+
+              ifSpeed_ = input.readUInt64();
+              break;
+            }
+            case 58: {
+              java.lang.String s = input.readStringRequireUtf8();
+
+              ifPhysAddress_ = s;
+              break;
+            }
+            case 64: {
+
+              ifAdminStatus_ = input.readUInt32();
+              break;
+            }
+            case 72: {
+
+              ifOperStatus_ = input.readUInt32();
+              break;
+            }
+            case 82: {
+              java.lang.String s = input.readStringRequireUtf8();
+
+              ifAlias_ = s;
+              break;
+            }
+          }
+        }
+      } catch (com.google.protobuf.InvalidProtocolBufferException e) {
+        throw e.setUnfinishedMessage(this);
+      } catch (java.io.IOException e) {
+        throw new com.google.protobuf.InvalidProtocolBufferException(
+            e).setUnfinishedMessage(this);
+      } finally {
+        this.unknownFields = unknownFields.build();
+        makeExtensionsImmutable();
+      }
+    }
+    public static final com.google.protobuf.Descriptors.Descriptor
+        getDescriptor() {
+      return org.opennms.features.kafka.producer.model.OpennmsModelProtos.internal_static_SnmpInterface_descriptor;
+    }
+
+    protected com.google.protobuf.GeneratedMessageV3.FieldAccessorTable
+        internalGetFieldAccessorTable() {
+      return org.opennms.features.kafka.producer.model.OpennmsModelProtos.internal_static_SnmpInterface_fieldAccessorTable
+          .ensureFieldAccessorsInitialized(
+              org.opennms.features.kafka.producer.model.OpennmsModelProtos.SnmpInterface.class, org.opennms.features.kafka.producer.model.OpennmsModelProtos.SnmpInterface.Builder.class);
+    }
+
+    public static final int ID_FIELD_NUMBER = 1;
+    private long id_;
+    /**
+     * <code>uint64 id = 1;</code>
+     */
+    public long getId() {
+      return id_;
+    }
+
+    public static final int IF_INDEX_FIELD_NUMBER = 2;
+    private int ifIndex_;
+    /**
+     * <code>uint32 if_index = 2;</code>
+     */
+    public int getIfIndex() {
+      return ifIndex_;
+    }
+
+    public static final int IF_DESCR_FIELD_NUMBER = 3;
+    private volatile java.lang.Object ifDescr_;
+    /**
+     * <code>string if_descr = 3;</code>
+     */
+    public java.lang.String getIfDescr() {
+      java.lang.Object ref = ifDescr_;
+      if (ref instanceof java.lang.String) {
+        return (java.lang.String) ref;
+      } else {
+        com.google.protobuf.ByteString bs = 
+            (com.google.protobuf.ByteString) ref;
+        java.lang.String s = bs.toStringUtf8();
+        ifDescr_ = s;
+        return s;
+      }
+    }
+    /**
+     * <code>string if_descr = 3;</code>
+     */
+    public com.google.protobuf.ByteString
+        getIfDescrBytes() {
+      java.lang.Object ref = ifDescr_;
+      if (ref instanceof java.lang.String) {
+        com.google.protobuf.ByteString b = 
+            com.google.protobuf.ByteString.copyFromUtf8(
+                (java.lang.String) ref);
+        ifDescr_ = b;
+        return b;
+      } else {
+        return (com.google.protobuf.ByteString) ref;
+      }
+    }
+
+    public static final int IF_TYPE_FIELD_NUMBER = 4;
+    private int ifType_;
+    /**
+     * <code>uint32 if_type = 4;</code>
+     */
+    public int getIfType() {
+      return ifType_;
+    }
+
+    public static final int IF_NAME_FIELD_NUMBER = 5;
+    private volatile java.lang.Object ifName_;
+    /**
+     * <code>string if_name = 5;</code>
+     */
+    public java.lang.String getIfName() {
+      java.lang.Object ref = ifName_;
+      if (ref instanceof java.lang.String) {
+        return (java.lang.String) ref;
+      } else {
+        com.google.protobuf.ByteString bs = 
+            (com.google.protobuf.ByteString) ref;
+        java.lang.String s = bs.toStringUtf8();
+        ifName_ = s;
+        return s;
+      }
+    }
+    /**
+     * <code>string if_name = 5;</code>
+     */
+    public com.google.protobuf.ByteString
+        getIfNameBytes() {
+      java.lang.Object ref = ifName_;
+      if (ref instanceof java.lang.String) {
+        com.google.protobuf.ByteString b = 
+            com.google.protobuf.ByteString.copyFromUtf8(
+                (java.lang.String) ref);
+        ifName_ = b;
+        return b;
+      } else {
+        return (com.google.protobuf.ByteString) ref;
+      }
+    }
+
+    public static final int IF_SPEED_FIELD_NUMBER = 6;
+    private long ifSpeed_;
+    /**
+     * <code>uint64 if_speed = 6;</code>
+     */
+    public long getIfSpeed() {
+      return ifSpeed_;
+    }
+
+    public static final int IF_PHYS_ADDRESS_FIELD_NUMBER = 7;
+    private volatile java.lang.Object ifPhysAddress_;
+    /**
+     * <code>string if_phys_address = 7;</code>
+     */
+    public java.lang.String getIfPhysAddress() {
+      java.lang.Object ref = ifPhysAddress_;
+      if (ref instanceof java.lang.String) {
+        return (java.lang.String) ref;
+      } else {
+        com.google.protobuf.ByteString bs = 
+            (com.google.protobuf.ByteString) ref;
+        java.lang.String s = bs.toStringUtf8();
+        ifPhysAddress_ = s;
+        return s;
+      }
+    }
+    /**
+     * <code>string if_phys_address = 7;</code>
+     */
+    public com.google.protobuf.ByteString
+        getIfPhysAddressBytes() {
+      java.lang.Object ref = ifPhysAddress_;
+      if (ref instanceof java.lang.String) {
+        com.google.protobuf.ByteString b = 
+            com.google.protobuf.ByteString.copyFromUtf8(
+                (java.lang.String) ref);
+        ifPhysAddress_ = b;
+        return b;
+      } else {
+        return (com.google.protobuf.ByteString) ref;
+      }
+    }
+
+    public static final int IF_ADMIN_STATUS_FIELD_NUMBER = 8;
+    private int ifAdminStatus_;
+    /**
+     * <code>uint32 if_admin_status = 8;</code>
+     */
+    public int getIfAdminStatus() {
+      return ifAdminStatus_;
+    }
+
+    public static final int IF_OPER_STATUS_FIELD_NUMBER = 9;
+    private int ifOperStatus_;
+    /**
+     * <code>uint32 if_oper_status = 9;</code>
+     */
+    public int getIfOperStatus() {
+      return ifOperStatus_;
+    }
+
+    public static final int IF_ALIAS_FIELD_NUMBER = 10;
+    private volatile java.lang.Object ifAlias_;
+    /**
+     * <code>string if_alias = 10;</code>
+     */
+    public java.lang.String getIfAlias() {
+      java.lang.Object ref = ifAlias_;
+      if (ref instanceof java.lang.String) {
+        return (java.lang.String) ref;
+      } else {
+        com.google.protobuf.ByteString bs = 
+            (com.google.protobuf.ByteString) ref;
+        java.lang.String s = bs.toStringUtf8();
+        ifAlias_ = s;
+        return s;
+      }
+    }
+    /**
+     * <code>string if_alias = 10;</code>
+     */
+    public com.google.protobuf.ByteString
+        getIfAliasBytes() {
+      java.lang.Object ref = ifAlias_;
+      if (ref instanceof java.lang.String) {
+        com.google.protobuf.ByteString b = 
+            com.google.protobuf.ByteString.copyFromUtf8(
+                (java.lang.String) ref);
+        ifAlias_ = b;
+        return b;
+      } else {
+        return (com.google.protobuf.ByteString) ref;
+      }
+    }
+
+    private byte memoizedIsInitialized = -1;
+    public final boolean isInitialized() {
+      byte isInitialized = memoizedIsInitialized;
+      if (isInitialized == 1) return true;
+      if (isInitialized == 0) return false;
+
+      memoizedIsInitialized = 1;
+      return true;
+    }
+
+    public void writeTo(com.google.protobuf.CodedOutputStream output)
+                        throws java.io.IOException {
+      if (id_ != 0L) {
+        output.writeUInt64(1, id_);
+      }
+      if (ifIndex_ != 0) {
+        output.writeUInt32(2, ifIndex_);
+      }
+      if (!getIfDescrBytes().isEmpty()) {
+        com.google.protobuf.GeneratedMessageV3.writeString(output, 3, ifDescr_);
+      }
+      if (ifType_ != 0) {
+        output.writeUInt32(4, ifType_);
+      }
+      if (!getIfNameBytes().isEmpty()) {
+        com.google.protobuf.GeneratedMessageV3.writeString(output, 5, ifName_);
+      }
+      if (ifSpeed_ != 0L) {
+        output.writeUInt64(6, ifSpeed_);
+      }
+      if (!getIfPhysAddressBytes().isEmpty()) {
+        com.google.protobuf.GeneratedMessageV3.writeString(output, 7, ifPhysAddress_);
+      }
+      if (ifAdminStatus_ != 0) {
+        output.writeUInt32(8, ifAdminStatus_);
+      }
+      if (ifOperStatus_ != 0) {
+        output.writeUInt32(9, ifOperStatus_);
+      }
+      if (!getIfAliasBytes().isEmpty()) {
+        com.google.protobuf.GeneratedMessageV3.writeString(output, 10, ifAlias_);
+      }
+      unknownFields.writeTo(output);
+    }
+
+    public int getSerializedSize() {
+      int size = memoizedSize;
+      if (size != -1) return size;
+
+      size = 0;
+      if (id_ != 0L) {
+        size += com.google.protobuf.CodedOutputStream
+          .computeUInt64Size(1, id_);
+      }
+      if (ifIndex_ != 0) {
+        size += com.google.protobuf.CodedOutputStream
+          .computeUInt32Size(2, ifIndex_);
+      }
+      if (!getIfDescrBytes().isEmpty()) {
+        size += com.google.protobuf.GeneratedMessageV3.computeStringSize(3, ifDescr_);
+      }
+      if (ifType_ != 0) {
+        size += com.google.protobuf.CodedOutputStream
+          .computeUInt32Size(4, ifType_);
+      }
+      if (!getIfNameBytes().isEmpty()) {
+        size += com.google.protobuf.GeneratedMessageV3.computeStringSize(5, ifName_);
+      }
+      if (ifSpeed_ != 0L) {
+        size += com.google.protobuf.CodedOutputStream
+          .computeUInt64Size(6, ifSpeed_);
+      }
+      if (!getIfPhysAddressBytes().isEmpty()) {
+        size += com.google.protobuf.GeneratedMessageV3.computeStringSize(7, ifPhysAddress_);
+      }
+      if (ifAdminStatus_ != 0) {
+        size += com.google.protobuf.CodedOutputStream
+          .computeUInt32Size(8, ifAdminStatus_);
+      }
+      if (ifOperStatus_ != 0) {
+        size += com.google.protobuf.CodedOutputStream
+          .computeUInt32Size(9, ifOperStatus_);
+      }
+      if (!getIfAliasBytes().isEmpty()) {
+        size += com.google.protobuf.GeneratedMessageV3.computeStringSize(10, ifAlias_);
+      }
+      size += unknownFields.getSerializedSize();
+      memoizedSize = size;
+      return size;
+    }
+
+    @java.lang.Override
+    public boolean equals(final java.lang.Object obj) {
+      if (obj == this) {
+       return true;
+      }
+      if (!(obj instanceof org.opennms.features.kafka.producer.model.OpennmsModelProtos.SnmpInterface)) {
+        return super.equals(obj);
+      }
+      org.opennms.features.kafka.producer.model.OpennmsModelProtos.SnmpInterface other = (org.opennms.features.kafka.producer.model.OpennmsModelProtos.SnmpInterface) obj;
+
+      boolean result = true;
+      result = result && (getId()
+          == other.getId());
+      result = result && (getIfIndex()
+          == other.getIfIndex());
+      result = result && getIfDescr()
+          .equals(other.getIfDescr());
+      result = result && (getIfType()
+          == other.getIfType());
+      result = result && getIfName()
+          .equals(other.getIfName());
+      result = result && (getIfSpeed()
+          == other.getIfSpeed());
+      result = result && getIfPhysAddress()
+          .equals(other.getIfPhysAddress());
+      result = result && (getIfAdminStatus()
+          == other.getIfAdminStatus());
+      result = result && (getIfOperStatus()
+          == other.getIfOperStatus());
+      result = result && getIfAlias()
+          .equals(other.getIfAlias());
+      result = result && unknownFields.equals(other.unknownFields);
+      return result;
+    }
+
+    @java.lang.Override
+    public int hashCode() {
+      if (memoizedHashCode != 0) {
+        return memoizedHashCode;
+      }
+      int hash = 41;
+      hash = (19 * hash) + getDescriptor().hashCode();
+      hash = (37 * hash) + ID_FIELD_NUMBER;
+      hash = (53 * hash) + com.google.protobuf.Internal.hashLong(
+          getId());
+      hash = (37 * hash) + IF_INDEX_FIELD_NUMBER;
+      hash = (53 * hash) + getIfIndex();
+      hash = (37 * hash) + IF_DESCR_FIELD_NUMBER;
+      hash = (53 * hash) + getIfDescr().hashCode();
+      hash = (37 * hash) + IF_TYPE_FIELD_NUMBER;
+      hash = (53 * hash) + getIfType();
+      hash = (37 * hash) + IF_NAME_FIELD_NUMBER;
+      hash = (53 * hash) + getIfName().hashCode();
+      hash = (37 * hash) + IF_SPEED_FIELD_NUMBER;
+      hash = (53 * hash) + com.google.protobuf.Internal.hashLong(
+          getIfSpeed());
+      hash = (37 * hash) + IF_PHYS_ADDRESS_FIELD_NUMBER;
+      hash = (53 * hash) + getIfPhysAddress().hashCode();
+      hash = (37 * hash) + IF_ADMIN_STATUS_FIELD_NUMBER;
+      hash = (53 * hash) + getIfAdminStatus();
+      hash = (37 * hash) + IF_OPER_STATUS_FIELD_NUMBER;
+      hash = (53 * hash) + getIfOperStatus();
+      hash = (37 * hash) + IF_ALIAS_FIELD_NUMBER;
+      hash = (53 * hash) + getIfAlias().hashCode();
+      hash = (29 * hash) + unknownFields.hashCode();
+      memoizedHashCode = hash;
+      return hash;
+    }
+
+    public static org.opennms.features.kafka.producer.model.OpennmsModelProtos.SnmpInterface parseFrom(
+        java.nio.ByteBuffer data)
+        throws com.google.protobuf.InvalidProtocolBufferException {
+      return PARSER.parseFrom(data);
+    }
+    public static org.opennms.features.kafka.producer.model.OpennmsModelProtos.SnmpInterface parseFrom(
+        java.nio.ByteBuffer data,
+        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
+        throws com.google.protobuf.InvalidProtocolBufferException {
+      return PARSER.parseFrom(data, extensionRegistry);
+    }
+    public static org.opennms.features.kafka.producer.model.OpennmsModelProtos.SnmpInterface parseFrom(
+        com.google.protobuf.ByteString data)
+        throws com.google.protobuf.InvalidProtocolBufferException {
+      return PARSER.parseFrom(data);
+    }
+    public static org.opennms.features.kafka.producer.model.OpennmsModelProtos.SnmpInterface parseFrom(
+        com.google.protobuf.ByteString data,
+        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
+        throws com.google.protobuf.InvalidProtocolBufferException {
+      return PARSER.parseFrom(data, extensionRegistry);
+    }
+    public static org.opennms.features.kafka.producer.model.OpennmsModelProtos.SnmpInterface parseFrom(byte[] data)
+        throws com.google.protobuf.InvalidProtocolBufferException {
+      return PARSER.parseFrom(data);
+    }
+    public static org.opennms.features.kafka.producer.model.OpennmsModelProtos.SnmpInterface parseFrom(
+        byte[] data,
+        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
+        throws com.google.protobuf.InvalidProtocolBufferException {
+      return PARSER.parseFrom(data, extensionRegistry);
+    }
+    public static org.opennms.features.kafka.producer.model.OpennmsModelProtos.SnmpInterface parseFrom(java.io.InputStream input)
+        throws java.io.IOException {
+      return com.google.protobuf.GeneratedMessageV3
+          .parseWithIOException(PARSER, input);
+    }
+    public static org.opennms.features.kafka.producer.model.OpennmsModelProtos.SnmpInterface parseFrom(
+        java.io.InputStream input,
+        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
+        throws java.io.IOException {
+      return com.google.protobuf.GeneratedMessageV3
+          .parseWithIOException(PARSER, input, extensionRegistry);
+    }
+    public static org.opennms.features.kafka.producer.model.OpennmsModelProtos.SnmpInterface parseDelimitedFrom(java.io.InputStream input)
+        throws java.io.IOException {
+      return com.google.protobuf.GeneratedMessageV3
+          .parseDelimitedWithIOException(PARSER, input);
+    }
+    public static org.opennms.features.kafka.producer.model.OpennmsModelProtos.SnmpInterface parseDelimitedFrom(
+        java.io.InputStream input,
+        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
+        throws java.io.IOException {
+      return com.google.protobuf.GeneratedMessageV3
+          .parseDelimitedWithIOException(PARSER, input, extensionRegistry);
+    }
+    public static org.opennms.features.kafka.producer.model.OpennmsModelProtos.SnmpInterface parseFrom(
+        com.google.protobuf.CodedInputStream input)
+        throws java.io.IOException {
+      return com.google.protobuf.GeneratedMessageV3
+          .parseWithIOException(PARSER, input);
+    }
+    public static org.opennms.features.kafka.producer.model.OpennmsModelProtos.SnmpInterface parseFrom(
+        com.google.protobuf.CodedInputStream input,
+        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
+        throws java.io.IOException {
+      return com.google.protobuf.GeneratedMessageV3
+          .parseWithIOException(PARSER, input, extensionRegistry);
+    }
+
+    public Builder newBuilderForType() { return newBuilder(); }
+    public static Builder newBuilder() {
+      return DEFAULT_INSTANCE.toBuilder();
+    }
+    public static Builder newBuilder(org.opennms.features.kafka.producer.model.OpennmsModelProtos.SnmpInterface prototype) {
+      return DEFAULT_INSTANCE.toBuilder().mergeFrom(prototype);
+    }
+    public Builder toBuilder() {
+      return this == DEFAULT_INSTANCE
+          ? new Builder() : new Builder().mergeFrom(this);
+    }
+
+    @java.lang.Override
+    protected Builder newBuilderForType(
+        com.google.protobuf.GeneratedMessageV3.BuilderParent parent) {
+      Builder builder = new Builder(parent);
+      return builder;
+    }
+    /**
+     * Protobuf type {@code SnmpInterface}
+     */
+    public static final class Builder extends
+        com.google.protobuf.GeneratedMessageV3.Builder<Builder> implements
+        // @@protoc_insertion_point(builder_implements:SnmpInterface)
+        org.opennms.features.kafka.producer.model.OpennmsModelProtos.SnmpInterfaceOrBuilder {
+      public static final com.google.protobuf.Descriptors.Descriptor
+          getDescriptor() {
+        return org.opennms.features.kafka.producer.model.OpennmsModelProtos.internal_static_SnmpInterface_descriptor;
+      }
+
+      protected com.google.protobuf.GeneratedMessageV3.FieldAccessorTable
+          internalGetFieldAccessorTable() {
+        return org.opennms.features.kafka.producer.model.OpennmsModelProtos.internal_static_SnmpInterface_fieldAccessorTable
+            .ensureFieldAccessorsInitialized(
+                org.opennms.features.kafka.producer.model.OpennmsModelProtos.SnmpInterface.class, org.opennms.features.kafka.producer.model.OpennmsModelProtos.SnmpInterface.Builder.class);
+      }
+
+      // Construct using org.opennms.features.kafka.producer.model.OpennmsModelProtos.SnmpInterface.newBuilder()
+      private Builder() {
+        maybeForceBuilderInitialization();
+      }
+
+      private Builder(
+          com.google.protobuf.GeneratedMessageV3.BuilderParent parent) {
+        super(parent);
+        maybeForceBuilderInitialization();
+      }
+      private void maybeForceBuilderInitialization() {
+        if (com.google.protobuf.GeneratedMessageV3
+                .alwaysUseFieldBuilders) {
+        }
+      }
+      public Builder clear() {
+        super.clear();
+        id_ = 0L;
+
+        ifIndex_ = 0;
+
+        ifDescr_ = "";
+
+        ifType_ = 0;
+
+        ifName_ = "";
+
+        ifSpeed_ = 0L;
+
+        ifPhysAddress_ = "";
+
+        ifAdminStatus_ = 0;
+
+        ifOperStatus_ = 0;
+
+        ifAlias_ = "";
+
+        return this;
+      }
+
+      public com.google.protobuf.Descriptors.Descriptor
+          getDescriptorForType() {
+        return org.opennms.features.kafka.producer.model.OpennmsModelProtos.internal_static_SnmpInterface_descriptor;
+      }
+
+      public org.opennms.features.kafka.producer.model.OpennmsModelProtos.SnmpInterface getDefaultInstanceForType() {
+        return org.opennms.features.kafka.producer.model.OpennmsModelProtos.SnmpInterface.getDefaultInstance();
+      }
+
+      public org.opennms.features.kafka.producer.model.OpennmsModelProtos.SnmpInterface build() {
+        org.opennms.features.kafka.producer.model.OpennmsModelProtos.SnmpInterface result = buildPartial();
+        if (!result.isInitialized()) {
+          throw newUninitializedMessageException(result);
+        }
+        return result;
+      }
+
+      public org.opennms.features.kafka.producer.model.OpennmsModelProtos.SnmpInterface buildPartial() {
+        org.opennms.features.kafka.producer.model.OpennmsModelProtos.SnmpInterface result = new org.opennms.features.kafka.producer.model.OpennmsModelProtos.SnmpInterface(this);
+        result.id_ = id_;
+        result.ifIndex_ = ifIndex_;
+        result.ifDescr_ = ifDescr_;
+        result.ifType_ = ifType_;
+        result.ifName_ = ifName_;
+        result.ifSpeed_ = ifSpeed_;
+        result.ifPhysAddress_ = ifPhysAddress_;
+        result.ifAdminStatus_ = ifAdminStatus_;
+        result.ifOperStatus_ = ifOperStatus_;
+        result.ifAlias_ = ifAlias_;
+        onBuilt();
+        return result;
+      }
+
+      public Builder clone() {
+        return (Builder) super.clone();
+      }
+      public Builder setField(
+          com.google.protobuf.Descriptors.FieldDescriptor field,
+          java.lang.Object value) {
+        return (Builder) super.setField(field, value);
+      }
+      public Builder clearField(
+          com.google.protobuf.Descriptors.FieldDescriptor field) {
+        return (Builder) super.clearField(field);
+      }
+      public Builder clearOneof(
+          com.google.protobuf.Descriptors.OneofDescriptor oneof) {
+        return (Builder) super.clearOneof(oneof);
+      }
+      public Builder setRepeatedField(
+          com.google.protobuf.Descriptors.FieldDescriptor field,
+          int index, java.lang.Object value) {
+        return (Builder) super.setRepeatedField(field, index, value);
+      }
+      public Builder addRepeatedField(
+          com.google.protobuf.Descriptors.FieldDescriptor field,
+          java.lang.Object value) {
+        return (Builder) super.addRepeatedField(field, value);
+      }
+      public Builder mergeFrom(com.google.protobuf.Message other) {
+        if (other instanceof org.opennms.features.kafka.producer.model.OpennmsModelProtos.SnmpInterface) {
+          return mergeFrom((org.opennms.features.kafka.producer.model.OpennmsModelProtos.SnmpInterface)other);
+        } else {
+          super.mergeFrom(other);
+          return this;
+        }
+      }
+
+      public Builder mergeFrom(org.opennms.features.kafka.producer.model.OpennmsModelProtos.SnmpInterface other) {
+        if (other == org.opennms.features.kafka.producer.model.OpennmsModelProtos.SnmpInterface.getDefaultInstance()) return this;
+        if (other.getId() != 0L) {
+          setId(other.getId());
+        }
+        if (other.getIfIndex() != 0) {
+          setIfIndex(other.getIfIndex());
+        }
+        if (!other.getIfDescr().isEmpty()) {
+          ifDescr_ = other.ifDescr_;
+          onChanged();
+        }
+        if (other.getIfType() != 0) {
+          setIfType(other.getIfType());
+        }
+        if (!other.getIfName().isEmpty()) {
+          ifName_ = other.ifName_;
+          onChanged();
+        }
+        if (other.getIfSpeed() != 0L) {
+          setIfSpeed(other.getIfSpeed());
+        }
+        if (!other.getIfPhysAddress().isEmpty()) {
+          ifPhysAddress_ = other.ifPhysAddress_;
+          onChanged();
+        }
+        if (other.getIfAdminStatus() != 0) {
+          setIfAdminStatus(other.getIfAdminStatus());
+        }
+        if (other.getIfOperStatus() != 0) {
+          setIfOperStatus(other.getIfOperStatus());
+        }
+        if (!other.getIfAlias().isEmpty()) {
+          ifAlias_ = other.ifAlias_;
+          onChanged();
+        }
+        this.mergeUnknownFields(other.unknownFields);
+        onChanged();
+        return this;
+      }
+
+      public final boolean isInitialized() {
+        return true;
+      }
+
+      public Builder mergeFrom(
+          com.google.protobuf.CodedInputStream input,
+          com.google.protobuf.ExtensionRegistryLite extensionRegistry)
+          throws java.io.IOException {
+        org.opennms.features.kafka.producer.model.OpennmsModelProtos.SnmpInterface parsedMessage = null;
+        try {
+          parsedMessage = PARSER.parsePartialFrom(input, extensionRegistry);
+        } catch (com.google.protobuf.InvalidProtocolBufferException e) {
+          parsedMessage = (org.opennms.features.kafka.producer.model.OpennmsModelProtos.SnmpInterface) e.getUnfinishedMessage();
+          throw e.unwrapIOException();
+        } finally {
+          if (parsedMessage != null) {
+            mergeFrom(parsedMessage);
+          }
+        }
+        return this;
+      }
+
+      private long id_ ;
+      /**
+       * <code>uint64 id = 1;</code>
+       */
+      public long getId() {
+        return id_;
+      }
+      /**
+       * <code>uint64 id = 1;</code>
+       */
+      public Builder setId(long value) {
+        
+        id_ = value;
+        onChanged();
+        return this;
+      }
+      /**
+       * <code>uint64 id = 1;</code>
+       */
+      public Builder clearId() {
+        
+        id_ = 0L;
+        onChanged();
+        return this;
+      }
+
+      private int ifIndex_ ;
+      /**
+       * <code>uint32 if_index = 2;</code>
+       */
+      public int getIfIndex() {
+        return ifIndex_;
+      }
+      /**
+       * <code>uint32 if_index = 2;</code>
+       */
+      public Builder setIfIndex(int value) {
+        
+        ifIndex_ = value;
+        onChanged();
+        return this;
+      }
+      /**
+       * <code>uint32 if_index = 2;</code>
+       */
+      public Builder clearIfIndex() {
+        
+        ifIndex_ = 0;
+        onChanged();
+        return this;
+      }
+
+      private java.lang.Object ifDescr_ = "";
+      /**
+       * <code>string if_descr = 3;</code>
+       */
+      public java.lang.String getIfDescr() {
+        java.lang.Object ref = ifDescr_;
+        if (!(ref instanceof java.lang.String)) {
+          com.google.protobuf.ByteString bs =
+              (com.google.protobuf.ByteString) ref;
+          java.lang.String s = bs.toStringUtf8();
+          ifDescr_ = s;
+          return s;
+        } else {
+          return (java.lang.String) ref;
+        }
+      }
+      /**
+       * <code>string if_descr = 3;</code>
+       */
+      public com.google.protobuf.ByteString
+          getIfDescrBytes() {
+        java.lang.Object ref = ifDescr_;
+        if (ref instanceof String) {
+          com.google.protobuf.ByteString b = 
+              com.google.protobuf.ByteString.copyFromUtf8(
+                  (java.lang.String) ref);
+          ifDescr_ = b;
+          return b;
+        } else {
+          return (com.google.protobuf.ByteString) ref;
+        }
+      }
+      /**
+       * <code>string if_descr = 3;</code>
+       */
+      public Builder setIfDescr(
+          java.lang.String value) {
+        if (value == null) {
+    throw new NullPointerException();
+  }
+  
+        ifDescr_ = value;
+        onChanged();
+        return this;
+      }
+      /**
+       * <code>string if_descr = 3;</code>
+       */
+      public Builder clearIfDescr() {
+        
+        ifDescr_ = getDefaultInstance().getIfDescr();
+        onChanged();
+        return this;
+      }
+      /**
+       * <code>string if_descr = 3;</code>
+       */
+      public Builder setIfDescrBytes(
+          com.google.protobuf.ByteString value) {
+        if (value == null) {
+    throw new NullPointerException();
+  }
+  checkByteStringIsUtf8(value);
+        
+        ifDescr_ = value;
+        onChanged();
+        return this;
+      }
+
+      private int ifType_ ;
+      /**
+       * <code>uint32 if_type = 4;</code>
+       */
+      public int getIfType() {
+        return ifType_;
+      }
+      /**
+       * <code>uint32 if_type = 4;</code>
+       */
+      public Builder setIfType(int value) {
+        
+        ifType_ = value;
+        onChanged();
+        return this;
+      }
+      /**
+       * <code>uint32 if_type = 4;</code>
+       */
+      public Builder clearIfType() {
+        
+        ifType_ = 0;
+        onChanged();
+        return this;
+      }
+
+      private java.lang.Object ifName_ = "";
+      /**
+       * <code>string if_name = 5;</code>
+       */
+      public java.lang.String getIfName() {
+        java.lang.Object ref = ifName_;
+        if (!(ref instanceof java.lang.String)) {
+          com.google.protobuf.ByteString bs =
+              (com.google.protobuf.ByteString) ref;
+          java.lang.String s = bs.toStringUtf8();
+          ifName_ = s;
+          return s;
+        } else {
+          return (java.lang.String) ref;
+        }
+      }
+      /**
+       * <code>string if_name = 5;</code>
+       */
+      public com.google.protobuf.ByteString
+          getIfNameBytes() {
+        java.lang.Object ref = ifName_;
+        if (ref instanceof String) {
+          com.google.protobuf.ByteString b = 
+              com.google.protobuf.ByteString.copyFromUtf8(
+                  (java.lang.String) ref);
+          ifName_ = b;
+          return b;
+        } else {
+          return (com.google.protobuf.ByteString) ref;
+        }
+      }
+      /**
+       * <code>string if_name = 5;</code>
+       */
+      public Builder setIfName(
+          java.lang.String value) {
+        if (value == null) {
+    throw new NullPointerException();
+  }
+  
+        ifName_ = value;
+        onChanged();
+        return this;
+      }
+      /**
+       * <code>string if_name = 5;</code>
+       */
+      public Builder clearIfName() {
+        
+        ifName_ = getDefaultInstance().getIfName();
+        onChanged();
+        return this;
+      }
+      /**
+       * <code>string if_name = 5;</code>
+       */
+      public Builder setIfNameBytes(
+          com.google.protobuf.ByteString value) {
+        if (value == null) {
+    throw new NullPointerException();
+  }
+  checkByteStringIsUtf8(value);
+        
+        ifName_ = value;
+        onChanged();
+        return this;
+      }
+
+      private long ifSpeed_ ;
+      /**
+       * <code>uint64 if_speed = 6;</code>
+       */
+      public long getIfSpeed() {
+        return ifSpeed_;
+      }
+      /**
+       * <code>uint64 if_speed = 6;</code>
+       */
+      public Builder setIfSpeed(long value) {
+        
+        ifSpeed_ = value;
+        onChanged();
+        return this;
+      }
+      /**
+       * <code>uint64 if_speed = 6;</code>
+       */
+      public Builder clearIfSpeed() {
+        
+        ifSpeed_ = 0L;
+        onChanged();
+        return this;
+      }
+
+      private java.lang.Object ifPhysAddress_ = "";
+      /**
+       * <code>string if_phys_address = 7;</code>
+       */
+      public java.lang.String getIfPhysAddress() {
+        java.lang.Object ref = ifPhysAddress_;
+        if (!(ref instanceof java.lang.String)) {
+          com.google.protobuf.ByteString bs =
+              (com.google.protobuf.ByteString) ref;
+          java.lang.String s = bs.toStringUtf8();
+          ifPhysAddress_ = s;
+          return s;
+        } else {
+          return (java.lang.String) ref;
+        }
+      }
+      /**
+       * <code>string if_phys_address = 7;</code>
+       */
+      public com.google.protobuf.ByteString
+          getIfPhysAddressBytes() {
+        java.lang.Object ref = ifPhysAddress_;
+        if (ref instanceof String) {
+          com.google.protobuf.ByteString b = 
+              com.google.protobuf.ByteString.copyFromUtf8(
+                  (java.lang.String) ref);
+          ifPhysAddress_ = b;
+          return b;
+        } else {
+          return (com.google.protobuf.ByteString) ref;
+        }
+      }
+      /**
+       * <code>string if_phys_address = 7;</code>
+       */
+      public Builder setIfPhysAddress(
+          java.lang.String value) {
+        if (value == null) {
+    throw new NullPointerException();
+  }
+  
+        ifPhysAddress_ = value;
+        onChanged();
+        return this;
+      }
+      /**
+       * <code>string if_phys_address = 7;</code>
+       */
+      public Builder clearIfPhysAddress() {
+        
+        ifPhysAddress_ = getDefaultInstance().getIfPhysAddress();
+        onChanged();
+        return this;
+      }
+      /**
+       * <code>string if_phys_address = 7;</code>
+       */
+      public Builder setIfPhysAddressBytes(
+          com.google.protobuf.ByteString value) {
+        if (value == null) {
+    throw new NullPointerException();
+  }
+  checkByteStringIsUtf8(value);
+        
+        ifPhysAddress_ = value;
+        onChanged();
+        return this;
+      }
+
+      private int ifAdminStatus_ ;
+      /**
+       * <code>uint32 if_admin_status = 8;</code>
+       */
+      public int getIfAdminStatus() {
+        return ifAdminStatus_;
+      }
+      /**
+       * <code>uint32 if_admin_status = 8;</code>
+       */
+      public Builder setIfAdminStatus(int value) {
+        
+        ifAdminStatus_ = value;
+        onChanged();
+        return this;
+      }
+      /**
+       * <code>uint32 if_admin_status = 8;</code>
+       */
+      public Builder clearIfAdminStatus() {
+        
+        ifAdminStatus_ = 0;
+        onChanged();
+        return this;
+      }
+
+      private int ifOperStatus_ ;
+      /**
+       * <code>uint32 if_oper_status = 9;</code>
+       */
+      public int getIfOperStatus() {
+        return ifOperStatus_;
+      }
+      /**
+       * <code>uint32 if_oper_status = 9;</code>
+       */
+      public Builder setIfOperStatus(int value) {
+        
+        ifOperStatus_ = value;
+        onChanged();
+        return this;
+      }
+      /**
+       * <code>uint32 if_oper_status = 9;</code>
+       */
+      public Builder clearIfOperStatus() {
+        
+        ifOperStatus_ = 0;
+        onChanged();
+        return this;
+      }
+
+      private java.lang.Object ifAlias_ = "";
+      /**
+       * <code>string if_alias = 10;</code>
+       */
+      public java.lang.String getIfAlias() {
+        java.lang.Object ref = ifAlias_;
+        if (!(ref instanceof java.lang.String)) {
+          com.google.protobuf.ByteString bs =
+              (com.google.protobuf.ByteString) ref;
+          java.lang.String s = bs.toStringUtf8();
+          ifAlias_ = s;
+          return s;
+        } else {
+          return (java.lang.String) ref;
+        }
+      }
+      /**
+       * <code>string if_alias = 10;</code>
+       */
+      public com.google.protobuf.ByteString
+          getIfAliasBytes() {
+        java.lang.Object ref = ifAlias_;
+        if (ref instanceof String) {
+          com.google.protobuf.ByteString b = 
+              com.google.protobuf.ByteString.copyFromUtf8(
+                  (java.lang.String) ref);
+          ifAlias_ = b;
+          return b;
+        } else {
+          return (com.google.protobuf.ByteString) ref;
+        }
+      }
+      /**
+       * <code>string if_alias = 10;</code>
+       */
+      public Builder setIfAlias(
+          java.lang.String value) {
+        if (value == null) {
+    throw new NullPointerException();
+  }
+  
+        ifAlias_ = value;
+        onChanged();
+        return this;
+      }
+      /**
+       * <code>string if_alias = 10;</code>
+       */
+      public Builder clearIfAlias() {
+        
+        ifAlias_ = getDefaultInstance().getIfAlias();
+        onChanged();
+        return this;
+      }
+      /**
+       * <code>string if_alias = 10;</code>
+       */
+      public Builder setIfAliasBytes(
+          com.google.protobuf.ByteString value) {
+        if (value == null) {
+    throw new NullPointerException();
+  }
+  checkByteStringIsUtf8(value);
+        
+        ifAlias_ = value;
+        onChanged();
+        return this;
+      }
+      public final Builder setUnknownFields(
+          final com.google.protobuf.UnknownFieldSet unknownFields) {
+        return super.setUnknownFieldsProto3(unknownFields);
+      }
+
+      public final Builder mergeUnknownFields(
+          final com.google.protobuf.UnknownFieldSet unknownFields) {
+        return super.mergeUnknownFields(unknownFields);
+      }
+
+
+      // @@protoc_insertion_point(builder_scope:SnmpInterface)
+    }
+
+    // @@protoc_insertion_point(class_scope:SnmpInterface)
+    private static final org.opennms.features.kafka.producer.model.OpennmsModelProtos.SnmpInterface DEFAULT_INSTANCE;
+    static {
+      DEFAULT_INSTANCE = new org.opennms.features.kafka.producer.model.OpennmsModelProtos.SnmpInterface();
+    }
+
+    public static org.opennms.features.kafka.producer.model.OpennmsModelProtos.SnmpInterface getDefaultInstance() {
+      return DEFAULT_INSTANCE;
+    }
+
+    private static final com.google.protobuf.Parser<SnmpInterface>
+        PARSER = new com.google.protobuf.AbstractParser<SnmpInterface>() {
+      public SnmpInterface parsePartialFrom(
+          com.google.protobuf.CodedInputStream input,
+          com.google.protobuf.ExtensionRegistryLite extensionRegistry)
+          throws com.google.protobuf.InvalidProtocolBufferException {
+        return new SnmpInterface(input, extensionRegistry);
+      }
+    };
+
+    public static com.google.protobuf.Parser<SnmpInterface> parser() {
+      return PARSER;
+    }
+
+    @java.lang.Override
+    public com.google.protobuf.Parser<SnmpInterface> getParserForType() {
+      return PARSER;
+    }
+
+    public org.opennms.features.kafka.producer.model.OpennmsModelProtos.SnmpInterface getDefaultInstanceForType() {
+      return DEFAULT_INSTANCE;
+    }
+
+  }
+
+  public interface NodeOrBuilder extends
+      // @@protoc_insertion_point(interface_extends:Node)
+      com.google.protobuf.MessageOrBuilder {
+
+    /**
+     * <code>uint64 id = 1;</code>
+     */
+    long getId();
+
+    /**
+     * <code>string foreign_source = 2;</code>
+     */
+    java.lang.String getForeignSource();
+    /**
+     * <code>string foreign_source = 2;</code>
+     */
+    com.google.protobuf.ByteString
+        getForeignSourceBytes();
+
+    /**
+     * <code>string foreign_id = 3;</code>
+     */
+    java.lang.String getForeignId();
+    /**
+     * <code>string foreign_id = 3;</code>
+     */
+    com.google.protobuf.ByteString
+        getForeignIdBytes();
+
+    /**
+     * <code>string location = 4;</code>
+     */
+    java.lang.String getLocation();
+    /**
+     * <code>string location = 4;</code>
+     */
+    com.google.protobuf.ByteString
+        getLocationBytes();
+
+    /**
+     * <code>repeated string category = 5;</code>
+     */
+    java.util.List<java.lang.String>
+        getCategoryList();
+    /**
+     * <code>repeated string category = 5;</code>
+     */
+    int getCategoryCount();
+    /**
+     * <code>repeated string category = 5;</code>
+     */
+    java.lang.String getCategory(int index);
+    /**
+     * <code>repeated string category = 5;</code>
+     */
+    com.google.protobuf.ByteString
+        getCategoryBytes(int index);
+
+    /**
+     * <code>string label = 6;</code>
+     */
+    java.lang.String getLabel();
+    /**
+     * <code>string label = 6;</code>
+     */
+    com.google.protobuf.ByteString
+        getLabelBytes();
+
+    /**
+     * <code>uint64 create_time = 7;</code>
+     */
+    long getCreateTime();
+
+    /**
+     * <code>string sys_contact = 8;</code>
+     */
+    java.lang.String getSysContact();
+    /**
+     * <code>string sys_contact = 8;</code>
+     */
+    com.google.protobuf.ByteString
+        getSysContactBytes();
+
+    /**
+     * <code>string sys_description = 9;</code>
+     */
+    java.lang.String getSysDescription();
+    /**
+     * <code>string sys_description = 9;</code>
+     */
+    com.google.protobuf.ByteString
+        getSysDescriptionBytes();
+
+    /**
+     * <code>string sys_object_id = 10;</code>
+     */
+    java.lang.String getSysObjectId();
+    /**
+     * <code>string sys_object_id = 10;</code>
+     */
+    com.google.protobuf.ByteString
+        getSysObjectIdBytes();
+
+    /**
+     * <code>repeated .IpInterface ip_interface = 11;</code>
+     */
+    java.util.List<org.opennms.features.kafka.producer.model.OpennmsModelProtos.IpInterface> 
+        getIpInterfaceList();
+    /**
+     * <code>repeated .IpInterface ip_interface = 11;</code>
+     */
+    org.opennms.features.kafka.producer.model.OpennmsModelProtos.IpInterface getIpInterface(int index);
+    /**
+     * <code>repeated .IpInterface ip_interface = 11;</code>
+     */
+    int getIpInterfaceCount();
+    /**
+     * <code>repeated .IpInterface ip_interface = 11;</code>
+     */
+    java.util.List<? extends org.opennms.features.kafka.producer.model.OpennmsModelProtos.IpInterfaceOrBuilder> 
+        getIpInterfaceOrBuilderList();
+    /**
+     * <code>repeated .IpInterface ip_interface = 11;</code>
+     */
+    org.opennms.features.kafka.producer.model.OpennmsModelProtos.IpInterfaceOrBuilder getIpInterfaceOrBuilder(
+        int index);
+
+    /**
+     * <code>repeated .SnmpInterface snmp_interface = 12;</code>
+     */
+    java.util.List<org.opennms.features.kafka.producer.model.OpennmsModelProtos.SnmpInterface> 
+        getSnmpInterfaceList();
+    /**
+     * <code>repeated .SnmpInterface snmp_interface = 12;</code>
+     */
+    org.opennms.features.kafka.producer.model.OpennmsModelProtos.SnmpInterface getSnmpInterface(int index);
+    /**
+     * <code>repeated .SnmpInterface snmp_interface = 12;</code>
+     */
+    int getSnmpInterfaceCount();
+    /**
+     * <code>repeated .SnmpInterface snmp_interface = 12;</code>
+     */
+    java.util.List<? extends org.opennms.features.kafka.producer.model.OpennmsModelProtos.SnmpInterfaceOrBuilder> 
+        getSnmpInterfaceOrBuilderList();
+    /**
+     * <code>repeated .SnmpInterface snmp_interface = 12;</code>
+     */
+    org.opennms.features.kafka.producer.model.OpennmsModelProtos.SnmpInterfaceOrBuilder getSnmpInterfaceOrBuilder(
+        int index);
+  }
+  /**
+   * Protobuf type {@code Node}
+   */
+  public  static final class Node extends
+      com.google.protobuf.GeneratedMessageV3 implements
+      // @@protoc_insertion_point(message_implements:Node)
+      NodeOrBuilder {
+  private static final long serialVersionUID = 0L;
+    // Use Node.newBuilder() to construct.
+    private Node(com.google.protobuf.GeneratedMessageV3.Builder<?> builder) {
+      super(builder);
+    }
+    private Node() {
+      id_ = 0L;
+      foreignSource_ = "";
+      foreignId_ = "";
+      location_ = "";
+      category_ = com.google.protobuf.LazyStringArrayList.EMPTY;
+      label_ = "";
+      createTime_ = 0L;
+      sysContact_ = "";
+      sysDescription_ = "";
+      sysObjectId_ = "";
+      ipInterface_ = java.util.Collections.emptyList();
+      snmpInterface_ = java.util.Collections.emptyList();
+    }
+
+    @java.lang.Override
+    public final com.google.protobuf.UnknownFieldSet
+    getUnknownFields() {
+      return this.unknownFields;
+    }
+    private Node(
+        com.google.protobuf.CodedInputStream input,
+        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
+        throws com.google.protobuf.InvalidProtocolBufferException {
+      this();
+      if (extensionRegistry == null) {
+        throw new java.lang.NullPointerException();
+      }
+      int mutable_bitField0_ = 0;
+      com.google.protobuf.UnknownFieldSet.Builder unknownFields =
+          com.google.protobuf.UnknownFieldSet.newBuilder();
+      try {
+        boolean done = false;
+        while (!done) {
+          int tag = input.readTag();
+          switch (tag) {
+            case 0:
+              done = true;
+              break;
+            default: {
+              if (!parseUnknownFieldProto3(
+                  input, unknownFields, extensionRegistry, tag)) {
+                done = true;
+              }
+              break;
+            }
+            case 8: {
+
+              id_ = input.readUInt64();
+              break;
+            }
+            case 18: {
+              java.lang.String s = input.readStringRequireUtf8();
+
+              foreignSource_ = s;
+              break;
+            }
+            case 26: {
+              java.lang.String s = input.readStringRequireUtf8();
+
+              foreignId_ = s;
+              break;
+            }
+            case 34: {
+              java.lang.String s = input.readStringRequireUtf8();
+
+              location_ = s;
+              break;
+            }
+            case 42: {
+              java.lang.String s = input.readStringRequireUtf8();
+              if (!((mutable_bitField0_ & 0x00000010) == 0x00000010)) {
+                category_ = new com.google.protobuf.LazyStringArrayList();
+                mutable_bitField0_ |= 0x00000010;
+              }
+              category_.add(s);
+              break;
+            }
+            case 50: {
+              java.lang.String s = input.readStringRequireUtf8();
+
+              label_ = s;
+              break;
+            }
+            case 56: {
+
+              createTime_ = input.readUInt64();
+              break;
+            }
+            case 66: {
+              java.lang.String s = input.readStringRequireUtf8();
+
+              sysContact_ = s;
+              break;
+            }
+            case 74: {
+              java.lang.String s = input.readStringRequireUtf8();
+
+              sysDescription_ = s;
+              break;
+            }
+            case 82: {
+              java.lang.String s = input.readStringRequireUtf8();
+
+              sysObjectId_ = s;
+              break;
+            }
+            case 90: {
+              if (!((mutable_bitField0_ & 0x00000400) == 0x00000400)) {
+                ipInterface_ = new java.util.ArrayList<org.opennms.features.kafka.producer.model.OpennmsModelProtos.IpInterface>();
+                mutable_bitField0_ |= 0x00000400;
+              }
+              ipInterface_.add(
+                  input.readMessage(org.opennms.features.kafka.producer.model.OpennmsModelProtos.IpInterface.parser(), extensionRegistry));
+              break;
+            }
+            case 98: {
+              if (!((mutable_bitField0_ & 0x00000800) == 0x00000800)) {
+                snmpInterface_ = new java.util.ArrayList<org.opennms.features.kafka.producer.model.OpennmsModelProtos.SnmpInterface>();
+                mutable_bitField0_ |= 0x00000800;
+              }
+              snmpInterface_.add(
+                  input.readMessage(org.opennms.features.kafka.producer.model.OpennmsModelProtos.SnmpInterface.parser(), extensionRegistry));
+              break;
+            }
+          }
+        }
+      } catch (com.google.protobuf.InvalidProtocolBufferException e) {
+        throw e.setUnfinishedMessage(this);
+      } catch (java.io.IOException e) {
+        throw new com.google.protobuf.InvalidProtocolBufferException(
+            e).setUnfinishedMessage(this);
+      } finally {
+        if (((mutable_bitField0_ & 0x00000010) == 0x00000010)) {
+          category_ = category_.getUnmodifiableView();
+        }
+        if (((mutable_bitField0_ & 0x00000400) == 0x00000400)) {
+          ipInterface_ = java.util.Collections.unmodifiableList(ipInterface_);
+        }
+        if (((mutable_bitField0_ & 0x00000800) == 0x00000800)) {
+          snmpInterface_ = java.util.Collections.unmodifiableList(snmpInterface_);
+        }
+        this.unknownFields = unknownFields.build();
+        makeExtensionsImmutable();
+      }
+    }
+    public static final com.google.protobuf.Descriptors.Descriptor
+        getDescriptor() {
+      return org.opennms.features.kafka.producer.model.OpennmsModelProtos.internal_static_Node_descriptor;
+    }
+
+    protected com.google.protobuf.GeneratedMessageV3.FieldAccessorTable
+        internalGetFieldAccessorTable() {
+      return org.opennms.features.kafka.producer.model.OpennmsModelProtos.internal_static_Node_fieldAccessorTable
+          .ensureFieldAccessorsInitialized(
+              org.opennms.features.kafka.producer.model.OpennmsModelProtos.Node.class, org.opennms.features.kafka.producer.model.OpennmsModelProtos.Node.Builder.class);
+    }
+
+    private int bitField0_;
+    public static final int ID_FIELD_NUMBER = 1;
+    private long id_;
+    /**
+     * <code>uint64 id = 1;</code>
+     */
+    public long getId() {
+      return id_;
+    }
+
+    public static final int FOREIGN_SOURCE_FIELD_NUMBER = 2;
+    private volatile java.lang.Object foreignSource_;
+    /**
+     * <code>string foreign_source = 2;</code>
+     */
+    public java.lang.String getForeignSource() {
+      java.lang.Object ref = foreignSource_;
+      if (ref instanceof java.lang.String) {
+        return (java.lang.String) ref;
+      } else {
+        com.google.protobuf.ByteString bs = 
+            (com.google.protobuf.ByteString) ref;
+        java.lang.String s = bs.toStringUtf8();
+        foreignSource_ = s;
+        return s;
+      }
+    }
+    /**
+     * <code>string foreign_source = 2;</code>
+     */
+    public com.google.protobuf.ByteString
+        getForeignSourceBytes() {
+      java.lang.Object ref = foreignSource_;
+      if (ref instanceof java.lang.String) {
+        com.google.protobuf.ByteString b = 
+            com.google.protobuf.ByteString.copyFromUtf8(
+                (java.lang.String) ref);
+        foreignSource_ = b;
+        return b;
+      } else {
+        return (com.google.protobuf.ByteString) ref;
+      }
+    }
+
+    public static final int FOREIGN_ID_FIELD_NUMBER = 3;
+    private volatile java.lang.Object foreignId_;
+    /**
+     * <code>string foreign_id = 3;</code>
+     */
+    public java.lang.String getForeignId() {
+      java.lang.Object ref = foreignId_;
+      if (ref instanceof java.lang.String) {
+        return (java.lang.String) ref;
+      } else {
+        com.google.protobuf.ByteString bs = 
+            (com.google.protobuf.ByteString) ref;
+        java.lang.String s = bs.toStringUtf8();
+        foreignId_ = s;
+        return s;
+      }
+    }
+    /**
+     * <code>string foreign_id = 3;</code>
+     */
+    public com.google.protobuf.ByteString
+        getForeignIdBytes() {
+      java.lang.Object ref = foreignId_;
+      if (ref instanceof java.lang.String) {
+        com.google.protobuf.ByteString b = 
+            com.google.protobuf.ByteString.copyFromUtf8(
+                (java.lang.String) ref);
+        foreignId_ = b;
+        return b;
+      } else {
+        return (com.google.protobuf.ByteString) ref;
+      }
+    }
+
+    public static final int LOCATION_FIELD_NUMBER = 4;
+    private volatile java.lang.Object location_;
+    /**
+     * <code>string location = 4;</code>
+     */
+    public java.lang.String getLocation() {
+      java.lang.Object ref = location_;
+      if (ref instanceof java.lang.String) {
+        return (java.lang.String) ref;
+      } else {
+        com.google.protobuf.ByteString bs = 
+            (com.google.protobuf.ByteString) ref;
+        java.lang.String s = bs.toStringUtf8();
+        location_ = s;
+        return s;
+      }
+    }
+    /**
+     * <code>string location = 4;</code>
+     */
+    public com.google.protobuf.ByteString
+        getLocationBytes() {
+      java.lang.Object ref = location_;
+      if (ref instanceof java.lang.String) {
+        com.google.protobuf.ByteString b = 
+            com.google.protobuf.ByteString.copyFromUtf8(
+                (java.lang.String) ref);
+        location_ = b;
+        return b;
+      } else {
+        return (com.google.protobuf.ByteString) ref;
+      }
+    }
+
+    public static final int CATEGORY_FIELD_NUMBER = 5;
+    private com.google.protobuf.LazyStringList category_;
+    /**
+     * <code>repeated string category = 5;</code>
+     */
+    public com.google.protobuf.ProtocolStringList
+        getCategoryList() {
+      return category_;
+    }
+    /**
+     * <code>repeated string category = 5;</code>
+     */
+    public int getCategoryCount() {
+      return category_.size();
+    }
+    /**
+     * <code>repeated string category = 5;</code>
+     */
+    public java.lang.String getCategory(int index) {
+      return category_.get(index);
+    }
+    /**
+     * <code>repeated string category = 5;</code>
+     */
+    public com.google.protobuf.ByteString
+        getCategoryBytes(int index) {
+      return category_.getByteString(index);
+    }
+
+    public static final int LABEL_FIELD_NUMBER = 6;
+    private volatile java.lang.Object label_;
+    /**
+     * <code>string label = 6;</code>
+     */
+    public java.lang.String getLabel() {
+      java.lang.Object ref = label_;
+      if (ref instanceof java.lang.String) {
+        return (java.lang.String) ref;
+      } else {
+        com.google.protobuf.ByteString bs = 
+            (com.google.protobuf.ByteString) ref;
+        java.lang.String s = bs.toStringUtf8();
+        label_ = s;
+        return s;
+      }
+    }
+    /**
+     * <code>string label = 6;</code>
+     */
+    public com.google.protobuf.ByteString
+        getLabelBytes() {
+      java.lang.Object ref = label_;
+      if (ref instanceof java.lang.String) {
+        com.google.protobuf.ByteString b = 
+            com.google.protobuf.ByteString.copyFromUtf8(
+                (java.lang.String) ref);
+        label_ = b;
+        return b;
+      } else {
+        return (com.google.protobuf.ByteString) ref;
+      }
+    }
+
+    public static final int CREATE_TIME_FIELD_NUMBER = 7;
+    private long createTime_;
+    /**
+     * <code>uint64 create_time = 7;</code>
+     */
+    public long getCreateTime() {
+      return createTime_;
+    }
+
+    public static final int SYS_CONTACT_FIELD_NUMBER = 8;
+    private volatile java.lang.Object sysContact_;
+    /**
+     * <code>string sys_contact = 8;</code>
+     */
+    public java.lang.String getSysContact() {
+      java.lang.Object ref = sysContact_;
+      if (ref instanceof java.lang.String) {
+        return (java.lang.String) ref;
+      } else {
+        com.google.protobuf.ByteString bs = 
+            (com.google.protobuf.ByteString) ref;
+        java.lang.String s = bs.toStringUtf8();
+        sysContact_ = s;
+        return s;
+      }
+    }
+    /**
+     * <code>string sys_contact = 8;</code>
+     */
+    public com.google.protobuf.ByteString
+        getSysContactBytes() {
+      java.lang.Object ref = sysContact_;
+      if (ref instanceof java.lang.String) {
+        com.google.protobuf.ByteString b = 
+            com.google.protobuf.ByteString.copyFromUtf8(
+                (java.lang.String) ref);
+        sysContact_ = b;
+        return b;
+      } else {
+        return (com.google.protobuf.ByteString) ref;
+      }
+    }
+
+    public static final int SYS_DESCRIPTION_FIELD_NUMBER = 9;
+    private volatile java.lang.Object sysDescription_;
+    /**
+     * <code>string sys_description = 9;</code>
+     */
+    public java.lang.String getSysDescription() {
+      java.lang.Object ref = sysDescription_;
+      if (ref instanceof java.lang.String) {
+        return (java.lang.String) ref;
+      } else {
+        com.google.protobuf.ByteString bs = 
+            (com.google.protobuf.ByteString) ref;
+        java.lang.String s = bs.toStringUtf8();
+        sysDescription_ = s;
+        return s;
+      }
+    }
+    /**
+     * <code>string sys_description = 9;</code>
+     */
+    public com.google.protobuf.ByteString
+        getSysDescriptionBytes() {
+      java.lang.Object ref = sysDescription_;
+      if (ref instanceof java.lang.String) {
+        com.google.protobuf.ByteString b = 
+            com.google.protobuf.ByteString.copyFromUtf8(
+                (java.lang.String) ref);
+        sysDescription_ = b;
+        return b;
+      } else {
+        return (com.google.protobuf.ByteString) ref;
+      }
+    }
+
+    public static final int SYS_OBJECT_ID_FIELD_NUMBER = 10;
+    private volatile java.lang.Object sysObjectId_;
+    /**
+     * <code>string sys_object_id = 10;</code>
+     */
+    public java.lang.String getSysObjectId() {
+      java.lang.Object ref = sysObjectId_;
+      if (ref instanceof java.lang.String) {
+        return (java.lang.String) ref;
+      } else {
+        com.google.protobuf.ByteString bs = 
+            (com.google.protobuf.ByteString) ref;
+        java.lang.String s = bs.toStringUtf8();
+        sysObjectId_ = s;
+        return s;
+      }
+    }
+    /**
+     * <code>string sys_object_id = 10;</code>
+     */
+    public com.google.protobuf.ByteString
+        getSysObjectIdBytes() {
+      java.lang.Object ref = sysObjectId_;
+      if (ref instanceof java.lang.String) {
+        com.google.protobuf.ByteString b = 
+            com.google.protobuf.ByteString.copyFromUtf8(
+                (java.lang.String) ref);
+        sysObjectId_ = b;
+        return b;
+      } else {
+        return (com.google.protobuf.ByteString) ref;
+      }
+    }
+
+    public static final int IP_INTERFACE_FIELD_NUMBER = 11;
+    private java.util.List<org.opennms.features.kafka.producer.model.OpennmsModelProtos.IpInterface> ipInterface_;
+    /**
+     * <code>repeated .IpInterface ip_interface = 11;</code>
+     */
+    public java.util.List<org.opennms.features.kafka.producer.model.OpennmsModelProtos.IpInterface> getIpInterfaceList() {
+      return ipInterface_;
+    }
+    /**
+     * <code>repeated .IpInterface ip_interface = 11;</code>
+     */
+    public java.util.List<? extends org.opennms.features.kafka.producer.model.OpennmsModelProtos.IpInterfaceOrBuilder> 
+        getIpInterfaceOrBuilderList() {
+      return ipInterface_;
+    }
+    /**
+     * <code>repeated .IpInterface ip_interface = 11;</code>
+     */
+    public int getIpInterfaceCount() {
+      return ipInterface_.size();
+    }
+    /**
+     * <code>repeated .IpInterface ip_interface = 11;</code>
+     */
+    public org.opennms.features.kafka.producer.model.OpennmsModelProtos.IpInterface getIpInterface(int index) {
+      return ipInterface_.get(index);
+    }
+    /**
+     * <code>repeated .IpInterface ip_interface = 11;</code>
+     */
+    public org.opennms.features.kafka.producer.model.OpennmsModelProtos.IpInterfaceOrBuilder getIpInterfaceOrBuilder(
+        int index) {
+      return ipInterface_.get(index);
+    }
+
+    public static final int SNMP_INTERFACE_FIELD_NUMBER = 12;
+    private java.util.List<org.opennms.features.kafka.producer.model.OpennmsModelProtos.SnmpInterface> snmpInterface_;
+    /**
+     * <code>repeated .SnmpInterface snmp_interface = 12;</code>
+     */
+    public java.util.List<org.opennms.features.kafka.producer.model.OpennmsModelProtos.SnmpInterface> getSnmpInterfaceList() {
+      return snmpInterface_;
+    }
+    /**
+     * <code>repeated .SnmpInterface snmp_interface = 12;</code>
+     */
+    public java.util.List<? extends org.opennms.features.kafka.producer.model.OpennmsModelProtos.SnmpInterfaceOrBuilder> 
+        getSnmpInterfaceOrBuilderList() {
+      return snmpInterface_;
+    }
+    /**
+     * <code>repeated .SnmpInterface snmp_interface = 12;</code>
+     */
+    public int getSnmpInterfaceCount() {
+      return snmpInterface_.size();
+    }
+    /**
+     * <code>repeated .SnmpInterface snmp_interface = 12;</code>
+     */
+    public org.opennms.features.kafka.producer.model.OpennmsModelProtos.SnmpInterface getSnmpInterface(int index) {
+      return snmpInterface_.get(index);
+    }
+    /**
+     * <code>repeated .SnmpInterface snmp_interface = 12;</code>
+     */
+    public org.opennms.features.kafka.producer.model.OpennmsModelProtos.SnmpInterfaceOrBuilder getSnmpInterfaceOrBuilder(
+        int index) {
+      return snmpInterface_.get(index);
+    }
+
+    private byte memoizedIsInitialized = -1;
+    public final boolean isInitialized() {
+      byte isInitialized = memoizedIsInitialized;
+      if (isInitialized == 1) return true;
+      if (isInitialized == 0) return false;
+
+      memoizedIsInitialized = 1;
+      return true;
+    }
+
+    public void writeTo(com.google.protobuf.CodedOutputStream output)
+                        throws java.io.IOException {
+      if (id_ != 0L) {
+        output.writeUInt64(1, id_);
+      }
+      if (!getForeignSourceBytes().isEmpty()) {
+        com.google.protobuf.GeneratedMessageV3.writeString(output, 2, foreignSource_);
+      }
+      if (!getForeignIdBytes().isEmpty()) {
+        com.google.protobuf.GeneratedMessageV3.writeString(output, 3, foreignId_);
+      }
+      if (!getLocationBytes().isEmpty()) {
+        com.google.protobuf.GeneratedMessageV3.writeString(output, 4, location_);
+      }
+      for (int i = 0; i < category_.size(); i++) {
+        com.google.protobuf.GeneratedMessageV3.writeString(output, 5, category_.getRaw(i));
+      }
+      if (!getLabelBytes().isEmpty()) {
+        com.google.protobuf.GeneratedMessageV3.writeString(output, 6, label_);
+      }
+      if (createTime_ != 0L) {
+        output.writeUInt64(7, createTime_);
+      }
+      if (!getSysContactBytes().isEmpty()) {
+        com.google.protobuf.GeneratedMessageV3.writeString(output, 8, sysContact_);
+      }
+      if (!getSysDescriptionBytes().isEmpty()) {
+        com.google.protobuf.GeneratedMessageV3.writeString(output, 9, sysDescription_);
+      }
+      if (!getSysObjectIdBytes().isEmpty()) {
+        com.google.protobuf.GeneratedMessageV3.writeString(output, 10, sysObjectId_);
+      }
+      for (int i = 0; i < ipInterface_.size(); i++) {
+        output.writeMessage(11, ipInterface_.get(i));
+      }
+      for (int i = 0; i < snmpInterface_.size(); i++) {
+        output.writeMessage(12, snmpInterface_.get(i));
+      }
+      unknownFields.writeTo(output);
+    }
+
+    public int getSerializedSize() {
+      int size = memoizedSize;
+      if (size != -1) return size;
+
+      size = 0;
+      if (id_ != 0L) {
+        size += com.google.protobuf.CodedOutputStream
+          .computeUInt64Size(1, id_);
+      }
+      if (!getForeignSourceBytes().isEmpty()) {
+        size += com.google.protobuf.GeneratedMessageV3.computeStringSize(2, foreignSource_);
+      }
+      if (!getForeignIdBytes().isEmpty()) {
+        size += com.google.protobuf.GeneratedMessageV3.computeStringSize(3, foreignId_);
+      }
+      if (!getLocationBytes().isEmpty()) {
+        size += com.google.protobuf.GeneratedMessageV3.computeStringSize(4, location_);
+      }
+      {
+        int dataSize = 0;
+        for (int i = 0; i < category_.size(); i++) {
+          dataSize += computeStringSizeNoTag(category_.getRaw(i));
+        }
+        size += dataSize;
+        size += 1 * getCategoryList().size();
+      }
+      if (!getLabelBytes().isEmpty()) {
+        size += com.google.protobuf.GeneratedMessageV3.computeStringSize(6, label_);
+      }
+      if (createTime_ != 0L) {
+        size += com.google.protobuf.CodedOutputStream
+          .computeUInt64Size(7, createTime_);
+      }
+      if (!getSysContactBytes().isEmpty()) {
+        size += com.google.protobuf.GeneratedMessageV3.computeStringSize(8, sysContact_);
+      }
+      if (!getSysDescriptionBytes().isEmpty()) {
+        size += com.google.protobuf.GeneratedMessageV3.computeStringSize(9, sysDescription_);
+      }
+      if (!getSysObjectIdBytes().isEmpty()) {
+        size += com.google.protobuf.GeneratedMessageV3.computeStringSize(10, sysObjectId_);
+      }
+      for (int i = 0; i < ipInterface_.size(); i++) {
+        size += com.google.protobuf.CodedOutputStream
+          .computeMessageSize(11, ipInterface_.get(i));
+      }
+      for (int i = 0; i < snmpInterface_.size(); i++) {
+        size += com.google.protobuf.CodedOutputStream
+          .computeMessageSize(12, snmpInterface_.get(i));
+      }
+      size += unknownFields.getSerializedSize();
+      memoizedSize = size;
+      return size;
+    }
+
+    @java.lang.Override
+    public boolean equals(final java.lang.Object obj) {
+      if (obj == this) {
+       return true;
+      }
+      if (!(obj instanceof org.opennms.features.kafka.producer.model.OpennmsModelProtos.Node)) {
+        return super.equals(obj);
+      }
+      org.opennms.features.kafka.producer.model.OpennmsModelProtos.Node other = (org.opennms.features.kafka.producer.model.OpennmsModelProtos.Node) obj;
+
+      boolean result = true;
+      result = result && (getId()
+          == other.getId());
+      result = result && getForeignSource()
+          .equals(other.getForeignSource());
+      result = result && getForeignId()
+          .equals(other.getForeignId());
+      result = result && getLocation()
+          .equals(other.getLocation());
+      result = result && getCategoryList()
+          .equals(other.getCategoryList());
+      result = result && getLabel()
+          .equals(other.getLabel());
+      result = result && (getCreateTime()
+          == other.getCreateTime());
+      result = result && getSysContact()
+          .equals(other.getSysContact());
+      result = result && getSysDescription()
+          .equals(other.getSysDescription());
+      result = result && getSysObjectId()
+          .equals(other.getSysObjectId());
+      result = result && getIpInterfaceList()
+          .equals(other.getIpInterfaceList());
+      result = result && getSnmpInterfaceList()
+          .equals(other.getSnmpInterfaceList());
+      result = result && unknownFields.equals(other.unknownFields);
+      return result;
+    }
+
+    @java.lang.Override
+    public int hashCode() {
+      if (memoizedHashCode != 0) {
+        return memoizedHashCode;
+      }
+      int hash = 41;
+      hash = (19 * hash) + getDescriptor().hashCode();
+      hash = (37 * hash) + ID_FIELD_NUMBER;
+      hash = (53 * hash) + com.google.protobuf.Internal.hashLong(
+          getId());
+      hash = (37 * hash) + FOREIGN_SOURCE_FIELD_NUMBER;
+      hash = (53 * hash) + getForeignSource().hashCode();
+      hash = (37 * hash) + FOREIGN_ID_FIELD_NUMBER;
+      hash = (53 * hash) + getForeignId().hashCode();
+      hash = (37 * hash) + LOCATION_FIELD_NUMBER;
+      hash = (53 * hash) + getLocation().hashCode();
+      if (getCategoryCount() > 0) {
+        hash = (37 * hash) + CATEGORY_FIELD_NUMBER;
+        hash = (53 * hash) + getCategoryList().hashCode();
+      }
+      hash = (37 * hash) + LABEL_FIELD_NUMBER;
+      hash = (53 * hash) + getLabel().hashCode();
+      hash = (37 * hash) + CREATE_TIME_FIELD_NUMBER;
+      hash = (53 * hash) + com.google.protobuf.Internal.hashLong(
+          getCreateTime());
+      hash = (37 * hash) + SYS_CONTACT_FIELD_NUMBER;
+      hash = (53 * hash) + getSysContact().hashCode();
+      hash = (37 * hash) + SYS_DESCRIPTION_FIELD_NUMBER;
+      hash = (53 * hash) + getSysDescription().hashCode();
+      hash = (37 * hash) + SYS_OBJECT_ID_FIELD_NUMBER;
+      hash = (53 * hash) + getSysObjectId().hashCode();
+      if (getIpInterfaceCount() > 0) {
+        hash = (37 * hash) + IP_INTERFACE_FIELD_NUMBER;
+        hash = (53 * hash) + getIpInterfaceList().hashCode();
+      }
+      if (getSnmpInterfaceCount() > 0) {
+        hash = (37 * hash) + SNMP_INTERFACE_FIELD_NUMBER;
+        hash = (53 * hash) + getSnmpInterfaceList().hashCode();
+      }
+      hash = (29 * hash) + unknownFields.hashCode();
+      memoizedHashCode = hash;
+      return hash;
+    }
+
+    public static org.opennms.features.kafka.producer.model.OpennmsModelProtos.Node parseFrom(
+        java.nio.ByteBuffer data)
+        throws com.google.protobuf.InvalidProtocolBufferException {
+      return PARSER.parseFrom(data);
+    }
+    public static org.opennms.features.kafka.producer.model.OpennmsModelProtos.Node parseFrom(
+        java.nio.ByteBuffer data,
+        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
+        throws com.google.protobuf.InvalidProtocolBufferException {
+      return PARSER.parseFrom(data, extensionRegistry);
+    }
+    public static org.opennms.features.kafka.producer.model.OpennmsModelProtos.Node parseFrom(
+        com.google.protobuf.ByteString data)
+        throws com.google.protobuf.InvalidProtocolBufferException {
+      return PARSER.parseFrom(data);
+    }
+    public static org.opennms.features.kafka.producer.model.OpennmsModelProtos.Node parseFrom(
+        com.google.protobuf.ByteString data,
+        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
+        throws com.google.protobuf.InvalidProtocolBufferException {
+      return PARSER.parseFrom(data, extensionRegistry);
+    }
+    public static org.opennms.features.kafka.producer.model.OpennmsModelProtos.Node parseFrom(byte[] data)
+        throws com.google.protobuf.InvalidProtocolBufferException {
+      return PARSER.parseFrom(data);
+    }
+    public static org.opennms.features.kafka.producer.model.OpennmsModelProtos.Node parseFrom(
+        byte[] data,
+        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
+        throws com.google.protobuf.InvalidProtocolBufferException {
+      return PARSER.parseFrom(data, extensionRegistry);
+    }
+    public static org.opennms.features.kafka.producer.model.OpennmsModelProtos.Node parseFrom(java.io.InputStream input)
+        throws java.io.IOException {
+      return com.google.protobuf.GeneratedMessageV3
+          .parseWithIOException(PARSER, input);
+    }
+    public static org.opennms.features.kafka.producer.model.OpennmsModelProtos.Node parseFrom(
+        java.io.InputStream input,
+        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
+        throws java.io.IOException {
+      return com.google.protobuf.GeneratedMessageV3
+          .parseWithIOException(PARSER, input, extensionRegistry);
+    }
+    public static org.opennms.features.kafka.producer.model.OpennmsModelProtos.Node parseDelimitedFrom(java.io.InputStream input)
+        throws java.io.IOException {
+      return com.google.protobuf.GeneratedMessageV3
+          .parseDelimitedWithIOException(PARSER, input);
+    }
+    public static org.opennms.features.kafka.producer.model.OpennmsModelProtos.Node parseDelimitedFrom(
+        java.io.InputStream input,
+        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
+        throws java.io.IOException {
+      return com.google.protobuf.GeneratedMessageV3
+          .parseDelimitedWithIOException(PARSER, input, extensionRegistry);
+    }
+    public static org.opennms.features.kafka.producer.model.OpennmsModelProtos.Node parseFrom(
+        com.google.protobuf.CodedInputStream input)
+        throws java.io.IOException {
+      return com.google.protobuf.GeneratedMessageV3
+          .parseWithIOException(PARSER, input);
+    }
+    public static org.opennms.features.kafka.producer.model.OpennmsModelProtos.Node parseFrom(
+        com.google.protobuf.CodedInputStream input,
+        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
+        throws java.io.IOException {
+      return com.google.protobuf.GeneratedMessageV3
+          .parseWithIOException(PARSER, input, extensionRegistry);
+    }
+
+    public Builder newBuilderForType() { return newBuilder(); }
+    public static Builder newBuilder() {
+      return DEFAULT_INSTANCE.toBuilder();
+    }
+    public static Builder newBuilder(org.opennms.features.kafka.producer.model.OpennmsModelProtos.Node prototype) {
+      return DEFAULT_INSTANCE.toBuilder().mergeFrom(prototype);
+    }
+    public Builder toBuilder() {
+      return this == DEFAULT_INSTANCE
+          ? new Builder() : new Builder().mergeFrom(this);
+    }
+
+    @java.lang.Override
+    protected Builder newBuilderForType(
+        com.google.protobuf.GeneratedMessageV3.BuilderParent parent) {
+      Builder builder = new Builder(parent);
+      return builder;
+    }
+    /**
+     * Protobuf type {@code Node}
+     */
+    public static final class Builder extends
+        com.google.protobuf.GeneratedMessageV3.Builder<Builder> implements
+        // @@protoc_insertion_point(builder_implements:Node)
+        org.opennms.features.kafka.producer.model.OpennmsModelProtos.NodeOrBuilder {
+      public static final com.google.protobuf.Descriptors.Descriptor
+          getDescriptor() {
+        return org.opennms.features.kafka.producer.model.OpennmsModelProtos.internal_static_Node_descriptor;
+      }
+
+      protected com.google.protobuf.GeneratedMessageV3.FieldAccessorTable
+          internalGetFieldAccessorTable() {
+        return org.opennms.features.kafka.producer.model.OpennmsModelProtos.internal_static_Node_fieldAccessorTable
+            .ensureFieldAccessorsInitialized(
+                org.opennms.features.kafka.producer.model.OpennmsModelProtos.Node.class, org.opennms.features.kafka.producer.model.OpennmsModelProtos.Node.Builder.class);
+      }
+
+      // Construct using org.opennms.features.kafka.producer.model.OpennmsModelProtos.Node.newBuilder()
+      private Builder() {
+        maybeForceBuilderInitialization();
+      }
+
+      private Builder(
+          com.google.protobuf.GeneratedMessageV3.BuilderParent parent) {
+        super(parent);
+        maybeForceBuilderInitialization();
+      }
+      private void maybeForceBuilderInitialization() {
+        if (com.google.protobuf.GeneratedMessageV3
+                .alwaysUseFieldBuilders) {
+          getIpInterfaceFieldBuilder();
+          getSnmpInterfaceFieldBuilder();
+        }
+      }
+      public Builder clear() {
+        super.clear();
+        id_ = 0L;
+
+        foreignSource_ = "";
+
+        foreignId_ = "";
+
+        location_ = "";
+
+        category_ = com.google.protobuf.LazyStringArrayList.EMPTY;
+        bitField0_ = (bitField0_ & ~0x00000010);
+        label_ = "";
+
+        createTime_ = 0L;
+
+        sysContact_ = "";
+
+        sysDescription_ = "";
+
+        sysObjectId_ = "";
+
+        if (ipInterfaceBuilder_ == null) {
+          ipInterface_ = java.util.Collections.emptyList();
+          bitField0_ = (bitField0_ & ~0x00000400);
+        } else {
+          ipInterfaceBuilder_.clear();
+        }
+        if (snmpInterfaceBuilder_ == null) {
+          snmpInterface_ = java.util.Collections.emptyList();
+          bitField0_ = (bitField0_ & ~0x00000800);
+        } else {
+          snmpInterfaceBuilder_.clear();
+        }
+        return this;
+      }
+
+      public com.google.protobuf.Descriptors.Descriptor
+          getDescriptorForType() {
+        return org.opennms.features.kafka.producer.model.OpennmsModelProtos.internal_static_Node_descriptor;
+      }
+
+      public org.opennms.features.kafka.producer.model.OpennmsModelProtos.Node getDefaultInstanceForType() {
+        return org.opennms.features.kafka.producer.model.OpennmsModelProtos.Node.getDefaultInstance();
+      }
+
+      public org.opennms.features.kafka.producer.model.OpennmsModelProtos.Node build() {
+        org.opennms.features.kafka.producer.model.OpennmsModelProtos.Node result = buildPartial();
+        if (!result.isInitialized()) {
+          throw newUninitializedMessageException(result);
+        }
+        return result;
+      }
+
+      public org.opennms.features.kafka.producer.model.OpennmsModelProtos.Node buildPartial() {
+        org.opennms.features.kafka.producer.model.OpennmsModelProtos.Node result = new org.opennms.features.kafka.producer.model.OpennmsModelProtos.Node(this);
+        int from_bitField0_ = bitField0_;
+        int to_bitField0_ = 0;
+        result.id_ = id_;
+        result.foreignSource_ = foreignSource_;
+        result.foreignId_ = foreignId_;
+        result.location_ = location_;
+        if (((bitField0_ & 0x00000010) == 0x00000010)) {
+          category_ = category_.getUnmodifiableView();
+          bitField0_ = (bitField0_ & ~0x00000010);
+        }
+        result.category_ = category_;
+        result.label_ = label_;
+        result.createTime_ = createTime_;
+        result.sysContact_ = sysContact_;
+        result.sysDescription_ = sysDescription_;
+        result.sysObjectId_ = sysObjectId_;
+        if (ipInterfaceBuilder_ == null) {
+          if (((bitField0_ & 0x00000400) == 0x00000400)) {
+            ipInterface_ = java.util.Collections.unmodifiableList(ipInterface_);
+            bitField0_ = (bitField0_ & ~0x00000400);
+          }
+          result.ipInterface_ = ipInterface_;
+        } else {
+          result.ipInterface_ = ipInterfaceBuilder_.build();
+        }
+        if (snmpInterfaceBuilder_ == null) {
+          if (((bitField0_ & 0x00000800) == 0x00000800)) {
+            snmpInterface_ = java.util.Collections.unmodifiableList(snmpInterface_);
+            bitField0_ = (bitField0_ & ~0x00000800);
+          }
+          result.snmpInterface_ = snmpInterface_;
+        } else {
+          result.snmpInterface_ = snmpInterfaceBuilder_.build();
+        }
+        result.bitField0_ = to_bitField0_;
+        onBuilt();
+        return result;
+      }
+
+      public Builder clone() {
+        return (Builder) super.clone();
+      }
+      public Builder setField(
+          com.google.protobuf.Descriptors.FieldDescriptor field,
+          java.lang.Object value) {
+        return (Builder) super.setField(field, value);
+      }
+      public Builder clearField(
+          com.google.protobuf.Descriptors.FieldDescriptor field) {
+        return (Builder) super.clearField(field);
+      }
+      public Builder clearOneof(
+          com.google.protobuf.Descriptors.OneofDescriptor oneof) {
+        return (Builder) super.clearOneof(oneof);
+      }
+      public Builder setRepeatedField(
+          com.google.protobuf.Descriptors.FieldDescriptor field,
+          int index, java.lang.Object value) {
+        return (Builder) super.setRepeatedField(field, index, value);
+      }
+      public Builder addRepeatedField(
+          com.google.protobuf.Descriptors.FieldDescriptor field,
+          java.lang.Object value) {
+        return (Builder) super.addRepeatedField(field, value);
+      }
+      public Builder mergeFrom(com.google.protobuf.Message other) {
+        if (other instanceof org.opennms.features.kafka.producer.model.OpennmsModelProtos.Node) {
+          return mergeFrom((org.opennms.features.kafka.producer.model.OpennmsModelProtos.Node)other);
+        } else {
+          super.mergeFrom(other);
+          return this;
+        }
+      }
+
+      public Builder mergeFrom(org.opennms.features.kafka.producer.model.OpennmsModelProtos.Node other) {
+        if (other == org.opennms.features.kafka.producer.model.OpennmsModelProtos.Node.getDefaultInstance()) return this;
+        if (other.getId() != 0L) {
+          setId(other.getId());
+        }
+        if (!other.getForeignSource().isEmpty()) {
+          foreignSource_ = other.foreignSource_;
+          onChanged();
+        }
+        if (!other.getForeignId().isEmpty()) {
+          foreignId_ = other.foreignId_;
+          onChanged();
+        }
+        if (!other.getLocation().isEmpty()) {
+          location_ = other.location_;
+          onChanged();
+        }
+        if (!other.category_.isEmpty()) {
+          if (category_.isEmpty()) {
+            category_ = other.category_;
+            bitField0_ = (bitField0_ & ~0x00000010);
+          } else {
+            ensureCategoryIsMutable();
+            category_.addAll(other.category_);
+          }
+          onChanged();
+        }
+        if (!other.getLabel().isEmpty()) {
+          label_ = other.label_;
+          onChanged();
+        }
+        if (other.getCreateTime() != 0L) {
+          setCreateTime(other.getCreateTime());
+        }
+        if (!other.getSysContact().isEmpty()) {
+          sysContact_ = other.sysContact_;
+          onChanged();
+        }
+        if (!other.getSysDescription().isEmpty()) {
+          sysDescription_ = other.sysDescription_;
+          onChanged();
+        }
+        if (!other.getSysObjectId().isEmpty()) {
+          sysObjectId_ = other.sysObjectId_;
+          onChanged();
+        }
+        if (ipInterfaceBuilder_ == null) {
+          if (!other.ipInterface_.isEmpty()) {
+            if (ipInterface_.isEmpty()) {
+              ipInterface_ = other.ipInterface_;
+              bitField0_ = (bitField0_ & ~0x00000400);
+            } else {
+              ensureIpInterfaceIsMutable();
+              ipInterface_.addAll(other.ipInterface_);
+            }
+            onChanged();
+          }
+        } else {
+          if (!other.ipInterface_.isEmpty()) {
+            if (ipInterfaceBuilder_.isEmpty()) {
+              ipInterfaceBuilder_.dispose();
+              ipInterfaceBuilder_ = null;
+              ipInterface_ = other.ipInterface_;
+              bitField0_ = (bitField0_ & ~0x00000400);
+              ipInterfaceBuilder_ = 
+                com.google.protobuf.GeneratedMessageV3.alwaysUseFieldBuilders ?
+                   getIpInterfaceFieldBuilder() : null;
+            } else {
+              ipInterfaceBuilder_.addAllMessages(other.ipInterface_);
+            }
+          }
+        }
+        if (snmpInterfaceBuilder_ == null) {
+          if (!other.snmpInterface_.isEmpty()) {
+            if (snmpInterface_.isEmpty()) {
+              snmpInterface_ = other.snmpInterface_;
+              bitField0_ = (bitField0_ & ~0x00000800);
+            } else {
+              ensureSnmpInterfaceIsMutable();
+              snmpInterface_.addAll(other.snmpInterface_);
+            }
+            onChanged();
+          }
+        } else {
+          if (!other.snmpInterface_.isEmpty()) {
+            if (snmpInterfaceBuilder_.isEmpty()) {
+              snmpInterfaceBuilder_.dispose();
+              snmpInterfaceBuilder_ = null;
+              snmpInterface_ = other.snmpInterface_;
+              bitField0_ = (bitField0_ & ~0x00000800);
+              snmpInterfaceBuilder_ = 
+                com.google.protobuf.GeneratedMessageV3.alwaysUseFieldBuilders ?
+                   getSnmpInterfaceFieldBuilder() : null;
+            } else {
+              snmpInterfaceBuilder_.addAllMessages(other.snmpInterface_);
+            }
+          }
+        }
+        this.mergeUnknownFields(other.unknownFields);
+        onChanged();
+        return this;
+      }
+
+      public final boolean isInitialized() {
+        return true;
+      }
+
+      public Builder mergeFrom(
+          com.google.protobuf.CodedInputStream input,
+          com.google.protobuf.ExtensionRegistryLite extensionRegistry)
+          throws java.io.IOException {
+        org.opennms.features.kafka.producer.model.OpennmsModelProtos.Node parsedMessage = null;
+        try {
+          parsedMessage = PARSER.parsePartialFrom(input, extensionRegistry);
+        } catch (com.google.protobuf.InvalidProtocolBufferException e) {
+          parsedMessage = (org.opennms.features.kafka.producer.model.OpennmsModelProtos.Node) e.getUnfinishedMessage();
+          throw e.unwrapIOException();
+        } finally {
+          if (parsedMessage != null) {
+            mergeFrom(parsedMessage);
+          }
+        }
+        return this;
+      }
+      private int bitField0_;
+
+      private long id_ ;
+      /**
+       * <code>uint64 id = 1;</code>
+       */
+      public long getId() {
+        return id_;
+      }
+      /**
+       * <code>uint64 id = 1;</code>
+       */
+      public Builder setId(long value) {
+        
+        id_ = value;
+        onChanged();
+        return this;
+      }
+      /**
+       * <code>uint64 id = 1;</code>
+       */
+      public Builder clearId() {
+        
+        id_ = 0L;
+        onChanged();
+        return this;
+      }
+
+      private java.lang.Object foreignSource_ = "";
+      /**
+       * <code>string foreign_source = 2;</code>
+       */
+      public java.lang.String getForeignSource() {
+        java.lang.Object ref = foreignSource_;
+        if (!(ref instanceof java.lang.String)) {
+          com.google.protobuf.ByteString bs =
+              (com.google.protobuf.ByteString) ref;
+          java.lang.String s = bs.toStringUtf8();
+          foreignSource_ = s;
+          return s;
+        } else {
+          return (java.lang.String) ref;
+        }
+      }
+      /**
+       * <code>string foreign_source = 2;</code>
+       */
+      public com.google.protobuf.ByteString
+          getForeignSourceBytes() {
+        java.lang.Object ref = foreignSource_;
+        if (ref instanceof String) {
+          com.google.protobuf.ByteString b = 
+              com.google.protobuf.ByteString.copyFromUtf8(
+                  (java.lang.String) ref);
+          foreignSource_ = b;
+          return b;
+        } else {
+          return (com.google.protobuf.ByteString) ref;
+        }
+      }
+      /**
+       * <code>string foreign_source = 2;</code>
+       */
+      public Builder setForeignSource(
+          java.lang.String value) {
+        if (value == null) {
+    throw new NullPointerException();
+  }
+  
+        foreignSource_ = value;
+        onChanged();
+        return this;
+      }
+      /**
+       * <code>string foreign_source = 2;</code>
+       */
+      public Builder clearForeignSource() {
+        
+        foreignSource_ = getDefaultInstance().getForeignSource();
+        onChanged();
+        return this;
+      }
+      /**
+       * <code>string foreign_source = 2;</code>
+       */
+      public Builder setForeignSourceBytes(
+          com.google.protobuf.ByteString value) {
+        if (value == null) {
+    throw new NullPointerException();
+  }
+  checkByteStringIsUtf8(value);
+        
+        foreignSource_ = value;
+        onChanged();
+        return this;
+      }
+
+      private java.lang.Object foreignId_ = "";
+      /**
+       * <code>string foreign_id = 3;</code>
+       */
+      public java.lang.String getForeignId() {
+        java.lang.Object ref = foreignId_;
+        if (!(ref instanceof java.lang.String)) {
+          com.google.protobuf.ByteString bs =
+              (com.google.protobuf.ByteString) ref;
+          java.lang.String s = bs.toStringUtf8();
+          foreignId_ = s;
+          return s;
+        } else {
+          return (java.lang.String) ref;
+        }
+      }
+      /**
+       * <code>string foreign_id = 3;</code>
+       */
+      public com.google.protobuf.ByteString
+          getForeignIdBytes() {
+        java.lang.Object ref = foreignId_;
+        if (ref instanceof String) {
+          com.google.protobuf.ByteString b = 
+              com.google.protobuf.ByteString.copyFromUtf8(
+                  (java.lang.String) ref);
+          foreignId_ = b;
+          return b;
+        } else {
+          return (com.google.protobuf.ByteString) ref;
+        }
+      }
+      /**
+       * <code>string foreign_id = 3;</code>
+       */
+      public Builder setForeignId(
+          java.lang.String value) {
+        if (value == null) {
+    throw new NullPointerException();
+  }
+  
+        foreignId_ = value;
+        onChanged();
+        return this;
+      }
+      /**
+       * <code>string foreign_id = 3;</code>
+       */
+      public Builder clearForeignId() {
+        
+        foreignId_ = getDefaultInstance().getForeignId();
+        onChanged();
+        return this;
+      }
+      /**
+       * <code>string foreign_id = 3;</code>
+       */
+      public Builder setForeignIdBytes(
+          com.google.protobuf.ByteString value) {
+        if (value == null) {
+    throw new NullPointerException();
+  }
+  checkByteStringIsUtf8(value);
+        
+        foreignId_ = value;
+        onChanged();
+        return this;
+      }
+
+      private java.lang.Object location_ = "";
+      /**
+       * <code>string location = 4;</code>
+       */
+      public java.lang.String getLocation() {
+        java.lang.Object ref = location_;
+        if (!(ref instanceof java.lang.String)) {
+          com.google.protobuf.ByteString bs =
+              (com.google.protobuf.ByteString) ref;
+          java.lang.String s = bs.toStringUtf8();
+          location_ = s;
+          return s;
+        } else {
+          return (java.lang.String) ref;
+        }
+      }
+      /**
+       * <code>string location = 4;</code>
+       */
+      public com.google.protobuf.ByteString
+          getLocationBytes() {
+        java.lang.Object ref = location_;
+        if (ref instanceof String) {
+          com.google.protobuf.ByteString b = 
+              com.google.protobuf.ByteString.copyFromUtf8(
+                  (java.lang.String) ref);
+          location_ = b;
+          return b;
+        } else {
+          return (com.google.protobuf.ByteString) ref;
+        }
+      }
+      /**
+       * <code>string location = 4;</code>
+       */
+      public Builder setLocation(
+          java.lang.String value) {
+        if (value == null) {
+    throw new NullPointerException();
+  }
+  
+        location_ = value;
+        onChanged();
+        return this;
+      }
+      /**
+       * <code>string location = 4;</code>
+       */
+      public Builder clearLocation() {
+        
+        location_ = getDefaultInstance().getLocation();
+        onChanged();
+        return this;
+      }
+      /**
+       * <code>string location = 4;</code>
+       */
+      public Builder setLocationBytes(
+          com.google.protobuf.ByteString value) {
+        if (value == null) {
+    throw new NullPointerException();
+  }
+  checkByteStringIsUtf8(value);
+        
+        location_ = value;
+        onChanged();
+        return this;
+      }
+
+      private com.google.protobuf.LazyStringList category_ = com.google.protobuf.LazyStringArrayList.EMPTY;
+      private void ensureCategoryIsMutable() {
+        if (!((bitField0_ & 0x00000010) == 0x00000010)) {
+          category_ = new com.google.protobuf.LazyStringArrayList(category_);
+          bitField0_ |= 0x00000010;
+         }
+      }
+      /**
+       * <code>repeated string category = 5;</code>
+       */
+      public com.google.protobuf.ProtocolStringList
+          getCategoryList() {
+        return category_.getUnmodifiableView();
+      }
+      /**
+       * <code>repeated string category = 5;</code>
+       */
+      public int getCategoryCount() {
+        return category_.size();
+      }
+      /**
+       * <code>repeated string category = 5;</code>
+       */
+      public java.lang.String getCategory(int index) {
+        return category_.get(index);
+      }
+      /**
+       * <code>repeated string category = 5;</code>
+       */
+      public com.google.protobuf.ByteString
+          getCategoryBytes(int index) {
+        return category_.getByteString(index);
+      }
+      /**
+       * <code>repeated string category = 5;</code>
+       */
+      public Builder setCategory(
+          int index, java.lang.String value) {
+        if (value == null) {
+    throw new NullPointerException();
+  }
+  ensureCategoryIsMutable();
+        category_.set(index, value);
+        onChanged();
+        return this;
+      }
+      /**
+       * <code>repeated string category = 5;</code>
+       */
+      public Builder addCategory(
+          java.lang.String value) {
+        if (value == null) {
+    throw new NullPointerException();
+  }
+  ensureCategoryIsMutable();
+        category_.add(value);
+        onChanged();
+        return this;
+      }
+      /**
+       * <code>repeated string category = 5;</code>
+       */
+      public Builder addAllCategory(
+          java.lang.Iterable<java.lang.String> values) {
+        ensureCategoryIsMutable();
+        com.google.protobuf.AbstractMessageLite.Builder.addAll(
+            values, category_);
+        onChanged();
+        return this;
+      }
+      /**
+       * <code>repeated string category = 5;</code>
+       */
+      public Builder clearCategory() {
+        category_ = com.google.protobuf.LazyStringArrayList.EMPTY;
+        bitField0_ = (bitField0_ & ~0x00000010);
+        onChanged();
+        return this;
+      }
+      /**
+       * <code>repeated string category = 5;</code>
+       */
+      public Builder addCategoryBytes(
+          com.google.protobuf.ByteString value) {
+        if (value == null) {
+    throw new NullPointerException();
+  }
+  checkByteStringIsUtf8(value);
+        ensureCategoryIsMutable();
+        category_.add(value);
+        onChanged();
+        return this;
+      }
+
+      private java.lang.Object label_ = "";
+      /**
+       * <code>string label = 6;</code>
+       */
+      public java.lang.String getLabel() {
+        java.lang.Object ref = label_;
+        if (!(ref instanceof java.lang.String)) {
+          com.google.protobuf.ByteString bs =
+              (com.google.protobuf.ByteString) ref;
+          java.lang.String s = bs.toStringUtf8();
+          label_ = s;
+          return s;
+        } else {
+          return (java.lang.String) ref;
+        }
+      }
+      /**
+       * <code>string label = 6;</code>
+       */
+      public com.google.protobuf.ByteString
+          getLabelBytes() {
+        java.lang.Object ref = label_;
+        if (ref instanceof String) {
+          com.google.protobuf.ByteString b = 
+              com.google.protobuf.ByteString.copyFromUtf8(
+                  (java.lang.String) ref);
+          label_ = b;
+          return b;
+        } else {
+          return (com.google.protobuf.ByteString) ref;
+        }
+      }
+      /**
+       * <code>string label = 6;</code>
+       */
+      public Builder setLabel(
+          java.lang.String value) {
+        if (value == null) {
+    throw new NullPointerException();
+  }
+  
+        label_ = value;
+        onChanged();
+        return this;
+      }
+      /**
+       * <code>string label = 6;</code>
+       */
+      public Builder clearLabel() {
+        
+        label_ = getDefaultInstance().getLabel();
+        onChanged();
+        return this;
+      }
+      /**
+       * <code>string label = 6;</code>
+       */
+      public Builder setLabelBytes(
+          com.google.protobuf.ByteString value) {
+        if (value == null) {
+    throw new NullPointerException();
+  }
+  checkByteStringIsUtf8(value);
+        
+        label_ = value;
+        onChanged();
+        return this;
+      }
+
+      private long createTime_ ;
+      /**
+       * <code>uint64 create_time = 7;</code>
+       */
+      public long getCreateTime() {
+        return createTime_;
+      }
+      /**
+       * <code>uint64 create_time = 7;</code>
+       */
+      public Builder setCreateTime(long value) {
+        
+        createTime_ = value;
+        onChanged();
+        return this;
+      }
+      /**
+       * <code>uint64 create_time = 7;</code>
+       */
+      public Builder clearCreateTime() {
+        
+        createTime_ = 0L;
+        onChanged();
+        return this;
+      }
+
+      private java.lang.Object sysContact_ = "";
+      /**
+       * <code>string sys_contact = 8;</code>
+       */
+      public java.lang.String getSysContact() {
+        java.lang.Object ref = sysContact_;
+        if (!(ref instanceof java.lang.String)) {
+          com.google.protobuf.ByteString bs =
+              (com.google.protobuf.ByteString) ref;
+          java.lang.String s = bs.toStringUtf8();
+          sysContact_ = s;
+          return s;
+        } else {
+          return (java.lang.String) ref;
+        }
+      }
+      /**
+       * <code>string sys_contact = 8;</code>
+       */
+      public com.google.protobuf.ByteString
+          getSysContactBytes() {
+        java.lang.Object ref = sysContact_;
+        if (ref instanceof String) {
+          com.google.protobuf.ByteString b = 
+              com.google.protobuf.ByteString.copyFromUtf8(
+                  (java.lang.String) ref);
+          sysContact_ = b;
+          return b;
+        } else {
+          return (com.google.protobuf.ByteString) ref;
+        }
+      }
+      /**
+       * <code>string sys_contact = 8;</code>
+       */
+      public Builder setSysContact(
+          java.lang.String value) {
+        if (value == null) {
+    throw new NullPointerException();
+  }
+  
+        sysContact_ = value;
+        onChanged();
+        return this;
+      }
+      /**
+       * <code>string sys_contact = 8;</code>
+       */
+      public Builder clearSysContact() {
+        
+        sysContact_ = getDefaultInstance().getSysContact();
+        onChanged();
+        return this;
+      }
+      /**
+       * <code>string sys_contact = 8;</code>
+       */
+      public Builder setSysContactBytes(
+          com.google.protobuf.ByteString value) {
+        if (value == null) {
+    throw new NullPointerException();
+  }
+  checkByteStringIsUtf8(value);
+        
+        sysContact_ = value;
+        onChanged();
+        return this;
+      }
+
+      private java.lang.Object sysDescription_ = "";
+      /**
+       * <code>string sys_description = 9;</code>
+       */
+      public java.lang.String getSysDescription() {
+        java.lang.Object ref = sysDescription_;
+        if (!(ref instanceof java.lang.String)) {
+          com.google.protobuf.ByteString bs =
+              (com.google.protobuf.ByteString) ref;
+          java.lang.String s = bs.toStringUtf8();
+          sysDescription_ = s;
+          return s;
+        } else {
+          return (java.lang.String) ref;
+        }
+      }
+      /**
+       * <code>string sys_description = 9;</code>
+       */
+      public com.google.protobuf.ByteString
+          getSysDescriptionBytes() {
+        java.lang.Object ref = sysDescription_;
+        if (ref instanceof String) {
+          com.google.protobuf.ByteString b = 
+              com.google.protobuf.ByteString.copyFromUtf8(
+                  (java.lang.String) ref);
+          sysDescription_ = b;
+          return b;
+        } else {
+          return (com.google.protobuf.ByteString) ref;
+        }
+      }
+      /**
+       * <code>string sys_description = 9;</code>
+       */
+      public Builder setSysDescription(
+          java.lang.String value) {
+        if (value == null) {
+    throw new NullPointerException();
+  }
+  
+        sysDescription_ = value;
+        onChanged();
+        return this;
+      }
+      /**
+       * <code>string sys_description = 9;</code>
+       */
+      public Builder clearSysDescription() {
+        
+        sysDescription_ = getDefaultInstance().getSysDescription();
+        onChanged();
+        return this;
+      }
+      /**
+       * <code>string sys_description = 9;</code>
+       */
+      public Builder setSysDescriptionBytes(
+          com.google.protobuf.ByteString value) {
+        if (value == null) {
+    throw new NullPointerException();
+  }
+  checkByteStringIsUtf8(value);
+        
+        sysDescription_ = value;
+        onChanged();
+        return this;
+      }
+
+      private java.lang.Object sysObjectId_ = "";
+      /**
+       * <code>string sys_object_id = 10;</code>
+       */
+      public java.lang.String getSysObjectId() {
+        java.lang.Object ref = sysObjectId_;
+        if (!(ref instanceof java.lang.String)) {
+          com.google.protobuf.ByteString bs =
+              (com.google.protobuf.ByteString) ref;
+          java.lang.String s = bs.toStringUtf8();
+          sysObjectId_ = s;
+          return s;
+        } else {
+          return (java.lang.String) ref;
+        }
+      }
+      /**
+       * <code>string sys_object_id = 10;</code>
+       */
+      public com.google.protobuf.ByteString
+          getSysObjectIdBytes() {
+        java.lang.Object ref = sysObjectId_;
+        if (ref instanceof String) {
+          com.google.protobuf.ByteString b = 
+              com.google.protobuf.ByteString.copyFromUtf8(
+                  (java.lang.String) ref);
+          sysObjectId_ = b;
+          return b;
+        } else {
+          return (com.google.protobuf.ByteString) ref;
+        }
+      }
+      /**
+       * <code>string sys_object_id = 10;</code>
+       */
+      public Builder setSysObjectId(
+          java.lang.String value) {
+        if (value == null) {
+    throw new NullPointerException();
+  }
+  
+        sysObjectId_ = value;
+        onChanged();
+        return this;
+      }
+      /**
+       * <code>string sys_object_id = 10;</code>
+       */
+      public Builder clearSysObjectId() {
+        
+        sysObjectId_ = getDefaultInstance().getSysObjectId();
+        onChanged();
+        return this;
+      }
+      /**
+       * <code>string sys_object_id = 10;</code>
+       */
+      public Builder setSysObjectIdBytes(
+          com.google.protobuf.ByteString value) {
+        if (value == null) {
+    throw new NullPointerException();
+  }
+  checkByteStringIsUtf8(value);
+        
+        sysObjectId_ = value;
+        onChanged();
+        return this;
+      }
+
+      private java.util.List<org.opennms.features.kafka.producer.model.OpennmsModelProtos.IpInterface> ipInterface_ =
+        java.util.Collections.emptyList();
+      private void ensureIpInterfaceIsMutable() {
+        if (!((bitField0_ & 0x00000400) == 0x00000400)) {
+          ipInterface_ = new java.util.ArrayList<org.opennms.features.kafka.producer.model.OpennmsModelProtos.IpInterface>(ipInterface_);
+          bitField0_ |= 0x00000400;
+         }
+      }
+
+      private com.google.protobuf.RepeatedFieldBuilderV3<
+          org.opennms.features.kafka.producer.model.OpennmsModelProtos.IpInterface, org.opennms.features.kafka.producer.model.OpennmsModelProtos.IpInterface.Builder, org.opennms.features.kafka.producer.model.OpennmsModelProtos.IpInterfaceOrBuilder> ipInterfaceBuilder_;
+
+      /**
+       * <code>repeated .IpInterface ip_interface = 11;</code>
+       */
+      public java.util.List<org.opennms.features.kafka.producer.model.OpennmsModelProtos.IpInterface> getIpInterfaceList() {
+        if (ipInterfaceBuilder_ == null) {
+          return java.util.Collections.unmodifiableList(ipInterface_);
+        } else {
+          return ipInterfaceBuilder_.getMessageList();
+        }
+      }
+      /**
+       * <code>repeated .IpInterface ip_interface = 11;</code>
+       */
+      public int getIpInterfaceCount() {
+        if (ipInterfaceBuilder_ == null) {
+          return ipInterface_.size();
+        } else {
+          return ipInterfaceBuilder_.getCount();
+        }
+      }
+      /**
+       * <code>repeated .IpInterface ip_interface = 11;</code>
+       */
+      public org.opennms.features.kafka.producer.model.OpennmsModelProtos.IpInterface getIpInterface(int index) {
+        if (ipInterfaceBuilder_ == null) {
+          return ipInterface_.get(index);
+        } else {
+          return ipInterfaceBuilder_.getMessage(index);
+        }
+      }
+      /**
+       * <code>repeated .IpInterface ip_interface = 11;</code>
+       */
+      public Builder setIpInterface(
+          int index, org.opennms.features.kafka.producer.model.OpennmsModelProtos.IpInterface value) {
+        if (ipInterfaceBuilder_ == null) {
+          if (value == null) {
+            throw new NullPointerException();
+          }
+          ensureIpInterfaceIsMutable();
+          ipInterface_.set(index, value);
+          onChanged();
+        } else {
+          ipInterfaceBuilder_.setMessage(index, value);
+        }
+        return this;
+      }
+      /**
+       * <code>repeated .IpInterface ip_interface = 11;</code>
+       */
+      public Builder setIpInterface(
+          int index, org.opennms.features.kafka.producer.model.OpennmsModelProtos.IpInterface.Builder builderForValue) {
+        if (ipInterfaceBuilder_ == null) {
+          ensureIpInterfaceIsMutable();
+          ipInterface_.set(index, builderForValue.build());
+          onChanged();
+        } else {
+          ipInterfaceBuilder_.setMessage(index, builderForValue.build());
+        }
+        return this;
+      }
+      /**
+       * <code>repeated .IpInterface ip_interface = 11;</code>
+       */
+      public Builder addIpInterface(org.opennms.features.kafka.producer.model.OpennmsModelProtos.IpInterface value) {
+        if (ipInterfaceBuilder_ == null) {
+          if (value == null) {
+            throw new NullPointerException();
+          }
+          ensureIpInterfaceIsMutable();
+          ipInterface_.add(value);
+          onChanged();
+        } else {
+          ipInterfaceBuilder_.addMessage(value);
+        }
+        return this;
+      }
+      /**
+       * <code>repeated .IpInterface ip_interface = 11;</code>
+       */
+      public Builder addIpInterface(
+          int index, org.opennms.features.kafka.producer.model.OpennmsModelProtos.IpInterface value) {
+        if (ipInterfaceBuilder_ == null) {
+          if (value == null) {
+            throw new NullPointerException();
+          }
+          ensureIpInterfaceIsMutable();
+          ipInterface_.add(index, value);
+          onChanged();
+        } else {
+          ipInterfaceBuilder_.addMessage(index, value);
+        }
+        return this;
+      }
+      /**
+       * <code>repeated .IpInterface ip_interface = 11;</code>
+       */
+      public Builder addIpInterface(
+          org.opennms.features.kafka.producer.model.OpennmsModelProtos.IpInterface.Builder builderForValue) {
+        if (ipInterfaceBuilder_ == null) {
+          ensureIpInterfaceIsMutable();
+          ipInterface_.add(builderForValue.build());
+          onChanged();
+        } else {
+          ipInterfaceBuilder_.addMessage(builderForValue.build());
+        }
+        return this;
+      }
+      /**
+       * <code>repeated .IpInterface ip_interface = 11;</code>
+       */
+      public Builder addIpInterface(
+          int index, org.opennms.features.kafka.producer.model.OpennmsModelProtos.IpInterface.Builder builderForValue) {
+        if (ipInterfaceBuilder_ == null) {
+          ensureIpInterfaceIsMutable();
+          ipInterface_.add(index, builderForValue.build());
+          onChanged();
+        } else {
+          ipInterfaceBuilder_.addMessage(index, builderForValue.build());
+        }
+        return this;
+      }
+      /**
+       * <code>repeated .IpInterface ip_interface = 11;</code>
+       */
+      public Builder addAllIpInterface(
+          java.lang.Iterable<? extends org.opennms.features.kafka.producer.model.OpennmsModelProtos.IpInterface> values) {
+        if (ipInterfaceBuilder_ == null) {
+          ensureIpInterfaceIsMutable();
+          com.google.protobuf.AbstractMessageLite.Builder.addAll(
+              values, ipInterface_);
+          onChanged();
+        } else {
+          ipInterfaceBuilder_.addAllMessages(values);
+        }
+        return this;
+      }
+      /**
+       * <code>repeated .IpInterface ip_interface = 11;</code>
+       */
+      public Builder clearIpInterface() {
+        if (ipInterfaceBuilder_ == null) {
+          ipInterface_ = java.util.Collections.emptyList();
+          bitField0_ = (bitField0_ & ~0x00000400);
+          onChanged();
+        } else {
+          ipInterfaceBuilder_.clear();
+        }
+        return this;
+      }
+      /**
+       * <code>repeated .IpInterface ip_interface = 11;</code>
+       */
+      public Builder removeIpInterface(int index) {
+        if (ipInterfaceBuilder_ == null) {
+          ensureIpInterfaceIsMutable();
+          ipInterface_.remove(index);
+          onChanged();
+        } else {
+          ipInterfaceBuilder_.remove(index);
+        }
+        return this;
+      }
+      /**
+       * <code>repeated .IpInterface ip_interface = 11;</code>
+       */
+      public org.opennms.features.kafka.producer.model.OpennmsModelProtos.IpInterface.Builder getIpInterfaceBuilder(
+          int index) {
+        return getIpInterfaceFieldBuilder().getBuilder(index);
+      }
+      /**
+       * <code>repeated .IpInterface ip_interface = 11;</code>
+       */
+      public org.opennms.features.kafka.producer.model.OpennmsModelProtos.IpInterfaceOrBuilder getIpInterfaceOrBuilder(
+          int index) {
+        if (ipInterfaceBuilder_ == null) {
+          return ipInterface_.get(index);  } else {
+          return ipInterfaceBuilder_.getMessageOrBuilder(index);
+        }
+      }
+      /**
+       * <code>repeated .IpInterface ip_interface = 11;</code>
+       */
+      public java.util.List<? extends org.opennms.features.kafka.producer.model.OpennmsModelProtos.IpInterfaceOrBuilder> 
+           getIpInterfaceOrBuilderList() {
+        if (ipInterfaceBuilder_ != null) {
+          return ipInterfaceBuilder_.getMessageOrBuilderList();
+        } else {
+          return java.util.Collections.unmodifiableList(ipInterface_);
+        }
+      }
+      /**
+       * <code>repeated .IpInterface ip_interface = 11;</code>
+       */
+      public org.opennms.features.kafka.producer.model.OpennmsModelProtos.IpInterface.Builder addIpInterfaceBuilder() {
+        return getIpInterfaceFieldBuilder().addBuilder(
+            org.opennms.features.kafka.producer.model.OpennmsModelProtos.IpInterface.getDefaultInstance());
+      }
+      /**
+       * <code>repeated .IpInterface ip_interface = 11;</code>
+       */
+      public org.opennms.features.kafka.producer.model.OpennmsModelProtos.IpInterface.Builder addIpInterfaceBuilder(
+          int index) {
+        return getIpInterfaceFieldBuilder().addBuilder(
+            index, org.opennms.features.kafka.producer.model.OpennmsModelProtos.IpInterface.getDefaultInstance());
+      }
+      /**
+       * <code>repeated .IpInterface ip_interface = 11;</code>
+       */
+      public java.util.List<org.opennms.features.kafka.producer.model.OpennmsModelProtos.IpInterface.Builder> 
+           getIpInterfaceBuilderList() {
+        return getIpInterfaceFieldBuilder().getBuilderList();
+      }
+      private com.google.protobuf.RepeatedFieldBuilderV3<
+          org.opennms.features.kafka.producer.model.OpennmsModelProtos.IpInterface, org.opennms.features.kafka.producer.model.OpennmsModelProtos.IpInterface.Builder, org.opennms.features.kafka.producer.model.OpennmsModelProtos.IpInterfaceOrBuilder> 
+          getIpInterfaceFieldBuilder() {
+        if (ipInterfaceBuilder_ == null) {
+          ipInterfaceBuilder_ = new com.google.protobuf.RepeatedFieldBuilderV3<
+              org.opennms.features.kafka.producer.model.OpennmsModelProtos.IpInterface, org.opennms.features.kafka.producer.model.OpennmsModelProtos.IpInterface.Builder, org.opennms.features.kafka.producer.model.OpennmsModelProtos.IpInterfaceOrBuilder>(
+                  ipInterface_,
+                  ((bitField0_ & 0x00000400) == 0x00000400),
+                  getParentForChildren(),
+                  isClean());
+          ipInterface_ = null;
+        }
+        return ipInterfaceBuilder_;
+      }
+
+      private java.util.List<org.opennms.features.kafka.producer.model.OpennmsModelProtos.SnmpInterface> snmpInterface_ =
+        java.util.Collections.emptyList();
+      private void ensureSnmpInterfaceIsMutable() {
+        if (!((bitField0_ & 0x00000800) == 0x00000800)) {
+          snmpInterface_ = new java.util.ArrayList<org.opennms.features.kafka.producer.model.OpennmsModelProtos.SnmpInterface>(snmpInterface_);
+          bitField0_ |= 0x00000800;
+         }
+      }
+
+      private com.google.protobuf.RepeatedFieldBuilderV3<
+          org.opennms.features.kafka.producer.model.OpennmsModelProtos.SnmpInterface, org.opennms.features.kafka.producer.model.OpennmsModelProtos.SnmpInterface.Builder, org.opennms.features.kafka.producer.model.OpennmsModelProtos.SnmpInterfaceOrBuilder> snmpInterfaceBuilder_;
+
+      /**
+       * <code>repeated .SnmpInterface snmp_interface = 12;</code>
+       */
+      public java.util.List<org.opennms.features.kafka.producer.model.OpennmsModelProtos.SnmpInterface> getSnmpInterfaceList() {
+        if (snmpInterfaceBuilder_ == null) {
+          return java.util.Collections.unmodifiableList(snmpInterface_);
+        } else {
+          return snmpInterfaceBuilder_.getMessageList();
+        }
+      }
+      /**
+       * <code>repeated .SnmpInterface snmp_interface = 12;</code>
+       */
+      public int getSnmpInterfaceCount() {
+        if (snmpInterfaceBuilder_ == null) {
+          return snmpInterface_.size();
+        } else {
+          return snmpInterfaceBuilder_.getCount();
+        }
+      }
+      /**
+       * <code>repeated .SnmpInterface snmp_interface = 12;</code>
+       */
+      public org.opennms.features.kafka.producer.model.OpennmsModelProtos.SnmpInterface getSnmpInterface(int index) {
+        if (snmpInterfaceBuilder_ == null) {
+          return snmpInterface_.get(index);
+        } else {
+          return snmpInterfaceBuilder_.getMessage(index);
+        }
+      }
+      /**
+       * <code>repeated .SnmpInterface snmp_interface = 12;</code>
+       */
+      public Builder setSnmpInterface(
+          int index, org.opennms.features.kafka.producer.model.OpennmsModelProtos.SnmpInterface value) {
+        if (snmpInterfaceBuilder_ == null) {
+          if (value == null) {
+            throw new NullPointerException();
+          }
+          ensureSnmpInterfaceIsMutable();
+          snmpInterface_.set(index, value);
+          onChanged();
+        } else {
+          snmpInterfaceBuilder_.setMessage(index, value);
+        }
+        return this;
+      }
+      /**
+       * <code>repeated .SnmpInterface snmp_interface = 12;</code>
+       */
+      public Builder setSnmpInterface(
+          int index, org.opennms.features.kafka.producer.model.OpennmsModelProtos.SnmpInterface.Builder builderForValue) {
+        if (snmpInterfaceBuilder_ == null) {
+          ensureSnmpInterfaceIsMutable();
+          snmpInterface_.set(index, builderForValue.build());
+          onChanged();
+        } else {
+          snmpInterfaceBuilder_.setMessage(index, builderForValue.build());
+        }
+        return this;
+      }
+      /**
+       * <code>repeated .SnmpInterface snmp_interface = 12;</code>
+       */
+      public Builder addSnmpInterface(org.opennms.features.kafka.producer.model.OpennmsModelProtos.SnmpInterface value) {
+        if (snmpInterfaceBuilder_ == null) {
+          if (value == null) {
+            throw new NullPointerException();
+          }
+          ensureSnmpInterfaceIsMutable();
+          snmpInterface_.add(value);
+          onChanged();
+        } else {
+          snmpInterfaceBuilder_.addMessage(value);
+        }
+        return this;
+      }
+      /**
+       * <code>repeated .SnmpInterface snmp_interface = 12;</code>
+       */
+      public Builder addSnmpInterface(
+          int index, org.opennms.features.kafka.producer.model.OpennmsModelProtos.SnmpInterface value) {
+        if (snmpInterfaceBuilder_ == null) {
+          if (value == null) {
+            throw new NullPointerException();
+          }
+          ensureSnmpInterfaceIsMutable();
+          snmpInterface_.add(index, value);
+          onChanged();
+        } else {
+          snmpInterfaceBuilder_.addMessage(index, value);
+        }
+        return this;
+      }
+      /**
+       * <code>repeated .SnmpInterface snmp_interface = 12;</code>
+       */
+      public Builder addSnmpInterface(
+          org.opennms.features.kafka.producer.model.OpennmsModelProtos.SnmpInterface.Builder builderForValue) {
+        if (snmpInterfaceBuilder_ == null) {
+          ensureSnmpInterfaceIsMutable();
+          snmpInterface_.add(builderForValue.build());
+          onChanged();
+        } else {
+          snmpInterfaceBuilder_.addMessage(builderForValue.build());
+        }
+        return this;
+      }
+      /**
+       * <code>repeated .SnmpInterface snmp_interface = 12;</code>
+       */
+      public Builder addSnmpInterface(
+          int index, org.opennms.features.kafka.producer.model.OpennmsModelProtos.SnmpInterface.Builder builderForValue) {
+        if (snmpInterfaceBuilder_ == null) {
+          ensureSnmpInterfaceIsMutable();
+          snmpInterface_.add(index, builderForValue.build());
+          onChanged();
+        } else {
+          snmpInterfaceBuilder_.addMessage(index, builderForValue.build());
+        }
+        return this;
+      }
+      /**
+       * <code>repeated .SnmpInterface snmp_interface = 12;</code>
+       */
+      public Builder addAllSnmpInterface(
+          java.lang.Iterable<? extends org.opennms.features.kafka.producer.model.OpennmsModelProtos.SnmpInterface> values) {
+        if (snmpInterfaceBuilder_ == null) {
+          ensureSnmpInterfaceIsMutable();
+          com.google.protobuf.AbstractMessageLite.Builder.addAll(
+              values, snmpInterface_);
+          onChanged();
+        } else {
+          snmpInterfaceBuilder_.addAllMessages(values);
+        }
+        return this;
+      }
+      /**
+       * <code>repeated .SnmpInterface snmp_interface = 12;</code>
+       */
+      public Builder clearSnmpInterface() {
+        if (snmpInterfaceBuilder_ == null) {
+          snmpInterface_ = java.util.Collections.emptyList();
+          bitField0_ = (bitField0_ & ~0x00000800);
+          onChanged();
+        } else {
+          snmpInterfaceBuilder_.clear();
+        }
+        return this;
+      }
+      /**
+       * <code>repeated .SnmpInterface snmp_interface = 12;</code>
+       */
+      public Builder removeSnmpInterface(int index) {
+        if (snmpInterfaceBuilder_ == null) {
+          ensureSnmpInterfaceIsMutable();
+          snmpInterface_.remove(index);
+          onChanged();
+        } else {
+          snmpInterfaceBuilder_.remove(index);
+        }
+        return this;
+      }
+      /**
+       * <code>repeated .SnmpInterface snmp_interface = 12;</code>
+       */
+      public org.opennms.features.kafka.producer.model.OpennmsModelProtos.SnmpInterface.Builder getSnmpInterfaceBuilder(
+          int index) {
+        return getSnmpInterfaceFieldBuilder().getBuilder(index);
+      }
+      /**
+       * <code>repeated .SnmpInterface snmp_interface = 12;</code>
+       */
+      public org.opennms.features.kafka.producer.model.OpennmsModelProtos.SnmpInterfaceOrBuilder getSnmpInterfaceOrBuilder(
+          int index) {
+        if (snmpInterfaceBuilder_ == null) {
+          return snmpInterface_.get(index);  } else {
+          return snmpInterfaceBuilder_.getMessageOrBuilder(index);
+        }
+      }
+      /**
+       * <code>repeated .SnmpInterface snmp_interface = 12;</code>
+       */
+      public java.util.List<? extends org.opennms.features.kafka.producer.model.OpennmsModelProtos.SnmpInterfaceOrBuilder> 
+           getSnmpInterfaceOrBuilderList() {
+        if (snmpInterfaceBuilder_ != null) {
+          return snmpInterfaceBuilder_.getMessageOrBuilderList();
+        } else {
+          return java.util.Collections.unmodifiableList(snmpInterface_);
+        }
+      }
+      /**
+       * <code>repeated .SnmpInterface snmp_interface = 12;</code>
+       */
+      public org.opennms.features.kafka.producer.model.OpennmsModelProtos.SnmpInterface.Builder addSnmpInterfaceBuilder() {
+        return getSnmpInterfaceFieldBuilder().addBuilder(
+            org.opennms.features.kafka.producer.model.OpennmsModelProtos.SnmpInterface.getDefaultInstance());
+      }
+      /**
+       * <code>repeated .SnmpInterface snmp_interface = 12;</code>
+       */
+      public org.opennms.features.kafka.producer.model.OpennmsModelProtos.SnmpInterface.Builder addSnmpInterfaceBuilder(
+          int index) {
+        return getSnmpInterfaceFieldBuilder().addBuilder(
+            index, org.opennms.features.kafka.producer.model.OpennmsModelProtos.SnmpInterface.getDefaultInstance());
+      }
+      /**
+       * <code>repeated .SnmpInterface snmp_interface = 12;</code>
+       */
+      public java.util.List<org.opennms.features.kafka.producer.model.OpennmsModelProtos.SnmpInterface.Builder> 
+           getSnmpInterfaceBuilderList() {
+        return getSnmpInterfaceFieldBuilder().getBuilderList();
+      }
+      private com.google.protobuf.RepeatedFieldBuilderV3<
+          org.opennms.features.kafka.producer.model.OpennmsModelProtos.SnmpInterface, org.opennms.features.kafka.producer.model.OpennmsModelProtos.SnmpInterface.Builder, org.opennms.features.kafka.producer.model.OpennmsModelProtos.SnmpInterfaceOrBuilder> 
+          getSnmpInterfaceFieldBuilder() {
+        if (snmpInterfaceBuilder_ == null) {
+          snmpInterfaceBuilder_ = new com.google.protobuf.RepeatedFieldBuilderV3<
+              org.opennms.features.kafka.producer.model.OpennmsModelProtos.SnmpInterface, org.opennms.features.kafka.producer.model.OpennmsModelProtos.SnmpInterface.Builder, org.opennms.features.kafka.producer.model.OpennmsModelProtos.SnmpInterfaceOrBuilder>(
+                  snmpInterface_,
+                  ((bitField0_ & 0x00000800) == 0x00000800),
+                  getParentForChildren(),
+                  isClean());
+          snmpInterface_ = null;
+        }
+        return snmpInterfaceBuilder_;
+      }
+      public final Builder setUnknownFields(
+          final com.google.protobuf.UnknownFieldSet unknownFields) {
+        return super.setUnknownFieldsProto3(unknownFields);
+      }
+
+      public final Builder mergeUnknownFields(
+          final com.google.protobuf.UnknownFieldSet unknownFields) {
+        return super.mergeUnknownFields(unknownFields);
+      }
+
+
+      // @@protoc_insertion_point(builder_scope:Node)
+    }
+
+    // @@protoc_insertion_point(class_scope:Node)
+    private static final org.opennms.features.kafka.producer.model.OpennmsModelProtos.Node DEFAULT_INSTANCE;
+    static {
+      DEFAULT_INSTANCE = new org.opennms.features.kafka.producer.model.OpennmsModelProtos.Node();
+    }
+
+    public static org.opennms.features.kafka.producer.model.OpennmsModelProtos.Node getDefaultInstance() {
+      return DEFAULT_INSTANCE;
+    }
+
+    private static final com.google.protobuf.Parser<Node>
+        PARSER = new com.google.protobuf.AbstractParser<Node>() {
+      public Node parsePartialFrom(
+          com.google.protobuf.CodedInputStream input,
+          com.google.protobuf.ExtensionRegistryLite extensionRegistry)
+          throws com.google.protobuf.InvalidProtocolBufferException {
+        return new Node(input, extensionRegistry);
+      }
+    };
+
+    public static com.google.protobuf.Parser<Node> parser() {
+      return PARSER;
+    }
+
+    @java.lang.Override
+    public com.google.protobuf.Parser<Node> getParserForType() {
+      return PARSER;
+    }
+
+    public org.opennms.features.kafka.producer.model.OpennmsModelProtos.Node getDefaultInstanceForType() {
+      return DEFAULT_INSTANCE;
+    }
+
+  }
+
+  private static final com.google.protobuf.Descriptors.Descriptor
+    internal_static_NodeCriteria_descriptor;
+  private static final 
+    com.google.protobuf.GeneratedMessageV3.FieldAccessorTable
+      internal_static_NodeCriteria_fieldAccessorTable;
+  private static final com.google.protobuf.Descriptors.Descriptor
+    internal_static_EventParameter_descriptor;
+  private static final 
+    com.google.protobuf.GeneratedMessageV3.FieldAccessorTable
+      internal_static_EventParameter_fieldAccessorTable;
+  private static final com.google.protobuf.Descriptors.Descriptor
+    internal_static_Event_descriptor;
+  private static final 
+    com.google.protobuf.GeneratedMessageV3.FieldAccessorTable
+      internal_static_Event_fieldAccessorTable;
+  private static final com.google.protobuf.Descriptors.Descriptor
+    internal_static_Alarm_descriptor;
+  private static final 
+    com.google.protobuf.GeneratedMessageV3.FieldAccessorTable
+      internal_static_Alarm_fieldAccessorTable;
+  private static final com.google.protobuf.Descriptors.Descriptor
+    internal_static_IpInterface_descriptor;
+  private static final 
+    com.google.protobuf.GeneratedMessageV3.FieldAccessorTable
+      internal_static_IpInterface_fieldAccessorTable;
+  private static final com.google.protobuf.Descriptors.Descriptor
+    internal_static_SnmpInterface_descriptor;
+  private static final 
+    com.google.protobuf.GeneratedMessageV3.FieldAccessorTable
+      internal_static_SnmpInterface_fieldAccessorTable;
+  private static final com.google.protobuf.Descriptors.Descriptor
+    internal_static_Node_descriptor;
+  private static final 
+    com.google.protobuf.GeneratedMessageV3.FieldAccessorTable
+      internal_static_Node_fieldAccessorTable;
+
+  public static com.google.protobuf.Descriptors.FileDescriptor
+      getDescriptor() {
+    return descriptor;
+  }
+  private static  com.google.protobuf.Descriptors.FileDescriptor
+      descriptor;
+  static {
+    java.lang.String[] descriptorData = {
+      "\n\ropennms.proto\"F\n\014NodeCriteria\022\n\n\002id\030\001 " +
+      "\001(\004\022\026\n\016foreign_source\030\002 \001(\t\022\022\n\nforeign_i" +
+      "d\030\003 \001(\t\";\n\016EventParameter\022\014\n\004name\030\001 \001(\t\022" +
+      "\r\n\005value\030\002 \001(\t\022\014\n\004type\030\003 \001(\t\"\221\002\n\005Event\022\n" +
+      "\n\002id\030\001 \001(\004\022\013\n\003uei\030\002 \001(\t\022\r\n\005label\030\003 \001(\t\022\014" +
+      "\n\004time\030\004 \001(\004\022\016\n\006source\030\005 \001(\t\022\"\n\tparamete" +
+      "r\030\006 \003(\0132\017.EventParameter\022\023\n\013create_time\030" +
+      "\007 \001(\004\022\023\n\013description\030\010 \001(\t\022\023\n\013log_messag" +
+      "e\030\t \001(\t\022\033\n\010severity\030\n \001(\0162\t.Severity\022\013\n\003" +
+      "log\030\013 \001(\010\022\017\n\007display\030\014 \001(\010\022$\n\rnode_crite" +
+      "ria\030\r \001(\0132\r.NodeCriteria\"\365\003\n\005Alarm\022\n\n\002id" +
+      "\030\001 \001(\004\022\013\n\003uei\030\002 \001(\t\022$\n\rnode_criteria\030\003 \001" +
+      "(\0132\r.NodeCriteria\022\022\n\nip_address\030\004 \001(\t\022\024\n" +
+      "\014service_name\030\005 \001(\t\022\025\n\rreduction_key\030\006 \001" +
+      "(\t\022\031\n\004type\030\007 \001(\0162\013.Alarm.Type\022\r\n\005count\030\010" +
+      " \001(\004\022\033\n\010severity\030\t \001(\0162\t.Severity\022\030\n\020fir" +
+      "st_event_time\030\n \001(\004\022\023\n\013description\030\013 \001(\t" +
+      "\022\023\n\013log_message\030\014 \001(\t\022\020\n\010ack_user\030\r \001(\t\022" +
+      "\020\n\010ack_time\030\016 \001(\004\022\032\n\nlast_event\030\017 \001(\0132\006." +
+      "Event\022\027\n\017last_event_time\030\020 \001(\004\022\020\n\010if_ind" +
+      "ex\030\021 \001(\r\022\035\n\025operator_instructions\030\022 \001(\t\022" +
+      "\021\n\tclear_key\030\023 \001(\t\"D\n\004Type\022\026\n\022PROBLEM_WI" +
+      "TH_CLEAR\020\000\022\t\n\005CLEAR\020\001\022\031\n\025PROBLEM_WITHOUT" +
+      "_CLEAR\020\002\"\275\001\n\013IpInterface\022\n\n\002id\030\001 \001(\004\022\022\n\n" +
+      "ip_address\030\002 \001(\t\022\020\n\010if_index\030\003 \001(\r\022.\n\014pr" +
+      "imary_type\030\004 \001(\0162\030.IpInterface.PrimaryTy" +
+      "pe\022\017\n\007service\030\005 \003(\t\";\n\013PrimaryType\022\013\n\007PR" +
+      "IMARY\020\000\022\r\n\tSECONDARY\020\001\022\020\n\014NOT_ELIGIBLE\020\002" +
+      "\"\317\001\n\rSnmpInterface\022\n\n\002id\030\001 \001(\004\022\020\n\010if_ind" +
+      "ex\030\002 \001(\r\022\020\n\010if_descr\030\003 \001(\t\022\017\n\007if_type\030\004 " +
+      "\001(\r\022\017\n\007if_name\030\005 \001(\t\022\020\n\010if_speed\030\006 \001(\004\022\027" +
+      "\n\017if_phys_address\030\007 \001(\t\022\027\n\017if_admin_stat" +
+      "us\030\010 \001(\r\022\026\n\016if_oper_status\030\t \001(\r\022\020\n\010if_a" +
+      "lias\030\n \001(\t\"\227\002\n\004Node\022\n\n\002id\030\001 \001(\004\022\026\n\016forei" +
+      "gn_source\030\002 \001(\t\022\022\n\nforeign_id\030\003 \001(\t\022\020\n\010l" +
+      "ocation\030\004 \001(\t\022\020\n\010category\030\005 \003(\t\022\r\n\005label" +
+      "\030\006 \001(\t\022\023\n\013create_time\030\007 \001(\004\022\023\n\013sys_conta" +
+      "ct\030\010 \001(\t\022\027\n\017sys_description\030\t \001(\t\022\025\n\rsys" +
+      "_object_id\030\n \001(\t\022\"\n\014ip_interface\030\013 \003(\0132\014" +
+      ".IpInterface\022&\n\016snmp_interface\030\014 \003(\0132\016.S" +
+      "nmpInterface*g\n\010Severity\022\021\n\rINDETERMINAT" +
+      "E\020\000\022\013\n\007CLEARED\020\001\022\n\n\006NORMAL\020\002\022\013\n\007WARNING\020" +
+      "\003\022\t\n\005MINOR\020\004\022\t\n\005MAJOR\020\005\022\014\n\010CRITICAL\020\006B?\n" +
+      ")org.opennms.features.kafka.producer.mod" +
+      "elB\022OpennmsModelProtosb\006proto3"
+    };
+    com.google.protobuf.Descriptors.FileDescriptor.InternalDescriptorAssigner assigner =
+        new com.google.protobuf.Descriptors.FileDescriptor.    InternalDescriptorAssigner() {
+          public com.google.protobuf.ExtensionRegistry assignDescriptors(
+              com.google.protobuf.Descriptors.FileDescriptor root) {
+            descriptor = root;
+            return null;
+          }
+        };
+    com.google.protobuf.Descriptors.FileDescriptor
+      .internalBuildGeneratedFileFrom(descriptorData,
+        new com.google.protobuf.Descriptors.FileDescriptor[] {
+        }, assigner);
+    internal_static_NodeCriteria_descriptor =
+      getDescriptor().getMessageTypes().get(0);
+    internal_static_NodeCriteria_fieldAccessorTable = new
+      com.google.protobuf.GeneratedMessageV3.FieldAccessorTable(
+        internal_static_NodeCriteria_descriptor,
+        new java.lang.String[] { "Id", "ForeignSource", "ForeignId", });
+    internal_static_EventParameter_descriptor =
+      getDescriptor().getMessageTypes().get(1);
+    internal_static_EventParameter_fieldAccessorTable = new
+      com.google.protobuf.GeneratedMessageV3.FieldAccessorTable(
+        internal_static_EventParameter_descriptor,
+        new java.lang.String[] { "Name", "Value", "Type", });
+    internal_static_Event_descriptor =
+      getDescriptor().getMessageTypes().get(2);
+    internal_static_Event_fieldAccessorTable = new
+      com.google.protobuf.GeneratedMessageV3.FieldAccessorTable(
+        internal_static_Event_descriptor,
+        new java.lang.String[] { "Id", "Uei", "Label", "Time", "Source", "Parameter", "CreateTime", "Description", "LogMessage", "Severity", "Log", "Display", "NodeCriteria", });
+    internal_static_Alarm_descriptor =
+      getDescriptor().getMessageTypes().get(3);
+    internal_static_Alarm_fieldAccessorTable = new
+      com.google.protobuf.GeneratedMessageV3.FieldAccessorTable(
+        internal_static_Alarm_descriptor,
+        new java.lang.String[] { "Id", "Uei", "NodeCriteria", "IpAddress", "ServiceName", "ReductionKey", "Type", "Count", "Severity", "FirstEventTime", "Description", "LogMessage", "AckUser", "AckTime", "LastEvent", "LastEventTime", "IfIndex", "OperatorInstructions", "ClearKey", });
+    internal_static_IpInterface_descriptor =
+      getDescriptor().getMessageTypes().get(4);
+    internal_static_IpInterface_fieldAccessorTable = new
+      com.google.protobuf.GeneratedMessageV3.FieldAccessorTable(
+        internal_static_IpInterface_descriptor,
+        new java.lang.String[] { "Id", "IpAddress", "IfIndex", "PrimaryType", "Service", });
+    internal_static_SnmpInterface_descriptor =
+      getDescriptor().getMessageTypes().get(5);
+    internal_static_SnmpInterface_fieldAccessorTable = new
+      com.google.protobuf.GeneratedMessageV3.FieldAccessorTable(
+        internal_static_SnmpInterface_descriptor,
+        new java.lang.String[] { "Id", "IfIndex", "IfDescr", "IfType", "IfName", "IfSpeed", "IfPhysAddress", "IfAdminStatus", "IfOperStatus", "IfAlias", });
+    internal_static_Node_descriptor =
+      getDescriptor().getMessageTypes().get(6);
+    internal_static_Node_fieldAccessorTable = new
+      com.google.protobuf.GeneratedMessageV3.FieldAccessorTable(
+        internal_static_Node_descriptor,
+        new java.lang.String[] { "Id", "ForeignSource", "ForeignId", "Location", "Category", "Label", "CreateTime", "SysContact", "SysDescription", "SysObjectId", "IpInterface", "SnmpInterface", });
+  }
+
+  // @@protoc_insertion_point(outer_class_scope)
+}
diff --git a/features/kafka/producer/src/main/java/org/opennms/features/kafka/producer/shell/EvaluateFilter.java b/features/kafka/producer/src/main/java/org/opennms/features/kafka/producer/shell/EvaluateFilter.java
new file mode 100644
index 00000000000..95b293d7e1f
--- /dev/null
+++ b/features/kafka/producer/src/main/java/org/opennms/features/kafka/producer/shell/EvaluateFilter.java
@@ -0,0 +1,93 @@
+/*******************************************************************************
+ * This file is part of OpenNMS(R).
+ *
+ * Copyright (C) 2018 The OpenNMS Group, Inc.
+ * OpenNMS(R) is Copyright (C) 1999-2018 The OpenNMS Group, Inc.
+ *
+ * OpenNMS(R) is a registered trademark of The OpenNMS Group, Inc.
+ *
+ * OpenNMS(R) is free software: you can redistribute it and/or modify
+ * it under the terms of the GNU Affero General Public License as published
+ * by the Free Software Foundation, either version 3 of the License,
+ * or (at your option) any later version.
+ *
+ * OpenNMS(R) is distributed in the hope that it will be useful,
+ * but WITHOUT ANY WARRANTY; without even the implied warranty of
+ * MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
+ * GNU Affero General Public License for more details.
+ *
+ * You should have received a copy of the GNU Affero General Public License
+ * along with OpenNMS(R).  If not, see:
+ *      http://www.gnu.org/licenses/
+ *
+ * For more information contact:
+ *     OpenNMS(R) Licensing <license@opennms.org>
+ *     http://www.opennms.org/
+ *     http://www.opennms.com/
+ *******************************************************************************/
+
+package org.opennms.features.kafka.producer.shell;
+
+import org.apache.karaf.shell.api.action.Action;
+import org.apache.karaf.shell.api.action.Argument;
+import org.apache.karaf.shell.api.action.Command;
+import org.apache.karaf.shell.api.action.Option;
+import org.apache.karaf.shell.api.action.lifecycle.Reference;
+import org.apache.karaf.shell.api.action.lifecycle.Service;
+import org.opennms.netmgt.dao.api.AlarmDao;
+import org.opennms.netmgt.model.OnmsAlarm;
+import org.opennms.netmgt.model.events.EventBuilder;
+import org.opennms.netmgt.xml.event.Event;
+import org.springframework.expression.Expression;
+import org.springframework.expression.ExpressionParser;
+import org.springframework.expression.spel.standard.SpelExpressionParser;
+import org.springframework.transaction.support.TransactionCallback;
+import org.springframework.transaction.support.TransactionOperations;
+
+@Command(scope = "kafka-producer", name = "evaluate-filter", description = "Compiles the given expression and optionally test it against an object.")
+@Service
+public class EvaluateFilter implements Action {
+    private static final ExpressionParser SPEL_PARSER = new SpelExpressionParser();
+
+    @Reference
+    private AlarmDao alarmDao;
+
+    @Reference
+    private TransactionOperations transactionOperations;
+
+    @Option(name = "-a", aliases = "--alarm-id", description = "Lookup an alarm by id and apply the given expression against it.")
+    private Integer alarmId;
+
+    @Option(name = "-e", aliases = "--event-uei", description = "Create a new event with the given UEI and apply the given expression against it.")
+    private String eventUei;
+
+    @Argument(description = "An SPEL expression.")
+    private String spelExpression;
+
+    @Override
+    public Object execute() {
+        final Expression expression = SPEL_PARSER.parseExpression(spelExpression);
+        System.out.printf("SPEL Expression: %s\n", expression.getExpressionString());
+        if (alarmId != null) {
+            transactionOperations.execute((TransactionCallback<Void>) status -> {
+                if (alarmId != null) {
+                    final OnmsAlarm alarm = alarmDao.get(alarmId);
+                    if (alarm == null) {
+                        System.out.printf("No alarm found with ID: %d\n", alarmId);
+                    } else {
+                        System.out.printf("Alarm with ID %d has reduction key: %s\n", alarmId, alarm.getReductionKey());
+                    }
+                    System.out.printf("Result: %s\n", expression.getValue(alarm, Boolean.class));
+                }
+                return null;
+            });
+        }
+        if (eventUei != null) {
+            final Event event = new EventBuilder(eventUei, "kafka-producer:evaluate-filter")
+                    .getEvent();
+            System.out.printf("Event has UEI: %s\n", event.getUei());
+            System.out.printf("Result: %s\n", expression.getValue(event, Boolean.class));
+        }
+        return null;
+    }
+}
diff --git a/features/kafka/producer/src/main/java/org/opennms/features/kafka/producer/shell/ListAlarms.java b/features/kafka/producer/src/main/java/org/opennms/features/kafka/producer/shell/ListAlarms.java
new file mode 100644
index 00000000000..313a1c807c0
--- /dev/null
+++ b/features/kafka/producer/src/main/java/org/opennms/features/kafka/producer/shell/ListAlarms.java
@@ -0,0 +1,76 @@
+/*******************************************************************************
+ * This file is part of OpenNMS(R).
+ *
+ * Copyright (C) 2018 The OpenNMS Group, Inc.
+ * OpenNMS(R) is Copyright (C) 1999-2018 The OpenNMS Group, Inc.
+ *
+ * OpenNMS(R) is a registered trademark of The OpenNMS Group, Inc.
+ *
+ * OpenNMS(R) is free software: you can redistribute it and/or modify
+ * it under the terms of the GNU Affero General Public License as published
+ * by the Free Software Foundation, either version 3 of the License,
+ * or (at your option) any later version.
+ *
+ * OpenNMS(R) is distributed in the hope that it will be useful,
+ * but WITHOUT ANY WARRANTY; without even the implied warranty of
+ * MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
+ * GNU Affero General Public License for more details.
+ *
+ * You should have received a copy of the GNU Affero General Public License
+ * along with OpenNMS(R).  If not, see:
+ *      http://www.gnu.org/licenses/
+ *
+ * For more information contact:
+ *     OpenNMS(R) Licensing <license@opennms.org>
+ *     http://www.opennms.org/
+ *     http://www.opennms.com/
+ *******************************************************************************/
+
+package org.opennms.features.kafka.producer.shell;
+
+import java.util.LinkedHashMap;
+import java.util.Map;
+
+import org.apache.karaf.shell.api.action.Action;
+import org.apache.karaf.shell.api.action.Command;
+import org.apache.karaf.shell.api.action.Option;
+import org.apache.karaf.shell.api.action.lifecycle.Reference;
+import org.apache.karaf.shell.api.action.lifecycle.Service;
+import org.opennms.features.kafka.producer.datasync.AlarmDataStore;
+import org.opennms.features.kafka.producer.model.OpennmsModelProtos;
+
+@Command(scope = "kafka-producer", name = "list-alarms", description = "Enumerates the alarms that are currently in the Kafka data store.")
+@Service
+public class ListAlarms implements Action {
+
+    @Reference
+    private AlarmDataStore alarmDataStore;
+
+    @Option(name = "-k", aliases = "--reduction-key", description = "Lookup the alarm at a specific reduction key.")
+    private String reductionKey;
+
+    @Override
+    public Object execute() {
+        if (!SyncAlarms.waitForAlarmDataStore(alarmDataStore)) {
+            return null;
+        }
+
+        // Get
+        final Map<String, OpennmsModelProtos.Alarm> alarmsByReductionKey = new LinkedHashMap<>();
+        if (reductionKey != null) {
+            alarmsByReductionKey.put(reductionKey, alarmDataStore.getAlarm(reductionKey));
+        } else {
+            alarmsByReductionKey.putAll(alarmDataStore.getAlarms());
+        }
+
+        // Dump
+        alarmsByReductionKey.forEach(this::printAlarm);
+
+        return null;
+    }
+
+    private void printAlarm(String reductionKey, OpennmsModelProtos.Alarm alarm) {
+        System.out.printf("%s\n\t%s\n", reductionKey, alarm != null ? alarm.getLastEvent().getLabel() : "(No alarm)");
+    }
+
+}
diff --git a/features/kafka/producer/src/main/java/org/opennms/features/kafka/producer/shell/SyncAlarms.java b/features/kafka/producer/src/main/java/org/opennms/features/kafka/producer/shell/SyncAlarms.java
new file mode 100644
index 00000000000..459aaf40991
--- /dev/null
+++ b/features/kafka/producer/src/main/java/org/opennms/features/kafka/producer/shell/SyncAlarms.java
@@ -0,0 +1,118 @@
+/*******************************************************************************
+ * This file is part of OpenNMS(R).
+ *
+ * Copyright (C) 2018 The OpenNMS Group, Inc.
+ * OpenNMS(R) is Copyright (C) 1999-2018 The OpenNMS Group, Inc.
+ *
+ * OpenNMS(R) is a registered trademark of The OpenNMS Group, Inc.
+ *
+ * OpenNMS(R) is free software: you can redistribute it and/or modify
+ * it under the terms of the GNU Affero General Public License as published
+ * by the Free Software Foundation, either version 3 of the License,
+ * or (at your option) any later version.
+ *
+ * OpenNMS(R) is distributed in the hope that it will be useful,
+ * but WITHOUT ANY WARRANTY; without even the implied warranty of
+ * MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
+ * GNU Affero General Public License for more details.
+ *
+ * You should have received a copy of the GNU Affero General Public License
+ * along with OpenNMS(R).  If not, see:
+ *      http://www.gnu.org/licenses/
+ *
+ * For more information contact:
+ *     OpenNMS(R) Licensing <license@opennms.org>
+ *     http://www.opennms.org/
+ *     http://www.opennms.com/
+ *******************************************************************************/
+
+package org.opennms.features.kafka.producer.shell;
+
+import java.util.Set;
+import java.util.concurrent.TimeUnit;
+
+import org.apache.karaf.shell.api.action.Action;
+import org.apache.karaf.shell.api.action.Command;
+import org.apache.karaf.shell.api.action.lifecycle.Reference;
+import org.apache.karaf.shell.api.action.lifecycle.Service;
+import org.opennms.features.kafka.producer.datasync.AlarmDataStore;
+import org.opennms.features.kafka.producer.datasync.AlarmSyncResults;
+
+@Command(scope = "kafka-producer", name = "sync-alarms", description = "Triggers a syncrhonization of the alarms topic against the database.")
+@Service
+public class SyncAlarms implements Action {
+
+    @Reference
+    private AlarmDataStore alarmDataStore;
+
+    @Override
+    public Object execute() {
+        if (!waitForAlarmDataStore(alarmDataStore)) {
+            return null;
+        }
+
+        System.out.println("Performing synchronization of alarms from the database with those in the ktable.");
+        final long start = System.currentTimeMillis();
+        final AlarmSyncResults results = alarmDataStore.synchronizeAlarmsWithDb();
+        final long delay = System.currentTimeMillis() - start;
+        System.out.printf("Executed %d updates in %dms.\n\n", results.getNumUpdates(), delay);
+
+        System.out.printf("Number of reduction keys in ktable: %d\n", results.getAlarmsInKtableByReductionKey().size());
+        System.out.printf("Number of reduction keys in the db: %d (%d alarms total)\n",
+                results.getAlarmsInDbByReductionKey().size(), results.getAlarmsInDb().size());
+
+        if (results.getNumUpdates() > 0) {
+            System.out.print("Reduction keys added to the ktable:");
+            printSet(results.getReductionKeysAdded());
+            System.out.print("Reduction keys deleted from the ktable:");
+            printSet(results.getReductionKeysDeleted());
+            System.out.print("Reduction keys updated in the ktable:");
+            printSet(results.getReductionKeysUpdated());
+        }
+        return null;
+    }
+
+    protected static boolean waitForAlarmDataStore(AlarmDataStore alarmDataStore) {
+        if (alarmDataStore.isEnabled()) {
+            System.out.println("The alarm data store is currently disabled and must be enabled for this shell command to function.");
+            return false;
+        }
+
+        // Wait for the alarm data store to be ready
+        if (!isAlarmDataStoreReady(alarmDataStore)) {
+            final long startTime = System.currentTimeMillis();
+            System.out.println("Waiting for alarm data store to be ready..");
+            while (true) {
+                try {
+                    System.out.print(".");
+                    Thread.sleep(TimeUnit.SECONDS.toMillis(1));
+                    if (isAlarmDataStoreReady(alarmDataStore)) {
+                        System.out.printf("\nReady in %d ms.\n\n", System.currentTimeMillis() - startTime);
+                        break;
+                    }
+                } catch (InterruptedException e) {
+                    System.out.println("\nInterrupted.");
+                    return false;
+                }
+            }
+        }
+        return true;
+    }
+
+    private static boolean isAlarmDataStoreReady(AlarmDataStore alarmDataStore) {
+        try {
+            return alarmDataStore.isReady();
+        } catch (Exception e) {
+            return false;
+        }
+    }
+
+    private static void printSet(Set<String> reductionKeys) {
+        if (reductionKeys.size() < 1) {
+            System.out.println(" (None)");
+        } else {
+            System.out.println();
+            reductionKeys.forEach(rkey -> System.out.printf("\t%s\n", rkey));
+        }
+    }
+}
diff --git a/features/kafka/producer/src/main/proto/opennms-kafka-producer.proto b/features/kafka/producer/src/main/proto/opennms-kafka-producer.proto
new file mode 100644
index 00000000000..5b864944f38
--- /dev/null
+++ b/features/kafka/producer/src/main/proto/opennms-kafka-producer.proto
@@ -0,0 +1,111 @@
+syntax = "proto3";
+option java_package = "org.opennms.features.kafka.producer.model";
+option java_outer_classname = "OpennmsModelProtos";
+
+// The values differ from the standard codes in OpenNMS
+// since proto3 enforces us to start at 0
+enum Severity {
+  INDETERMINATE = 0;
+  CLEARED = 1;
+  NORMAL = 2;
+  WARNING = 3;
+  MINOR = 4;
+  MAJOR = 5;
+  CRITICAL = 6;
+}
+
+message NodeCriteria {
+  uint64 id = 1;
+  string foreign_source = 2;
+  string foreign_id = 3;
+}
+
+message EventParameter {
+  string name = 1;
+  string value = 2;
+  string type = 3;
+}
+
+message Event {
+  uint64 id = 1;
+  string uei = 2;
+  string label = 3;
+  uint64 time = 4;
+  string source = 5;
+  repeated EventParameter parameter = 6;
+  uint64 create_time = 7;
+  string description = 8;
+  string log_message = 9;
+  Severity severity = 10;
+  bool log = 11;
+  bool display = 12;
+  NodeCriteria node_criteria = 13;
+}
+
+message Alarm {
+  uint64 id = 1;
+  string uei = 2;
+  NodeCriteria node_criteria = 3;
+  string ip_address = 4;
+  string service_name = 5;
+  string reduction_key = 6;
+  enum Type {
+    PROBLEM_WITH_CLEAR = 0;
+    CLEAR = 1;
+    PROBLEM_WITHOUT_CLEAR = 2;
+  }
+  Type type = 7;
+  uint64 count = 8;
+  Severity severity = 9;
+  uint64 first_event_time = 10;
+  string description = 11;
+  string log_message = 12;
+  string ack_user = 13;
+  uint64 ack_time = 14;
+  Event last_event = 15;
+  uint64 last_event_time = 16;
+  uint32 if_index = 17;
+  string operator_instructions = 18;
+  string clear_key = 19;
+}
+
+message IpInterface {
+  uint64 id = 1;
+  string ip_address = 2;
+  uint32 if_index = 3;
+  enum PrimaryType {
+    PRIMARY = 0;
+    SECONDARY = 1;
+    NOT_ELIGIBLE = 2;
+  }
+  PrimaryType primary_type = 4;
+  repeated string service = 5;
+}
+
+message SnmpInterface {
+  uint64 id = 1;
+  uint32 if_index = 2;
+  string if_descr = 3;
+  uint32 if_type = 4;
+  string if_name = 5;
+  uint64 if_speed = 6;
+  string if_phys_address = 7;
+  uint32 if_admin_status = 8;
+  uint32 if_oper_status = 9;
+  string if_alias = 10;
+}
+
+message Node {
+  uint64 id = 1;
+  string foreign_source = 2;
+  string foreign_id = 3;
+  string location = 4;
+  repeated string category = 5;
+  string label = 6;
+  uint64 create_time = 7;
+  string sys_contact = 8;
+  string sys_description = 9;
+  string sys_object_id = 10;
+  repeated IpInterface ip_interface = 11;
+  repeated SnmpInterface snmp_interface = 12;
+}
diff --git a/features/kafka/producer/src/main/resources/OSGI-INF/blueprint/blueprint-kafka-producer.xml b/features/kafka/producer/src/main/resources/OSGI-INF/blueprint/blueprint-kafka-producer.xml
new file mode 100644
index 00000000000..cf3f7f457e4
--- /dev/null
+++ b/features/kafka/producer/src/main/resources/OSGI-INF/blueprint/blueprint-kafka-producer.xml
@@ -0,0 +1,72 @@
+<blueprint
+	xmlns="http://www.osgi.org/xmlns/blueprint/v1.0.0"
+	xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"
+	xmlns:cm="http://aries.apache.org/blueprint/xmlns/blueprint-cm/v1.1.0"
+	xsi:schemaLocation="
+		http://www.osgi.org/xmlns/blueprint/v1.0.0
+		http://www.osgi.org/xmlns/blueprint/v1.0.0/blueprint.xsd
+		
+		http://aries.apache.org/blueprint/xmlns/blueprint-cm/v1.1.0
+		http://aries.apache.org/schemas/blueprint-cm/blueprint-cm-1.1.0.xsd
+">
+
+  <!-- Configuration properties -->
+  <cm:property-placeholder id="kafkaProducerProperties" persistent-id="org.opennms.features.kafka.producer" update-strategy="reload">
+    <cm:default-properties>
+      <cm:property name="eventTopic" value="events"/>
+      <cm:property name="alarmTopic" value="alarms"/>
+      <cm:property name="nodeTopic" value="nodes"/>
+      <cm:property name="nodeRefreshTimeoutMs" value="300000"/> <!-- 5 minutes -->
+      <cm:property name="alarmSyncIntervalMs" value="300000"/> <!-- 5 minutes -->
+      <cm:property name="eventFilter" value=""/>
+      <cm:property name="alarmFilter" value=""/>
+    </cm:default-properties>
+  </cm:property-placeholder>
+
+  <reference id="configAdmin" interface="org.osgi.service.cm.ConfigurationAdmin" />
+  <reference id="eventConfDao" interface="org.opennms.netmgt.config.api.EventConfDao" />
+  <reference id="eventSubscriptionService" interface="org.opennms.netmgt.events.api.EventSubscriptionService" />
+  <reference id="alarmLifecycleSubscriptionService" interface="org.opennms.netmgt.alarmd.api.AlarmLifecycleSubscriptionService" />
+  <reference id="nodeDao" interface="org.opennms.netmgt.dao.api.NodeDao" />
+  <reference id="transactionOperations" interface="org.springframework.transaction.support.TransactionOperations" />
+  <reference id="alarmDao" interface="org.opennms.netmgt.dao.api.AlarmDao" />
+
+  <bean id="protobufMapper" class="org.opennms.features.kafka.producer.ProtobufMapper">
+    <argument ref="eventConfDao"/>
+  </bean>
+
+  <bean id="nodeCache" class="org.opennms.features.kafka.producer.NodeCache">
+    <argument ref="nodeDao"/>
+    <argument ref="transactionOperations"/>
+    <property name="timeoutInMs" value="${nodeRefreshTimeoutMs}"/>
+  </bean>
+
+  <bean id="kafkaProducer" class="org.opennms.features.kafka.producer.OpennmsKafkaProducer"
+          init-method="init" destroy-method="destroy">
+    <argument ref="protobufMapper"/>
+    <argument ref="nodeCache"/>
+    <argument ref="configAdmin"/>
+    <argument ref="eventSubscriptionService"/>
+    <argument ref="alarmLifecycleSubscriptionService"/>
+
+    <property name="eventTopic" value="${eventTopic}"/>
+    <property name="alarmTopic" value="${alarmTopic}"/>
+    <property name="nodeTopic" value="${nodeTopic}"/>
+    <property name="eventFilter" value="${eventFilter}"/>
+    <property name="alarmFilter" value="${alarmFilter}"/>
+  </bean>
+
+  <service ref="alarmDataSync" interface="org.opennms.features.kafka.producer.datasync.AlarmDataStore" />
+
+  <bean id="alarmDataSync" class="org.opennms.features.kafka.producer.datasync.KafkaAlarmDataSync"
+		init-method="init" destroy-method="destroy">
+    <argument ref="configAdmin"/>
+    <argument ref="kafkaProducer"/>
+    <argument ref="alarmDao" />
+    <argument ref="protobufMapper" />
+    <argument ref="transactionOperations"/>
+    <property name="alarmTopic" value="${alarmTopic}"/>
+    <property name="alarmSyncIntervalMs" value="${alarmSyncIntervalMs}"/>
+  </bean>
+
+</blueprint>
diff --git a/features/kafka/producer/src/test/java/org/opennms/features/kafka/producer/KafkaForwarderIT.java b/features/kafka/producer/src/test/java/org/opennms/features/kafka/producer/KafkaForwarderIT.java
new file mode 100644
index 00000000000..5c2c33b4ddf
--- /dev/null
+++ b/features/kafka/producer/src/test/java/org/opennms/features/kafka/producer/KafkaForwarderIT.java
@@ -0,0 +1,384 @@
+/*******************************************************************************
+ * This file is part of OpenNMS(R).
+ *
+ * Copyright (C) 2018 The OpenNMS Group, Inc.
+ * OpenNMS(R) is Copyright (C) 1999-2018 The OpenNMS Group, Inc.
+ *
+ * OpenNMS(R) is a registered trademark of The OpenNMS Group, Inc.
+ *
+ * OpenNMS(R) is free software: you can redistribute it and/or modify
+ * it under the terms of the GNU Affero General Public License as published
+ * by the Free Software Foundation, either version 3 of the License,
+ * or (at your option) any later version.
+ *
+ * OpenNMS(R) is distributed in the hope that it will be useful,
+ * but WITHOUT ANY WARRANTY; without even the implied warranty of
+ * MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
+ * GNU Affero General Public License for more details.
+ *
+ * You should have received a copy of the GNU Affero General Public License
+ * along with OpenNMS(R).  If not, see:
+ *      http://www.gnu.org/licenses/
+ *
+ * For more information contact:
+ *     OpenNMS(R) Licensing <license@opennms.org>
+ *     http://www.opennms.org/
+ *     http://www.opennms.com/
+ *******************************************************************************/
+
+package org.opennms.features.kafka.producer;
+
+import static com.jayway.awaitility.Awaitility.await;
+import static org.hamcrest.MatcherAssert.assertThat;
+import static org.hamcrest.Matchers.equalTo;
+import static org.hamcrest.Matchers.hasItem;
+import static org.hamcrest.Matchers.hasItems;
+import static org.hamcrest.Matchers.not;
+import static org.hamcrest.Matchers.nullValue;
+import static org.mockito.Mockito.RETURNS_DEEP_STUBS;
+import static org.mockito.Mockito.mock;
+import static org.mockito.Mockito.when;
+
+import java.io.File;
+import java.io.IOException;
+import java.util.ArrayList;
+import java.util.Arrays;
+import java.util.Hashtable;
+import java.util.LinkedHashMap;
+import java.util.List;
+import java.util.Map;
+import java.util.Objects;
+import java.util.Properties;
+import java.util.Set;
+import java.util.UUID;
+import java.util.concurrent.ExecutorService;
+import java.util.concurrent.Executors;
+import java.util.concurrent.TimeUnit;
+import java.util.concurrent.atomic.AtomicBoolean;
+import java.util.concurrent.atomic.AtomicInteger;
+import java.util.stream.Collectors;
+
+import org.apache.kafka.clients.consumer.ConsumerConfig;
+import org.apache.kafka.clients.consumer.ConsumerRecord;
+import org.apache.kafka.clients.consumer.ConsumerRecords;
+import org.apache.kafka.clients.consumer.KafkaConsumer;
+import org.apache.kafka.common.serialization.ByteArrayDeserializer;
+import org.apache.kafka.common.serialization.StringDeserializer;
+import org.apache.kafka.streams.StreamsConfig;
+import org.junit.After;
+import org.junit.Before;
+import org.junit.Ignore;
+import org.junit.Rule;
+import org.junit.Test;
+import org.junit.rules.TemporaryFolder;
+import org.junit.runner.RunWith;
+import org.opennms.core.test.OpenNMSJUnit4ClassRunner;
+import org.opennms.core.test.db.MockDatabase;
+import org.opennms.core.test.db.TemporaryDatabaseAware;
+import org.opennms.core.test.db.annotations.JUnitTemporaryDatabase;
+import org.opennms.core.test.kafka.JUnitKafkaServer;
+import org.opennms.features.kafka.producer.datasync.KafkaAlarmDataSync;
+import org.opennms.features.kafka.producer.model.OpennmsModelProtos;
+import org.opennms.netmgt.alarmd.AlarmLifecycleListenerManager;
+import org.opennms.netmgt.dao.DatabasePopulator;
+import org.opennms.netmgt.dao.api.AlarmDao;
+import org.opennms.netmgt.dao.mock.MockEventIpcManager;
+import org.opennms.netmgt.events.api.EventConstants;
+import org.opennms.netmgt.mock.MockEventUtil;
+import org.opennms.netmgt.model.OnmsAlarm;
+import org.opennms.netmgt.model.OnmsSeverity;
+import org.opennms.test.JUnitConfigurationEnvironment;
+import org.osgi.service.cm.ConfigurationAdmin;
+import org.slf4j.Logger;
+import org.slf4j.LoggerFactory;
+import org.springframework.beans.factory.annotation.Autowired;
+import org.springframework.test.context.ContextConfiguration;
+import org.springframework.transaction.support.TransactionTemplate;
+
+/**
+ * Verifies events/alarms/nodes forwarded to Kafka.
+ *
+ * @author cgorantla
+ * @author jwhite
+ */
+@Ignore
+@RunWith(OpenNMSJUnit4ClassRunner.class)
+@ContextConfiguration(locations = { "classpath:/META-INF/opennms/applicationContext-soa.xml",
+        "classpath:/META-INF/opennms/applicationContext-commonConfigs.xml",
+        "classpath:/META-INF/opennms/applicationContext-minimal-conf.xml",
+        "classpath:/META-INF/opennms/applicationContext-mockDao.xml",
+        "classpath:/META-INF/opennms/applicationContext-daemon.xml",
+        "classpath:/META-INF/opennms/mockEventIpcManager.xml",
+        "classpath:/META-INF/opennms/applicationContext-alarmd.xml",
+        "classpath:/applicationContext-test-kafka-producer.xml" })
+@JUnitConfigurationEnvironment
+@JUnitTemporaryDatabase(dirtiesContext = false, tempDbClass = MockDatabase.class, reuseDatabase = false)
+public class KafkaForwarderIT implements TemporaryDatabaseAware<MockDatabase> {
+    private static final Logger LOG = LoggerFactory.getLogger(KafkaForwarderIT.class);
+
+    private static final String EVENT_TOPIC_NAME = "events";
+    private static final String ALARM_TOPIC_NAME = "test-alarms";
+    private static final String NODE_TOPIC_NAME = "test-nodes";
+
+    @Rule
+    public TemporaryFolder tempFolder = new TemporaryFolder();
+
+    @Rule
+    public JUnitKafkaServer kafkaServer = new JUnitKafkaServer(tempFolder);
+
+    @Autowired
+    private MockEventIpcManager eventdIpcMgr;
+
+    @Autowired
+    private ProtobufMapper protobufMapper;
+
+    @Autowired
+    private NodeCache nodeCache;
+
+    @Autowired
+    private AlarmLifecycleListenerManager alarmLifecycleListenerManager;
+
+    @Autowired
+    private TransactionTemplate transactionTemplate;
+
+    @Autowired
+    private AlarmDao alarmDao;
+
+    @Autowired
+    private DatabasePopulator databasePopulator;
+
+    private MockDatabase mockDatabase;
+
+    private OpennmsKafkaProducer kafkaProducer;
+
+    private KafkaAlarmDataSync kafkaAlarmaDataStore;
+
+    private ExecutorService executor;
+
+    private KafkaMessageConsumerRunner kafkaConsumer;
+
+    @Before
+    public void setUp() throws IOException {
+        File data = tempFolder.newFolder("data");
+        eventdIpcMgr.setEventWriter(mockDatabase);
+
+        databasePopulator.populateDatabase();
+
+        Hashtable<String, Object> producerConfig = new Hashtable<>();
+        producerConfig.put(ConsumerConfig.GROUP_ID_CONFIG, KafkaForwarderIT.class.getCanonicalName());
+        producerConfig.put(ConsumerConfig.BOOTSTRAP_SERVERS_CONFIG, kafkaServer.getKafkaConnectString());
+        ConfigurationAdmin configAdmin = mock(ConfigurationAdmin.class, RETURNS_DEEP_STUBS);
+        Hashtable<String, Object> streamsConfig = new Hashtable<>();
+        streamsConfig.put(StreamsConfig.STATE_DIR_CONFIG, data.getAbsolutePath());
+        streamsConfig.put(StreamsConfig.COMMIT_INTERVAL_MS_CONFIG, 1000);
+        streamsConfig.put(StreamsConfig.METADATA_MAX_AGE_CONFIG, 1000);
+        when(configAdmin.getConfiguration(OpennmsKafkaProducer.KAFKA_CLIENT_PID).getProperties()).thenReturn(producerConfig);
+        when(configAdmin.getConfiguration(KafkaAlarmDataSync.KAFKA_STREAMS_PID).getProperties()).thenReturn(streamsConfig);
+
+        kafkaProducer = new OpennmsKafkaProducer(protobufMapper, nodeCache, configAdmin, eventdIpcMgr,
+                alarmLifecycleListenerManager);
+        kafkaProducer.setEventTopic(EVENT_TOPIC_NAME);
+        // Don't forward newSuspect events
+        kafkaProducer.setEventFilter("!getUei().equals(\"" + EventConstants.NEW_SUSPECT_INTERFACE_EVENT_UEI + "\")");
+        kafkaProducer.setAlarmTopic(ALARM_TOPIC_NAME);
+        // No alarm filtering
+        kafkaProducer.setAlarmFilter(null);
+        kafkaProducer.setNodeTopic(NODE_TOPIC_NAME);
+        kafkaProducer.init();
+
+        kafkaAlarmaDataStore = new KafkaAlarmDataSync(configAdmin, kafkaProducer, alarmDao, protobufMapper,
+                transactionTemplate);
+        kafkaAlarmaDataStore.setAlarmTopic(ALARM_TOPIC_NAME);
+        kafkaAlarmaDataStore.setAlarmSyncIntervalMs(1000);
+        kafkaAlarmaDataStore.init();
+    }
+
+    @Test
+    public void canProducerAndConsumeMessages() throws Exception {
+        // Send a node down event (should be forwarded)
+        eventdIpcMgr.sendNow(MockEventUtil.createNodeDownEventBuilder("test", databasePopulator.getNode1()).getEvent());
+        // Create and trigger the associated alarm
+        final String alarmReductionKey = String.format("%s:%d", EventConstants.NODE_DOWN_EVENT_UEI, databasePopulator.getNode1().getId());
+        final OnmsAlarm alarm = new OnmsAlarm();
+        {
+            alarm.setId(1);
+            alarm.setUei(EventConstants.NODE_DOWN_EVENT_UEI);
+            alarm.setNode(databasePopulator.getNode1());
+            alarm.setCounter(1);
+            alarm.setDescription("node down");
+            alarm.setAlarmType(1);
+            alarm.setLogMsg("node down");
+            alarm.setSeverity(OnmsSeverity.NORMAL);
+            alarm.setReductionKey(alarmReductionKey);
+            alarmDao.save(alarm);
+            kafkaProducer.handleNewOrUpdatedAlarm(alarm);
+        }
+
+        // Send a unrelated newSuspect event (should not be forwarded)
+        eventdIpcMgr.sendNow(MockEventUtil.createNewSuspectEventBuilder("test",
+                EventConstants.NEW_SUSPECT_INTERFACE_EVENT_UEI, "192.168.1.1")
+                .getEvent());
+
+        // Send a node up (should be forwarded)
+        eventdIpcMgr.sendNow(MockEventUtil.createNodeUpEventBuilder("test", databasePopulator.getNode2()).getEvent());
+
+        if (!kafkaProducer.getEventForwardedLatch().await(1, TimeUnit.MINUTES)) {
+            throw new Exception("No events were successfully forwarded in time!");
+        }
+        if (!kafkaProducer.getNodeForwardedLatch().await(1, TimeUnit.MINUTES)) {
+            throw new Exception("No nodes were successfully forwarded in time!");
+        }
+        if (!kafkaProducer.getAlarmForwardedLatch().await(1, TimeUnit.MINUTES)) {
+            throw new Exception("No alarm were successfully forwarded in time!");
+        }
+
+        // Fire up the consumer
+        executor = Executors.newSingleThreadExecutor();
+        kafkaConsumer = new KafkaMessageConsumerRunner(kafkaServer.getKafkaConnectString());
+        executor.execute(kafkaConsumer);
+
+        // Wait for the events to be consumed
+        await().atMost(1, TimeUnit.MINUTES).until(this::getUeisForConsumedEvents, hasItems(
+                EventConstants.NODE_DOWN_EVENT_UEI, EventConstants.NODE_UP_EVENT_UEI));
+        assertThat(getUeisForConsumedEvents(), not(hasItem(EventConstants.NEW_SUSPECT_INTERFACE_EVENT_UEI)));
+        // Wait for the nodes to be consumed
+        await().atMost(1, TimeUnit.MINUTES).until(this::getIdsForConsumedNodes, hasItems(
+                databasePopulator.getNode1().getId(), databasePopulator.getNode2().getId()));
+        // Wait for the alarms to be consumed
+        await().atMost(1, TimeUnit.MINUTES).until(() -> kafkaConsumer.getAlarmByReductionKey(alarmReductionKey), not(nullValue()));
+
+        // Events, nodes and alarms were forwarded and consumed!
+
+        // Verify the consumed alarm object
+        assertThat(kafkaConsumer.getAlarmByReductionKey(alarmReductionKey).getDescription(), equalTo("node down"));
+
+        // Now delete the alarm directly in the database
+        alarmDao.delete(alarm);
+
+        // Wait until the synchronization process kicks off and delete the alarm
+        await().atMost(2, TimeUnit.MINUTES).until(() ->
+                kafkaConsumer.getAlarmByReductionKey(alarmReductionKey), nullValue());
+
+    }
+
+    private Set<String> getUeisForConsumedEvents() {
+        return kafkaConsumer.getEvents().stream()
+                .map(OpennmsModelProtos.Event::getUei)
+                .collect(Collectors.toSet());
+    }
+
+    private Set<Integer> getIdsForConsumedNodes() {
+        return kafkaConsumer.getNodes().stream()
+                .filter(Objects::nonNull)
+                .map(n -> (int)n.getId())
+                .collect(Collectors.toSet());
+    }
+
+    private Set<String> getReductionKeysForConsumedAlarms() {
+        return kafkaConsumer.getAlarms().stream()
+                .filter(Objects::nonNull)
+                .map(OpennmsModelProtos.Alarm::getReductionKey)
+                .collect(Collectors.toSet());
+    }
+
+    private static class KafkaMessageConsumerRunner implements Runnable {
+        private final AtomicBoolean closed = new AtomicBoolean(false);
+        private KafkaConsumer<String, byte[]> consumer;
+        private String kafkaConnectString;
+        private List<OpennmsModelProtos.Event> events = new ArrayList<>();
+        private List<OpennmsModelProtos.Node> nodes = new ArrayList<>();
+        private List<OpennmsModelProtos.Alarm> alarms = new ArrayList<>();
+        private Map<String, OpennmsModelProtos.Alarm> alarmsByReductionKey = new LinkedHashMap<>();
+        private AtomicInteger numRecordsConsumed = new AtomicInteger(0);
+
+        public KafkaMessageConsumerRunner(String kafkaConnectString) {
+            this.kafkaConnectString = Objects.requireNonNull(kafkaConnectString);
+        }
+
+        @Override
+        public void run() {
+            Properties props = new Properties();
+            props.put(ConsumerConfig.BOOTSTRAP_SERVERS_CONFIG, kafkaConnectString);
+            props.put(ConsumerConfig.GROUP_ID_CONFIG, KafkaMessageConsumerRunner.class.getCanonicalName() + "-" + UUID.randomUUID().toString());
+            props.put(ConsumerConfig.KEY_DESERIALIZER_CLASS_CONFIG, StringDeserializer.class);
+            props.put(ConsumerConfig.VALUE_DESERIALIZER_CLASS_CONFIG, ByteArrayDeserializer.class);
+            props.put(ConsumerConfig.AUTO_OFFSET_RESET_CONFIG, "earliest");
+            props.put(ConsumerConfig.ENABLE_AUTO_COMMIT_CONFIG, Boolean.TRUE.toString());
+            props.put(ConsumerConfig.METADATA_MAX_AGE_CONFIG, "1000");
+            props.put(ConsumerConfig.AUTO_COMMIT_INTERVAL_MS_CONFIG, "1000");
+            consumer = new KafkaConsumer<>(props);
+            consumer.subscribe(Arrays.asList(EVENT_TOPIC_NAME, NODE_TOPIC_NAME, ALARM_TOPIC_NAME));
+
+            while (!closed.get()) {
+                ConsumerRecords<String, byte[]> records = consumer.poll(1000);
+                for (ConsumerRecord<String, byte[]> record : records) {
+                    try {
+                        switch (record.topic()) {
+                            case EVENT_TOPIC_NAME:
+                                events.add(OpennmsModelProtos.Event.parseFrom(record.value()));
+                                break;
+                            case NODE_TOPIC_NAME:
+                                nodes.add(record.value() != null ?
+                                        OpennmsModelProtos.Node.parseFrom(record.value()) : null);
+                                break;
+                            case ALARM_TOPIC_NAME:
+                                final OpennmsModelProtos.Alarm alarm = record.value() != null ?
+                                        OpennmsModelProtos.Alarm.parseFrom(record.value()) : null;
+                                alarms.add(alarm);
+                                alarmsByReductionKey.put(record.key(), alarm);
+                                break;
+                        }
+                        numRecordsConsumed.incrementAndGet();
+                    } catch (Exception e) {
+                        LOG.error("Failed to parse record: {}",  record, e);
+                    }
+                }
+            }
+            consumer.close(1, TimeUnit.MINUTES);
+        }
+
+        public AtomicInteger getNumRecordsConsumed() {
+            return numRecordsConsumed;
+        }
+
+        public List<OpennmsModelProtos.Event> getEvents() {
+            return events;
+        }
+
+        public List<OpennmsModelProtos.Node> getNodes() {
+            return nodes;
+        }
+
+        public List<OpennmsModelProtos.Alarm> getAlarms() {
+            return alarms;
+        }
+
+        public Map<String, OpennmsModelProtos.Alarm> getAlarmsByReductionKey() {
+            return alarmsByReductionKey;
+        }
+
+        public OpennmsModelProtos.Alarm getAlarmByReductionKey(String reductionKey) {
+            return alarmsByReductionKey.get(reductionKey);
+        }
+
+        public void shutdown() {
+            closed.set(true);
+        }
+    }
+
+    @After
+    public void tearDown() {
+        if (kafkaConsumer != null) {
+            kafkaConsumer.shutdown();
+        }
+        if (executor != null) {
+            executor.shutdown();
+        }
+        databasePopulator.resetDatabase();
+    }
+
+    @Override
+    public void setTemporaryDatabase(MockDatabase database) {
+        mockDatabase = database;
+    }
+}
diff --git a/features/kafka/producer/src/test/resources/applicationContext-test-kafka-producer.xml b/features/kafka/producer/src/test/resources/applicationContext-test-kafka-producer.xml
new file mode 100644
index 00000000000..439c171393c
--- /dev/null
+++ b/features/kafka/producer/src/test/resources/applicationContext-test-kafka-producer.xml
@@ -0,0 +1,26 @@
+<?xml version="1.0" encoding="UTF-8"?>
+<beans xmlns="http://www.springframework.org/schema/beans"
+       xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"
+       xmlns:context="http://www.springframework.org/schema/context"
+       xmlns:util="http://www.springframework.org/schema/util"
+       xmlns:onmsgi="http://xmlns.opennms.org/xsd/spring/onms-osgi"
+       xsi:schemaLocation="
+  http://www.springframework.org/schema/beans http://www.springframework.org/schema/beans/spring-beans-4.2.xsd
+  http://www.springframework.org/schema/context http://www.springframework.org/schema/context/spring-context-4.2.xsd
+  http://www.springframework.org/schema/util http://www.springframework.org/schema/util/spring-util-4.2.xsd
+  http://xmlns.opennms.org/xsd/spring/onms-osgi http://xmlns.opennms.org/xsd/spring/onms-osgi.xsd
+">
+
+    <context:annotation-config/>
+
+    <bean id="protobufMapper" class="org.opennms.features.kafka.producer.ProtobufMapper">
+        <constructor-arg ref="eventConfDao"/>
+    </bean>
+
+    <bean id="nodeCache" class="org.opennms.features.kafka.producer.NodeCache">
+        <constructor-arg ref="nodeDao"/>
+        <constructor-arg ref="transactionTemplate"/>
+        <property name="timeoutInMs" value="300000"/>
+    </bean>
+
+</beans>
\ No newline at end of file
diff --git a/features/minion/container/karaf/pom.xml b/features/minion/container/karaf/pom.xml
index 0445995893e..061649ae0af 100644
--- a/features/minion/container/karaf/pom.xml
+++ b/features/minion/container/karaf/pom.xml
@@ -40,10 +40,14 @@
                         <feature>wrapper</feature>
 
                         <!-- OPENNMS: Add Spring features that we need in the base container -->
-                        <!-- These versions match the versions shipped with Apache Karaf 4.1.2 -->
+                        <!-- These versions match the versions shipped with Apache Karaf 4.1.5 -->
+                        <feature>spring/3.1.4.RELEASE</feature>
                         <feature>spring/3.2.18.RELEASE_1</feature>
-                        <feature>spring/4.0.7.RELEASE_3</feature>
+                        <feature>spring/4.0.9.RELEASE_1</feature>
                         <feature>spring/4.1.9.RELEASE_1</feature>
+                        <feature>spring/4.2.9.RELEASE_1</feature>
+                        <feature>spring/4.3.14.RELEASE_1</feature>
+
                         <feature>spring-jms/4.1.9.RELEASE_1</feature>
                         <feature>spring/${springVersion}</feature>
                         <feature>spring-jms/${springVersion}</feature>
diff --git a/features/minion/container/karaf/src/main/filtered-resources/etc/startup.properties b/features/minion/container/karaf/src/main/filtered-resources/etc/startup.properties
index dfdf7be9e11..6c7e3e1694d 100644
--- a/features/minion/container/karaf/src/main/filtered-resources/etc/startup.properties
+++ b/features/minion/container/karaf/src/main/filtered-resources/etc/startup.properties
@@ -1,13 +1,14 @@
 # Bundles to be started on startup, with startlevel
-mvn\:org.apache.karaf.features/org.apache.karaf.features.extension/4.1.2 = 1
-mvn\:org.apache.felix/org.apache.felix.metatype/1.1.2 = 5
-mvn\:org.apache.karaf.services/org.apache.karaf.services.eventadmin/4.1.2 = 5
-mvn\:org.ops4j.pax.url/pax-url-aether/2.5.2 = 5
+mvn\:org.apache.karaf.features/org.apache.karaf.features.extension/4.1.5 = 1
+mvn\:org.apache.felix/org.apache.felix.metatype/1.1.6 = 5
+mvn\:org.apache.karaf.services/org.apache.karaf.services.eventadmin/4.1.5 = 5
+mvn\:org.ops4j.pax.url/pax-url-aether/2.5.4 = 5
+mvn\:org.fusesource.jansi/jansi/1.17 = 8
 mvn\:org.ops4j.pax.logging/pax-logging-api/1.10.1 = 8
 mvn\:org.ops4j.pax.logging/pax-logging-log4j2/1.10.1 = 8
-mvn\:org.apache.felix/org.apache.felix.configadmin/1.8.14 = 10
-mvn\:org.apache.felix/org.apache.felix.fileinstall/3.6.0 = 11
-mvn\:org.apache.karaf.features/org.apache.karaf.features.core/4.1.2 = 15
+mvn\:org.apache.felix/org.apache.felix.configadmin/1.8.16 = 10
+mvn\:org.apache.felix/org.apache.felix.fileinstall/3.6.4 = 11
+mvn\:org.apache.karaf.features/org.apache.karaf.features.core/4.1.5 = 15
 
 # OPENNMS: Add JNA bundles to prevent jline from refreshing (KARAF-5251)
 mvn\:net.java.dev.jna/jna/${jnaVersion} = 5
diff --git a/features/minion/container/karaf/src/main/filtered-resources/etc/system.properties b/features/minion/container/karaf/src/main/filtered-resources/etc/system.properties
index 4483333d7bb..d7b444ea881 100644
--- a/features/minion/container/karaf/src/main/filtered-resources/etc/system.properties
+++ b/features/minion/container/karaf/src/main/filtered-resources/etc/system.properties
@@ -49,7 +49,7 @@ karaf.default.repository = system
 # additional commands.
 # Do not use absolute paths to avoid problems on windows.
 #
-karaf.shell.init.script = etc/shell.init.script,etc/scripts/*.script
+# karaf.shell.init.script = etc/shell.init.script,etc/scripts/*.script
 
 #
 # Sets the maximum size of the shell command history. If not set,
diff --git a/features/minion/repository/src/main/resources/features.boot b/features/minion/repository/src/main/resources/features.boot
index 8c9cfc3eff4..ceac17312f6 100644
--- a/features/minion/repository/src/main/resources/features.boot
+++ b/features/minion/repository/src/main/resources/features.boot
@@ -1,5 +1,9 @@
 # Minion Default Features
 pax-war
+# Install specific versions of the spring and spring-jms features to
+# reduce the computations needed by the bundle dependency resolver
+spring/${springVersion}
+spring-jms/${springVersion}
 opennms-core-ipc-rpc-jms
 opennms-core-ipc-sink-camel
 opennms-syslogd-listener-camel-netty
diff --git a/features/opennms-es-rest/main-module/src/main/java/org/opennms/plugins/elasticsearch/rest/EventToIndex.java b/features/opennms-es-rest/main-module/src/main/java/org/opennms/plugins/elasticsearch/rest/EventToIndex.java
index edef9bd9af0..7ce387dac68 100644
--- a/features/opennms-es-rest/main-module/src/main/java/org/opennms/plugins/elasticsearch/rest/EventToIndex.java
+++ b/features/opennms-es-rest/main-module/src/main/java/org/opennms/plugins/elasticsearch/rest/EventToIndex.java
@@ -46,6 +46,7 @@ import java.util.stream.Collectors;
 
 import javax.xml.bind.DatatypeConverter;
 
+import org.json.simple.JSONArray;
 import org.json.simple.JSONObject;
 import org.json.simple.parser.JSONParser;
 import org.json.simple.parser.ParseException;
@@ -157,6 +158,8 @@ public class EventToIndex implements AutoCloseable {
 
 	private boolean archiveNewAlarmValues=true;
 
+	private boolean groupOidParameters = false;
+
 	private NodeCache nodeCache=null;
 
 	private JestClient jestClient = null;
@@ -278,6 +281,10 @@ public class EventToIndex implements AutoCloseable {
 		this.archiveNewAlarmValues = archiveNewAlarmValues;
 	}
 
+	public void setGroupOidParameters(boolean groupOidParameters) {
+		this.groupOidParameters = groupOidParameters;
+	}
+
 
 	/**
 	 * returns a singleton jest client from factory for use by this class
@@ -589,7 +596,7 @@ public class EventToIndex implements AutoCloseable {
 	 */
 	public Index populateEventIndexBodyFromEvent( Event event, String rootIndexName, String indexType) {
 
-		Map<String,String> body=new HashMap<String,String>();
+		final JSONObject body = new JSONObject();
 
 		Integer id=(event.getDbid()==null ? null: event.getDbid());
 
@@ -622,10 +629,9 @@ public class EventToIndex implements AutoCloseable {
 
 		body.put("host",event.getHost());
 
-		//get params from event
-		for(Parm parm : event.getParmCollection()) {
-			body.put("p_" + parm.getParmName(), parm.getValue().getContent());
-		}
+		// Parse event parameters
+		final JSONParser jsonParser = new JSONParser();
+		handleParameters(event, body);
 
 		// remove old and new alarm values parms if not needed
 		if(! archiveNewAlarmValues){
@@ -666,10 +672,7 @@ public class EventToIndex implements AutoCloseable {
 					+ "/"+completeIndexName
 					+ "/"+indexType
 					+ "/"+id
-					+ "\n   body: ";
-			for (String key:body.keySet()){
-				str=str+"["+ key+" : "+body.get(key)+"]";
-			}
+					+ "\n   body: \n" + body.toJSONString();
 			LOG.debug(str);
 		}
 
@@ -689,6 +692,55 @@ public class EventToIndex implements AutoCloseable {
 		return index;
 	}
 
+	private void handleParameters(Event event, JSONObject body) {
+		// Decide if oids should be grouped in a single JsonArray or flattened
+		if (groupOidParameters) {
+			final List<Parm> oidParameters = event.getParmCollection().stream().filter(p -> isOID(p.getParmName())).collect(Collectors.toList());
+			final List<Parm> normalParameters = event.getParmCollection();
+			normalParameters.removeAll(oidParameters);
+
+			// Handle non oid paramaters as always
+			handleParameters(event, normalParameters, body);
+
+			// Special treatment for oid parameters
+			if (!oidParameters.isEmpty()) {
+				final JSONArray jsonArray = new JSONArray();
+				for (Parm eachOid : oidParameters) {
+					final JSONObject eachOidObject = new JSONObject();
+					eachOidObject.put("oid", eachOid.getParmName());
+					eachOidObject.put("value", eachOid.getValue().getContent());
+					jsonArray.add(eachOidObject);
+				}
+				body.put("p_oids", jsonArray);
+			}
+		} else { // flattened
+			handleParameters(event, event.getParmCollection(), body);
+		}
+	}
+
+	private void handleParameters(Event event, List<Parm> parameters, JSONObject body) {
+		final JSONParser jsonParser = new JSONParser();
+		for(Parm parm : parameters) {
+			final String parmName = "p_" + parm.getParmName().replaceAll("\\.", "_");
+
+			// Some parameter values are of type json and should be decoded properly.
+			// See HZN-1272
+			if ("json".equalsIgnoreCase(parm.getValue().getType())) {
+				try {
+					JSONObject tmpJson = (JSONObject) jsonParser.parse(parm.getValue().getContent());
+					body.put(parmName, tmpJson);
+				} catch (ParseException ex) {
+					LOG.error("Cannot parse parameter content '{}' of parameter '{}' from eventid {} to json: {}",
+									parm.getValue().getContent(), parm.getParmName(), event.getDbid(), ex.getMessage(), ex);
+					// To not lose the data, just use as is
+					body.put(parmName, parm.getValue().getContent());
+				}
+			} else {
+				body.put(parmName, parm.getValue().getContent());
+			}
+		}
+	}
+
 	/**
 	 * An alarm change event will have a payload corresponding to the json representation of the
 	 * Alarms table row for this alarm id. Both "oldalarmvalues" and "newalarmvalues" params may be populated
@@ -964,4 +1016,8 @@ public class EventToIndex implements AutoCloseable {
 		}
 	}
 
+	public static boolean isOID(String input) {
+		return input.matches("^(\\.[0-9]+)+$");
+	}
+
 }
diff --git a/features/opennms-es-rest/main-module/src/main/resources/OSGI-INF/blueprint/mainModuleBlueprint.xml b/features/opennms-es-rest/main-module/src/main/resources/OSGI-INF/blueprint/mainModuleBlueprint.xml
index 4956d570025..a61d37ddfb7 100644
--- a/features/opennms-es-rest/main-module/src/main/resources/OSGI-INF/blueprint/mainModuleBlueprint.xml
+++ b/features/opennms-es-rest/main-module/src/main/resources/OSGI-INF/blueprint/mainModuleBlueprint.xml
@@ -30,6 +30,7 @@
       <cm:property name="archiveOldAlarmValues" value="true" />
       <cm:property name="archiveNewAlarmValues" value="true" />
       <cm:property name="archiveAssetData" value="true" />
+      <cm:property name="groupOidParameters" value="false" />
       <cm:property name="timeout" value="3000" /> <!-- 3 second timeout for Elasticsearch operations -->
       <cm:property name="retries" value="0" /> <!-- Disable retries by default -->
       <cm:property name="socketTimeout" value="3000" /> <!-- 3 second timeout for Elasticsearch socket reads -->
@@ -93,6 +94,7 @@
     <property name="archiveAlarmChangeEvents" value="${archiveAlarmChangeEvents}" />
     <property name="archiveOldAlarmValues" value="${archiveOldAlarmValues}" />
     <property name="archiveNewAlarmValues" value="${archiveNewAlarmValues}" />
+    <property name="groupOidParameters" value="${groupOidParameters}" />
   </bean>
 
   <bean id="indexNameFunction" class="org.opennms.plugins.elasticsearch.rest.IndexNameFunction">
diff --git a/features/opennms-es-rest/main-module/src/main/resources/eventsIndexTemplate.json b/features/opennms-es-rest/main-module/src/main/resources/eventsIndexTemplate.json
index d924ea02eb4..cb8fddb2ec6 100644
--- a/features/opennms-es-rest/main-module/src/main/resources/eventsIndexTemplate.json
+++ b/features/opennms-es-rest/main-module/src/main/resources/eventsIndexTemplate.json
@@ -58,6 +58,9 @@
                "hour":{
                   "type":"long"
                },
+               "p_oids": {
+                  "type": "nested"
+               },
                "p_alarmseverity":{
                   "type":"long"
                },
diff --git a/features/opennms-es-rest/main-module/src/test/java/org/opennms/plugins/elasticsearch/test/AlarmEventToIndexTest.java b/features/opennms-es-rest/main-module/src/test/java/org/opennms/plugins/elasticsearch/test/AlarmEventToIndexTest.java
index 9a9e6e00d15..b321e0aef82 100644
--- a/features/opennms-es-rest/main-module/src/test/java/org/opennms/plugins/elasticsearch/test/AlarmEventToIndexTest.java
+++ b/features/opennms-es-rest/main-module/src/test/java/org/opennms/plugins/elasticsearch/test/AlarmEventToIndexTest.java
@@ -29,23 +29,38 @@
 package org.opennms.plugins.elasticsearch.test;
 
 import static org.junit.Assert.assertEquals;
+import static org.junit.Assert.assertNotNull;
 
+import java.io.IOException;
+import java.net.MalformedURLException;
+import java.util.Arrays;
 import java.util.Collections;
+import java.util.Date;
 import java.util.concurrent.TimeUnit;
+import java.util.stream.IntStream;
 
 import org.json.simple.JSONArray;
 import org.json.simple.JSONObject;
 import org.json.simple.parser.JSONParser;
+import org.junit.After;
+import org.junit.Before;
 import org.junit.Test;
+import org.opennms.netmgt.dao.api.DistPollerDao;
+import org.opennms.netmgt.events.api.EventConstants;
+import org.opennms.netmgt.model.OnmsSeverity;
 import org.opennms.netmgt.model.events.EventBuilder;
 import org.opennms.netmgt.xml.event.Event;
+import org.opennms.netmgt.xml.event.Parm;
+import org.opennms.netmgt.xml.event.Value;
 import org.opennms.plugins.elasticsearch.rest.EventToIndex;
 import org.opennms.plugins.elasticsearch.rest.IndexNameFunction;
-import org.opennms.plugins.elasticsearch.rest.NodeCache;
 import org.opennms.plugins.elasticsearch.rest.RestClientFactory;
 import org.slf4j.Logger;
 import org.slf4j.LoggerFactory;
 
+import com.google.gson.JsonArray;
+import com.google.gson.JsonObject;
+
 import io.searchbox.client.JestClient;
 import io.searchbox.core.Search;
 import io.searchbox.core.SearchResult;
@@ -105,6 +120,34 @@ public class AlarmEventToIndexTest {
 			+ "\"qosalarmstate\":null,\"clearkey\":null,\"ifindex\":null,\"eventparms\":\"eventReason=Unknown(string,text)\","
 			+ "\"stickymemo\":null,\"systemid\":\"00000000-0000-0000-0000-000000000000\"}";
 
+	private EventToIndex eventToIndex;
+	private JestClient jestClient;
+
+	@Before
+	public void setUp() throws MalformedURLException {
+		jestClient = new RestClientFactory("http://localhost:9200","", "").getJestClient();
+
+		eventToIndex = new EventToIndex();
+		eventToIndex.setRestClientFactory(new RestClientFactory("http://localhost:9200","", ""));
+		eventToIndex.setNodeCache(new MockNodeCache());
+		eventToIndex.setIndexNameFunction(new IndexNameFunction("yyyy.MM"));
+		eventToIndex.setLogEventDescription(true);
+		eventToIndex.setArchiveRawEvents(true);
+		eventToIndex.setArchiveAlarms(true);
+		eventToIndex.setArchiveAlarmChangeEvents(true);
+		eventToIndex.setArchiveOldAlarmValues(true);
+		eventToIndex.setArchiveNewAlarmValues(true);
+	}
+
+	@After
+	public void tearDown() {
+		if (jestClient != null) {
+			jestClient.shutdownClient();
+		}
+		if (eventToIndex != null) {
+			eventToIndex.close();
+		}
+	}
 
 	/**
 	 * simple test to create an alarm change event which will create a new alarm in the alarm index
@@ -114,32 +157,9 @@ public class AlarmEventToIndexTest {
 	public void jestClientAlarmToESTest(){
 		LOG.debug("***************** start of test jestClientAlarmToESTest");
 
-		EventToIndex eventToIndex = new EventToIndex();
-		JestClient jestClient=null;
 
 		try {
 
-			// Get Jest client
-			String esusername="";
-			String espassword="";
-			String elasticsearchUrl="http://localhost:9200";
-
-			RestClientFactory restClientFactory = new RestClientFactory(elasticsearchUrl,esusername,espassword);
-
-			IndexNameFunction indexNameFunction = new IndexNameFunction("yyyy.MM");
-
-			NodeCache nodeCache = new MockNodeCache();
-
-			eventToIndex.setRestClientFactory(restClientFactory);
-			eventToIndex.setNodeCache(nodeCache);
-			eventToIndex.setIndexNameFunction(indexNameFunction);
-			eventToIndex.setLogEventDescription(true);
-			eventToIndex.setArchiveRawEvents(true);
-			eventToIndex.setArchiveAlarms(true);
-			eventToIndex.setArchiveAlarmChangeEvents(true);
-			eventToIndex.setArchiveOldAlarmValues(true);
-			eventToIndex.setArchiveNewAlarmValues(true);
-
 			// create an alarm change event
 			EventBuilder eb = new EventBuilder( ALARM_ACKNOWLEDGED_EVENT, EVENT_SOURCE_NAME);
 
@@ -159,8 +179,6 @@ public class AlarmEventToIndexTest {
 			} catch (InterruptedException e) { }
 
 			// send query to check that alarm has been created
-			jestClient = restClientFactory.getJestClient();
-
 			// search for resulting alarm
 			String query = "{\n" 
 					+"\n       \"query\": {"
@@ -201,14 +219,7 @@ public class AlarmEventToIndexTest {
             } catch (InterruptedException e) { }
 			
 			// search for resulting alarm change event
-			String eventquery = "{\n" 
-					+"\n       \"query\": {"
-					+ "\n         \"match\": {"
-					+ "\n         \"id\": \"100\""
-					+ "\n          }"
-					+ "\n        }"
-					+ "\n     }";
-			
+			final String eventquery = buildSearchQuery(100);
 			LOG.debug("event check search query: "+eventquery);
 
 			Search eventsearch = new Search.Builder(eventquery)
@@ -261,5 +272,124 @@ public class AlarmEventToIndexTest {
 		LOG.debug("***************** end of test jestClientAlarmToESTest");
 	}
 
+	// See NMS-9831 for more information
+	@Test
+	public void verifyOidMapping() throws InterruptedException, IOException {
+		int eventId = 13;
+		final Event event = createDummyEventWithOids(eventId);
+		eventToIndex.forwardEvents(Arrays.asList(event));
 
+		TimeUnit.SECONDS.sleep(INDEX_WAIT_SECONDS);
+
+		final String query = buildSearchQuery(eventId);
+		final Search search = new Search.Builder(query)
+			.addIndex("opennms-events-raw-*")
+			.build();
+		final SearchResult result = jestClient.execute(search);
+		assertEquals(200, result.getResponseCode());
+		assertEquals(Integer.valueOf(1), result.getTotal());
+	}
+
+	// See NMS-9831 for more information
+	@Test
+	public void verifyOidGrouping() throws InterruptedException, IOException {
+		int eventId = 15;
+		final Event event = createDummyEventWithOids(eventId);
+		eventToIndex.setGroupOidParameters(true);
+		eventToIndex.forwardEvents(Arrays.asList(event));
+
+		TimeUnit.SECONDS.sleep(INDEX_WAIT_SECONDS);
+
+		final String query = buildSearchQuery(eventId);
+		final Search search = new Search.Builder(query)
+				.addIndex("opennms-events-raw-*")
+				.build();
+		final SearchResult result = jestClient.execute(search);
+		assertEquals(200, result.getResponseCode());
+		assertEquals(Integer.valueOf(1), result.getTotal());
+
+		// Verify oids
+		final JsonArray oids = result.getJsonObject()
+				.get("hits").getAsJsonObject()
+					.get("hits").getAsJsonArray()
+						.get(0).getAsJsonObject()
+							.get("_source").getAsJsonObject()
+								.get("p_oids").getAsJsonArray();
+		assertNotNull(oids);
+		assertEquals(99, oids.size());
+	}
+
+	// See HZN-1272
+	@Test
+	public void verifyJsonEventParameters() throws InterruptedException, IOException {
+		final int eventId = 17;
+		final Event event = createDummyEvent(eventId);
+
+		final JsonObject addressObject = new JsonObject();
+		addressObject.addProperty("street", "950 Windy Rd, Ste 300");
+		addressObject.addProperty("city", "Apex");
+		addressObject.addProperty("state", "NC");
+		final JsonObject jsonObject = new JsonObject();
+		jsonObject.add("address", addressObject);
+		jsonObject.addProperty("name", "The OpenNMS Group");
+
+				// Create Event Parameter, which carries a json representation
+						final Value value = new Value();
+		value.setType("json");
+		value.setEncoding("text");
+		value.setContent(jsonObject.toString());
+		final Parm p = new Parm();
+		p.setValue(value);
+		p.setParmName("name");
+		event.addParm(p);
+
+		// Forward event...
+		eventToIndex.forwardEvents(Arrays.asList(event));
+		TimeUnit.SECONDS.sleep(INDEX_WAIT_SECONDS);
+
+		// ... and verify that the json was actually persisted as json and not as string
+		final String query = buildSearchQuery(eventId);
+		final Search search = new Search.Builder(query)
+						.addIndex("opennms-events-raw-*")
+						.build();
+		final SearchResult result = jestClient.execute(search);
+		assertEquals(200, result.getResponseCode());
+		assertEquals(Integer.valueOf(1), result.getTotal());
+		final JsonArray jsonArray = result.getJsonObject().get("hits").getAsJsonObject().get("hits").getAsJsonArray();
+		assertEquals(jsonObject, jsonArray.get(0).getAsJsonObject().get("_source").getAsJsonObject().get("p_name").getAsJsonObject());
+	}
+
+	private static Event createDummyEvent(int eventId) {
+		final Event event = new Event();
+		event.setUei(EventConstants.ALARM_CLEARED_UEI);
+		event.setCreationTime(new Date());
+		event.setDistPoller(DistPollerDao.DEFAULT_DIST_POLLER_ID);
+		event.setDescr("Dummy Event");
+		event.setSeverity(OnmsSeverity.WARNING.getLabel());
+		event.setDbid(eventId);
+		return event;
+	}
+
+	private static Event createDummyEventWithOids(int eventId) {
+		final Event event = createDummyEvent(eventId);
+		IntStream.range(1, 100).forEach(i -> {
+			Parm parm = new Parm();
+			parm.setParmName("." + i + ".0.0.0.0.0.0.0.0.0"); // 10 * 100 -> 1000 fields at least
+			parm.setValue(new Value("dummy value"));
+			event.addParm(parm);
+		});
+		return event;
+	}
+
+
+	private static String buildSearchQuery(int eventId) {
+		return "{\n"
+					+"\n       \"query\": {"
+					+ "\n         \"match\": {"
+					+ "\n         \"id\": \"" + eventId + "\""
+					+ "\n          }"
+					+ "\n        }"
+					+ "\n     }";
+
+	}
 }
diff --git a/features/opennms-es-rest/main-module/src/test/java/org/opennms/plugins/elasticsearch/test/EventToIndexTest.java b/features/opennms-es-rest/main-module/src/test/java/org/opennms/plugins/elasticsearch/test/EventToIndexTest.java
new file mode 100644
index 00000000000..720c798ac71
--- /dev/null
+++ b/features/opennms-es-rest/main-module/src/test/java/org/opennms/plugins/elasticsearch/test/EventToIndexTest.java
@@ -0,0 +1,46 @@
+/*******************************************************************************
+ * This file is part of OpenNMS(R).
+ *
+ * Copyright (C) 2018-2018 The OpenNMS Group, Inc.
+ * OpenNMS(R) is Copyright (C) 1999-2018 The OpenNMS Group, Inc.
+ *
+ * OpenNMS(R) is a registered trademark of The OpenNMS Group, Inc.
+ *
+ * OpenNMS(R) is free software: you can redistribute it and/or modify
+ * it under the terms of the GNU Affero General Public License as published
+ * by the Free Software Foundation, either version 3 of the License,
+ * or (at your option) any later version.
+ *
+ * OpenNMS(R) is distributed in the hope that it will be useful,
+ * but WITHOUT ANY WARRANTY; without even the implied warranty of
+ * MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
+ * GNU Affero General Public License for more details.
+ *
+ * You should have received a copy of the GNU Affero General Public License
+ * along with OpenNMS(R).  If not, see:
+ *      http://www.gnu.org/licenses/
+ *
+ * For more information contact:
+ *     OpenNMS(R) Licensing <license@opennms.org>
+ *     http://www.opennms.org/
+ *     http://www.opennms.com/
+ *******************************************************************************/
+
+package org.opennms.plugins.elasticsearch.test;
+
+import static org.hamcrest.CoreMatchers.is;
+import static org.junit.Assert.assertThat;
+import static org.opennms.plugins.elasticsearch.rest.EventToIndex.isOID;
+
+import org.junit.Test;
+
+public class EventToIndexTest {
+    @Test
+    public void verifyIsOID() {
+        assertThat(isOID(".3"), is(true));
+        assertThat(isOID(".3.1.2"), is(true));
+        assertThat(isOID("..3.."), is(false));
+        assertThat(isOID("192.168.0.1"), is(false));
+        assertThat(isOID("nodeLabel"), is(false));
+    }
+}
diff --git a/features/pom.xml b/features/pom.xml
index 5efb282f5e0..02889e14607 100644
--- a/features/pom.xml
+++ b/features/pom.xml
@@ -29,6 +29,8 @@
     <!-- Graphml -->
     <module>graphml</module>
 
+    <module>kafka</module>
+
     <!-- Executor factories -->
     <module>executor-factory</module>
 
diff --git a/features/rest/mapper/src/main/java/org/opennms/web/rest/mapper/v2/AlarmMapper.java b/features/rest/mapper/src/main/java/org/opennms/web/rest/mapper/v2/AlarmMapper.java
index ef730f56f19..30f6b49ed68 100644
--- a/features/rest/mapper/src/main/java/org/opennms/web/rest/mapper/v2/AlarmMapper.java
+++ b/features/rest/mapper/src/main/java/org/opennms/web/rest/mapper/v2/AlarmMapper.java
@@ -28,23 +28,25 @@
 
 package org.opennms.web.rest.mapper.v2;
 
+import java.util.Arrays;
+import java.util.List;
+import java.util.Objects;
+import java.util.stream.Collectors;
+
 import org.mapstruct.AfterMapping;
 import org.mapstruct.InheritInverseConfiguration;
 import org.mapstruct.Mapper;
 import org.mapstruct.Mapping;
 import org.mapstruct.MappingTarget;
 import org.mapstruct.Mappings;
+import org.opennms.netmgt.model.AckType;
 import org.opennms.netmgt.model.OnmsAlarm;
 import org.opennms.netmgt.model.OnmsEventParameter;
 import org.opennms.netmgt.model.TroubleTicketState;
 import org.opennms.web.rest.model.v2.AlarmDTO;
+import org.opennms.web.rest.model.v2.AlarmSummaryDTO;
 import org.opennms.web.rest.model.v2.EventParameterDTO;
 
-import java.util.Arrays;
-import java.util.List;
-import java.util.Objects;
-import java.util.stream.Collectors;
-
 @Mapper(componentModel = "spring", uses = {EventMapper.class})
 public abstract class AlarmMapper {
 
@@ -54,6 +56,8 @@ public abstract class AlarmMapper {
             @Mapping(source = "distPoller.location", target = "location"),
             @Mapping(source = "ipAddr", target = "ipAddress"),
             @Mapping(source = "alarmType", target = "type"),
+            @Mapping(source = "causes", target = "causes"),
+            @Mapping(source = "impacts", target = "impacts"),
             @Mapping(source = "counter", target = "count"),
             @Mapping(source = "severityLabel", target = "severity"),
             @Mapping(source = "logMsg", target = "logMessage"),
@@ -98,6 +102,12 @@ public abstract class AlarmMapper {
 
     public abstract EventParameterDTO eventParameterToEventParameterDTO(OnmsEventParameter eventParameter);
 
+    public abstract AlarmSummaryDTO alarmToAlarmSummaryDTO(OnmsAlarm alarm);
+
+    public Integer ackTypeToInteger(AckType ack) {
+        return ack.getId();
+    }
+
     public void setTicketUrlTemplate(String ticketUrlTemplate) {
         this.ticketUrlTemplate = ticketUrlTemplate;
     }
@@ -108,4 +118,5 @@ public abstract class AlarmMapper {
         Objects.requireNonNull(ticketId);
         return ticketUrlTemplate.replaceAll("\\$\\{id\\}", ticketId);
     }
+
 }
diff --git a/features/rest/mapper/src/test/java/org/opennms/web/rest/mapper/v2/AlarmMapperTest.java b/features/rest/mapper/src/test/java/org/opennms/web/rest/mapper/v2/AlarmMapperTest.java
index 74f4fddf493..f4179d3c945 100644
--- a/features/rest/mapper/src/test/java/org/opennms/web/rest/mapper/v2/AlarmMapperTest.java
+++ b/features/rest/mapper/src/test/java/org/opennms/web/rest/mapper/v2/AlarmMapperTest.java
@@ -141,6 +141,9 @@ public class AlarmMapperTest {
         alarm.setTTicketId("NMS-9587");
         alarm.setTTicketState(TroubleTicketState.OPEN);
 
+        alarm.setCauses(null);
+        alarm.setImpacts(null);
+
         AlarmDTO alarmDTO = alarmMapper.alarmToAlarmDTO(alarm);
         mapAndMarshalToFromXmlAndJson(alarmDTO,
                 "alarm.34.dto.xml",
diff --git a/features/rest/model/src/main/java/org/opennms/web/rest/model/v2/AlarmDTO.java b/features/rest/model/src/main/java/org/opennms/web/rest/model/v2/AlarmDTO.java
index b8068b77b8d..a1c6e67f883 100644
--- a/features/rest/model/src/main/java/org/opennms/web/rest/model/v2/AlarmDTO.java
+++ b/features/rest/model/src/main/java/org/opennms/web/rest/model/v2/AlarmDTO.java
@@ -168,6 +168,12 @@ public class AlarmDTO {
     @XmlElement(name="stickyMemo")
     private MemoDTO stickyMemo;
 
+    @XmlElement(name="impacts")
+    private List<AlarmSummaryDTO> impacts;
+
+    @XmlElement(name="causes")
+    private List<AlarmSummaryDTO> causes;
+    
     public Integer getId() {
         return id;
     }
@@ -487,6 +493,22 @@ public class AlarmDTO {
     public void setStickyMemo(MemoDTO stickyMemo) {
         this.stickyMemo = stickyMemo;
     }
+    
+    public List<AlarmSummaryDTO> getImpacts() {
+        return impacts;
+    }
+
+    public void setImpacts(List<AlarmSummaryDTO> impacts) {
+        this.impacts = impacts;
+    }
+
+    public List<AlarmSummaryDTO> getCauses() {
+        return causes;
+    }
+
+    public void setCauses(List<AlarmSummaryDTO> causes) {
+        this.causes = causes;
+    }
 
     @Override
     public boolean equals(Object o) {
@@ -532,11 +554,17 @@ public class AlarmDTO {
                 Objects.equals(lastAutomationTime, alarmDTO.lastAutomationTime) &&
                 Objects.equals(ifIndex, alarmDTO.ifIndex) &&
                 Objects.equals(reductionKeyMemo, alarmDTO.reductionKeyMemo) &&
-                Objects.equals(stickyMemo, alarmDTO.stickyMemo);
+                Objects.equals(stickyMemo, alarmDTO.stickyMemo) &&
+                Objects.equals(impacts, alarmDTO.impacts) &&
+                Objects.equals(causes, alarmDTO.causes);
     }
 
     @Override
     public int hashCode() {
-        return Objects.hash(id, uei, location, nodeId, nodeLabel, ipAddress, serviceType, reductionKey, type, count, severity, firstEventTime, description, logMessage, operatorInstructions, troubleTicket, troubleTicketState, troubleTicketLink, mouseOverText, suppressedUntil, suppressedBy, suppressedTime, ackUser, ackTime, clearKey, lastEvent, parameters, lastEventTime, applicationDN, managedObjectInstance, managedObjectType, ossPrimaryKey, x733AlarmType, x733ProbableCause, qosAlarmState, firstAutomationTime, lastAutomationTime, ifIndex, reductionKeyMemo, stickyMemo);
+        return Objects.hash(id, uei, location, nodeId, nodeLabel, ipAddress, serviceType, reductionKey, type, count, severity, firstEventTime, description,
+                            logMessage, operatorInstructions, troubleTicket, troubleTicketState, troubleTicketLink, mouseOverText, suppressedUntil,
+                            suppressedBy, suppressedTime, ackUser, ackTime, clearKey, lastEvent, parameters, lastEventTime, applicationDN,
+                            managedObjectInstance, managedObjectType, ossPrimaryKey, x733AlarmType, x733ProbableCause, qosAlarmState, firstAutomationTime,
+                            lastAutomationTime, ifIndex, reductionKeyMemo, stickyMemo, impacts, causes);
     }
 }
diff --git a/features/rest/model/src/main/java/org/opennms/web/rest/model/v2/AlarmSummaryDTO.java b/features/rest/model/src/main/java/org/opennms/web/rest/model/v2/AlarmSummaryDTO.java
new file mode 100644
index 00000000000..37dfd21d1cc
--- /dev/null
+++ b/features/rest/model/src/main/java/org/opennms/web/rest/model/v2/AlarmSummaryDTO.java
@@ -0,0 +1,115 @@
+/*******************************************************************************
+ * This file is part of OpenNMS(R).
+ *
+ * Copyright (C) 2017-2017 The OpenNMS Group, Inc.
+ * OpenNMS(R) is Copyright (C) 1999-2017 The OpenNMS Group, Inc.
+ *
+ * OpenNMS(R) is a registered trademark of The OpenNMS Group, Inc.
+ *
+ * OpenNMS(R) is free software: you can redistribute it and/or modify
+ * it under the terms of the GNU Affero General Public License as published
+ * by the Free Software Foundation, either version 3 of the License,
+ * or (at your option) any later version.
+ *
+ * OpenNMS(R) is distributed in the hope that it will be useful,
+ * but WITHOUT ANY WARRANTY; without even the implied warranty of
+ * MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
+ * GNU Affero General Public License for more details.
+ *
+ * You should have received a copy of the GNU Affero General Public License
+ * along with OpenNMS(R).  If not, see:
+ *      http://www.gnu.org/licenses/
+ *
+ * For more information contact:
+ *     OpenNMS(R) Licensing <license@opennms.org>
+ *     http://www.opennms.org/
+ *     http://www.opennms.com/
+ *******************************************************************************/
+
+package org.opennms.web.rest.model.v2;
+
+import java.util.Objects;
+
+import javax.xml.bind.annotation.XmlAccessType;
+import javax.xml.bind.annotation.XmlAccessorType;
+import javax.xml.bind.annotation.XmlAttribute;
+import javax.xml.bind.annotation.XmlElement;
+import javax.xml.bind.annotation.XmlRootElement;
+
+@XmlRootElement(name="alarm")
+@XmlAccessorType(XmlAccessType.NONE)
+public class AlarmSummaryDTO {
+
+    @XmlAttribute(name="id")
+    private Integer id;
+
+    @XmlElement(name="reductionKey")
+    private String reductionKey;
+
+    @XmlAttribute(name="type")
+    private Integer type;
+
+    @XmlAttribute(name="severity")
+    private String severity;
+
+    @XmlElement(name="description")
+    private String description;
+    
+    public Integer getId() {
+        return id;
+    }
+
+    public void setId(Integer id) {
+        this.id = id;
+    }
+
+    public String getReductionKey() {
+        return reductionKey;
+    }
+
+    public void setReductionKey(String reductionKey) {
+        this.reductionKey = reductionKey;
+    }
+
+    public Integer getType() {
+        return type;
+    }
+
+    public void setType(Integer type) {
+        this.type = type;
+    }
+
+    public String getSeverity() {
+        return severity;
+    }
+
+    public void setSeverity(String severity) {
+        this.severity = severity;
+    }
+
+    public String getDescription() {
+        return description;
+    }
+
+    public void setDescription(String description) {
+        this.description = description;
+    }
+
+    @Override
+    public boolean equals(Object o) {
+        if (this == o) return true;
+        if (o == null || getClass() != o.getClass()) return false;
+        AlarmSummaryDTO alarmDTO = (AlarmSummaryDTO) o;
+        return Objects.equals(id, alarmDTO.id) &&
+                Objects.equals(reductionKey, alarmDTO.reductionKey) &&
+                Objects.equals(type, alarmDTO.type) &&
+                Objects.equals(severity, alarmDTO.severity) &&
+                Objects.equals(description, alarmDTO.description);
+    }
+
+    @Override
+    public int hashCode() {
+        return Objects.hash(id, reductionKey, type, severity, description);
+    }
+}
+
diff --git a/features/springframework-security/src/main/java/org/opennms/web/springframework/security/UserGroupLdapAuthoritiesPopulator.java b/features/springframework-security/src/main/java/org/opennms/web/springframework/security/UserGroupLdapAuthoritiesPopulator.java
index 3917700d202..7e9a35282f2 100644
--- a/features/springframework-security/src/main/java/org/opennms/web/springframework/security/UserGroupLdapAuthoritiesPopulator.java
+++ b/features/springframework-security/src/main/java/org/opennms/web/springframework/security/UserGroupLdapAuthoritiesPopulator.java
@@ -104,6 +104,9 @@ public class UserGroupLdapAuthoritiesPopulator extends DefaultLdapAuthoritiesPop
 				this.groupRoleAttribute
 		);
 
+		// A Role mapping with an empty name is always applied to all users
+		userRoles.add("");
+
 		for(String group : userRoles) {
 			final List<String> rolesForGroup = this.groupToRoleMap.get(group);
 			LOG.debug("Checking {} for an associated role", group);
diff --git a/features/telemetry/itests/src/test/java/org/opennms/netmgt/telemetry/itests/JtiIT.java b/features/telemetry/itests/src/test/java/org/opennms/netmgt/telemetry/itests/JtiIT.java
index 4076c70c0b1..f9d6b681d24 100644
--- a/features/telemetry/itests/src/test/java/org/opennms/netmgt/telemetry/itests/JtiIT.java
+++ b/features/telemetry/itests/src/test/java/org/opennms/netmgt/telemetry/itests/JtiIT.java
@@ -28,7 +28,18 @@
 
 package org.opennms.netmgt.telemetry.itests;
 
-import com.google.common.io.Resources;
+import static com.jayway.awaitility.Awaitility.await;
+import static org.hamcrest.CoreMatchers.equalTo;
+import static org.junit.Assert.assertTrue;
+
+import java.io.File;
+import java.io.IOException;
+import java.net.DatagramPacket;
+import java.net.DatagramSocket;
+import java.net.InetAddress;
+import java.nio.file.Paths;
+import java.util.concurrent.TimeUnit;
+
 import org.junit.Before;
 import org.junit.Rule;
 import org.junit.Test;
@@ -39,7 +50,6 @@ import org.opennms.core.test.db.MockDatabase;
 import org.opennms.core.test.db.annotations.JUnitTemporaryDatabase;
 import org.opennms.core.utils.InetAddressUtils;
 import org.opennms.core.xml.JaxbUtils;
-import org.opennms.netmgt.collection.api.CollectionSet;
 import org.opennms.netmgt.dao.api.InterfaceToNodeCache;
 import org.opennms.netmgt.dao.api.NodeDao;
 import org.opennms.netmgt.model.NetworkBuilder;
@@ -60,20 +70,8 @@ import org.opennms.test.JUnitConfigurationEnvironment;
 import org.springframework.beans.factory.annotation.Autowired;
 import org.springframework.core.io.FileSystemResource;
 import org.springframework.test.context.ContextConfiguration;
-import org.springframework.transaction.support.TransactionOperations;
-
-import java.io.File;
-import java.io.IOException;
-import java.net.DatagramPacket;
-import java.net.DatagramSocket;
-import java.net.InetAddress;
-import java.nio.file.Paths;
-import java.util.concurrent.TimeUnit;
-import java.util.concurrent.atomic.AtomicReference;
 
-import static com.jayway.awaitility.Awaitility.await;
-import static org.hamcrest.CoreMatchers.equalTo;
-import static org.junit.Assert.assertTrue;
+import com.google.common.io.Resources;
 
 @RunWith(OpenNMSJUnit4ClassRunner.class)
 @ContextConfiguration(locations={
@@ -88,6 +86,7 @@ import static org.junit.Assert.assertTrue;
         "classpath:/META-INF/opennms/mockEventIpcManager.xml",
         "classpath:/META-INF/opennms/applicationContext-queuingservice-mq-vm.xml",
         "classpath:/META-INF/opennms/applicationContext-ipc-sink-server-camel.xml",
+        "classpath:/META-INF/opennms/applicationContext-collectionAgentFactory.xml",
         "classpath:/META-INF/opennms/applicationContext-telemetryDaemon.xml"
 })
 @JUnitConfigurationEnvironment
@@ -106,16 +105,11 @@ public class JtiIT {
     @Autowired
     private InterfaceToNodeCache interfaceToNodeCache;
 
-    @Autowired
-    private TransactionOperations transOperation;
-
     @Rule
     public TemporaryFolder tempFolder = new TemporaryFolder();
 
     private File rrdBaseDir;
 
-    private AtomicReference<CollectionSet> collectionSetRef = new AtomicReference<>();
-
     @Before
     public void setUp() throws IOException {
         rrdBaseDir = tempFolder.newFolder("rrd");
@@ -151,10 +145,9 @@ public class JtiIT {
         DatagramSocket socket = new DatagramSocket();
         socket.send(packet);
 
-        // Wait until our reference is set
-        await().atMost(30, TimeUnit.SECONDS).until(() -> {
-            return rrdBaseDir.toPath().resolve(Paths.get("1", "ge_0_0_3", "ifOutOctets.jrb")).toFile().canRead();
-        }, equalTo(true));
+        // Wait until the JRB archive is created
+        await().atMost(30, TimeUnit.SECONDS).until(() -> rrdBaseDir.toPath()
+                .resolve(Paths.get("1", "ge_0_0_3", "ifOutOctets.jrb")).toFile().canRead(), equalTo(true));
     }
 
     private void updateDaoWithConfig(TelemetrydConfiguration config) throws IOException {
diff --git a/features/telemetry/itests/src/test/resources/META-INF/opennms/applicationContext-collectionAgentFactory.xml b/features/telemetry/itests/src/test/resources/META-INF/opennms/applicationContext-collectionAgentFactory.xml
new file mode 100644
index 00000000000..995c56282f2
--- /dev/null
+++ b/features/telemetry/itests/src/test/resources/META-INF/opennms/applicationContext-collectionAgentFactory.xml
@@ -0,0 +1,20 @@
+<?xml version="1.0" encoding="UTF-8"?>
+<beans xmlns="http://www.springframework.org/schema/beans"
+  xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"
+  xmlns:tx="http://www.springframework.org/schema/tx"
+  xmlns:context="http://www.springframework.org/schema/context"
+  xmlns:onmsgi="http://xmlns.opennms.org/xsd/spring/onms-osgi"
+  xsi:schemaLocation="
+  http://www.springframework.org/schema/beans http://www.springframework.org/schema/beans/spring-beans-4.2.xsd
+  http://www.springframework.org/schema/context http://www.springframework.org/schema/context/spring-context-4.2.xsd
+  http://www.springframework.org/schema/tx http://www.springframework.org/schema/tx/spring-tx-4.2.xsd
+  http://xmlns.opennms.org/xsd/spring/onms-osgi http://xmlns.opennms.org/xsd/spring/onms-osgi.xsd
+">
+
+    <context:annotation-config />
+    <tx:annotation-driven/>
+
+    <bean id="collectionAgentFactory" class="org.opennms.netmgt.collectd.DefaultSnmpCollectionAgentFactory" />
+    <onmsgi:service interface="org.opennms.netmgt.collection.api.CollectionAgentFactory" ref="collectionAgentFactory" />
+
+</beans>
diff --git a/integrations/opennms-jasperstudio-extension/pom.xml b/integrations/opennms-jasperstudio-extension/pom.xml
index 74595e91950..2e3b2646e62 100644
--- a/integrations/opennms-jasperstudio-extension/pom.xml
+++ b/integrations/opennms-jasperstudio-extension/pom.xml
@@ -66,34 +66,29 @@
             <artifactId>org.apache.servicemix.bundles.spring-expression</artifactId>
             <version>${springVersion}</version>
         </dependency>
-        <!--<dependency>-->
-            <!--<groupId>org.apache.servicemix.bundles</groupId>-->
-            <!--<artifactId>org.apache.servicemix.bundles.spring-asm</artifactId>-->
-            <!--<version>${springVersion}</version>-->
-        <!--</dependency>-->
         <dependency>
             <groupId>org.apache.servicemix.bundles</groupId>
-            <artifactId>org.apache.servicemix.bundles.spring-aop</artifactId>
+            <artifactId>org.apache.servicemix.bundles.spring-tx</artifactId>
             <version>${springVersion}</version>
         </dependency>
         <dependency>
             <groupId>org.apache.servicemix.bundles</groupId>
-            <artifactId>org.apache.servicemix.bundles.spring-context</artifactId>
+            <artifactId>org.apache.servicemix.bundles.spring-aop</artifactId>
             <version>${springVersion}</version>
         </dependency>
         <dependency>
             <groupId>org.apache.servicemix.bundles</groupId>
-            <artifactId>org.apache.servicemix.bundles.spring-beans</artifactId>
+            <artifactId>org.apache.servicemix.bundles.spring-context</artifactId>
             <version>${springVersion}</version>
         </dependency>
         <dependency>
             <groupId>org.apache.servicemix.bundles</groupId>
-            <artifactId>org.apache.servicemix.bundles.spring-core</artifactId>
+            <artifactId>org.apache.servicemix.bundles.spring-beans</artifactId>
             <version>${springVersion}</version>
         </dependency>
         <dependency>
             <groupId>org.apache.servicemix.bundles</groupId>
-            <artifactId>org.apache.servicemix.bundles.spring-aop</artifactId>
+            <artifactId>org.apache.servicemix.bundles.spring-core</artifactId>
             <version>${springVersion}</version>
         </dependency>
         <dependency>
diff --git a/integrations/opennms-snmp-hardware-inventory-provisioning-adapter/src/main/java/org/opennms/netmgt/provision/snmp/EntityPhysicalTableRow.java b/integrations/opennms-snmp-hardware-inventory-provisioning-adapter/src/main/java/org/opennms/netmgt/provision/snmp/EntityPhysicalTableRow.java
index c78215d9a04..c93c08aaaa8 100644
--- a/integrations/opennms-snmp-hardware-inventory-provisioning-adapter/src/main/java/org/opennms/netmgt/provision/snmp/EntityPhysicalTableRow.java
+++ b/integrations/opennms-snmp-hardware-inventory-provisioning-adapter/src/main/java/org/opennms/netmgt/provision/snmp/EntityPhysicalTableRow.java
@@ -46,6 +46,9 @@ import org.springframework.beans.PropertyAccessorFactory;
  */
 public class EntityPhysicalTableRow extends SnmpRowResult {
 
+    /** The Constant entAliasMappingTable. */
+    public final static SnmpObjId entAliasMappingTable = SnmpObjId.get(".1.3.6.1.2.1.47.1.3.2.1.2");
+
     /** The Constant entPhysicalDescr. */
     public final static SnmpObjId entPhysicalDescr = SnmpObjId.get(".1.3.6.1.2.1.47.1.1.1.1.2");
 
@@ -99,6 +102,7 @@ public class EntityPhysicalTableRow extends SnmpRowResult {
 
     /** The Constant ELEMENTS. */
     public static final SnmpObjId[] ELEMENTS = new SnmpObjId[] {
+        entAliasMappingTable,
         entPhysicalDescr,
         entPhysicalVendorType,
         entPhysicalContainedIn,
@@ -241,4 +245,4 @@ public class EntityPhysicalTableRow extends SnmpRowResult {
         }
         return CLASSES[2]; // Assuming unknown to avoid ArrayIndexOutOfBoundsException
     }
-}
\ No newline at end of file
+}
diff --git a/integrations/opennms-snmp-hardware-inventory-provisioning-adapter/src/main/java/org/opennms/netmgt/provision/snmp/EntityPhysicalTableTracker.java b/integrations/opennms-snmp-hardware-inventory-provisioning-adapter/src/main/java/org/opennms/netmgt/provision/snmp/EntityPhysicalTableTracker.java
index 0d2526e798f..db5eb0aa79a 100644
--- a/integrations/opennms-snmp-hardware-inventory-provisioning-adapter/src/main/java/org/opennms/netmgt/provision/snmp/EntityPhysicalTableTracker.java
+++ b/integrations/opennms-snmp-hardware-inventory-provisioning-adapter/src/main/java/org/opennms/netmgt/provision/snmp/EntityPhysicalTableTracker.java
@@ -29,14 +29,22 @@
 package org.opennms.netmgt.provision.snmp;
 
 import java.util.ArrayList;
+import java.util.HashMap;
+import java.util.HashSet;
 import java.util.List;
 import java.util.Map;
+import java.util.Set;
+import java.util.SortedSet;
+import java.util.TreeSet;
+import java.util.regex.Pattern;
 
 import org.opennms.netmgt.model.HwEntityAttributeType;
+import org.opennms.netmgt.model.OnmsEntityAlias;
 import org.opennms.netmgt.model.OnmsHwEntity;
 import org.opennms.netmgt.snmp.RowCallback;
 import org.opennms.netmgt.snmp.SnmpInstId;
 import org.opennms.netmgt.snmp.SnmpObjId;
+import org.opennms.netmgt.snmp.SnmpResult;
 import org.opennms.netmgt.snmp.SnmpRowResult;
 import org.opennms.netmgt.snmp.TableTracker;
 import org.slf4j.Logger;
@@ -55,6 +63,9 @@ public class EntityPhysicalTableTracker extends TableTracker {
     /** The entities. */
     private List<OnmsHwEntity> entities = new ArrayList<>();
 
+    /** The aliases. */
+    private Map<Integer, SortedSet<OnmsEntityAlias>> aliases = new HashMap<>();
+
     /** The vendor attributes. */
     private Map<SnmpObjId, HwEntityAttributeType> vendorAttributes;
 
@@ -98,16 +109,20 @@ public class EntityPhysicalTableTracker extends TableTracker {
      */
     @Override
     public void rowCompleted(SnmpRowResult row) {
-        OnmsHwEntity entity = ((EntityPhysicalTableRow) row).getOnmsHwEntity(vendorAttributes, replacementMap);
-        LOG.debug("rowCompleted: found entity {}, index: {}, parent: {}", entity.getEntPhysicalName(), entity.getEntPhysicalIndex(), entity.getEntPhysicalContainedIn());
-        if (entity.getEntPhysicalContainedIn() != null && entity.getEntPhysicalContainedIn() > 0) {
-            OnmsHwEntity parent = getParent(entity.getEntPhysicalContainedIn().intValue());
-            if (parent != null) {
-                LOG.debug("rowCompleted: adding child index {} to parent index {}", entity.getEntPhysicalIndex(), parent.getEntPhysicalIndex());
-                parent.addChildEntity(entity);
+        if (row.getInstance().toString().contains(".")) {
+            aliasRowCompleted(row, row.getInstance().toString().split(Pattern.quote(".")));
+        } else {
+            OnmsHwEntity entity = ((EntityPhysicalTableRow) row).getOnmsHwEntity(vendorAttributes, replacementMap);
+            LOG.debug("rowCompleted: found entity {}, index: {}, parent: {}", entity.getEntPhysicalName(), entity.getEntPhysicalIndex(), entity.getEntPhysicalContainedIn());
+            if (entity.getEntPhysicalContainedIn() != null && entity.getEntPhysicalContainedIn() > 0) {
+                OnmsHwEntity parent = getParent(entity.getEntPhysicalContainedIn().intValue());
+                if (parent != null) {
+                    LOG.debug("rowCompleted: adding child index {} to parent index {}", entity.getEntPhysicalIndex(), parent.getEntPhysicalIndex());
+                    parent.addChildEntity(entity);
+                }
             }
+            entities.add(entity);
         }
-        entities.add(entity);
     }
 
     /**
@@ -116,12 +131,19 @@ public class EntityPhysicalTableTracker extends TableTracker {
      * @return the root entity
      */
     public OnmsHwEntity getRootEntity() {
+        OnmsHwEntity root = null;
         for (OnmsHwEntity entity : entities) {
-            if (entity.isRoot()) {
-                return entity;
+            // Need to attach all aliases to their respective entries before returning the root.
+            if (aliases.get(entity.getEntPhysicalIndex()) != null) {
+                LOG.debug("Adding entAliasMapping: {} to entity {} ", aliases.get(entity.getEntPhysicalIndex()),  entity.getEntPhysicalIndex());
+                entity.setEntAliases(aliases.get(entity.getEntPhysicalIndex()));
+            }
+
+            if (root == null && entity.isRoot()) {
+                root = entity;
             }
         }
-        return null;
+        return root;
     }
 
     /**
@@ -138,4 +160,26 @@ public class EntityPhysicalTableTracker extends TableTracker {
         }
         return null;
     }
+
+    /**
+     * Convert a SnmpRowResult to OnmsEntityAlias results and track them under each entry.
+     * 
+     * @param row
+     */
+    private void aliasRowCompleted(SnmpRowResult row, String[] instance) {
+        // Alias row instances in the the form '1012.0'
+        Integer entAliasEntry = Integer.parseInt(instance[0]);
+        Integer entAliasIndex = Integer.parseInt(instance[1]);
+        SortedSet<OnmsEntityAlias> aliasSet = aliases.get(entAliasEntry);
+        if (aliasSet == null) {
+            aliasSet = new TreeSet<>();
+            aliases.put(entAliasEntry, aliasSet);
+        }
+        for (SnmpResult result : row.getResults()) {
+            aliasSet.add(new OnmsEntityAlias(entAliasIndex, result.getValue().toString()));
+            LOG.debug("rowCompleted from entAliasMappingTable: found entry {} index: {} oid: {}", entAliasEntry,  entAliasIndex, result.getValue());
+        }
+    }
+
+
 }
diff --git a/opennms-alarms/api/src/main/java/org/opennms/netmgt/alarmd/api/AlarmLifecycleListener.java b/opennms-alarms/api/src/main/java/org/opennms/netmgt/alarmd/api/AlarmLifecycleListener.java
new file mode 100644
index 00000000000..413d11dce53
--- /dev/null
+++ b/opennms-alarms/api/src/main/java/org/opennms/netmgt/alarmd/api/AlarmLifecycleListener.java
@@ -0,0 +1,39 @@
+/*******************************************************************************
+ * This file is part of OpenNMS(R).
+ *
+ * Copyright (C) 2018 The OpenNMS Group, Inc.
+ * OpenNMS(R) is Copyright (C) 1999-2018 The OpenNMS Group, Inc.
+ *
+ * OpenNMS(R) is a registered trademark of The OpenNMS Group, Inc.
+ *
+ * OpenNMS(R) is free software: you can redistribute it and/or modify
+ * it under the terms of the GNU Affero General Public License as published
+ * by the Free Software Foundation, either version 3 of the License,
+ * or (at your option) any later version.
+ *
+ * OpenNMS(R) is distributed in the hope that it will be useful,
+ * but WITHOUT ANY WARRANTY; without even the implied warranty of
+ * MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
+ * GNU Affero General Public License for more details.
+ *
+ * You should have received a copy of the GNU Affero General Public License
+ * along with OpenNMS(R).  If not, see:
+ *      http://www.gnu.org/licenses/
+ *
+ * For more information contact:
+ *     OpenNMS(R) Licensing <license@opennms.org>
+ *     http://www.opennms.org/
+ *     http://www.opennms.com/
+ *******************************************************************************/
+
+package org.opennms.netmgt.alarmd.api;
+
+import org.opennms.netmgt.model.OnmsAlarm;
+
+public interface AlarmLifecycleListener {
+
+    void handleNewOrUpdatedAlarm(OnmsAlarm alarm);
+
+    void handleDeletedAlarm(int alarmId, String reductionKey);
+
+}
diff --git a/opennms-alarms/api/src/main/java/org/opennms/netmgt/alarmd/api/AlarmLifecycleSubscriptionService.java b/opennms-alarms/api/src/main/java/org/opennms/netmgt/alarmd/api/AlarmLifecycleSubscriptionService.java
new file mode 100644
index 00000000000..335e1b4ad43
--- /dev/null
+++ b/opennms-alarms/api/src/main/java/org/opennms/netmgt/alarmd/api/AlarmLifecycleSubscriptionService.java
@@ -0,0 +1,37 @@
+/*******************************************************************************
+ * This file is part of OpenNMS(R).
+ *
+ * Copyright (C) 2018 The OpenNMS Group, Inc.
+ * OpenNMS(R) is Copyright (C) 1999-2018 The OpenNMS Group, Inc.
+ *
+ * OpenNMS(R) is a registered trademark of The OpenNMS Group, Inc.
+ *
+ * OpenNMS(R) is free software: you can redistribute it and/or modify
+ * it under the terms of the GNU Affero General Public License as published
+ * by the Free Software Foundation, either version 3 of the License,
+ * or (at your option) any later version.
+ *
+ * OpenNMS(R) is distributed in the hope that it will be useful,
+ * but WITHOUT ANY WARRANTY; without even the implied warranty of
+ * MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
+ * GNU Affero General Public License for more details.
+ *
+ * You should have received a copy of the GNU Affero General Public License
+ * along with OpenNMS(R).  If not, see:
+ *      http://www.gnu.org/licenses/
+ *
+ * For more information contact:
+ *     OpenNMS(R) Licensing <license@opennms.org>
+ *     http://www.opennms.org/
+ *     http://www.opennms.com/
+ *******************************************************************************/
+
+package org.opennms.netmgt.alarmd.api;
+
+public interface AlarmLifecycleSubscriptionService {
+
+    void addAlarmLifecyleListener(AlarmLifecycleListener listener);
+
+    void removeAlarmLifecycleListener(AlarmLifecycleListener listener);
+
+}
diff --git a/opennms-alarms/daemon/src/main/java/org/opennms/netmgt/alarmd/AlarmLifecycleListenerManager.java b/opennms-alarms/daemon/src/main/java/org/opennms/netmgt/alarmd/AlarmLifecycleListenerManager.java
new file mode 100644
index 00000000000..0987d7dac04
--- /dev/null
+++ b/opennms-alarms/daemon/src/main/java/org/opennms/netmgt/alarmd/AlarmLifecycleListenerManager.java
@@ -0,0 +1,159 @@
+/*******************************************************************************
+ * This file is part of OpenNMS(R).
+ *
+ * Copyright (C) 2018 The OpenNMS Group, Inc.
+ * OpenNMS(R) is Copyright (C) 1999-2018 The OpenNMS Group, Inc.
+ *
+ * OpenNMS(R) is a registered trademark of The OpenNMS Group, Inc.
+ *
+ * OpenNMS(R) is free software: you can redistribute it and/or modify
+ * it under the terms of the GNU Affero General Public License as published
+ * by the Free Software Foundation, either version 3 of the License,
+ * or (at your option) any later version.
+ *
+ * OpenNMS(R) is distributed in the hope that it will be useful,
+ * but WITHOUT ANY WARRANTY; without even the implied warranty of
+ * MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
+ * GNU Affero General Public License for more details.
+ *
+ * You should have received a copy of the GNU Affero General Public License
+ * along with OpenNMS(R).  If not, see:
+ *      http://www.gnu.org/licenses/
+ *
+ * For more information contact:
+ *     OpenNMS(R) Licensing <license@opennms.org>
+ *     http://www.opennms.org/
+ *     http://www.opennms.com/
+ *******************************************************************************/
+
+package org.opennms.netmgt.alarmd;
+
+import java.util.LinkedHashSet;
+import java.util.Set;
+import java.util.concurrent.locks.ReadWriteLock;
+import java.util.concurrent.locks.ReentrantReadWriteLock;
+
+import org.opennms.netmgt.alarmd.api.AlarmLifecycleListener;
+import org.opennms.netmgt.alarmd.api.AlarmLifecycleSubscriptionService;
+import org.opennms.netmgt.dao.api.AlarmDao;
+import org.opennms.netmgt.events.api.EventConstants;
+import org.opennms.netmgt.events.api.annotations.EventHandler;
+import org.opennms.netmgt.events.api.annotations.EventListener;
+import org.opennms.netmgt.model.OnmsAlarm;
+import org.opennms.netmgt.xml.event.Event;
+import org.opennms.netmgt.xml.event.Parm;
+import org.slf4j.Logger;
+import org.slf4j.LoggerFactory;
+import org.springframework.beans.factory.annotation.Autowired;
+import org.springframework.transaction.TransactionStatus;
+import org.springframework.transaction.support.TransactionCallbackWithoutResult;
+import org.springframework.transaction.support.TransactionTemplate;
+
+@EventListener(name="alarmLifecycleListenerManager", logPrefix="alarmd")
+public class AlarmLifecycleListenerManager implements AlarmLifecycleSubscriptionService {
+
+    private static final Logger LOG = LoggerFactory.getLogger(AlarmLifecycleListenerManager.class);
+
+    private final Set<AlarmLifecycleListener> listeners = new LinkedHashSet<>();
+    private final ReadWriteLock rwLock = new ReentrantReadWriteLock();
+
+    @Autowired
+    private AlarmDao alarmDao;
+
+    @Autowired
+    private TransactionTemplate template;
+
+    @EventHandler(ueis = {
+            EventConstants.ALARM_CREATED_UEI,
+            EventConstants.ALARM_ESCALATED_UEI,
+            EventConstants.ALARM_CLEARED_UEI,
+            EventConstants.ALARM_UNCLEARED_UEI,
+            EventConstants.ALARM_UPDATED_WITH_REDUCED_EVENT_UEI,
+            EventConstants.ALARM_DELETED_EVENT_UEI
+    })
+    public void handleAlarmLifecycleEvents(Event e) {
+        rwLock.readLock().lock();
+        try {
+            if (e == null || listeners.size() < 1) {
+                // Return quick if we weren't given an event, or if there are no listeners defined
+                // in which case we don't need to perform any further handling
+                return;
+            }
+
+            final Parm alarmIdParm = e.getParm(EventConstants.PARM_ALARM_ID);
+            if (alarmIdParm == null || alarmIdParm.getValue() == null) {
+                LOG.warn("The alarmId parameter has no value on event with uei: {}. Ignoring.", e.getUei());
+                return;
+            }
+
+            int alarmId;
+            try {
+                alarmId = Integer.parseInt(alarmIdParm.getValue().getContent());
+            } catch (NumberFormatException ee) {
+                LOG.warn("Failed to retrieve the alarmId for event with uei: {}. Ignoring.", e.getUei(), ee);
+                return;
+            }
+
+            if (EventConstants.ALARM_DELETED_EVENT_UEI.equals(e.getUei())) {
+                final Parm reductionKeyParm = e.getParm(EventConstants.PARM_ALARM_REDUCTION_KEY);
+                if (reductionKeyParm == null) {
+                    LOG.warn("Received alarm deleted event without reduction key. Ignoring.");
+                    return;
+                }
+                if (reductionKeyParm.getValue() == null) {
+                    LOG.warn("Received alarm deleted event with null reduction key value. Ignoring.");
+                    return;
+                }
+                final String reductionKey = reductionKeyParm.getValue().getContent();
+                if (reductionKey == null) {
+                    LOG.warn("Received alarm deleted event with null reduction key content. Ignoring.");
+                    return;
+                }
+
+                handleAlarmDeleted(alarmId, reductionKey);
+            } else {
+                handleAlarmCreatedOrUpdated(e, alarmId);
+            }
+        } finally {
+            rwLock.readLock().unlock();
+        }
+    }
+
+    private void handleAlarmCreatedOrUpdated(Event e, int alarmId) {
+        template.execute(new TransactionCallbackWithoutResult() {
+            @Override
+            protected void doInTransactionWithoutResult(TransactionStatus status) {
+                final OnmsAlarm alarm = alarmDao.get(alarmId);
+                if (alarm == null) {
+                    LOG.error("Could not find alarm with id: {} for event with uei: {}. Ignoring.", alarmId, e.getUei());
+                    return;
+                }
+                listeners.forEach(l -> l.handleNewOrUpdatedAlarm(alarm));
+            }
+        });
+    }
+
+    private void handleAlarmDeleted(int alarmId, String reductionKey) {
+        listeners.forEach(l -> l.handleDeletedAlarm(alarmId, reductionKey));
+    }
+
+    @Override
+    public void addAlarmLifecyleListener(AlarmLifecycleListener listener) {
+        rwLock.writeLock().lock();
+        try {
+            listeners.add(listener);
+        } finally {
+            rwLock.writeLock().unlock();
+        }
+    }
+
+    @Override
+    public void removeAlarmLifecycleListener(AlarmLifecycleListener listener) {
+        rwLock.writeLock().lock();
+        try {
+            listeners.remove(listener);
+        } finally {
+            rwLock.writeLock().unlock();
+        }
+    }
+}
diff --git a/opennms-alarms/daemon/src/main/java/org/opennms/netmgt/alarmd/AlarmPersisterImpl.java b/opennms-alarms/daemon/src/main/java/org/opennms/netmgt/alarmd/AlarmPersisterImpl.java
index 2a33e6c2c63..a499c1638b5 100644
--- a/opennms-alarms/daemon/src/main/java/org/opennms/netmgt/alarmd/AlarmPersisterImpl.java
+++ b/opennms-alarms/daemon/src/main/java/org/opennms/netmgt/alarmd/AlarmPersisterImpl.java
@@ -28,11 +28,15 @@
 
 package org.opennms.netmgt.alarmd;
 
+import java.util.ArrayList;
 import java.util.Arrays;
 import java.util.Collection;
 import java.util.Collections;
+import java.util.List;
 import java.util.concurrent.locks.Lock;
 import java.util.concurrent.locks.ReadWriteLock;
+import java.util.stream.Collectors;
+import java.util.stream.Stream;
 
 import org.hibernate.Hibernate;
 import org.opennms.netmgt.dao.api.AlarmDao;
@@ -44,6 +48,7 @@ import org.opennms.netmgt.model.OnmsEvent;
 import org.opennms.netmgt.model.OnmsSeverity;
 import org.opennms.netmgt.model.events.EventBuilder;
 import org.opennms.netmgt.xml.event.Event;
+import org.opennms.netmgt.xml.event.Parm;
 import org.opennms.netmgt.xml.event.UpdateField;
 import org.slf4j.Logger;
 import org.slf4j.LoggerFactory;
@@ -52,6 +57,8 @@ import org.springframework.transaction.support.TransactionCallback;
 import org.springframework.transaction.support.TransactionOperations;
 import org.springframework.util.Assert;
 
+import com.fasterxml.jackson.databind.DeserializationFeature;
+import com.fasterxml.jackson.databind.ObjectMapper;
 import com.google.common.base.Supplier;
 import com.google.common.util.concurrent.Striped;
 
@@ -66,7 +73,7 @@ public class AlarmPersisterImpl implements AlarmPersister {
 
     protected static final Integer NUM_STRIPE_LOCKS = Integer.getInteger("org.opennms.alarmd.stripe.locks", Alarmd.THREADS * 4);
 
-    private AlarmDao m_alarmDao;
+    private static AlarmDao m_alarmDao;
     private EventDao m_eventDao;
     private EventForwarder m_eventForwarder;
     private TransactionOperations m_transactionOperations;
@@ -258,11 +265,33 @@ public class AlarmPersisterImpl implements AlarmPersister {
         alarm.setSuppressedTime(e.getEventTime()); //TODO: Fix UI to not require this be set
         //alarm.setTTicketId(e.getEventTTicket());
         //alarm.setTTicketState(TroubleTicketState.CANCEL_FAILED);  //FIXME
+        alarm.setImpacts(getAlarms(event.getParm("impacts")));
+        alarm.setCauses(getAlarms(event.getParm("causes")));
         alarm.setUei(e.getEventUei());
         e.setAlarm(alarm);
         return alarm;
     }
     
+    private static List<OnmsAlarm> getAlarms(Parm parm) {
+        return getReductionKeys(parm).map(reductionKey -> m_alarmDao.findByReductionKey(reductionKey)).collect(Collectors.toList());
+    }
+
+    private static Stream<String> getReductionKeys(Parm parm) {
+        if (parm == null || parm.getValue().getContent() == null) {
+            return Stream.empty();
+        }
+        // Expects a JSON style string of reductionkeys
+        String value = parm.getValue().getContent();
+        ObjectMapper mapper = new ObjectMapper();
+        // Support both List and single value
+        mapper.enable(DeserializationFeature.ACCEPT_SINGLE_VALUE_AS_ARRAY);
+        try {
+            return Arrays.stream(mapper.readValue(value, String[].class));
+        } catch (Exception e) {
+            return Stream.empty();
+        }
+    }
+
     private static boolean checkEventSanityAndDoWeProcess(final Event event) {
         // 2009-01-07 pbrane: TODO: Understand why we use Assert
         Assert.notNull(event, "Incoming event was null, aborting"); 
diff --git a/opennms-alarms/daemon/src/main/resources/META-INF/opennms/applicationContext-alarmd.xml b/opennms-alarms/daemon/src/main/resources/META-INF/opennms/applicationContext-alarmd.xml
index 6765ddb273e..08f3a324158 100644
--- a/opennms-alarms/daemon/src/main/resources/META-INF/opennms/applicationContext-alarmd.xml
+++ b/opennms-alarms/daemon/src/main/resources/META-INF/opennms/applicationContext-alarmd.xml
@@ -1,12 +1,15 @@
 <?xml version="1.0" encoding="UTF-8"?>
 <beans xmlns="http://www.springframework.org/schema/beans" 
        xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"
+       xmlns:context="http://www.springframework.org/schema/context"
        xmlns:tx="http://www.springframework.org/schema/tx" 
        xmlns:onmsgi="http://xmlns.opennms.org/xsd/spring/onms-osgi"
        xsi:schemaLocation="http://www.springframework.org/schema/beans http://www.springframework.org/schema/beans/spring-beans.xsd
+       http://www.springframework.org/schema/context http://www.springframework.org/schema/context/spring-context-4.2.xsd
        http://www.springframework.org/schema/tx http://www.springframework.org/schema/tx/spring-tx-4.2.xsd
        http://xmlns.opennms.org/xsd/spring/onms-osgi http://xmlns.opennms.org/xsd/spring/onms-osgi.xsd">
 
+  <context:annotation-config />
   <tx:annotation-driven />
 
   <bean id="alarmPersister" class="org.opennms.netmgt.alarmd.AlarmPersisterImpl" >
@@ -29,4 +32,13 @@
     <onmsgi:listener ref="daemon" bind-method="onNorthbounderRegistered" unbind-method="onNorthbounderUnregistered" />
   </onmsgi:list>
 
+  <bean id="alarmLifecycleListenerManager" class="org.opennms.netmgt.alarmd.AlarmLifecycleListenerManager" />
+
+  <bean id="alarmLifecycleListenerManagerListener" class="org.opennms.netmgt.events.api.AnnotationBasedEventListenerAdapter">
+    <property name="annotatedListener" ref="alarmLifecycleListenerManager" />
+    <property name="eventSubscriptionService" ref="eventSubscriptionService" />
+  </bean>
+
+  <onmsgi:service interface="org.opennms.netmgt.alarmd.api.AlarmLifecycleSubscriptionService" ref="alarmLifecycleListenerManager"/>
+
 </beans>
diff --git a/opennms-alarms/daemon/src/test/java/org/opennms/netmgt/alarmd/AlarmImpactAssociationIT.java b/opennms-alarms/daemon/src/test/java/org/opennms/netmgt/alarmd/AlarmImpactAssociationIT.java
new file mode 100644
index 00000000000..629b3d34e38
--- /dev/null
+++ b/opennms-alarms/daemon/src/test/java/org/opennms/netmgt/alarmd/AlarmImpactAssociationIT.java
@@ -0,0 +1,146 @@
+/*******************************************************************************
+ * This file is part of OpenNMS(R).
+ *
+ * Copyright (C) 2017-2017 The OpenNMS Group, Inc.
+ * OpenNMS(R) is Copyright (C) 1999-2017 The OpenNMS Group, Inc.
+ *
+ * OpenNMS(R) is a registered trademark of The OpenNMS Group, Inc.
+ *
+ * OpenNMS(R) is free software: you can redistribute it and/or modify
+ * it under the terms of the GNU Affero General Public License as published
+ * by the Free Software Foundation, either version 3 of the License,
+ * or (at your option) any later version.
+ *
+ * OpenNMS(R) is distributed in the hope that it will be useful,
+ * but WITHOUT ANY WARRANTY; without even the implied warranty of
+ * MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
+ * GNU Affero General Public License for more details.
+ *
+ * You should have received a copy of the GNU Affero General Public License
+ * along with OpenNMS(R).  If not, see:
+ *      http://www.gnu.org/licenses/
+ *
+ * For more information contact:
+ *     OpenNMS(R) Licensing <license@opennms.org>
+ *     http://www.opennms.org/
+ *     http://www.opennms.com/
+ *******************************************************************************/
+
+package org.opennms.netmgt.alarmd;
+
+import static org.junit.Assert.assertEquals;
+import static org.junit.Assert.assertFalse;
+import static org.junit.Assert.assertTrue;
+
+import java.util.List;
+
+import org.junit.Test;
+import org.junit.runner.RunWith;
+import org.opennms.core.test.OpenNMSJUnit4ClassRunner;
+import org.opennms.core.test.db.annotations.JUnitTemporaryDatabase;
+import org.opennms.netmgt.dao.api.AlarmDao;
+import org.opennms.netmgt.dao.api.DistPollerDao;
+import org.opennms.netmgt.model.OnmsAlarm;
+import org.opennms.test.JUnitConfigurationEnvironment;
+import org.springframework.beans.factory.annotation.Autowired;
+import org.springframework.test.context.ContextConfiguration;
+import org.springframework.transaction.TransactionStatus;
+import org.springframework.transaction.support.TransactionCallbackWithoutResult;
+import org.springframework.transaction.support.TransactionTemplate;
+
+@RunWith(OpenNMSJUnit4ClassRunner.class)
+@ContextConfiguration(locations={
+        "classpath:/META-INF/opennms/applicationContext-soa.xml",
+        "classpath:/META-INF/opennms/applicationContext-commonConfigs.xml",
+        "classpath:/META-INF/opennms/applicationContext-minimal-conf.xml",
+        "classpath:/META-INF/opennms/applicationContext-dao.xml",
+        "classpath*:/META-INF/opennms/component-dao.xml",
+        "classpath:/META-INF/opennms/applicationContext-daemon.xml",
+        "classpath:/META-INF/opennms/mockEventIpcManager.xml",
+        "classpath:/META-INF/opennms/applicationContext-alarmd.xml"
+})
+@JUnitConfigurationEnvironment
+@JUnitTemporaryDatabase(reuseDatabase=false)
+public class AlarmImpactAssociationIT {
+
+    @Autowired
+    private AlarmDao m_alarmDao;
+
+    @Autowired
+    private DistPollerDao m_distPollerDao;
+
+    @Autowired
+    private TransactionTemplate m_transactionTemplate;
+
+    @Test
+    public void canAssociateImpactingAlarms() {
+        // Create a first alarms
+        final OnmsAlarm linkDownAlarmOnR1 = new OnmsAlarm();
+        linkDownAlarmOnR1.setDistPoller(m_distPollerDao.whoami());
+        linkDownAlarmOnR1.setCounter(1);
+        linkDownAlarmOnR1.setUei("linkDown");
+
+        // Create a second alarm
+        final OnmsAlarm linkDownAlarmOnR2 = new OnmsAlarm();
+        linkDownAlarmOnR2.setDistPoller(m_distPollerDao.whoami());
+        linkDownAlarmOnR2.setCounter(1);
+        linkDownAlarmOnR2.setUei("linkDown");
+
+        // Save them and associate them together in one transaction
+        m_transactionTemplate.execute(new TransactionCallbackWithoutResult() {
+            @Override
+            protected void doInTransactionWithoutResult(TransactionStatus status) {
+                m_alarmDao.save(linkDownAlarmOnR1);
+                verifyInitialState(linkDownAlarmOnR1);
+
+                // Associate
+                associate(linkDownAlarmOnR1, linkDownAlarmOnR2);
+
+                // Verify
+                verifyAssociation(linkDownAlarmOnR1, linkDownAlarmOnR2);
+            }
+        });
+
+        m_transactionTemplate.execute(new TransactionCallbackWithoutResult() {
+            @Override
+            protected void doInTransactionWithoutResult(TransactionStatus status) {
+                // Now reload the entities
+                OnmsAlarm r1 = m_alarmDao.get(linkDownAlarmOnR1.getId());
+                OnmsAlarm r2 = m_alarmDao.get(linkDownAlarmOnR2.getId());
+
+                // And verify again
+                verifyAssociation(r1, r2);
+            }
+        });
+    }
+
+    void associate(OnmsAlarm cause, OnmsAlarm impacted) {
+        List<OnmsAlarm> impacts = cause.getImpacts();
+        impacts.add(impacted);
+        cause.setImpacts(impacts);
+        List<OnmsAlarm> causes = impacted.getCauses();
+        causes.add(cause);
+        impacted.setCauses((causes));
+        m_alarmDao.saveOrUpdate(cause);
+        m_alarmDao.saveOrUpdate(impacted);
+    }
+
+    void verifyInitialState(OnmsAlarm alarm) {
+        assertFalse("cause should default to false", alarm.isCause());
+        assertFalse("impacted should default to false", alarm.isImpacted());
+        assertEquals(0, alarm.getImpacts().size());
+        assertEquals(0, alarm.getCauses().size());
+    }
+
+    void verifyAssociation(OnmsAlarm cause, OnmsAlarm impacted) {
+        assertEquals(1, cause.getImpacts().size());
+        assertEquals(0, cause.getCauses().size());
+        assertTrue(cause.isCause());
+        assertFalse(cause.isImpacted());
+
+        assertEquals(0, impacted.getImpacts().size());
+        assertEquals(1, impacted.getCauses().size());
+        assertFalse(impacted.isCause());
+        assertTrue(impacted.isImpacted());
+    }
+}
\ No newline at end of file
diff --git a/opennms-assemblies/remote-poller-nsis/pom.xml b/opennms-assemblies/remote-poller-nsis/pom.xml
index 8e2ae2a0781..7d18a52e395 100644
--- a/opennms-assemblies/remote-poller-nsis/pom.xml
+++ b/opennms-assemblies/remote-poller-nsis/pom.xml
@@ -55,8 +55,8 @@
             <artifactId>nsis-maven-plugin</artifactId>
             <version>1.0-alpha-1</version>
             <configuration>
-              <!-- You may have to change this path if you install NSIS in a different directory -->
-              <makensisBin>C:\Progra~1\NSIS\makensis.exe</makensisBin>
+              <!-- Use makensis.exe available in the %PATH% -->
+              <makensisBin>makensis.exe</makensisBin>
               <scriptFile>remote-poller.nsi</scriptFile>
             </configuration>
             <executions>
diff --git a/opennms-base-assembly/src/main/filtered/bin/opennms-thread-dump b/opennms-base-assembly/src/main/filtered/bin/generate-opennms-thread-dump
similarity index 100%
rename from opennms-base-assembly/src/main/filtered/bin/opennms-thread-dump
rename to opennms-base-assembly/src/main/filtered/bin/generate-opennms-thread-dump
diff --git a/opennms-base-assembly/src/main/filtered/etc/create.sql b/opennms-base-assembly/src/main/filtered/etc/create.sql
index c8f27b99c6c..48bc8f7741c 100644
--- a/opennms-base-assembly/src/main/filtered/etc/create.sql
+++ b/opennms-base-assembly/src/main/filtered/etc/create.sql
@@ -1086,8 +1086,10 @@ create table alarms (
     qosAlarmState           VARCHAR(31),
     ifIndex                 INTEGER,
     clearKey                VARCHAR(256),
-    stickymemo              INTEGER, CONSTRAINT fk_stickyMemo FOREIGN KEY (stickymemo) REFERENCES memos (id) ON DELETE CASCADE
-);
+    stickymemo              INTEGER, CONSTRAINT fk_stickyMemo FOREIGN KEY (stickymemo) REFERENCES memos (id) ON DELETE CASCADE,
+    cause                   boolean DEFAULT false NOT NULL,
+    impacted                boolean DEFAULT false NOT NULL
+    );
 
 CREATE INDEX alarm_uei_idx ON alarms(eventUei);
 CREATE INDEX alarm_nodeid_idx ON alarms(nodeID);
@@ -1122,6 +1124,13 @@ CREATE TABLE alarm_attributes (
 CREATE INDEX alarm_attributes_idx ON alarm_attributes(alarmID);
 CREATE UNIQUE INDEX alarm_attributes_aan_idx ON alarm_attributes(alarmID, attributeName);
 
+CREATE TABLE impacted_alarms (
+    cause_alarmid integer NOT NULL,
+    impacted_alarmid integer NOT NULL
+);
+
+CREATE UNIQUE INDEX impacted_alarms_idx ON impacted_alarms(cause_alarmid, impacted_alarmid);
+
 --# This constraint not understood by installer
 --#        CONSTRAINT pk_usersNotified PRIMARY KEY (userID,notifyID) );
 --#
@@ -2329,6 +2338,17 @@ create table hwEntityAttribute (
 );
 create unique index hwEntityAttribute_unique_idx on hwEntityAttribute(hwEntityId,hwAttribTypeId);
 
+create table hwEntityAlias (
+    id          integer default nextval('opennmsNxtId') not null,
+    hwEntityId  integer ,
+    index       integer not null,
+    oid         varchar(256) not null,
+    constraint pk_hwentityalias PRIMARY KEY (id),
+    constraint fk_hwentity_hwentityalias foreign key (hwentityid) references hwEntity (id) on delete cascade
+);
+
+
+create unique index hwentityalias_unique_idx on hwentityalias(hwentityid, index);
 
 --##################################################################
 --# NCS component tables
diff --git a/opennms-dao-mock/src/main/java/org/opennms/netmgt/dao/mock/MockAlarmDao.java b/opennms-dao-mock/src/main/java/org/opennms/netmgt/dao/mock/MockAlarmDao.java
index 5e2075585a9..5ff5741d82c 100644
--- a/opennms-dao-mock/src/main/java/org/opennms/netmgt/dao/mock/MockAlarmDao.java
+++ b/opennms-dao-mock/src/main/java/org/opennms/netmgt/dao/mock/MockAlarmDao.java
@@ -78,7 +78,12 @@ public class MockAlarmDao extends AbstractMockDao<OnmsAlarm, Integer> implements
 
     @Override
     public OnmsAlarm findByReductionKey(final String reductionKey) {
-        throw new UnsupportedOperationException("Not yet implemented!");
+        for (OnmsAlarm alarm : findAll()) {
+            if (alarm.getReductionKey().equals(reductionKey)) {
+                return alarm;
+            }
+        }
+        return null;
     }
 
     @Override
diff --git a/opennms-dao/src/main/resources/META-INF/opennms/applicationContext-dao.xml b/opennms-dao/src/main/resources/META-INF/opennms/applicationContext-dao.xml
index 26dc5ed6179..2f4cabdfa50 100644
--- a/opennms-dao/src/main/resources/META-INF/opennms/applicationContext-dao.xml
+++ b/opennms-dao/src/main/resources/META-INF/opennms/applicationContext-dao.xml
@@ -493,10 +493,6 @@
 
   <onmsgi:service interface="org.opennms.netmgt.dao.api.TopologyDao" ref="topologyDao" />
 
-  <bean id="collectionAgentFactory" class="org.opennms.netmgt.collection.core.DefaultCollectionAgentFactory" />
-
-  <onmsgi:service interface="org.opennms.netmgt.collection.api.CollectionAgentFactory" ref="collectionAgentFactory" />
-
   <!-- The time-series strategy specific context should provide beans that implement:
             org.opennms.netmgt.collection.api.PersisterFactory
             org.opennms.netmgt.dao.api.ResourceStorageDao
diff --git a/opennms-doc/guide-admin/src/asciidoc/index.adoc b/opennms-doc/guide-admin/src/asciidoc/index.adoc
index ad063c9c6ba..3a6a31ce85a 100644
--- a/opennms-doc/guide-admin/src/asciidoc/index.adoc
+++ b/opennms-doc/guide-admin/src/asciidoc/index.adoc
@@ -171,6 +171,7 @@ include::text/events/sources/xml-tcp.adoc[]
 include::text/events/sources/eif-adapter.adoc[]
 include::text/events/sources/tl1.adoc[]
 include::text/events/eventbus.adoc[]
+include::text/events/event-configuration.adoc[]
 
 [[ga-alarms]]
 == Alarms
@@ -326,3 +327,7 @@ include::text/telemetryd/protocols/nxos/nxos-adapter.adoc[]
 [[ga-telemetryd-listener]]
 === Listener Reference
 include::text/telemetryd/listener/udp-listener.adoc[]
+
+[[ga-kafka-producer]]
+== Kafka Producer
+include::text/kafka-producer/kafka-producer.adoc[]
diff --git a/opennms-doc/guide-admin/src/asciidoc/text/events/event-configuration.adoc b/opennms-doc/guide-admin/src/asciidoc/text/events/event-configuration.adoc
new file mode 100644
index 00000000000..29f26fea4de
--- /dev/null
+++ b/opennms-doc/guide-admin/src/asciidoc/text/events/event-configuration.adoc
@@ -0,0 +1,184 @@
+// Allow GitHub image rendering
+:imagesdir: ../../images
+
+[[ga-events-event-configuration]]
+=== Event Configuration
+The back-end configuration surrounding events is broken into two areas: the configuration of `Eventd` itself, and the configuration of all types of events known to {opennms-product-name}.
+
+==== The eventd-configuration.xml file
+
+The overall behavior of `Eventd` is configured in the file `OPENNMS_HOME/etc/eventd-configuration.xml`.
+This file does not need to be changed in most installations.
+The configurable items include:
+
+TCPAddress::
+    The IP address to which the `Eventd` XML/TCP listener will bind. Defaults to `127.0.0.1`.
+TCPPort::
+    The TCP port number on `TCPAddress` to which the `Eventd` XML/TCP listener will bind. Defaults to `5817`.
+UDPAddress::
+    The IP address to which the `Eventd` XML/UDP listener will bind. Defaults to `127.0.0.1`.
+UDPPort::
+    The UDP port number on `TCPAddress` to which the `Eventd` XML/UDP listener will bind. Defaults to `5817`.
+receivers::
+    The number of threads allocated to service the event intake work done by `Eventd`.
+queueLength::
+    The maximum number of events that may be queued for processing. Additional events will be dropped. Defaults to unlimited.
+getNextEventID::
+    An SQL query statement used to retrieve the ID of the next new event. Changing this setting is not recommended.
+socketSoTimeoutRequired::
+    Whether to set a timeout value on the `Eventd` receiver socket.
+socketSoTimeoutPeriod::
+    The socket timeout, in milliseconds, to set if `socketSoTimeoutRequired` is set to `yes`.
+logEventSummaries::
+    Whether to log a simple (terse) summary of every event at level `INFO`. Useful when troubleshooting event processing on busy systems where `DEBUG` logging is not practical.
+
+
+==== The eventconf.xml file and its tributaries
+
+The set of known events is configured in `OPENNMS_HOME/etc/eventconf.xml`.
+This file opens with a `<global>` element, whose `<security>` child element defines which event fields may not be overridden in the body of an event submitted via any `Eventd` listener.
+This mechanism stops a mailicious actor from, for instance, sending an event whose `operator-action` field amounts to a phishing attack.
+
+After the `<global>` element, this file consists of a series of `<event-file>` elements.
+The content of each `<event-file>` element specifies the path of a *tributary file* whose contents will be read and incorporated into the event configuration.
+These paths are resolved relative to the `OPENNMS_HOME/etc` directory; absolute paths are not allowed.
+
+Each *tributary file* contains a top-level `<events>` element with one or more `<event>` child elements.
+Consider the following event definition:
+
+[source,xml]
+----
+   <event>
+      <uei>uei.opennms.org/nodes/nodeLostService</uei>
+      <event-label>OpenNMS-defined node event: nodeLostService</event-label>
+      <descr>&lt;p>A %service% outage was identified on interface
+            %interface% because of the following condition: %parm[eventReason]%.&lt;/p> &lt;p>
+            A new Outage record has been created and service level
+            availability calculations will be impacted until this outage is
+            resolved.&lt;/p></descr>
+      <logmsg dest="logndisplay">
+            %service% outage identified on interface %interface%.
+        </logmsg>
+      <severity>Minor</severity>
+      <alarm-data reduction-key="%uei%:%dpname%:%nodeid%:%interface%:%service%" alarm-type="1" auto-clean="false"/>
+   </event>
+----
+
+Every event definition has this same basic structure.
+See <<ga-events-anatomy-of-an-event,Anatomy of an Event>> for a discussion of the structural elements.
+
+.A word about severities
+When setting severities of events, it's important to consider each event in the context of your infrastructure as a whole.
+Events whose severity is critical at the zoomed-in level of a single device may not merit a `Critical` severity in the zoomed-out view of your entire enterprise.
+Since an event with `Critical` severity can never have its alarms escalated, this severity level should usually be reserved for events that unequivocally indicate a truly critical impact to the business.
+Rock legend Nigel Tufnel offered https://www.youtube.com/watch?v=4xgx4k83zzc[some wisdom] on the subject.
+
+.Replacement tokens
+Various tokens can be included in the description, log message, operator instruction and automatic actions for each event.
+These tokens will be replaced by values from the current event when the text for the event is constructed.
+Not all events will have values for all tokens, and some refer specifically to information available only in events derived from SNMP traps.
+
+`%eventid%`::
+    The event's numeric database ID
+`%uei%`::
+    The Universal Event Identifier for the event.
+`%source%`::
+    The source of the event (which {opennms-product-name} service daemon created it).
+`%time%`::
+    The time of the event.
+`%dpname%`::
+    The ID of the Minion (formerly distributed poller) that the event was received on.
+`%nodeid%`::
+    The numeric node ID of the device that caused the event, if any.
+`%nodelabel%`::
+    The node label for the node given in `%nodeid%` if available.
+`%host%`::
+`%interface%`::
+    The IP interface associated with the event, if any.
+`%interfaceresolv%`::
+    Does a reverse lookup on the `%interface%` and returns its name if available.
+`%service%`::
+    The service associated with the event, if any.
+`%severity%`::
+    The severity of the event.
+`%snmphost%`::
+    The host of the SNMP agent that generated the event.
+`%id%`::
+    The SNMP Enterprise OID for the event.
+`%idtext%`::
+    The decoded (human-readable) SNMP Enterprise OID for the event (?).
+`%ifalias%`::
+    The interface' SNMP ifAlias.
+`%generic%`::
+    The Generic trap-type number for the event.
+`%specific%`::
+    The Specific trap-type number for the event.
+`%community%`::
+    The community string for the trap.
+`%version%`::
+    The SNMP version of the trap.
+`%snmp%`::
+    The SNMP information associated with the event.
+`%operinstruct%`::
+    The operator instructions for the event.
+`%mouseovertext%`::
+    The mouse over text for the event.
+
+.Parameter tokens
+Many events carry additional information in *parameters* (see <<ga-events-anatomy-of-an-event,Anatomy of an Event>>).
+These parameters may start life as SNMP trap *variable bindings*, or *varbinds* for short.
+You can access event parameters using the `parm` replacement token, which takes several forms:
+
+`%parm[all]%`::
+    Space-separated list of all parameter values in the form `parmName1="parmValue1" parmName2="parmValue2"` and so on.
+`%parm[values-all]%`::
+    Space-separated list of all parameter values (without their names) associated with the event.
+`%parm[names-all]%`::
+    Space-separated list of all parameter names (without their values) associated with the event.
+`%parm[<name>]%`::
+    Will return the value of the parameter named `<name>` if it exists.
+`%parm[##]%`::
+    Will return the total number of parameters as an integer.
+`%parm[#<num>]%`::
+    Will return the value of parameter number `<num>` (one-indexed).
+`%parm[name-#<num>]%`::
+    Will return the name of parameter number `<num>` (one-indexed).
+
+.The structure of the `eventconf.xml` tributary files
+The ordering of event definitions is very important, as an incoming event is matched against them in order.
+It is possible and often useful to have several event definitions which could match variant forms of a given event, for example based on the values of SNMP trap variable bindings.
+
+The tributary files included via the `<event-file>` tag have been broken up by vendor. When {opennms-product-name} starts, each tributary file is loaded in order.
+The ordering of events inside each tributary file is also preserved.
+
+The tributary files listed at the very end of `eventconf.xml` contain catch-all event definitions.
+When slotting your own event definitions, take care not to place them below these catch-all files; otherwise your definitions will be effectively unreachable.
+
+.A few tips
+* To save memory and shorten startup times, you may wish to remove event definition files that you know you do not need.
+* If you need to customize some events in one of the default tributary files, you may wish to make a copy of the file containing only the customized events, and slot the copy above the original; this practice will make it easier to maintain your customizations in case the default file changes in a future release of {opennms-product-name}.
+
+==== Reloading the event configuration
+
+After making manual changes to `OPENNMS_HOME/etc/eventconf.xml` or any of its tributary files, you can trigger a reload of the event configuration by issuing the following command on the {opennms-product-name} server:
+
+[source,sh]
+----
+OPENNMS_HOME/bin/send-event.pl uei.opennms.org/internal/reloadDaemonConfig -p 'daemonName Eventd'
+----
+
+=== Debugging
+
+When debugging events, it may be helpful to lower the minimum severity at which `Eventd` will log from the default level of `WARN`.
+To change this setting, edit `OPENNMS_HOME/etc/log4j2.xml` and locate the following line:
+
+[source,xml]
+----
+        <KeyValuePair key="eventd"               value="WARN" />
+----
+
+Changes to `log42.xml` will be take effect within 60 seconds with no extra action needed.
+At level `DEBUG`, `Eventd` will log a verbose description of every event it handles to `OPENNMS_HOME/logs/eventd.log`.
+On busy systems, this setting may create so much noise as to be impractical.
+In these cases, you can get terse event summaries by setting `Eventd` to log at level `INFO` and setting `logEventSummaries="yes"` in `OPENNMS_HOME/etc/eventd-configuration.xml`.
+Note that changes to `eventd-configuration.xml` require a full restart of {opennms-product-name}.
diff --git a/opennms-doc/guide-admin/src/asciidoc/text/kafka-producer/kafka-producer.adoc b/opennms-doc/guide-admin/src/asciidoc/text/kafka-producer/kafka-producer.adoc
new file mode 100644
index 00000000000..470b9a4e46e
--- /dev/null
+++ b/opennms-doc/guide-admin/src/asciidoc/text/kafka-producer/kafka-producer.adoc
@@ -0,0 +1,220 @@
+// Allow GitHub image rendering
+:imagesdir: ../../images
+
+=== Overview
+
+The _Kafka Producer feature_ allows events, alarms and nodes from _{opennms-product-name}_ to be forwarded to _Kafka_.
+
+These objects are stored in different topics and the payloads are encoded using link:https://developers.google.com/protocol-buffers/[Google Protocol Buffers (GPB)].
+See `opennms-kafka-producer.proto` in the corresponding source distribution for the model definitions.
+
+==== Events
+
+The _Kafka Producer_ listens for all events on the event bus and forwards these to a _Kafka_ topic.
+The records are keyed by event _UEI_ and contain a _GPB_ encoded model of the event.
+
+By default, all events are forwarded to a topic named `events`.
+
+The name of the topic used can be configured, and an optional filtering expression can be set to help control which events are sent to the topic.
+
+==== Alarms
+
+The _Kafka Producer_ listens for changes made to the current set of alarms and forwards the resulting alarms to a _Kafka_ topic.
+The records are keyed by alarm reduction key and contain a _GPB_ encoded model of the alarm.
+When an alarm is deleted, a _null_ value is sent with the corresponding reduction key.
+Publishing records in this fashion allows the topic to be used as a link:https://docs.confluent.io/current/streams/concepts.html#ktable[KTable].
+The _Kafka Producer_ will also perform periodic synchronization tasks to ensure that the contents of the Kafka topic reflect the current state of alarms in the _{opennms-product-name}_ database.
+
+By default, all alarms (and subsequent updates) are forwarded to a topic named `alarms`.
+
+The name of the topic used can be configured, and an optional filtering expression can be set to help control which alarms are sent to the topic.
+
+==== Nodes
+
+If an event or alarm being forwarded reference a node, then the corresponding node is also forwarded.
+The records are keyed by "node criteria" (see bellow) and contain a _GPB_ encoded model of the alarm.
+A caching mechanism is in place to help avoid forwarding nodes that have been successfully forwarded, and have not changed since.
+
+The name of the topic used can be configured.
+
+IMPORTANT: The node topic is not intended to include all of the nodes in the system, it only includes records for nodes that relate to events or alarms that have been forwarded.
+
+===== Node Criteria
+
+The _node criteria_ is a string representation of the unique identifier for a given node.
+If the node is associated with a _foreign source (fs)_  and _foreign id (fid)_, the node criteria resulting node criteria will be the name of the _foreign source_, followed by a colon (:) and then the foreign id i.e. (fs:fid).
+If the node is not associated with both a _foreign source_ and _foreign id_, then the node id (database id) will be used.
+
+=== Enabling the Kafka Producer
+
+The _Kafka Producer_ is disabled by default and can be enabled as follows.
+
+First, login to the _Karaf_ shell of your _{opennms-product-name}_ instance and configure the _Kafka_ client settings to point to your _Kafka_ broker.
+See link:https://kafka.apache.org/10/documentation.html#producerconfigs[Producer Configs] for a complete list of available options.
+
+[source]
+----
+$ ssh -p 8101 admin@localhost
+...
+admin@opennms()> config:edit org.opennms.features.kafka.producer.client
+admin@opennms()> config:property-set bootstrap.servers 127.0.0.1:9092
+admin@opennms()> config:update
+----
+
+Next, install the `opennms-kafka-producer` feature from that same shell using:
+
+[source]
+----
+admin@opennms()> feature:install opennms-kafka-producer
+----
+
+In order to ensure that the feature continues to be installed as subsequent restarts, add `opennms-kafka-producer` to the `featuresBoot` property in the `${OPENNMS_HOME}/etc/org.apache.karaf.features.cfg`.
+
+=== Configuring the Kafka Producer
+
+The _Kafka Producer_ exposes the following options to help fine tune its behavior.
+
+[options="header, autowidth"]
+|===
+| Name                    | Default Value        | Description
+| `eventTopic`            | `events`             | Name of the topic used for events.
+                                                   Set this to an empty string to disable forwarding events.
+| `alarmTopic`            | `alarms`             | Name of the topic used for alarms.
+                                                   Set this to an empty string to disable forwarding alarms.
+| `nodeTopic`             | `nodes`              | Name of the topic used for nodes.
+                                                   Set this to an empty string to disable forwarding nodes.
+| `eventFilter`           | `-`                  | A _Spring SpEL expression_ (see bellow) used to filter events.
+                                                   Set this to an empty string to disable filtering, and forward all events.
+| `alarmFilter`           | `-`                  | A _Spring SpEL expression_ (see bellow) used to filter alarms.
+                                                   Set this to an empty string to disable filtering, and forward all alarms.
+| `nodeRefreshTimeoutMs`  | `300000` (5 minutes) | Number of milliseconds to wait before looking up a node in the database again.
+                                                   Decrease this value to improve accuracy at the cost of additional database look ups.
+| `alarmSyncIntervalMs`   | `300000` (5 minutes) | Number of milliseconds at which the contents of the alarm topic will be synchronized with the local database.
+                                                   Decrease this to improve accuracy at the cost of additional database look ups.
+                                                   Set this value to 0 to disable alarm synchronization.
+|===
+
+==== Configuring Filtering
+
+Filtering can be used to selectively forward events and/or alarms to the _Kafka_ topics.
+
+Filtering is performed using a link:https://docs.spring.io/spring/docs/4.2.9.RELEASE/spring-framework-reference/html/expressions.html[Spring SpEL expression] which is evaluated against each object to determine if it should be forwarded.
+The expression must return a boolean value i.e. `true` or `false`.
+
+===== Enabling Event Filtering
+
+To enable event filtering, set the value of the `eventFilter` property to a valid _SpEL expression_.
+
+[source]
+----
+$ ssh -p 8101 admin@localhost
+...
+admin@opennms()> config:edit org.opennms.features.kafka.producer
+admin@opennms()> config:property-set eventFilter 'getUei().equals("uei.opennms.org/internal/discovery/newSuspect")'
+admin@opennms()> config:update
+----
+
+In the example above, the filter is configured such that only events with the given _UEI_ are forwarded.
+Consult the source code of the `org.opennms.netmgt.xml.event.OnmsEvent` class in your distribution for a complete list of available properties.
+
+===== Enabling Alarm Filtering
+
+To enable alarm filtering, set the value of the `alarmFilter` property to a valid _SpEL expression_.
+
+[source]
+----
+$ ssh -p 8101 admin@localhost
+...
+admin@opennms()> config:edit org.opennms.features.kafka.producer
+admin@opennms()> config:property-set alarmFilter 'getTTicketId() != null'
+admin@opennms()> config:update
+----
+
+In the example above, the filter is configured such that only alarms that are associated with a _ticket id_ are forwarded.
+Consult the source code of the `org.opennms.netmgt.model.OnmsAlarm` class in your distribution for a complete list of available properties.
+
+==== Configuring Topic Names
+
+By default three topics are created i.e. `events`, `alarms`, `nodes`.
+To change these, you can use:
+
+[source]
+----
+$ ssh -p 8101 admin@localhost
+...
+admin@opennms()> config:edit org.opennms.features.kafka.producer
+admin@opennms()> config:property-set eventTopic ""
+admin@opennms()> config:property-set nodeTopic "opennms-nodes"
+admin@opennms()> config:update
+----
+
+In the example above, we disable event forwarding by setting an empty topic name and change the node topic name to `opennms-nodes`.
+
+=== Shell Commands
+
+The _Kafka Producer_ also provides a series of shell commands to help administering and debugging the service.
+
+==== kafka-producer:list-alarms
+
+The `list-alarms` command can be used to enumerate the reduction keys and show the associated event labels for the alarms that are present in the topic.
+This command leverages functionality used by the alarm synchronization process, and as a result this must be enabled in for this command to function.
+
+[source]
+----
+$ ssh -p 8101 admin@localhost
+...
+admin@opennms> kafka-producer:list-alarms
+uei.opennms.org/alarms/trigger:n33:0.0.0.0:HTTPS_POOLs
+        Alarm: Generic Trigger
+----
+
+==== kafka-producer:sync-alarms
+
+The `sync-alarms` command can be used to manually trigger the alarm synchronization process.
+
+[source]
+----
+$ ssh -p 8101 admin@localhost
+...
+admin@opennms> kafka-producer:sync-alarms
+Performing synchronization of alarms from the database with those in the ktable.
+Executed 1 updates in 47ms.
+
+Number of reduction keys in ktable: 4
+Number of reduction keys in the db: 4 (4 alarms total)
+Reduction keys added to the ktable: (None)
+Reduction keys deleted from the ktable: (None)
+Reduction keys updated in the ktable:
+        uei.opennms.org/nodes/nodeLostService::1:127.0.0.1:Minion-RPC
+----
+
+==== kafka-producer:evaluate-filter
+
+The `evaluate-filter` command can be used to test arbitrary _SpEL_ filtering expressions against alarms or events.
+
+===== Evaluating filters against alarms
+
+To test a filter against an alarm, specify the database id of the alarm and the expression to test:
+
+[source]
+----
+admin@opennms> kafka-producer:evaluate-filter --alarm-id 57 "getReductionKey().contains('n33')"
+SPEL Expression: getReductionKey().contains('n33')
+Alarm with ID 57 has reduction key: uei.opennms.org/alarms/trigger:n33:0.0.0.0:HTTPS_POOLs
+Result: true
+----
+
+===== Evaluating filters against events
+
+To test a filter against an event, specify the _UEI_ of the event and the expression to test:
+
+[source]
+----
+admin@opennms> kafka-producer:evaluate-filter --event-uei uei.opennms.org/alarms/trigger "getUei().contains('alarm')"
+SPEL Expression: getUei().contains('alarm')
+Event has UEI: uei.opennms.org/alarms/trigger
+Result: true
+----
+
+In this case, a new event will be created with the given _UEI_, and the filter will be evaluated against this new event object.
+At this time, existing events cannot be referenced by this tool, so this functionality only serves to help make sure the expressions are syntactically valid.
diff --git a/opennms-doc/guide-admin/src/asciidoc/text/performance-data-collection/shell/introduction.adoc b/opennms-doc/guide-admin/src/asciidoc/text/performance-data-collection/shell/introduction.adoc
index 9327a04d3d9..ec3d7583f2e 100644
--- a/opennms-doc/guide-admin/src/asciidoc/text/performance-data-collection/shell/introduction.adoc
+++ b/opennms-doc/guide-admin/src/asciidoc/text/performance-data-collection/shell/introduction.adoc
@@ -13,3 +13,5 @@ ssh -p 8101 admin@localhost
 
 NOTE: The Karaf shell uses the same credential as the web interface.
       Users must be associated with the `ADMIN` role to access the shell.
+
+IMPORTANT: In order to keep the session open while executing long-running tasks without any user input add `-o ServerAliveInterval=10` to your ssh command.
\ No newline at end of file
diff --git a/opennms-doc/guide-admin/src/asciidoc/text/plugins/opennms-es-rest.adoc b/opennms-doc/guide-admin/src/asciidoc/text/plugins/opennms-es-rest.adoc
index 4deeb079db0..3862d945b2b 100644
--- a/opennms-doc/guide-admin/src/asciidoc/text/plugins/opennms-es-rest.adoc
+++ b/opennms-doc/guide-admin/src/asciidoc/text/plugins/opennms-es-rest.adoc
@@ -38,6 +38,7 @@ With the following properties (defaults shown will be used if file is not presen
 |`archiveAssetData`         | true                  | optional | If true The following attributes representing useful node asset fields from the node asset table are included in archived events and alarms. These are included only where the values are not null or empty strings in the table. 
 
 (asset-latitude,asset-longitude,asset-region,asset-building,asset-floor,asset-room,asset-rack,asset-slot,asset-port,asset-category,asset-displaycategory,asset-notifycategory,asset-pollercategory,asset-thresholdcategory,asset-managedobjecttype,asset-managedobjectinstance,asset-manufacturer,asset-vendor,asset-modelnumber,parent-nodelabel,parent-nodeid,parent-foreignsource,parent-foreignid)
+|`groupOidParameters`       | false                 | optional | If `true` all oid from the event parameters are stored in a single array `p_oids` instead of a flattened structue.
 |`logAllEvents`             | false                 | optional | If changed to true, then archive all events even if they have not been persisted in the _{opennms-product-name}_ database.
 |`retries`                  | 0                     | optional | The number of times to retry an _Elasticsearch_ operation that fails completely. You can increase `retries` to avoid losing forwarded events and alarms when _Elasticsearch_ is down or unreachable.
 |`timeout`                  | 5000                  | optional | The interval between subsequent retries when a `retries` value greater than 1 is being used.
diff --git a/opennms-doc/guide-development/src/asciidoc/images/docs/03_officialdocs-wiki-template-source.png b/opennms-doc/guide-development/src/asciidoc/images/docs/03_officialdocs-wiki-template-source.png
new file mode 100644
index 00000000000..a2072a5a35a
Binary files /dev/null and b/opennms-doc/guide-development/src/asciidoc/images/docs/03_officialdocs-wiki-template-source.png differ
diff --git a/opennms-doc/guide-development/src/asciidoc/images/docs/04_officialdocs-wiki-template-rendered-completed.png b/opennms-doc/guide-development/src/asciidoc/images/docs/04_officialdocs-wiki-template-rendered-completed.png
new file mode 100644
index 00000000000..986cf490669
Binary files /dev/null and b/opennms-doc/guide-development/src/asciidoc/images/docs/04_officialdocs-wiki-template-rendered-completed.png differ
diff --git a/opennms-doc/guide-development/src/asciidoc/images/docs/04_officialdocs-wiki-template-rendered-pending.png b/opennms-doc/guide-development/src/asciidoc/images/docs/04_officialdocs-wiki-template-rendered-pending.png
new file mode 100644
index 00000000000..5ac3a3555d8
Binary files /dev/null and b/opennms-doc/guide-development/src/asciidoc/images/docs/04_officialdocs-wiki-template-rendered-pending.png differ
diff --git a/opennms-doc/guide-development/src/asciidoc/images/docs/05_officialdocs-wiki-template-rendered-completed.png b/opennms-doc/guide-development/src/asciidoc/images/docs/05_officialdocs-wiki-template-rendered-completed.png
new file mode 100644
index 00000000000..b39121e3e29
Binary files /dev/null and b/opennms-doc/guide-development/src/asciidoc/images/docs/05_officialdocs-wiki-template-rendered-completed.png differ
diff --git a/opennms-doc/guide-development/src/asciidoc/index.adoc b/opennms-doc/guide-development/src/asciidoc/index.adoc
index 1e6aa6c6de0..0dcfcfadf62 100644
--- a/opennms-doc/guide-development/src/asciidoc/index.adoc
+++ b/opennms-doc/guide-development/src/asciidoc/index.adoc
@@ -82,6 +82,7 @@ include::text/docs/writing.adoc[]
 include::text/docs/images.adoc[]
 include::text/docs/include-source.adoc[]
 include::text/docs/cheat-sheets.adoc[]
+include::text/docs/migrating-from-wiki.adoc[]
 
 == AMQP Integration
 include::text/amqp/introduction.adoc[]
diff --git a/opennms-doc/guide-development/src/asciidoc/text/docs/migrating-from-wiki.adoc b/opennms-doc/guide-development/src/asciidoc/text/docs/migrating-from-wiki.adoc
new file mode 100644
index 00000000000..3e411bc08a5
--- /dev/null
+++ b/opennms-doc/guide-development/src/asciidoc/text/docs/migrating-from-wiki.adoc
@@ -0,0 +1,52 @@
+
+// Allow image rendering
+:imagesdir: ../../images
+
+[[gd-docs-migrating-from-wiki]]
+=== Migrating content from project wiki
+The https://wiki.opennms.org[project wiki] contains much information that ought to be migrated to the official documentation set.
+To help with this effort, we have a wiki template which informs readers of articles that are tagged for migration to the official docs, or that have already been migrated.
+When you identify an article in the OpenNMS wiki whose information should be migrated (either in its entirety, or just individual sections), use the following process.
+
+1. If you do not already have a wiki account, https://wiki.opennms.org/wiki/Special:RequestAccount[request one] before getting started. Your request must be approved by a wiki admin. If you don't get approved within a day, send a note to the https://sourceforge.net/projects/opennms/lists/opennms-devel[opennms-devel mailing list] or on the https://chat.opennms.com/opennms/channels/opennms-development[*OpenNMS Development* chat channel].
+2. Create an issue in the https://issues.opennms.org/projects/NMS/[project issue tracker, in project *NMS*]. Note the issue number; you will use it below.
+3. After logging in to the wiki, visit the article whose content should be migrated.
+4. Click on the *Edit Source* link at the top of the article view.
+5. Add text like the following to the top of the article source editor:
+
+[source]
+----
+{{OfficialDocs | scope=article | guide=admin | issue=NMS-9926 | date=March 2018 | completed=false}}
+----
+
+** The value of the `scope` attribute must be either `article`, if the entire article should be migrated,or `section` if only specific section(s) should be migrated.
+*** When using `scope = section`, it's fine to use this template multiple times in a single article.
+** The value of the `guide` attribute must be one of `admin`, `development`, `install`, or `user`.
+*** If the information in an article should be migrated to multiple official guides, use multiple instances of the `{{OfficialDocs}}` template; try to target these by section when possible.
+** The value of the `issue` parameter must be a valid issue ID in the https://issues.opennms.org[project issue tracker], and will become a live link
+** The value of the `date` parameter should be the month and year when the tag was added, **e.g.** `March 2018`.
+** The `completed` parameter is optional; it is assumed to be false if omitted, or true if its value is either `true` or `yes`.
+
+.Wiki source editor with example `OfficialDocs` template usage
+image::docs/03_officialdocs-wiki-template-source.png[]
+
+[start=6]
+6. Enter an edit summary such as *Tagged for migration to official docs, NMS-12345* and click *Show preview*
+7. After verifying that your changes render as expected (see image), click *Save changes*.
+
+.Rendering of `OfficialDocs` wiki template on an article pending migration
+image::docs/04_officialdocs-wiki-template-rendered-pending.png[]
+
+[start=8]
+8. Migrate the information, making sure to follow the guidelines laid out earlier in this section; do not just copy and paste, and watch out for obsolete information. If you need help, contact the developers through one of the methods mentioned above.
+9. Once the migration is complete and the issue is closed, edit the wiki article again and change `completed=false` to `completed=true`.
+10. The rendering of the template will change to indicate that the migration has been completed.
+
+.Rendering of `OfficialDocs` wiki template on an article whose migration is completed
+image::docs/04_officialdocs-wiki-template-rendered-completed.png[]
+
+Adding the `{{OfficialDocs}}` template to an article will implicitly add that article to a pair of wiki categories:
+
+* *Migration to official docs pending* or *Migration to official docs completed*, according to the value of the `completed` attribute
+* *Migrate to `X` guide*, according to the value of the `guide` attribute
+
diff --git a/opennms-full-assembly/pom.xml b/opennms-full-assembly/pom.xml
index 9dfeb6058ec..507016dae42 100644
--- a/opennms-full-assembly/pom.xml
+++ b/opennms-full-assembly/pom.xml
@@ -358,10 +358,12 @@
                 <!-- Karaf Spring features -->
                 <feature>spring/3.1.4.RELEASE</feature>
                 <feature>spring/3.2.18.RELEASE_1</feature>
-                <feature>spring/4.0.7.RELEASE_3</feature>
-                <feature>spring-jms/4.0.7.RELEASE_3</feature>
+                <feature>spring/4.0.9.RELEASE_1</feature>
+                <feature>spring-jms/4.0.9.RELEASE_1</feature>
                 <feature>spring/4.1.9.RELEASE_1</feature>
                 <feature>spring-jms/4.1.9.RELEASE_1</feature>
+                <feature>spring/4.2.9.RELEASE_1</feature>
+                <feature>spring/4.3.14.RELEASE_1</feature>
                 <feature>spring/${springVersion}</feature>
                 <feature>spring-aspects/${springVersion}</feature>
                 <feature>spring-instrument/${springVersion}</feature>
diff --git a/opennms-full-assembly/src/test/java/org/opennms/assemblies/karaf/OnmsFeatureKarafIT.java b/opennms-full-assembly/src/test/java/org/opennms/assemblies/karaf/OnmsFeatureKarafIT.java
index a4562bb952d..994a63a9498 100644
--- a/opennms-full-assembly/src/test/java/org/opennms/assemblies/karaf/OnmsFeatureKarafIT.java
+++ b/opennms-full-assembly/src/test/java/org/opennms/assemblies/karaf/OnmsFeatureKarafIT.java
@@ -513,6 +513,7 @@ public class OnmsFeatureKarafIT extends KarafTestCase {
 	}
 	@Test
 	public void testInstallFeatureOpennmsProvisioningDetectors() {
+		installFeature("pax-http"); // Provides javax.servlet version 2.6
 		installFeature("opennms-config"); // System classpath
 		installFeature("opennms-provisioning-detectors", EnumSet.of(FeaturesService.Option.NoAutoRefreshBundles));
 		System.out.println(executeCommand("feature:list -i"));
@@ -662,6 +663,7 @@ public class OnmsFeatureKarafIT extends KarafTestCase {
 	}
 	@Test
 	public void testInstallFeatureTsrmTroubleticketer() {
+		installFeature("pax-http"); // Provides javax.servlet version 2.6
 		installFeature("opennms-core"); // System classpath
 		installFeature("tsrm-troubleticketer");
 		System.out.println(executeCommand("feature:list -i"));
diff --git a/opennms-model/src/main/java/org/opennms/netmgt/model/AckType.java b/opennms-model/src/main/java/org/opennms/netmgt/model/AckType.java
index 6fd9d993726..6e255df9097 100644
--- a/opennms-model/src/main/java/org/opennms/netmgt/model/AckType.java
+++ b/opennms-model/src/main/java/org/opennms/netmgt/model/AckType.java
@@ -68,7 +68,7 @@ public enum AckType {
         m_label = label;
     }
     
-    private Integer getId() {
+    public Integer getId() {
         return m_id;
     }
     
diff --git a/opennms-model/src/main/java/org/opennms/netmgt/model/OnmsAlarm.java b/opennms-model/src/main/java/org/opennms/netmgt/model/OnmsAlarm.java
index 1f94cdb55a8..2f997efc270 100644
--- a/opennms-model/src/main/java/org/opennms/netmgt/model/OnmsAlarm.java
+++ b/opennms-model/src/main/java/org/opennms/netmgt/model/OnmsAlarm.java
@@ -30,6 +30,7 @@ package org.opennms.netmgt.model;
 
 import java.io.Serializable;
 import java.net.InetAddress;
+import java.util.ArrayList;
 import java.util.Calendar;
 import java.util.Date;
 import java.util.List;
@@ -46,6 +47,7 @@ import javax.persistence.GeneratedValue;
 import javax.persistence.Id;
 import javax.persistence.JoinColumn;
 import javax.persistence.JoinTable;
+import javax.persistence.ManyToMany;
 import javax.persistence.ManyToOne;
 import javax.persistence.MapKeyColumn;
 import javax.persistence.OneToOne;
@@ -77,7 +79,7 @@ import org.springframework.core.style.ToStringCreator;
 @Filter(name=FilterManager.AUTH_FILTER_NAME, condition="exists (select distinct x.nodeid from node x join category_node cn on x.nodeid = cn.nodeid join category_group cg on cn.categoryId = cg.categoryId where x.nodeid = nodeid and cg.groupId in (:userGroups))")
 @JsonIgnoreProperties({"hibernateLazyInitializer", "handler"})
 public class OnmsAlarm implements Acknowledgeable, Serializable {
-    private static final long serialVersionUID = 7275548439687562161L;
+    private static final long serialVersionUID = 3;
     
     /** Constant <code>PROBLEM_TYPE=1</code> */
     public static final int PROBLEM_TYPE = 1;
@@ -85,6 +87,9 @@ public class OnmsAlarm implements Acknowledgeable, Serializable {
     /** Constant <code>RESOLUTION_TYPE=2</code> */
     public static final int RESOLUTION_TYPE = 2;
 
+    /** Constant <code>PROBLEM_WITHOUT_RESOLUTION_TYPE=3</code> */
+    public static final int PROBLEM_WITHOUT_RESOLUTION_TYPE = 3;
+
     /** identifier field */
     private Integer m_id;
 
@@ -192,6 +197,14 @@ public class OnmsAlarm implements Acknowledgeable, Serializable {
     
     private OnmsReductionKeyMemo m_reductionKeyMemo;
     
+    private boolean m_impacted = false;
+
+    private boolean m_cause = false;
+
+    private List<OnmsAlarm> m_impacts = new ArrayList<>();
+
+    private List<OnmsAlarm> m_causes = new ArrayList<>();
+
     /**
      * default constructor
      */
@@ -1143,5 +1156,47 @@ public class OnmsAlarm implements Acknowledgeable, Serializable {
     public Date getAckTime() {
         return m_alarmAckTime;
     }
-    
+
+    public void setImpacted(boolean impacted) {
+        m_impacted = impacted;
+    }
+
+    @Column(name="impacted")
+    @XmlAttribute(name="impacted")
+    public boolean isImpacted() {
+        return m_impacted;
+    }
+
+    public void setCause(boolean cause) {
+        m_cause = cause;
+    }
+
+    @Column(name="cause")
+    @XmlAttribute(name="cause")
+    public boolean isCause() {
+        return m_cause;
+    }
+
+    @ManyToMany(cascade={CascadeType.ALL})
+    @JoinTable(name="impacted_alarms", 
+        joinColumns={@JoinColumn(name="impacted_alarmid")}, 
+        inverseJoinColumns={@JoinColumn(name="cause_alarmid")})
+    public List<OnmsAlarm> getImpacts() {
+        return m_impacts;
+    }
+
+    public void setImpacts(List<OnmsAlarm> impacts) {
+        m_cause = impacts != null && !impacts.isEmpty();
+        m_impacts = impacts;
+    }
+
+    @ManyToMany(mappedBy="impacts")
+    public List<OnmsAlarm> getCauses() {
+        return m_causes;
+    }
+
+    public void setCauses(List<OnmsAlarm> causes) {
+        m_impacted = causes != null && !causes.isEmpty();
+        m_causes = causes;
+    }
 }
diff --git a/opennms-model/src/main/java/org/opennms/netmgt/model/OnmsEntityAlias.java b/opennms-model/src/main/java/org/opennms/netmgt/model/OnmsEntityAlias.java
new file mode 100644
index 00000000000..4e7b519d493
--- /dev/null
+++ b/opennms-model/src/main/java/org/opennms/netmgt/model/OnmsEntityAlias.java
@@ -0,0 +1,196 @@
+/*******************************************************************************
+ * This file is part of OpenNMS(R).
+ *
+ * Copyright (C) 2008-2014 The OpenNMS Group, Inc.
+ * OpenNMS(R) is Copyright (C) 1999-2014 The OpenNMS Group, Inc.
+ *
+ * OpenNMS(R) is a registered trademark of The OpenNMS Group, Inc.
+ *
+ * OpenNMS(R) is free software: you can redistribute it and/or modify
+ * it under the terms of the GNU Affero General Public License as published
+ * by the Free Software Foundation, either version 3 of the License,
+ * or (at your option) any later version.
+ *
+ * OpenNMS(R) is distributed in the hope that it will be useful,
+ * but WITHOUT ANY WARRANTY; without even the implied warranty of
+ * MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
+ * GNU Affero General Public License for more details.
+ *
+ * You should have received a copy of the GNU Affero General Public License
+ * along with OpenNMS(R).  If not, see:
+ *      http://www.gnu.org/licenses/
+ *
+ * For more information contact:
+ *     OpenNMS(R) Licensing <license@opennms.org>
+ *     http://www.opennms.org/
+ *     http://www.opennms.com/
+ *******************************************************************************/
+package org.opennms.netmgt.model;
+
+import java.io.Serializable;
+
+import javax.persistence.Column;
+import javax.persistence.Entity;
+import javax.persistence.FetchType;
+import javax.persistence.GeneratedValue;
+import javax.persistence.Id;
+import javax.persistence.JoinColumn;
+import javax.persistence.ManyToOne;
+import javax.persistence.SequenceGenerator;
+import javax.persistence.Table;
+import javax.xml.bind.annotation.XmlAccessType;
+import javax.xml.bind.annotation.XmlAccessorType;
+import javax.xml.bind.annotation.XmlAttribute;
+import javax.xml.bind.annotation.XmlRootElement;
+import javax.xml.bind.annotation.XmlTransient;
+
+import org.apache.commons.lang.builder.ToStringBuilder;
+import org.apache.commons.lang.builder.ToStringStyle;
+import org.codehaus.jackson.annotate.JsonIgnoreProperties;
+
+@XmlRootElement(name = "entAlias")
+@Entity
+@Table(name="hwEntityAlias")
+@XmlAccessorType(XmlAccessType.NONE)
+@JsonIgnoreProperties({"hibernateLazyInitializer", "handler"})
+public class OnmsEntityAlias implements Serializable, Comparable<OnmsEntityAlias> {
+
+    /** The Constant serialVersionUID. */
+    private static final long serialVersionUID = -2863137645849222221L;
+
+    /** The id. */
+    private Integer m_id;
+    
+    /** The entity Alias index. */
+    private Integer m_index;
+
+    /** The entity physical index. */
+    private String m_oid;
+
+    /** The hardware entity. */
+    private OnmsHwEntity m_hwEntity;
+    
+    /**
+     * The Constructor.
+     */
+    public OnmsEntityAlias() {
+    }
+
+    /**
+     * The Constructor.
+     *
+     * @param index the alias index
+     * @param oid the alias oid 
+     */
+    public OnmsEntityAlias(Integer index, String oid) {
+        super();
+        this.m_index = index;
+        this.m_oid = oid;
+    }
+
+    /**
+     * @return the id
+     */
+    @Id
+    @Column(nullable=false)
+    @XmlTransient
+    @SequenceGenerator(name="opennmsSequence", sequenceName="opennmsNxtId")
+    @GeneratedValue(generator="opennmsSequence")
+    public Integer getId() {
+        return m_id;
+    }
+
+    /**
+     * @param id the m_id to set
+     */
+    public void setId(Integer id) {
+        this.m_id = id;
+    }
+
+    /**
+     * Gets the hardware entity.
+     *
+     * @return the hardware entity
+     */
+    @ManyToOne(optional=false, fetch=FetchType.LAZY)
+    @JoinColumn(name="hwEntityId")
+    @XmlTransient
+    public OnmsHwEntity getHwEntity() {
+        return m_hwEntity;
+    }
+
+    /**
+     * Sets the hardware entity.
+     *
+     * @param hwEntity the hardware entity
+     */
+    public void setHwEntity(OnmsHwEntity hwEntity) {
+        m_hwEntity = hwEntity;
+    }
+
+    /**
+     * @return the m_entAliasId
+     */
+    public Integer getIndex() {
+        return m_index;
+    }
+
+    /**
+     * @param index the index to set
+     */
+    @XmlAttribute(name="index")
+    public void setIndex(Integer index) {
+        this.m_index = index;
+    }
+
+    /**
+     * @return the m_entAliasOid
+     */
+    @XmlAttribute(name="oid")
+    public String getOid() {
+        return m_oid;
+    }
+
+    /**
+     * @param oid the oid to set
+     */
+    public void setOid(String oid) {
+        this.m_oid = oid;
+    }
+
+    @Override
+    public String toString() {
+        ToStringBuilder b = new ToStringBuilder(OnmsEntityAlias.class.getSimpleName(), ToStringStyle.SHORT_PREFIX_STYLE);
+        if (m_hwEntity != null) {
+            b.append("entity", m_hwEntity.getEntPhysicalIndex());
+        }
+        if (m_index != null) {
+            b.append("idx", m_index);
+        }
+        if (m_oid != null) {
+            b.append("oid", m_oid);
+        }
+        return b.toString();
+    }
+
+    @Override
+    public int hashCode() {
+        return toString().hashCode();
+    }
+
+    @Override
+    public boolean equals(Object obj) {
+        if (obj == null) return false;
+        if (obj instanceof OnmsEntityAlias) {
+            return toString().equals(obj.toString());
+        }
+        return false;
+    }
+
+    @Override
+    public int compareTo(OnmsEntityAlias o) {
+        if (o == null) return -1;
+        return toString().compareTo(o.toString());
+    }
+    
+}
diff --git a/opennms-model/src/main/java/org/opennms/netmgt/model/OnmsHwEntity.java b/opennms-model/src/main/java/org/opennms/netmgt/model/OnmsHwEntity.java
index 7ced3326b1a..a3ca82dd0d2 100644
--- a/opennms-model/src/main/java/org/opennms/netmgt/model/OnmsHwEntity.java
+++ b/opennms-model/src/main/java/org/opennms/netmgt/model/OnmsHwEntity.java
@@ -136,6 +136,9 @@ public class OnmsHwEntity implements Serializable, Comparable<OnmsHwEntity> {
     /** The OpenNMS node. */
     private OnmsNode m_node;
 
+    /** The custom hardware attributes. */
+    private SortedSet<OnmsEntityAlias> m_entAliases = new TreeSet<>();
+
     /** The custom hardware attributes. */
     private SortedSet<OnmsHwEntityAttribute> m_hwAttributes = new TreeSet<>();
 
@@ -174,6 +177,27 @@ public class OnmsHwEntity implements Serializable, Comparable<OnmsHwEntity> {
         m_id = id;
     }
 
+    /**
+     * Gets the entity alias mappings.
+     * 
+     * @return the entity alias mappings
+     */
+    @OneToMany(mappedBy="hwEntity", fetch=FetchType.LAZY, cascade={CascadeType.ALL}, orphanRemoval=true)
+    @Sort(type = SortType.NATURAL)
+    @XmlElement(name="hwEntityAliases")
+    public SortedSet<OnmsEntityAlias> getEntAliases() {
+        return m_entAliases;
+    }
+
+    /**
+     * Sets the entity alias mappings.
+     * 
+     * @param entAliases the entity alias mappings to set
+     */
+    public void setEntAliases(SortedSet<OnmsEntityAlias> entAliases) {
+        this.m_entAliases = entAliases;
+    }
+
     /**
      * Gets the entity id.
      *
diff --git a/opennms-model/src/main/java/org/opennms/netmgt/model/events/EventUtils.java b/opennms-model/src/main/java/org/opennms/netmgt/model/events/EventUtils.java
index a654c3da5b5..8c58112dc24 100644
--- a/opennms-model/src/main/java/org/opennms/netmgt/model/events/EventUtils.java
+++ b/opennms-model/src/main/java/org/opennms/netmgt/model/events/EventUtils.java
@@ -1,7 +1,7 @@
 /*******************************************************************************
  * This file is part of OpenNMS(R).
  *
- * Copyright (C) 2008-2014 The OpenNMS Group, Inc.
+ * Copyright (C) 2008-2018 The OpenNMS Group, Inc.
  * OpenNMS(R) is Copyright (C) 1999-2014 The OpenNMS Group, Inc.
  *
  * OpenNMS(R) is a registered trademark of The OpenNMS Group, Inc.
@@ -49,6 +49,7 @@ import java.net.InetAddress;
 import java.util.Collection;
 import java.util.Date;
 import java.util.Iterator;
+import java.util.Objects;
 
 import org.opennms.core.utils.InsufficientInformationException;
 import org.opennms.core.utils.WebSecurityUtils;
@@ -562,23 +563,22 @@ public abstract class EventUtils {
      * @return a boolean.
      */
     public static boolean eventsMatch(final Event e1, final Event e2) {
-    	if (e1 == e2) {
+        if (e1 == e2) {
             return true;
         }
         if (e1 == null || e2 == null) {
             return false;
         }
-        if (e1.getUei() != e2.getUei() && (e1.getUei() == null || e2.getUei() == null || !e1.getUei().equals(e2.getUei()))) {
-        		return false;
+        if (!Objects.equals(e1.getUei(), e2.getUei())) {
+            return false;
         }
-    
-        if (e1.getNodeid() != e2.getNodeid()) {
+        if (!Objects.equals(e1.getNodeid(), e2.getNodeid())) {
             return false;
         }
-        if (e1.getInterface() != e2.getInterface() && (e1.getInterface() == null || e2.getInterface() == null || !e1.getInterface().equals(e2.getInterface()))) {
+        if (!Objects.equals(e1.getInterface(), e2.getInterface())) {
             return false;
         }
-        if (e1.getService() != e2.getService() && (e1.getService() == null || e2.getService() == null || !e1.getService().equals(e2.getService()))) {
+        if (!Objects.equals(e1.getService(), e2.getService())) {
             return false;
         }
     
@@ -595,7 +595,7 @@ public abstract class EventUtils {
      */
     static public void checkInterface(Event e) throws InsufficientInformationException {
         if (e == null) {
-            throw new NullPointerException("e is null");
+            throw new NullPointerException("Event is null");
         } else if (e.getInterface() == null) {
             throw new InsufficientInformationException("ipaddr for event is unavailable");
         }
diff --git a/features/collection/core/src/main/java/org/opennms/netmgt/collection/core/DefaultCollectionAgentFactory.java b/opennms-services/src/main/java/org/opennms/netmgt/collectd/DefaultSnmpCollectionAgentFactory.java
similarity index 83%
rename from features/collection/core/src/main/java/org/opennms/netmgt/collection/core/DefaultCollectionAgentFactory.java
rename to opennms-services/src/main/java/org/opennms/netmgt/collectd/DefaultSnmpCollectionAgentFactory.java
index 5274e8907ad..2bd30c5f1d6 100644
--- a/features/collection/core/src/main/java/org/opennms/netmgt/collection/core/DefaultCollectionAgentFactory.java
+++ b/opennms-services/src/main/java/org/opennms/netmgt/collectd/DefaultSnmpCollectionAgentFactory.java
@@ -26,21 +26,22 @@
  *     http://www.opennms.com/
  *******************************************************************************/
 
-package org.opennms.netmgt.collection.core;
+package org.opennms.netmgt.collectd;
 
 import java.net.InetAddress;
 
+import org.opennms.core.utils.InetAddressUtils;
 import org.opennms.netmgt.collection.api.CollectionAgent;
 import org.opennms.netmgt.collection.api.CollectionAgentFactory;
+import org.opennms.netmgt.collection.core.DefaultCollectionAgent;
 import org.opennms.netmgt.dao.api.IpInterfaceDao;
 import org.opennms.netmgt.dao.api.NodeDao;
 import org.opennms.netmgt.model.OnmsIpInterface;
 import org.opennms.netmgt.model.OnmsNode;
-import org.opennms.netmgt.snmp.InetAddrUtils;
 import org.springframework.beans.factory.annotation.Autowired;
 import org.springframework.transaction.PlatformTransactionManager;
 
-public class DefaultCollectionAgentFactory implements CollectionAgentFactory {
+public class DefaultSnmpCollectionAgentFactory implements CollectionAgentFactory {
 
     @Autowired
     private NodeDao nodeDao;
@@ -60,12 +61,12 @@ public class DefaultCollectionAgentFactory implements CollectionAgentFactory {
                     nodeCriteria));
         }
         final OnmsIpInterface ipInterface = ipInterfaceDao.findByNodeIdAndIpAddress(
-                node.getId(), InetAddrUtils.str(ipAddr));
+                node.getId(), InetAddressUtils.str(ipAddr));
         if (ipInterface == null) {
             throw new IllegalArgumentException(String.format("No interface found with IP %s on node %s",
-                    InetAddrUtils.str(ipAddr), nodeCriteria));
+                    InetAddressUtils.str(ipAddr), nodeCriteria));
         }
-        return DefaultCollectionAgent.create(ipInterface.getId(), ipInterfaceDao, transMgr, location);
+        return DefaultSnmpCollectionAgent.create(ipInterface.getId(), ipInterfaceDao, transMgr, location);
     }
 
     @Override
@@ -75,7 +76,7 @@ public class DefaultCollectionAgentFactory implements CollectionAgentFactory {
 
     @Override
     public CollectionAgent createCollectionAgent(OnmsIpInterface ipIf) {
-        return DefaultCollectionAgent.create(ipIf.getId(), ipInterfaceDao, transMgr);
+        return DefaultSnmpCollectionAgent.create(ipIf.getId(), ipInterfaceDao, transMgr);
     }
 
 }
diff --git a/opennms-services/src/main/java/org/opennms/netmgt/collectd/SnmpCollector.java b/opennms-services/src/main/java/org/opennms/netmgt/collectd/SnmpCollector.java
index ad2bd77a073..613776c74dd 100644
--- a/opennms-services/src/main/java/org/opennms/netmgt/collectd/SnmpCollector.java
+++ b/opennms-services/src/main/java/org/opennms/netmgt/collectd/SnmpCollector.java
@@ -39,6 +39,7 @@ import org.opennms.netmgt.collection.api.CollectionAgent;
 import org.opennms.netmgt.collection.api.CollectionException;
 import org.opennms.netmgt.collection.api.CollectionInitializationException;
 import org.opennms.netmgt.collection.api.CollectionSet;
+import org.opennms.netmgt.collection.api.InvalidCollectionAgentException;
 import org.opennms.netmgt.collection.api.ServiceParameters;
 import org.opennms.netmgt.config.DataCollectionConfigFactory;
 import org.opennms.netmgt.config.SnmpPeerFactory;
@@ -229,6 +230,11 @@ public class SnmpCollector extends AbstractServiceCollector {
             if (m_client == null) {
                 m_client = BeanUtils.getBean("daoContext", "locationAwareSnmpClient", LocationAwareSnmpClient.class);
             }
+
+            if (!(agent instanceof SnmpCollectionAgent)) {
+                throw new InvalidCollectionAgentException(String.format("Expected agent of type: %s, but got: %s",
+                        SnmpCollectionAgent.class.getCanonicalName(), agent.getClass().getCanonicalName()));
+            }
             OnmsSnmpCollection snmpCollection = new OnmsSnmpCollection((SnmpCollectionAgent)agent, params, m_client);
 
             final EventProxy eventProxy = EventIpcManagerFactory.getIpcManager();
diff --git a/opennms-services/src/main/resources/META-INF/opennms/applicationContext-collectd.xml b/opennms-services/src/main/resources/META-INF/opennms/applicationContext-collectd.xml
index 234d635b534..35887ec9fd7 100644
--- a/opennms-services/src/main/resources/META-INF/opennms/applicationContext-collectd.xml
+++ b/opennms-services/src/main/resources/META-INF/opennms/applicationContext-collectd.xml
@@ -23,6 +23,9 @@
       <property name="eventIpcManager" ref="eventIpcManager"/>
     </bean>
 
+    <bean id="collectionAgentFactory" class="org.opennms.netmgt.collectd.DefaultSnmpCollectionAgentFactory" />
+    <onmsgi:service interface="org.opennms.netmgt.collection.api.CollectionAgentFactory" ref="collectionAgentFactory" />
+
     <bean id="defaultResourceTypeMapper" class="org.opennms.netmgt.collectd.DefaultResourceTypeMapper" />
 
 </beans>
diff --git a/opennms-webapp-rest/src/main/java/org/opennms/web/rest/support/BooleanCollection.java b/opennms-webapp-rest/src/main/java/org/opennms/web/rest/support/BooleanCollection.java
new file mode 100644
index 00000000000..9d0724f685d
--- /dev/null
+++ b/opennms-webapp-rest/src/main/java/org/opennms/web/rest/support/BooleanCollection.java
@@ -0,0 +1,57 @@
+/*******************************************************************************
+ * This file is part of OpenNMS(R).
+ *
+ * Copyright (C) 2008-2014 The OpenNMS Group, Inc.
+ * OpenNMS(R) is Copyright (C) 1999-2014 The OpenNMS Group, Inc.
+ *
+ * OpenNMS(R) is a registered trademark of The OpenNMS Group, Inc.
+ *
+ * OpenNMS(R) is free software: you can redistribute it and/or modify
+ * it under the terms of the GNU Affero General Public License as published
+ * by the Free Software Foundation, either version 3 of the License,
+ * or (at your option) any later version.
+ *
+ * OpenNMS(R) is distributed in the hope that it will be useful,
+ * but WITHOUT ANY WARRANTY; without even the implied warranty of
+ * MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
+ * GNU Affero General Public License for more details.
+ *
+ * You should have received a copy of the GNU Affero General Public License
+ * along with OpenNMS(R).  If not, see:
+ *      http://www.gnu.org/licenses/
+ *
+ * For more information contact:
+ *     OpenNMS(R) Licensing <license@opennms.org>
+ *     http://www.opennms.org/
+ *     http://www.opennms.com/
+ *******************************************************************************/
+
+package org.opennms.web.rest.support;
+
+import java.util.Collection;
+import java.util.List;
+
+import javax.xml.bind.annotation.XmlElement;
+import javax.xml.bind.annotation.XmlRootElement;
+
+import org.codehaus.jackson.annotate.JsonProperty;
+import org.codehaus.jackson.map.annotate.JsonRootName;
+import org.opennms.core.config.api.JaxbListWrapper;
+
+@XmlRootElement(name="values")
+@JsonRootName("values")
+public class BooleanCollection extends JaxbListWrapper<Boolean> {
+
+    private static final long serialVersionUID = -1744248005342837375L;
+
+    public BooleanCollection() { super(); }
+    public BooleanCollection(final Collection<Boolean> items) {
+        super(items);
+    }
+
+    @XmlElement(name="value")
+    @JsonProperty("value")
+    public List<Boolean> getObjects() {
+        return super.getObjects();
+    }
+}
diff --git a/opennms-webapp-rest/src/main/java/org/opennms/web/rest/support/CriteriaBehaviors.java b/opennms-webapp-rest/src/main/java/org/opennms/web/rest/support/CriteriaBehaviors.java
index 2d0564b84b6..2594cc42bbf 100644
--- a/opennms-webapp-rest/src/main/java/org/opennms/web/rest/support/CriteriaBehaviors.java
+++ b/opennms-webapp-rest/src/main/java/org/opennms/web/rest/support/CriteriaBehaviors.java
@@ -28,6 +28,7 @@
 
 package org.opennms.web.rest.support;
 
+import static org.opennms.web.rest.support.CriteriaValueConverters.BOOLEAN_CONVERTER;
 import static org.opennms.web.rest.support.CriteriaValueConverters.DATE_CONVERTER;
 import static org.opennms.web.rest.support.CriteriaValueConverters.FLOAT_CONVERTER;
 import static org.opennms.web.rest.support.CriteriaValueConverters.INET_ADDRESS_CONVERTER;
@@ -198,6 +199,8 @@ public abstract class CriteriaBehaviors {
         ALARM_BEHAVIORS.put("suppressedUntil", new CriteriaBehavior<Date>(DATE_CONVERTER));
         ALARM_BEHAVIORS.put("troubleTicketState", new CriteriaBehavior<TroubleTicketState>(TroubleTicketState::valueOf));
         ALARM_BEHAVIORS.put("x733ProbableCause", new CriteriaBehavior<Integer>(INT_CONVERTER));
+        ALARM_BEHAVIORS.put("impacted", new CriteriaBehavior<Boolean>(BOOLEAN_CONVERTER));
+        ALARM_BEHAVIORS.put("cause", new CriteriaBehavior<Boolean>(BOOLEAN_CONVERTER));
 
         ALARM_LASTEVENT_PARAMETER_BEHAVIORS.put("name", new EventParameterBehavior("lastEvent.eventParameters", "lasteventid", "name"));
         ALARM_LASTEVENT_PARAMETER_BEHAVIORS.put("value", new EventParameterBehavior("lastEvent.eventParameters", "lasteventid", "value"));
diff --git a/opennms-webapp-rest/src/main/java/org/opennms/web/rest/support/CriteriaValueConverters.java b/opennms-webapp-rest/src/main/java/org/opennms/web/rest/support/CriteriaValueConverters.java
index c9c9f33b52b..25058ae212d 100644
--- a/opennms-webapp-rest/src/main/java/org/opennms/web/rest/support/CriteriaValueConverters.java
+++ b/opennms-webapp-rest/src/main/java/org/opennms/web/rest/support/CriteriaValueConverters.java
@@ -42,6 +42,23 @@ import org.opennms.core.utils.InetAddressUtils;
  */
 public abstract class CriteriaValueConverters {
 
+
+    public static final Function<String,Boolean> BOOLEAN_CONVERTER = new Function<String,Boolean>() {
+        @Override
+        public Boolean apply(String s) {
+            return Boolean.parseBoolean(s);
+        }
+
+        /**
+         * Override {@link #toString()} on this functional interface
+         * to make it identifiable inside a debugger.
+         */
+        @Override
+        public String toString() {
+            return "BOOLEAN_CONVERTER";
+        }
+    };
+
     public static final Function<String,Date> DATE_CONVERTER = new Function<String,Date>() {
         @Override
         public Date apply(String t) {
diff --git a/opennms-webapp-rest/src/main/java/org/opennms/web/rest/support/SearchProperties.java b/opennms-webapp-rest/src/main/java/org/opennms/web/rest/support/SearchProperties.java
index e05f1f2b3c2..ad893906ba6 100644
--- a/opennms-webapp-rest/src/main/java/org/opennms/web/rest/support/SearchProperties.java
+++ b/opennms-webapp-rest/src/main/java/org/opennms/web/rest/support/SearchProperties.java
@@ -28,6 +28,7 @@
 
 package org.opennms.web.rest.support;
 
+import static org.opennms.web.rest.support.SearchProperty.SearchPropertyType.BOOLEAN;
 import static org.opennms.web.rest.support.SearchProperty.SearchPropertyType.FLOAT;
 import static org.opennms.web.rest.support.SearchProperty.SearchPropertyType.INTEGER;
 import static org.opennms.web.rest.support.SearchProperty.SearchPropertyType.IP_ADDRESS;
@@ -76,10 +77,17 @@ public abstract class SearchProperties {
 	 */
 	private static final Map<String,String> ONMS_SEVERITIES = Arrays.stream(OnmsSeverity.values()).collect(Collectors.toMap(s -> String.valueOf(s.getId()), OnmsSeverity::getLabel));
 
+	private static final Map<String, String> TRUE_OR_FALSE = ImmutableMap.<String,String>builder()
+	        .put("1", "TRUE")
+	        .put("0", "FALSE")
+	        .build();
+
 	static final SortedSet<SearchProperty> ALARM_PROPERTIES = new TreeSet<>(Arrays.asList(new SearchProperty[] {
 		new SearchProperty(OnmsAlarm.class, "id", "ID", INTEGER),
 		new SearchProperty(OnmsAlarm.class, "alarmAckTime", "Acknowledged Time", TIMESTAMP),
-		new SearchProperty(OnmsAlarm.class, "alarmAckUser", "Acknowledging User", STRING),
+        new SearchProperty(OnmsAlarm.class, "alarmAckUser", "Acknowledging User", STRING),
+        new SearchProperty(OnmsAlarm.class, "cause", "Causes", BOOLEAN, TRUE_OR_FALSE),
+        new SearchProperty(OnmsAlarm.class, "impacted", "Impacts", BOOLEAN, TRUE_OR_FALSE),
 		new SearchProperty(OnmsAlarm.class, "alarmType", "Alarm Type", INTEGER, ImmutableMap.<String,String>builder()
 			.put(String.valueOf(OnmsAlarm.PROBLEM_TYPE), "Problem")
 			.put(String.valueOf(OnmsAlarm.RESOLUTION_TYPE), "Resolution")
@@ -464,7 +472,7 @@ public abstract class SearchProperties {
 		ALARM_SERVICE_PROPERTIES.addAll(withAliasPrefix(Aliases.location, "Location", LOCATION_PROPERTIES));
 		ALARM_SERVICE_PROPERTIES.addAll(withAliasPrefix(Aliases.node, "Node", NODE_PROPERTIES));
 		ALARM_SERVICE_PROPERTIES.addAll(withAliasPrefix(Aliases.serviceType, "Service", SERVICE_TYPE_PROPERTIES));
-		ALARM_SERVICE_PROPERTIES.addAll(withAliasPrefix(Aliases.snmpInterface, "SNMP Interface", SNMP_INTERFACE_PROPERTIES));
+        ALARM_SERVICE_PROPERTIES.addAll(withAliasPrefix(Aliases.snmpInterface, "SNMP Interface", SNMP_INTERFACE_PROPERTIES));
 
 		// Root prefix
 		APPLICATION_SERVICE_PROPERTIES.addAll(APPLICATION_PROPERTIES);
diff --git a/opennms-webapp-rest/src/main/java/org/opennms/web/rest/support/SearchProperty.java b/opennms-webapp-rest/src/main/java/org/opennms/web/rest/support/SearchProperty.java
index cf12473051b..57412a53614 100644
--- a/opennms-webapp-rest/src/main/java/org/opennms/web/rest/support/SearchProperty.java
+++ b/opennms-webapp-rest/src/main/java/org/opennms/web/rest/support/SearchProperty.java
@@ -55,6 +55,7 @@ public class SearchProperty implements Comparable<SearchProperty> {
 		.thenComparing(SearchProperty::getId);
 
 	public static enum SearchPropertyType {
+        BOOLEAN,
 		FLOAT,
 		INTEGER,
 		IP_ADDRESS,
diff --git a/opennms-webapp-rest/src/main/java/org/opennms/web/rest/v2/AbstractDaoRestServiceWithDTO.java b/opennms-webapp-rest/src/main/java/org/opennms/web/rest/v2/AbstractDaoRestServiceWithDTO.java
index 210a40947c8..4ffb5e08e61 100644
--- a/opennms-webapp-rest/src/main/java/org/opennms/web/rest/v2/AbstractDaoRestServiceWithDTO.java
+++ b/opennms-webapp-rest/src/main/java/org/opennms/web/rest/v2/AbstractDaoRestServiceWithDTO.java
@@ -81,6 +81,7 @@ import org.opennms.netmgt.events.api.EventProxyException;
 import org.opennms.netmgt.xml.event.Event;
 import org.opennms.web.api.ISO8601DateEditor;
 import org.opennms.web.api.RestUtils;
+import org.opennms.web.rest.support.BooleanCollection;
 import org.opennms.web.rest.support.CriteriaBehavior;
 import org.opennms.web.rest.support.CriteriaBuilderSearchVisitor;
 import org.opennms.web.rest.support.DateCollection;
@@ -378,6 +379,8 @@ public abstract class AbstractDaoRestServiceWithDTO<T,D,Q,K extends Serializable
                 }
 
                 switch(property.type) {
+                    case BOOLEAN:
+                        return Response.ok(new BooleanCollection(validValues.stream().map(Boolean::parseBoolean).collect(Collectors.toList()))).build();
                     case FLOAT:
                         return Response.ok(new FloatCollection(validValues.stream().map(Float::parseFloat).collect(Collectors.toList()))).build();
                     case INTEGER:
diff --git a/opennms-webapp-rest/src/test/java/org/opennms/web/rest/v2/SearchPropertiesIT.java b/opennms-webapp-rest/src/test/java/org/opennms/web/rest/v2/SearchPropertiesIT.java
index 4f3bffc5a1e..5d736a91a6b 100644
--- a/opennms-webapp-rest/src/test/java/org/opennms/web/rest/v2/SearchPropertiesIT.java
+++ b/opennms-webapp-rest/src/test/java/org/opennms/web/rest/v2/SearchPropertiesIT.java
@@ -137,6 +137,9 @@ public class SearchPropertiesIT extends AbstractSpringJerseyRestTestCase {
         for (SearchProperty prop : properties) {
             System.err.println("Testing " + prop.getId());
             switch(prop.type) {
+            case BOOLEAN:
+                sendRequest(GET, url, parseParamData(String.format("_s=%s==true;%s!=true", prop.getId(), prop.getId())), 204);
+                break;
             case FLOAT:
                 sendRequest(GET, url, parseParamData(String.format("_s=%s==1.0;%s!=1.0", prop.getId(), prop.getId())), 204);
                 break;
diff --git a/opennms-webapp-rest/src/test/resources/v1/alarms.json b/opennms-webapp-rest/src/test/resources/v1/alarms.json
index 0dc96168a63..0093ded6582 100644
--- a/opennms-webapp-rest/src/test/resources/v1/alarms.json
+++ b/opennms-webapp-rest/src/test/resources/v1/alarms.json
@@ -2,11 +2,15 @@
     "alarm": [
         {
             "ackId": 1, 
+            "cause": false,
+            "causes": [],
             "count": 1, 
             "description": "This is a test alarm", 
             "firstEventTime": 1436881548292, 
             "id": 1, 
             "ifIndex": null, 
+            "impacted": false,
+            "impacts": [],
             "ipAddress": "192.168.1.1", 
             "lastEvent": {
                 "createTime": 1436881548292, 
diff --git a/opennms-webapp-rest/src/test/resources/v1/stats_alarms.json b/opennms-webapp-rest/src/test/resources/v1/stats_alarms.json
index 3785aa1a93c..fc946d897c3 100644
--- a/opennms-webapp-rest/src/test/resources/v1/stats_alarms.json
+++ b/opennms-webapp-rest/src/test/resources/v1/stats_alarms.json
@@ -5,11 +5,15 @@
             "ackId": 4, 
             "ackTime": 1282329200000, 
             "ackUser": "admin", 
+            "cause": false,
+            "causes": [],
             "count": 1, 
             "description": "This is a test alarm", 
             "firstEventTime": 1262329200000, 
             "id": 4, 
             "ifIndex": null, 
+            "impacted": false,
+            "impacts": [],
             "ipAddress": "192.0.2.123", 
             "lastEvent": {
                 "createTime": 1262329200000, 
@@ -60,11 +64,15 @@
     "newestUnacked": [
         {
             "ackId": 7, 
+            "cause": false,
+            "causes": [],
             "count": 1, 
             "description": "This is a test alarm", 
             "firstEventTime": 1262340000000, 
             "id": 7, 
             "ifIndex": null, 
+            "impacted": false,
+            "impacts": [],
             "ipAddress": "192.0.2.123", 
             "lastEvent": {
                 "createTime": 1262340000000, 
@@ -117,11 +125,15 @@
             "ackId": 2, 
             "ackTime": 1282329200000, 
             "ackUser": "admin", 
+            "cause": false,
+            "causes": [],
             "count": 1, 
             "description": "This is a test alarm", 
             "firstEventTime": 1262322000000, 
             "id": 2, 
             "ifIndex": null, 
+            "impacted": false,
+            "impacts": [],
             "ipAddress": "192.0.2.123", 
             "lastEvent": {
                 "createTime": 1262322000000, 
@@ -172,11 +184,15 @@
     "oldestUnacked": [
         {
             "ackId": 5, 
+            "cause": false,
+            "causes": [],
             "count": 1, 
             "description": "This is a test alarm", 
             "firstEventTime": 1262332800000, 
             "id": 5, 
             "ifIndex": null, 
+            "impacted": false,
+            "impacts": [],
             "ipAddress": "192.0.2.123", 
             "lastEvent": {
                 "createTime": 1262332800000, 
diff --git a/opennms-webapp/src/main/webapp/WEB-INF/spring-security.d/activeDirectory.xml.disabled b/opennms-webapp/src/main/webapp/WEB-INF/spring-security.d/activeDirectory.xml.disabled
index 6efb0fc80d4..6c915cca59f 100644
--- a/opennms-webapp/src/main/webapp/WEB-INF/spring-security.d/activeDirectory.xml.disabled
+++ b/opennms-webapp/src/main/webapp/WEB-INF/spring-security.d/activeDirectory.xml.disabled
@@ -67,6 +67,15 @@
     <!-- <beans:property name="groupSearchFilter" value="member:1.2.840.113556.1.4.1941:={0}" /> -->
     <beans:property name="groupToRoleMap">
       <beans:map>
+        <!-- If the is an empty string, the roles are applied to all users -->
+        <!--
+        <beans:entry>
+          <beans:key><beans:value></beans:value></beans:key>
+          <beans:list>
+            <beans:value>ROLE_USER</beans:value>
+          </beans:list>
+        </beans:entry>
+        -->
         <beans:entry>
           <!-- Name of the AD group for normal (non-admin) OpenNMS users -->
           <beans:key><beans:value>OpenNMS-Users</beans:value></beans:key>
diff --git a/opennms-webapp/src/main/webapp/WEB-INF/spring-security.d/ldap.xml.disabled b/opennms-webapp/src/main/webapp/WEB-INF/spring-security.d/ldap.xml.disabled
index c419970e454..7fe41510d98 100644
--- a/opennms-webapp/src/main/webapp/WEB-INF/spring-security.d/ldap.xml.disabled
+++ b/opennms-webapp/src/main/webapp/WEB-INF/spring-security.d/ldap.xml.disabled
@@ -62,6 +62,15 @@
     <beans:property name="groupSearchFilter" value="member={0}" />
     <beans:property name="groupToRoleMap">
       <beans:map>
+        <!-- If the is an empty string, the roles are applied to all users -->
+        <!--
+        <beans:entry>
+          <beans:key><beans:value></beans:value></beans:key>
+          <beans:list>
+            <beans:value>ROLE_USER</beans:value>
+          </beans:list>
+        </beans:entry>
+        -->
         <beans:entry>
           <!-- Name of the LDAP group for normal (non-admin) OpenNMS users -->
           <beans:key><beans:value>opennms-users</beans:value></beans:key>
diff --git a/pom.xml b/pom.xml
index 7058d6e627f..e60696f7582 100644
--- a/pom.xml
+++ b/pom.xml
@@ -1319,7 +1319,9 @@
     <jrubyVersion>9.0.4.0</jrubyVersion>
     <jsonVersion>20171018</jsonVersion>
     <jsoupVersion>1.7.2</jsoupVersion>
-    <karafVersion>4.1.2</karafVersion>
+    <karafVersion>4.1.5</karafVersion>
+    <kafkaStreamsVersion>1.0.1</kafkaStreamsVersion>
+    <kafkaStreamsBundleVersion>1.0.1_1</kafkaStreamsBundleVersion>
     <felixVersion>3.0.0</felixVersion>
     <liquibaseVersion>2.0.5-ONMS20160524b</liquibaseVersion>
     <lmaxDisruptorVersion>3.3.2</lmaxDisruptorVersion>
@@ -1335,6 +1337,7 @@
     <paxSwissboxVersion>1.8.2</paxSwissboxVersion>
     <paxWebVersion>4.3.0</paxWebVersion>
     <protobufVersion>2.6.1</protobufVersion>
+    <protobuf3Version>3.5.1</protobuf3Version>
     <postgresqlVersion>9.4.1211</postgresqlVersion>
     <powermockVersion>1.6.4</powermockVersion>
     <osgiVersion>6.0.0</osgiVersion>
@@ -1370,7 +1373,8 @@
     <jungVersion>2.0.1</jungVersion>
     <vaadinVersion>7.2.7</vaadinVersion>
     <vaadinSharedEpsVersion>1.0.2</vaadinSharedEpsVersion>
-    <vaadin.plugin.version>${vaadinVersion}</vaadin.plugin.version>
+    <!-- Requiring a more recent plugin version which passes the classpath via ENV -->
+    <vaadin.plugin.version>8.1.0</vaadin.plugin.version>
     <vaadinAddonContextMenuVersion>4.2.1</vaadinAddonContextMenuVersion>
     <vaadinAddonRefresherVersion>1.2.3.7</vaadinAddonRefresherVersion>
     <vaadinAddonConfirmDialogVersion>2.0.4</vaadinAddonConfirmDialogVersion>
diff --git a/smoke-test/pom.xml b/smoke-test/pom.xml
index 37930662283..b952311899b 100644
--- a/smoke-test/pom.xml
+++ b/smoke-test/pom.xml
@@ -12,7 +12,7 @@
     <camelVersion>2.19.1</camelVersion>
     <frontendPluginVersion>0.0.29</frontendPluginVersion>
     <jackson2Version>2.6.6</jackson2Version>
-    <karafVersion>4.1.2</karafVersion>
+    <karafVersion>4.1.5</karafVersion>
     <test.fork.count>1</test.fork.count>
   </properties>
   <build>
diff --git a/smoke-test/src/test/java/org/opennms/smoketest/KafkaProducerIT.java b/smoke-test/src/test/java/org/opennms/smoketest/KafkaProducerIT.java
new file mode 100644
index 00000000000..f966a381d4b
--- /dev/null
+++ b/smoke-test/src/test/java/org/opennms/smoketest/KafkaProducerIT.java
@@ -0,0 +1,129 @@
+/*******************************************************************************
+ * This file is part of OpenNMS(R).
+ *
+ * Copyright (C) 2018 The OpenNMS Group, Inc.
+ * OpenNMS(R) is Copyright (C) 1999-2018 The OpenNMS Group, Inc.
+ *
+ * OpenNMS(R) is a registered trademark of The OpenNMS Group, Inc.
+ *
+ * OpenNMS(R) is free software: you can redistribute it and/or modify
+ * it under the terms of the GNU Affero General Public License as published
+ * by the Free Software Foundation, either version 3 of the License,
+ * or (at your option) any later version.
+ *
+ * OpenNMS(R) is distributed in the hope that it will be useful,
+ * but WITHOUT ANY WARRANTY; without even the implied warranty of
+ * MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
+ * GNU Affero General Public License for more details.
+ *
+ * You should have received a copy of the GNU Affero General Public License
+ * along with OpenNMS(R).  If not, see:
+ *      http://www.gnu.org/licenses/
+ *
+ * For more information contact:
+ *     OpenNMS(R) Licensing <license@opennms.org>
+ *     http://www.opennms.org/
+ *     http://www.opennms.com/
+ *******************************************************************************/
+
+package org.opennms.smoketest;
+
+import static com.jayway.awaitility.Awaitility.await;
+import static java.util.concurrent.TimeUnit.MINUTES;
+import static java.util.concurrent.TimeUnit.SECONDS;
+import static org.hamcrest.Matchers.containsString;
+
+import java.io.PrintStream;
+import java.net.InetSocketAddress;
+import java.util.ArrayList;
+import java.util.List;
+
+import org.apache.commons.lang.StringUtils;
+import org.junit.Assume;
+import org.junit.Before;
+import org.junit.ClassRule;
+import org.junit.Test;
+import org.opennms.netmgt.xml.event.Event;
+import org.opennms.netmgt.xml.event.Parm;
+import org.opennms.smoketest.minion.CommandTestUtils;
+import org.opennms.smoketest.utils.RestClient;
+import org.opennms.test.system.api.NewTestEnvironment.ContainerAlias;
+import org.opennms.test.system.api.TestEnvironment;
+import org.opennms.test.system.api.TestEnvironmentBuilder;
+import org.opennms.test.system.api.utils.SshClient;
+
+public class KafkaProducerIT {
+
+    private static TestEnvironment m_testEnvironment;
+    private static RestClient restClient;
+    private InetSocketAddress opennmsKarafSshAddr;
+
+    @ClassRule
+    public static final TestEnvironment getTestEnvironment() {
+        if (!OpenNMSSeleniumTestCase.isDockerEnabled()) {
+            return new NullTestEnvironment();
+        }
+        try {
+            final TestEnvironmentBuilder builder = TestEnvironment.builder().all().kafka();
+            OpenNMSSeleniumTestCase.configureTestEnvironment(builder);
+            m_testEnvironment = builder.build();
+            return m_testEnvironment;
+        } catch (final Throwable t) {
+            throw new RuntimeException(t);
+        }
+    }
+
+    @Before
+    public void checkForDocker() {
+        Assume.assumeTrue(OpenNMSSeleniumTestCase.isDockerEnabled());
+        if (m_testEnvironment == null) {
+            return;
+        }
+        final InetSocketAddress opennmsHttp = m_testEnvironment.getServiceAddress(ContainerAlias.OPENNMS, 8980);
+        restClient = new RestClient(opennmsHttp);
+        opennmsKarafSshAddr = m_testEnvironment.getServiceAddress(ContainerAlias.OPENNMS, 8101);
+    }
+
+    @Test
+    public void testKafkaAlarmStoreData() throws Exception {
+        // Enable and install the Kafka producer feature
+        String kafkaHost = m_testEnvironment.getContainerInfo(ContainerAlias.KAFKA).networkSettings().ipAddress();
+        try (final SshClient sshClient = new SshClient(opennmsKarafSshAddr, "admin", "admin")) {
+            PrintStream pipe = sshClient.openShell();
+            pipe.println("config:edit org.opennms.features.kafka.producer.client");
+            pipe.println("config:property-set bootstrap.servers " + kafkaHost + ":9092");
+            pipe.println("config:update");
+            pipe.println("feature:install opennms-kafka-producer");
+            pipe.println("logout");
+            await().atMost(1, MINUTES).until(sshClient.isShellClosedCallable());
+        }
+
+        await().atMost(2, MINUTES).pollInterval(15, SECONDS)
+                .until(this::triggerAlarmAndListReductionKeysInKtable, containsString("uei.opennms.org/alarms/trigger:::kafka-producer-test"));
+    }
+
+    private String triggerAlarmAndListReductionKeysInKtable() throws Exception {
+        // On every call, send another event to trigger the alarm
+        Event event = new Event();
+        event.setUei("uei.opennms.org/alarms/trigger");
+        event.setSeverity("7");
+        List<Parm> parms = new ArrayList<>();
+        Parm parm = new Parm("service", "kafka-producer-test");
+        parms.add(parm);
+        event.setParmCollection(parms);
+        restClient.sendEvent(event, true);
+
+        // Grab the output from the
+        String shellOutput;
+        try (final SshClient sshClient = new SshClient(opennmsKarafSshAddr, "admin", "admin")) {
+            PrintStream pipe = sshClient.openShell();
+            pipe.println("kafka-producer:list-alarms");
+            pipe.println("logout");
+            await().atMost(30, SECONDS).until(sshClient.isShellClosedCallable());
+            shellOutput = CommandTestUtils.stripAnsiCodes(sshClient.getStdout());
+            shellOutput = StringUtils.substringAfter(shellOutput, "kafka-producer:list-alarms");
+        }
+        return shellOutput;
+    }
+
+}
diff --git a/tests/mock-elements/src/main/java/org/opennms/netmgt/mock/MockEventUtil.java b/tests/mock-elements/src/main/java/org/opennms/netmgt/mock/MockEventUtil.java
index 2231f0ce013..1b57f08994f 100644
--- a/tests/mock-elements/src/main/java/org/opennms/netmgt/mock/MockEventUtil.java
+++ b/tests/mock-elements/src/main/java/org/opennms/netmgt/mock/MockEventUtil.java
@@ -357,7 +357,20 @@ public abstract class MockEventUtil {
         event.setAlarmData(alarmData);
         return event;
     }
-    
+
+    public static EventBuilder createNodeUpEventBuilder(String source, OnmsNode node) {
+        EventBuilder event = createNodeEventBuilder(source, EventConstants.NODE_UP_EVENT_UEI, node);
+        event.setSeverity(OnmsSeverity.NORMAL.getLabel());
+        // <alarm-data reduction-key="%uei%:%dpname%:%nodeid%" alarm-type="2" clear-key="uei.opennms.org/nodes/nodeDown:%dpname%:%nodeid%" auto-clean="false" />
+        AlarmData alarmData = new AlarmData();
+        alarmData.setReductionKey("%uei%:%dpname%:%nodeid%");
+        alarmData.setAlarmType(2);
+        alarmData.setClearKey("uei.opennms.org/nodes/nodeDown:%dpname%:%nodeid%");
+        alarmData.setAutoClean(false);
+        event.setAlarmData(alarmData);
+        return event;
+    }
+
     /**
      * <p>createNodeUpEvent</p>
      *
@@ -679,4 +692,5 @@ public abstract class MockEventUtil {
             printEvent(prefix, event);
         }
     }
+
 }
